{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc0cfb5-fb6e-47c5-ab0a-4b3f3021d9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9919548126428125e-80\n"
     ]
    }
   ],
   "source": [
    "def __clear_env():\n",
    "    for key in globals().keys():\n",
    "        if not key.startswith(\"__\"):# 排除系统内建函数\n",
    "            globals().pop(key)\n",
    "__clear_env\n",
    "import example_pendulum\n",
    "import torch; torch.manual_seed(6)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "#import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b199479c-728d-4425-ba21-8216ff0642c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_route = R'/mnt/ssd1/stilrmy/Autoencoder-conservtive_expression/progress/AE'\n",
    "device = 'cuda:0'\n",
    "data = example_pendulum.get_pendulum_data(40)\n",
    "val_data = example_pendulum.get_pendulum_data(10)\n",
    "save_params = True\n",
    "load_params = False\n",
    "\n",
    "load_date = str(datetime.date.today())\n",
    "load_ver = 1\n",
    "widths = [1024,512,128]\n",
    "params={}\n",
    "params['ver'] = \"1\"\n",
    "params['accumulate_epochs'] = 0\n",
    "params['date'] = '4-21'\n",
    "params['widths'] = widths\n",
    "params['activation'] = 'sigmoid'\n",
    "params['max_epochs'] = 40000\n",
    "params['epoch_size'] = data[\"x\"].shape[0]\n",
    "params['batch_size'] = 500\n",
    "params['learning_rate'] = 0\n",
    "params['loss_weight_x'] = 1\n",
    "params['loss_weight_dx'] = 0\n",
    "params['loss_weight_ddx'] = 5e-5\n",
    "params['learning_rate_switching_point'] = 500\n",
    "loss_history = []\n",
    "loss_z_history = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e8acc6-fe30-4a7c-9e70-17ced93a831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['learning_rate_stage1'] = 1e-6\n",
    "params['learning_rate_stage2'] = 1e-6\n",
    "params['learning_rate'] = params['learning_rate_stage1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e3c08a-5221-4677-b438-f97797ff3e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(input_dim,latent_dim,widths,device):\n",
    "    #generate the parameters of the autoencoder\n",
    "    encoder_weights,encoder_biases = build_network_layers(input_dim,latent_dim,widths,device)\n",
    "    decoder_weights, decoder_biases = build_network_layers(latent_dim, input_dim, widths[::-1],device)\n",
    "    return encoder_weights,encoder_biases,decoder_weights,decoder_biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df85ec5-9e1f-4660-9747-58ada3d52edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network_layers(input_dim,output_dim,widths,device):\n",
    "    #universal function for building network\n",
    "    weights = []\n",
    "    biases = []\n",
    "    last_width = input_dim\n",
    "    #middle layers\n",
    "    for i,n_units in enumerate(widths):\n",
    "        w = torch.Tensor(last_width,n_units,).to(device)\n",
    "        nn.init.xavier_uniform_(w, gain=1.0)\n",
    "        w = Variable(w, requires_grad=True)\n",
    "        b = torch.Tensor(n_units).to(device)\n",
    "        nn.init.constant_(b, 0.0)\n",
    "        b = Variable(b, requires_grad=True)\n",
    "        last_width = n_units\n",
    "        weights.append(w)\n",
    "        biases.append(b)\n",
    "    #latent layer\n",
    "    w = torch.Tensor(last_width,output_dim).to(device)\n",
    "    nn.init.xavier_uniform_(w, gain=1.0)\n",
    "    w = Variable(w,requires_grad=True)\n",
    "    b = torch.Tensor(output_dim).to(device)\n",
    "    nn.init.constant_(b, 0.0)\n",
    "    b = Variable(b, requires_grad=True)\n",
    "    weights.append(w)\n",
    "    biases.append(b)\n",
    "    return weights,biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d9d0ce-9c55-487f-9979-eb26dfe73b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_forward(input,params):\n",
    "    #pass through the autoencoder\n",
    "    for i,weights in enumerate(params['encoder_weights']):\n",
    "        input = torch.matmul(input,weights)+params['encoder_biases'][i]\n",
    "        if params['activation'] == 'sigmoid' and i <len(params['encoder_weights'])-1:\n",
    "            input = torch.sigmoid(input)\n",
    "    for i,weights in enumerate(params['decoder_weights']):\n",
    "        input = torch.matmul(input,weights)+params['decoder_biases'][i]\n",
    "        if params['activation'] == 'sigmoid'and i <len(params['decoder_weights'])-1:\n",
    "            input = torch.sigmoid(input)\n",
    "    return input\n",
    "\n",
    "def encoder_forward(input,params):\n",
    "    for i,weights in enumerate(params['encoder_weights']):\n",
    "        input = torch.matmul(input,weights)+params['encoder_biases'][i]\n",
    "        if params['activation'] == 'sigmoid' and i <len(params['encoder_weights'])-1:\n",
    "            input = torch.sigmoid(input)\n",
    "    return input\n",
    "\n",
    "def decoder_forward(input,params):\n",
    "    for i,weights in enumerate(params['decoder_weights']):\n",
    "        input = torch.matmul(input,weights)+params['decoder_biases'][i]\n",
    "        if params['activation'] == 'sigmoid' and i <len(params['decoder_weights'])-1:\n",
    "            input = torch.sigmoid(input)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc9d1c44-974a-40a5-99c8-7dffe6010430",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encoder_derivative(image,image_t,image_tt,params):\n",
    "    #calculate the time/second time derivative of the latent(s) using the autoencoder\n",
    "    dz = image_t\n",
    "    ddz = image_tt\n",
    "    input = image\n",
    "    weights = params['encoder_weights']\n",
    "    biases = params['encoder_biases']\n",
    "    if params['activation'] == 'sigmoid':\n",
    "        for i in range(len(weights)-1):\n",
    "            input = torch.matmul(input,weights[i])+biases[i]\n",
    "            input = torch.sigmoid(input)\n",
    "            dz_prev = torch.matmul(dz,weights[i])\n",
    "            sigmoid_derivative = torch.multiply(input,1-input)\n",
    "            sigmoid_derivative2 = torch.multiply(sigmoid_derivative,1-2*input)\n",
    "            dz = torch.multiply(sigmoid_derivative,dz_prev)\n",
    "            ddz = torch.multiply(sigmoid_derivative2,torch.square(dz_prev))\\\n",
    "                  + torch.multiply(sigmoid_derivative,torch.matmul(ddz,weights[i]))\n",
    "        dz = torch.matmul(dz,weights[-1])\n",
    "        ddz = torch.matmul(ddz,weights[-1])\n",
    "    return dz,ddz\n",
    "\n",
    "def decoder_derivative(z,dz,ddz,params):\n",
    "    #calculate the time/second time derivative of the latent(s) using the autoencoder\n",
    "    input = z\n",
    "    weights = params['decoder_weights']\n",
    "    biases = params['decoder_biases']\n",
    "    if params['activation'] == 'sigmoid':\n",
    "        for i in range(len(weights)-1):\n",
    "            input = torch.matmul(input,weights[i])+biases[i]\n",
    "            input = torch.sigmoid(input)\n",
    "            dz_prev = torch.matmul(dz,weights[i])\n",
    "            sigmoid_derivative = torch.multiply(input,1-input)\n",
    "            sigmoid_derivative2 = torch.multiply(sigmoid_derivative,1-2*input)\n",
    "            dz = torch.multiply(sigmoid_derivative,dz_prev)\n",
    "            #print(sigmoid_derivative.shape)\n",
    "            ddz = torch.multiply(sigmoid_derivative2,torch.square(dz_prev))\\\n",
    "                  + torch.multiply(sigmoid_derivative,torch.matmul(ddz,weights[i]))\n",
    "        dz = torch.matmul(dz,weights[-1])\n",
    "        ddz = torch.matmul(ddz,weights[-1])\n",
    "    return dz,ddz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e69dd597-1ed1-4d11-9f38-85a473af0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(data,params,device):\n",
    "    opt = torch.optim.Adam(generate_parameter(params), lr=params['learning_rate'])\n",
    "    total_loss = 0\n",
    "    total_loss_z = 0\n",
    "    for j in range(params['epoch_size']//params['batch_size']):\n",
    "        batch_idxs = np.arange(j * params['batch_size'], (j + 1) * params['batch_size'])\n",
    "        z = torch.from_numpy(data['z'][batch_idxs]).to(torch.float32).to(device)\n",
    "        x = torch.from_numpy(data['x'][batch_idxs]).to(torch.float32).to(device)\n",
    "        dx = torch.from_numpy(data['dx'][batch_idxs]).to(torch.float32).to(device)\n",
    "        ddx = torch.from_numpy(data['ddx'][batch_idxs]).to(torch.float32).to(device)\n",
    "        x_predict = autoencoder_forward(x,params)\n",
    "        z_predict = encoder_forward(x,params)\n",
    "        dz_predict,ddz_predict = encoder_derivative(x,dx,ddx,params)\n",
    "        dx_predict,ddx_predict = decoder_derivative(z_predict,dz_predict,ddz_predict,params)\n",
    "        loss_x = torch.mean((x - x_predict)**2)\n",
    "        loss_dx = torch.mean((dx - dx_predict) ** 2)\n",
    "        loss_ddx = torch.mean((ddx - ddx_predict) ** 2)\n",
    "        loss_z = torch.mean((z - z_predict)**2)\n",
    "        loss = params['loss_weight_x'] * loss_x \\\n",
    "               + params['loss_weight_dx'] * loss_dx \\\n",
    "               + params['loss_weight_ddx'] * loss_ddx\n",
    "        total_loss += loss\n",
    "        total_loss_z += loss_z\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    avg_loss = total_loss/(params['epoch_size']//params['batch_size'])\n",
    "    avg_loss_z = total_loss_z/(params['epoch_size']//params['batch_size'])\n",
    "    return avg_loss,avg_loss_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832f43d0-2d2a-4527-a19e-bdf70e84c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parameter(params):\n",
    "    encoder_weights = params['encoder_weights']\n",
    "    encoder_biases = params['encoder_biases']\n",
    "    params_temp = []\n",
    "    for i in range(len(params['widths'])):\n",
    "        params_temp.append(encoder_weights[i])\n",
    "        params_temp.append(encoder_biases[i])\n",
    "    decoder_weights = params['decoder_weights']\n",
    "    decoder_biases = params['decoder_biases']\n",
    "    for i in range(len(params['widths'])):\n",
    "        params_temp.append(decoder_weights[i])\n",
    "        params_temp.append(decoder_biases[i])\n",
    "    return params_temp\n",
    "\n",
    "def generate_vhat(vhat):\n",
    "    vhat = tuple(vhat)\n",
    "    yield vhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d0474d4-99c4-4ed7-b5fd-730544f1bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(data,params,device):\n",
    "    total_loss = 0\n",
    "    total_loss_z = 0\n",
    "    params['epoch_size'] = val_data[\"x\"].shape[0]\n",
    "    for j in range(params['epoch_size']//params['batch_size']):\n",
    "        batch_idxs = np.arange(j * params['batch_size'], (j + 1) * params['batch_size'])\n",
    "        z = torch.from_numpy(data['z'][batch_idxs]).to(torch.float32).to(device)\n",
    "        x = torch.from_numpy(data['x'][batch_idxs]).to(torch.float32).to(device)\n",
    "        dx = torch.from_numpy(data['dx'][batch_idxs]).to(torch.float32).to(device)\n",
    "        ddx = torch.from_numpy(data['ddx'][batch_idxs]).to(torch.float32).to(device)\n",
    "        x_predict = autoencoder_forward(x,params)\n",
    "        z_predict = encoder_forward(x,params)\n",
    "        dz_predict,ddz_predict = encoder_derivative(x,dx,ddx,params)\n",
    "        dx_predict,ddx_predict = decoder_derivative(z_predict,dz_predict,ddz_predict,params)\n",
    "        loss_x = torch.mean((x - x_predict)**2)\n",
    "        loss_dx = torch.mean((x - dx_predict) ** 2)\n",
    "        loss_ddx = torch.mean((x - ddx_predict) ** 2)\n",
    "        loss_z = torch.mean((z - z_predict)**2)\n",
    "        loss = params['loss_weight_x'] * loss_x \\\n",
    "               + params['loss_weight_dx'] * loss_dx \\\n",
    "               + params['loss_weight_ddx'] * loss_ddx\n",
    "        total_loss += loss\n",
    "        total_loss_z += loss_z\n",
    "        print('batch_{} --- image loss: {} --- z loss: {}'.format(j,loss,loss_z))\n",
    "    avg_loss = total_loss/(params['epoch_size']//params['batch_size'])\n",
    "    avg_loss_z = total_loss_z/(params['epoch_size']//params['batch_size'])\n",
    "    return avg_loss,avg_loss_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "824989ee-33b0-46a8-b1a2-e164e6902549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving(params):\n",
    "    PATH = os.path.join('/mnt/ssd1/stilrmy/Autoencoder-conservtive_expression/progress',params['date'],params['ver'])\n",
    "    if os.path.exists(PATH) == False:\n",
    "        os.makedirs(PATH)\n",
    "    params_names = [params['encoder_weights'],params['encoder_biases'],params['decoder_weights'],params['decoder_biases']]\n",
    "    params_names_str = ['encoder_weights','encoder_biases','decoder_weights','decoder_biases']\n",
    "    for j,param_set in enumerate(params_names):\n",
    "        for i,elements in enumerate(param_set):\n",
    "            np.save(r\"/mnt/ssd1/stilrmy/Autoencoder-conservtive_expression/progress/{}/{}/autoencoder_{}_layer{}.npy\".format(params['date'],params['ver'],params_names_str[j],i),\n",
    "                   elements.clone().detach().cpu().numpy())\n",
    "    sub_params = params.copy()\n",
    "    del sub_params['encoder_weights']\n",
    "    del sub_params['encoder_biases']\n",
    "    del sub_params['decoder_weights']\n",
    "    del sub_params['decoder_biases']\n",
    "    with open(r\"/mnt/ssd1/stilrmy/Autoencoder-conservtive_expression/progress/{}/{}/params.txt\".format(params['date'],params['ver']),'w') as file:\n",
    "        file.write(str(sub_params))\n",
    "        file.write('\\r\\t')\n",
    "        file.close()\n",
    "    print('params saved')\n",
    "    return\n",
    "\n",
    "def loading_coef(params,date,load_number,file_route,device):\n",
    "    print('loading params')\n",
    "    params_names_str = ['encoder_weights', 'encoder_biases', 'decoder_weights', 'decoder_biases']\n",
    "    for param_name in params_names_str:\n",
    "        params['{}'.format(param_name)] = []\n",
    "        for i in range(len(params['widths'])+1):\n",
    "            file_name = 'autoencoder_{}_layer{}.npy'.format(param_name,i)\n",
    "            route = os.path.join(file_route,date,load_number,file_name)\n",
    "            temp_loader = np.load(route)\n",
    "            temp_loader = torch.tensor(temp_loader).to(device)\n",
    "            temp_loader = Variable(temp_loader, requires_grad=True)\n",
    "            print(temp_loader.shape)\n",
    "            params['{}'.format(param_name)].append(temp_loader)\n",
    "    #coef = np.load(r'{}\\{}\\{}\\coef.npy'.format(file_route,date,load_number))\n",
    "    #coef = torch.Tensor(coef).to(device)\n",
    "    #coef = Variable(coef,requires_grad=True)\n",
    "    #expr = np.load(r'{}\\{}\\{}\\expr.npy'.format(file_route,date,load_number))\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5284f09f-b5f7-4d2c-8498-60064b590849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(loss_history,loss_z_history):\n",
    "    fig, a = plt.subplots(2, 1)\n",
    "    a[0].plot(loss_history)\n",
    "    a[0].set_title(\"loss\")\n",
    "    a[1].plot(loss_z_history)\n",
    "    a[1].set_title(\"z_loss\")\n",
    "    plt.subplots_adjust(hspace=1)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4933057b-96b4-4111-870c-591a95d26dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_params == True:\n",
    "    params = loading(params,load_date,load_ver,file_route,device)\n",
    "else:\n",
    "    encoder_weights,encoder_biases,decoder_weights,decoder_biases = autoencoder(2601,1,widths,device)\n",
    "    params['encoder_weights'] = encoder_weights\n",
    "    params['encoder_biases'] = encoder_biases\n",
    "    params['decoder_weights'] = decoder_weights\n",
    "    params['decoder_biases'] = decoder_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82b00fec-1118-49be-8577-86e9c658c78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 === loss: 0.21595712006092072\t=== loss_z: 1.3008414506912231\n",
      "epoch: 1 === loss: 0.21446369588375092\t=== loss_z: 1.3258637189865112\n",
      "epoch: 2 === loss: 0.21297971904277802\t=== loss_z: 1.3582417964935303\n",
      "epoch: 3 === loss: 0.21150508522987366\t=== loss_z: 1.3979045152664185\n",
      "epoch: 4 === loss: 0.21003977954387665\t=== loss_z: 1.4447702169418335\n",
      "epoch: 5 === loss: 0.20858381688594818\t=== loss_z: 1.498747706413269\n",
      "epoch: 6 === loss: 0.20713721215724945\t=== loss_z: 1.5597331523895264\n",
      "epoch: 7 === loss: 0.20569972693920135\t=== loss_z: 1.6276123523712158\n",
      "epoch: 8 === loss: 0.20427151024341583\t=== loss_z: 1.7022594213485718\n",
      "epoch: 9 === loss: 0.20285236835479736\t=== loss_z: 1.7835358381271362\n",
      "epoch: 10 === loss: 0.2014424353837967\t=== loss_z: 1.871291995048523\n",
      "epoch: 11 === loss: 0.2000414878129959\t=== loss_z: 1.9653666019439697\n",
      "epoch: 12 === loss: 0.19864962995052338\t=== loss_z: 2.065584897994995\n",
      "epoch: 13 === loss: 0.19726675748825073\t=== loss_z: 2.1717584133148193\n",
      "epoch: 14 === loss: 0.19589295983314514\t=== loss_z: 2.2836837768554688\n",
      "epoch: 15 === loss: 0.19452814757823944\t=== loss_z: 2.4011447429656982\n",
      "epoch: 16 === loss: 0.19317232072353363\t=== loss_z: 2.52390718460083\n",
      "epoch: 17 === loss: 0.1918254941701889\t=== loss_z: 2.651721239089966\n",
      "epoch: 18 === loss: 0.19048760831356049\t=== loss_z: 2.7843196392059326\n",
      "epoch: 19 === loss: 0.1891585886478424\t=== loss_z: 2.921417236328125\n",
      "epoch: 20 === loss: 0.18783842027187347\t=== loss_z: 3.0627057552337646\n",
      "epoch: 21 === loss: 0.1865270584821701\t=== loss_z: 3.207850217819214\n",
      "epoch: 22 === loss: 0.1852244883775711\t=== loss_z: 3.3564870357513428\n",
      "epoch: 23 === loss: 0.18393057584762573\t=== loss_z: 3.50822114944458\n",
      "epoch: 24 === loss: 0.18264532089233398\t=== loss_z: 3.6626198291778564\n",
      "epoch: 25 === loss: 0.18136873841285706\t=== loss_z: 3.8192105293273926\n",
      "epoch: 26 === loss: 0.1801007091999054\t=== loss_z: 3.977466344833374\n",
      "epoch: 27 === loss: 0.1788412481546402\t=== loss_z: 4.136800289154053\n",
      "epoch: 28 === loss: 0.1775902658700943\t=== loss_z: 4.29654598236084\n",
      "epoch: 29 === loss: 0.1763477921485901\t=== loss_z: 4.45593786239624\n",
      "epoch: 30 === loss: 0.17511378228664398\t=== loss_z: 4.614080905914307\n",
      "epoch: 31 === loss: 0.1738881766796112\t=== loss_z: 4.769889831542969\n",
      "epoch: 32 === loss: 0.17267099022865295\t=== loss_z: 4.922012805938721\n",
      "epoch: 33 === loss: 0.17146216332912445\t=== loss_z: 5.068710803985596\n",
      "epoch: 34 === loss: 0.1702617108821869\t=== loss_z: 5.207646369934082\n",
      "epoch: 35 === loss: 0.16906952857971191\t=== loss_z: 5.335450172424316\n",
      "epoch: 36 === loss: 0.16788573563098907\t=== loss_z: 5.446813583374023\n",
      "epoch: 37 === loss: 0.16671022772789001\t=== loss_z: 5.532220363616943\n",
      "epoch: 38 === loss: 0.16554304957389832\t=== loss_z: 5.573454856872559\n",
      "epoch: 39 === loss: 0.16438406705856323\t=== loss_z: 5.552908420562744\n",
      "epoch: 40 === loss: 0.16323339939117432\t=== loss_z: 5.480368614196777\n",
      "epoch: 41 === loss: 0.16209091246128082\t=== loss_z: 5.37685489654541\n",
      "epoch: 42 === loss: 0.16095666587352753\t=== loss_z: 5.254875183105469\n",
      "epoch: 43 === loss: 0.15983064472675323\t=== loss_z: 5.120894908905029\n",
      "epoch: 44 === loss: 0.15871284902095795\t=== loss_z: 4.978733062744141\n",
      "epoch: 45 === loss: 0.15760330855846405\t=== loss_z: 4.830915451049805\n",
      "epoch: 46 === loss: 0.15650205314159393\t=== loss_z: 4.6792473793029785\n",
      "epoch: 47 === loss: 0.15540899336338043\t=== loss_z: 4.525102138519287\n",
      "epoch: 48 === loss: 0.15432415902614594\t=== loss_z: 4.3695597648620605\n",
      "epoch: 49 === loss: 0.15324759483337402\t=== loss_z: 4.213503837585449\n",
      "epoch: 50 === loss: 0.1521792709827423\t=== loss_z: 4.057672500610352\n",
      "epoch: 51 === loss: 0.15111911296844482\t=== loss_z: 3.902705430984497\n",
      "epoch: 52 === loss: 0.15006718039512634\t=== loss_z: 3.7491605281829834\n",
      "epoch: 53 === loss: 0.1490233838558197\t=== loss_z: 3.5975334644317627\n",
      "epoch: 54 === loss: 0.14798782765865326\t=== loss_z: 3.4482686519622803\n",
      "epoch: 55 === loss: 0.14696040749549866\t=== loss_z: 3.3017661571502686\n",
      "epoch: 56 === loss: 0.1459411233663559\t=== loss_z: 3.158395767211914\n",
      "epoch: 57 === loss: 0.14492999017238617\t=== loss_z: 3.0184953212738037\n",
      "epoch: 58 === loss: 0.1439269632101059\t=== loss_z: 2.8823814392089844\n",
      "epoch: 59 === loss: 0.14293207228183746\t=== loss_z: 2.750347852706909\n",
      "epoch: 60 === loss: 0.14194530248641968\t=== loss_z: 2.6226680278778076\n",
      "epoch: 61 === loss: 0.14096665382385254\t=== loss_z: 2.49959397315979\n",
      "epoch: 62 === loss: 0.13999612629413605\t=== loss_z: 2.381359100341797\n",
      "epoch: 63 === loss: 0.139033704996109\t=== loss_z: 2.2681844234466553\n",
      "epoch: 64 === loss: 0.13807940483093262\t=== loss_z: 2.160273551940918\n",
      "epoch: 65 === loss: 0.1371331661939621\t=== loss_z: 2.057818651199341\n",
      "epoch: 66 === loss: 0.1361950784921646\t=== loss_z: 1.9609969854354858\n",
      "epoch: 67 === loss: 0.135265052318573\t=== loss_z: 1.8699754476547241\n",
      "epoch: 68 === loss: 0.13434314727783203\t=== loss_z: 1.7849081754684448\n",
      "epoch: 69 === loss: 0.1334293931722641\t=== loss_z: 1.7059377431869507\n",
      "epoch: 70 === loss: 0.13252373039722443\t=== loss_z: 1.6331977844238281\n",
      "epoch: 71 === loss: 0.1316262185573578\t=== loss_z: 1.5668085813522339\n",
      "epoch: 72 === loss: 0.13073676824569702\t=== loss_z: 1.506881594657898\n",
      "epoch: 73 === loss: 0.12985548377037048\t=== loss_z: 1.453517198562622\n",
      "epoch: 74 === loss: 0.1289823204278946\t=== loss_z: 1.406805396080017\n",
      "epoch: 75 === loss: 0.12811727821826935\t=== loss_z: 1.3668270111083984\n",
      "epoch: 76 === loss: 0.12726032733917236\t=== loss_z: 1.333652377128601\n",
      "epoch: 77 === loss: 0.12641148269176483\t=== loss_z: 1.3073421716690063\n",
      "epoch: 78 === loss: 0.12557078897953033\t=== loss_z: 1.2879482507705688\n",
      "epoch: 79 === loss: 0.12473809719085693\t=== loss_z: 1.2755126953125\n",
      "epoch: 80 === loss: 0.12391356378793716\t=== loss_z: 1.2700693607330322\n",
      "epoch: 81 === loss: 0.1230970248579979\t=== loss_z: 1.271644949913025\n",
      "epoch: 82 === loss: 0.12228858470916748\t=== loss_z: 1.280274748802185\n",
      "epoch: 83 === loss: 0.12148822844028473\t=== loss_z: 1.2959855794906616\n",
      "epoch: 84 === loss: 0.12069588899612427\t=== loss_z: 1.3187922239303589\n",
      "epoch: 85 === loss: 0.1199115514755249\t=== loss_z: 1.3487019538879395\n",
      "epoch: 86 === loss: 0.1191352978348732\t=== loss_z: 1.3857101202011108\n",
      "epoch: 87 === loss: 0.11836709082126617\t=== loss_z: 1.4298051595687866\n",
      "epoch: 88 === loss: 0.11760684102773666\t=== loss_z: 1.4809651374816895\n",
      "epoch: 89 === loss: 0.11685469001531601\t=== loss_z: 1.5391610860824585\n",
      "epoch: 90 === loss: 0.11611052602529526\t=== loss_z: 1.6043556928634644\n",
      "epoch: 91 === loss: 0.11537432670593262\t=== loss_z: 1.6765025854110718\n",
      "epoch: 92 === loss: 0.11464615166187286\t=== loss_z: 1.7555503845214844\n",
      "epoch: 93 === loss: 0.11392593383789062\t=== loss_z: 1.841437578201294\n",
      "epoch: 94 === loss: 0.11321371048688889\t=== loss_z: 1.934098243713379\n",
      "epoch: 95 === loss: 0.11250938475131989\t=== loss_z: 2.033456802368164\n",
      "epoch: 96 === loss: 0.1118130087852478\t=== loss_z: 2.1394336223602295\n",
      "epoch: 97 === loss: 0.11112455278635025\t=== loss_z: 2.2519419193267822\n",
      "epoch: 98 === loss: 0.11044397205114365\t=== loss_z: 2.37088942527771\n",
      "epoch: 99 === loss: 0.10977126657962799\t=== loss_z: 2.4961769580841064\n",
      "epoch: 100 === loss: 0.10910642147064209\t=== loss_z: 2.6277027130126953\n",
      "epoch: 101 === loss: 0.10844941437244415\t=== loss_z: 2.765357494354248\n",
      "epoch: 102 === loss: 0.10780016332864761\t=== loss_z: 2.909026861190796\n",
      "epoch: 103 === loss: 0.10715872049331665\t=== loss_z: 3.0585930347442627\n",
      "epoch: 104 === loss: 0.1065249964594841\t=== loss_z: 3.2139344215393066\n",
      "epoch: 105 === loss: 0.10589899867773056\t=== loss_z: 3.3749241828918457\n",
      "epoch: 106 === loss: 0.10528071224689484\t=== loss_z: 3.541430711746216\n",
      "epoch: 107 === loss: 0.10467007011175156\t=== loss_z: 3.713322401046753\n",
      "epoch: 108 === loss: 0.10406706482172012\t=== loss_z: 3.890462636947632\n",
      "epoch: 109 === loss: 0.10347165167331696\t=== loss_z: 4.072711944580078\n",
      "epoch: 110 === loss: 0.10288380831480026\t=== loss_z: 4.259929180145264\n",
      "epoch: 111 === loss: 0.10230350494384766\t=== loss_z: 4.451969623565674\n",
      "epoch: 112 === loss: 0.10173069685697556\t=== loss_z: 4.648688793182373\n",
      "epoch: 113 === loss: 0.10116530954837799\t=== loss_z: 4.849941730499268\n",
      "epoch: 114 === loss: 0.10060737282037735\t=== loss_z: 5.055578231811523\n",
      "epoch: 115 === loss: 0.10005684196949005\t=== loss_z: 5.265454292297363\n",
      "epoch: 116 === loss: 0.09951364994049072\t=== loss_z: 5.4794158935546875\n",
      "epoch: 117 === loss: 0.09897775202989578\t=== loss_z: 5.697316646575928\n",
      "epoch: 118 === loss: 0.09844912588596344\t=== loss_z: 5.919007778167725\n",
      "epoch: 119 === loss: 0.09792773425579071\t=== loss_z: 6.144341945648193\n",
      "epoch: 120 === loss: 0.09741350263357162\t=== loss_z: 6.373169422149658\n",
      "epoch: 121 === loss: 0.09690646082162857\t=== loss_z: 6.605343818664551\n",
      "epoch: 122 === loss: 0.0964064821600914\t=== loss_z: 6.840721130371094\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epochs \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate_switching_point\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      3\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate_stage2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m loss,loss_z \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m loss_history\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m      6\u001b[0m loss_z_history\u001b[38;5;241m.\u001b[39mappend(loss_z\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(data, params, device)\u001b[0m\n\u001b[0;32m     22\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     23\u001b[0m total_loss_z \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_z\n\u001b[1;32m---> 24\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     26\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epochs in range(params['max_epochs']):\n",
    "    if epochs >= params['learning_rate_switching_point']:\n",
    "        params['learning_rate'] = params['learning_rate_stage2']\n",
    "    loss,loss_z = training(data,params,device)\n",
    "    loss_history.append(loss.clone().detach().cpu().numpy())\n",
    "    loss_z_history.append(loss_z.clone().detach().cpu().numpy())\n",
    "    #if epochs % 100 == 0:\n",
    "    print('epoch: {} === loss: {}\\t=== loss_z: {}'.format(epochs,loss,loss_z))\n",
    "\n",
    "validation(val_data,params,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eff876-2bc0-4a7a-a3e8-67ae9fd0ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_params == True:\n",
    "    saving(params)\n",
    "plotting(loss_history,loss_z_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff75b85-abf4-44cc-850a-673c9abaa539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d67dc-e2da-4c2e-a611-d2f32c8b93d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183a9ee-1547-436c-b6e2-63d4ed00fddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
