{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21abee7a-e86d-4999-a297-36f121b1dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys \n",
    "\n",
    "\n",
    "from sympy import symbols, simplify, derive_by_array\n",
    "from scipy.integrate import solve_ivp\n",
    "from xLSINDy_sp_friction import *\n",
    "from sympy.physics.mechanics import *\n",
    "from sympy import *\n",
    "from Data_generator_py_friction import image_process\n",
    "import sympy\n",
    "import torch\n",
    "import sys\n",
    "import HLsearch as HL\n",
    "import example_pendulum\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3931f0-8bba-44e2-8d56-b263f77bac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "environment = \"server\"\n",
    "sample_size = 10\n",
    "device = 'cuda:7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e864928-be31-4c73-b320-bfe0a2143ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample version: c=-0.14\n",
      "type of t:  float64\n",
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(r'../../../HLsearch/')\n",
    "#Saving Directory\n",
    "params = {}\n",
    "params['adding_noise'] = False\n",
    "params['noise_type'] = 'image_noise'\n",
    "params['noiselevel'] = 1e-1\n",
    "params['changing_length'] = False\n",
    "if environment == 'laptop':\n",
    "    root_dir =R'C:\\Users\\87106\\OneDrive\\sindy\\progress'\n",
    "elif environment == 'desktop':\n",
    "    root_dir = R'E:\\OneDrive\\sindy\\progress'\n",
    "elif environment == 'server':\n",
    "    root_dir = R'/mnt/ssd1/stilrmy/Autoencoder-conservtive_expression'\n",
    "x,dx,ddx = image_process(sample_size,params)\n",
    "X = []\n",
    "Xdot = []\n",
    "for i in range(len(x)):\n",
    "    temp_list = [float(x[i]),float(dx[i])]\n",
    "    X.append(temp_list)\n",
    "    temp_list = [float(dx[i]),float(ddx[i])]\n",
    "    Xdot.append(temp_list)\n",
    "X = np.vstack(X)\n",
    "print(X.shape)\n",
    "Xdot = np.vstack(Xdot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8250a64-b76e-48f3-810e-28b181740486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states are: (x0, x0_t)\n",
      "states derivatives are:  (x0_t, x0_tt)\n"
     ]
    }
   ],
   "source": [
    "states_dim = 2\n",
    "states = ()\n",
    "states_dot = ()\n",
    "for i in range(states_dim):\n",
    "    if(i<states_dim//2):\n",
    "        states = states + (symbols('x{}'.format(i)),)\n",
    "        states_dot = states_dot + (symbols('x{}_t'.format(i)),)\n",
    "    else:\n",
    "        states = states + (symbols('x{}_t'.format(i-states_dim//2)),)\n",
    "        states_dot = states_dot + (symbols('x{}_tt'.format(i-states_dim//2)),)\n",
    "print('states are:',states)\n",
    "print('states derivatives are: ', states_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6dddc-ac3c-4e37-91dc-ac6bab075c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn from sympy to str\n",
    "states_sym = states\n",
    "states_dot_sym = states_dot\n",
    "states = list(str(descr) for descr in states)\n",
    "states_dot = list(str(descr) for descr in states_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f71e4d-17ce-4af8-9d22-dc28cfc93f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x0', 'x0_t', 'sin(x0)', 'cos(x0)', 'x0**2', 'x0*x0_t', 'x0_t**2', 'x0*sin(x0)', 'x0_t*sin(x0)', 'sin(x0)**2', 'x0*cos(x0)', 'x0_t*cos(x0)', 'sin(x0)*cos(x0)', 'cos(x0)**2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'x0*x0_t'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build function expression for the library in str\n",
    "expr= HL.buildFunctionExpressions(2,states_dim,states,use_sine=True)\n",
    "#expr=['x0', 'x0_t', 'sin(x0)', 'cos(x0)', 'x0**2', 'x0*x0_t', 'x0_t**2', 'x0*sin(x0)', 'x0_t*sin(x0)', 'sin(x0)**2', 'x0*cos(x0)', 'x0_t*cos(x0)', 'sin(x0)*cos(x0)', 'cos(x0)**2']\n",
    "\"a list of candidate function\"\n",
    "print(expr)\n",
    "expr.pop(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad60fa-1b07-423b-b96d-be7e84e9f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zeta, Eta, Delta,Gamma = LagrangianLibraryTensor(X,Xdot,expr,states,states_dot,device,scaling=True)\n",
    "Eta = Eta.to(device)\n",
    "Zeta = Zeta.to(device)\n",
    "Delta = Delta.to(device)\n",
    "Gamma = Gamma.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e559dd-c8b0-4041-b1f8-64e6124095be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ones(len(expr),device=device)\n",
    "xi_L = torch.ones(len(expr), device=device).data.uniform_(-10,10)\n",
    "prevxi_L = xi_L.clone().detach()\n",
    "c = torch.ones(1,device=device)*-1\n",
    "prec = c.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8134ecd-8d51-42b3-bd18-0a0f50901312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(pred, targ):\n",
    "    loss = torch.mean((pred - targ)**2) \n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c008f0b2-21b3-4433-afbf-8353931150dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(w, alpha):\n",
    "    clipped = torch.minimum(w,alpha)\n",
    "    clipped = torch.maximum(clipped,-alpha)\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16edbe1-038d-45e5-b403-07e08b441d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxL1norm(w_hat, alpha):\n",
    "    if(torch.is_tensor(alpha)==False):\n",
    "        alpha = torch.tensor(alpha)\n",
    "    w = w_hat - clip(w_hat,alpha)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace203e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(coef,c, prevcoef,prec, Zeta, Eta, Delta,Gamma,xdot, bs, lr, lam, momentum = True, beta1=0.9, beta2=0.999, eps=1e-8):\n",
    "    loss_list = []\n",
    "    tl = xdot.shape[0]\n",
    "    n = xdot.shape[1]\n",
    "\n",
    "    v = coef.clone().detach().to(device).requires_grad_(True)\n",
    "    prev = prevcoef.clone().detach().to(device).requires_grad_(True)\n",
    "    prec = prec.clone().detach().to(device).requires_grad_(True)\n",
    "    \n",
    "    # Initialize moving averages for Adam\n",
    "    m_v = torch.zeros_like(v)\n",
    "    m_c = torch.zeros_like(c)\n",
    "    v_v = torch.zeros_like(v)\n",
    "    v_c = torch.zeros_like(c)\n",
    "\n",
    "    for i in range(tl//bs):\n",
    "        vhat = v.requires_grad_(True).clone().detach().requires_grad_(True)\n",
    "        chat = c.requires_grad_(True).clone().detach().requires_grad_(True)\n",
    "        prev = v\n",
    "        prec = c\n",
    "        \n",
    "        zeta = Zeta[:,i*bs:(i+1)*bs]\n",
    "        eta = Eta[:,i*bs:(i+1)*bs]\n",
    "        delta = Delta[:,i*bs:(i+1)*bs]\n",
    "        gamma = Gamma[:,i*bs:(i+1)*bs]\n",
    "        x_t = xdot[i*bs:(i+1)*bs,:]\n",
    "\n",
    "        q_tt_pred = lagrangianforward(vhat,chat,zeta,eta,delta,gamma,x_t,device)\n",
    "        q_tt_true = xdot[i*bs:(i+1)*bs,n//2:].T\n",
    "        q_tt_true = torch.from_numpy(q_tt_true).to(device).float()\n",
    "        lossval = loss(q_tt_pred, q_tt_true)\n",
    "        lossval.requires_grad_(True)\n",
    "        \n",
    "        lossval.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Update moving averages\n",
    "            m_v = beta1 * m_v + (1 - beta1) * vhat.grad\n",
    "            v_v = beta2 * v_v + (1 - beta2) * (vhat.grad ** 2)\n",
    "            m_c = beta1 * m_c + (1 - beta1) * chat.grad\n",
    "            v_c = beta2 * v_c + (1 - beta2) * (chat.grad ** 2)\n",
    "\n",
    "            # Compute bias-corrected moving averages\n",
    "            m_v_hat = m_v / (1 - beta1 ** (i + 1))\n",
    "            v_v_hat = v_v / (1 - beta2 ** (i + 1))\n",
    "            m_c_hat = m_c / (1 - beta1 ** (i + 1))\n",
    "            v_c_hat = v_c / (1 - beta2 ** (i + 1))\n",
    "\n",
    "            # Update parameters\n",
    "            c = chat - lr * m_c_hat / (torch.sqrt(v_c_hat) + eps)\n",
    "            c = proxL1norm(c, lr * lam)\n",
    "            v = vhat - lr * m_v_hat / (torch.sqrt(v_v_hat) + eps)\n",
    "            v = proxL1norm(v, lr * lam)\n",
    "        loss_list.append(lossval.item())\n",
    "    return v,prev,c,prec,torch.tensor(loss_list).mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ace20-122c-4072-9ccf-9a3bd554abc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Stage 1\n",
      "Epoch 20/100\n",
      "Learning rate :  0.001\n",
      "Average loss :  32.938602447509766\n",
      "\n",
      "\n",
      "Stage 1\n",
      "Epoch 40/100\n",
      "Learning rate :  0.001\n",
      "Average loss :  30.137357711791992\n",
      "\n",
      "\n",
      "Stage 1\n",
      "Epoch 60/100\n",
      "Learning rate :  0.001\n",
      "Average loss :  26.571229934692383\n",
      "\n",
      "\n",
      "Stage 1\n",
      "Epoch 80/100\n",
      "Learning rate :  0.001\n",
      "Average loss :  21.84833335876465\n",
      "\n",
      "\n",
      "Stage 1\n",
      "Epoch 100/100\n",
      "Learning rate :  0.001\n",
      "Average loss :  15.776118278503418\n"
     ]
    }
   ],
   "source": [
    "Epoch = 100\n",
    "i = 1\n",
    "lr = 1e-3\n",
    "lam = 0.1\n",
    "temp = 1000\n",
    "while(i<=Epoch):\n",
    "    xi_L , prevxi_L,c,prec, lossitem= training_loop(xi_L,c,prevxi_L,prec,Zeta,Eta,Delta,Gamma,Xdot,128,lr=lr,lam=lam)\n",
    "    if i %20 == 0:\n",
    "        print(\"\\n\")\n",
    "        print(\"Stage 1\")\n",
    "        print(\"Epoch \"+str(i) + \"/\" + str(Epoch))\n",
    "        print(\"Learning rate : \", lr)\n",
    "        print(\"Average loss : \" , lossitem)\n",
    "    if(temp <=5e-3):\n",
    "        break\n",
    "    if(temp <=1e-1):\n",
    "        lr = 1e-5\n",
    "    temp = lossitem\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e39cf-6dac-45ba-8c38-8bfeaf4626b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "-1.16*x0 + 0.29*x0_t + -8.45*sin(x0) + 12.25*cos(x0) + 5.7*x0**2 + 2.72*x0_t**2 + -5.26*x0*sin(x0) + 7.73*x0_t*sin(x0) + -8.81*sin(x0)**2 + 8.7*x0*cos(x0) + -6.91*x0_t*cos(x0) + -7.31*sin(x0)*cos(x0) + 1.57*cos(x0)**2 + \n"
     ]
    }
   ],
   "source": [
    "threshold = 1e-2\n",
    "surv_index = ((torch.abs(xi_L) >= threshold)).nonzero(as_tuple=True)[0].detach().cpu().numpy()\n",
    "expr = np.array(expr)[surv_index].tolist()\n",
    "\n",
    "xi_L =xi_L[surv_index].clone().detach().requires_grad_(True)\n",
    "prevxi_L = xi_L.clone().detach()\n",
    "mask = torch.ones(len(expr),device=device)\n",
    "\n",
    "## obtaining analytical model\n",
    "xi_Lcpu = np.around(xi_L.detach().cpu().numpy(),decimals=2)\n",
    "L = HL.generateExpression(xi_Lcpu,expr)\n",
    "print(len(xi_L))\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc14c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2464], device='cuda:7')\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbbf84e-74af-4e42-a56c-c701b029dbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Stage  0\n",
      "Epoch 50/200\n",
      "Learning rate :  0.001\n",
      "Average loss :  7.856019692553673e-06\n",
      "\n",
      "\n",
      "Stage  0\n",
      "Epoch 100/200\n",
      "Learning rate :  0.001\n",
      "Average loss :  5.560499630519189e-06\n",
      "\n",
      "\n",
      "Stage  0\n",
      "Epoch 150/200\n",
      "Learning rate :  0.001\n",
      "Average loss :  1.4514201211568434e-05\n",
      "\n",
      "\n",
      "Stage  0\n",
      "Epoch 200/200\n",
      "Learning rate :  0.001\n",
      "Average loss :  7.868423381296452e-06\n",
      "expression length:\t 5\n",
      "Result stage 2: -1.815*sin(x0) + 24.936*cos(x0) + 1.415*x0_t**2 + 20.278*x0_t*sin(x0) + -13.003*x0_t*cos(x0) + \n",
      "exp([0.13982226]*t)\n",
      "\n",
      "\n",
      "Stage  1\n",
      "Epoch 50/200\n",
      "Learning rate :  0.000990049833749168\n",
      "Average loss :  6.285237759584561e-06\n",
      "\n",
      "\n",
      "Stage  1\n",
      "Epoch 100/200\n",
      "Learning rate :  0.000990049833749168\n",
      "Average loss :  6.5794506554084364e-06\n",
      "\n",
      "\n",
      "Stage  1\n",
      "Epoch 150/200\n",
      "Learning rate :  0.000990049833749168\n",
      "Average loss :  5.330814474291401e-06\n",
      "\n",
      "\n",
      "Stage  1\n",
      "Epoch 200/200\n",
      "Learning rate :  0.000990049833749168\n",
      "Average loss :  1.097550102713285e-05\n",
      "expression length:\t 5\n",
      "Result stage 3: -1.818*sin(x0) + 24.938*cos(x0) + 1.416*x0_t**2 + 20.268*x0_t*sin(x0) + -12.987*x0_t*cos(x0) + \n",
      "exp([0.13993375]*t)\n",
      "\n",
      "\n",
      "Stage  2\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0009801986733067552\n",
      "Average loss :  7.18924366083229e-06\n",
      "\n",
      "\n",
      "Stage  2\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0009801986733067552\n",
      "Average loss :  7.154753802751657e-06\n",
      "\n",
      "\n",
      "Stage  2\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0009801986733067552\n",
      "Average loss :  1.2654119927901775e-05\n",
      "\n",
      "\n",
      "Stage  2\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0009801986733067552\n",
      "Average loss :  1.752711432345677e-05\n",
      "expression length:\t 5\n",
      "Result stage 4: -1.811*sin(x0) + 24.942*cos(x0) + 1.415*x0_t**2 + 20.26*x0_t*sin(x0) + -12.981*x0_t*cos(x0) + \n",
      "exp([0.1396883]*t)\n",
      "\n",
      "\n",
      "Stage  3\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0009704455335485082\n",
      "Average loss :  7.250083399412688e-06\n",
      "\n",
      "\n",
      "Stage  3\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0009704455335485082\n",
      "Average loss :  1.4269366147345863e-05\n",
      "\n",
      "\n",
      "Stage  3\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0009704455335485082\n",
      "Average loss :  6.494951776403468e-06\n",
      "\n",
      "\n",
      "Stage  3\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0009704455335485082\n",
      "Average loss :  6.55553185424651e-06\n",
      "expression length:\t 5\n",
      "Result stage 5: -1.811*sin(x0) + 24.944*cos(x0) + 1.416*x0_t**2 + 20.251*x0_t*sin(x0) + -12.968*x0_t*cos(x0) + \n",
      "exp([0.13951434]*t)\n",
      "\n",
      "\n",
      "Stage  4\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0009607894391523232\n",
      "Average loss :  8.238126611104235e-06\n",
      "\n",
      "\n",
      "Stage  4\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0009607894391523232\n",
      "Average loss :  6.422740170819452e-06\n",
      "\n",
      "\n",
      "Stage  4\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0009607894391523232\n",
      "Average loss :  6.430145731428638e-06\n",
      "\n",
      "\n",
      "Stage  4\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0009607894391523232\n",
      "Average loss :  7.379764156212332e-06\n",
      "expression length:\t 5\n",
      "Result stage 6: -1.809*sin(x0) + 24.947*cos(x0) + 1.415*x0_t**2 + 20.243*x0_t*sin(x0) + -12.959*x0_t*cos(x0) + \n",
      "exp([0.13961151]*t)\n",
      "\n",
      "\n",
      "Stage  5\n",
      "Epoch 50/200\n",
      "Learning rate :  0.000951229424500714\n",
      "Average loss :  1.1497554623929318e-05\n",
      "\n",
      "\n",
      "Stage  5\n",
      "Epoch 100/200\n",
      "Learning rate :  0.000951229424500714\n",
      "Average loss :  6.986632797634229e-06\n",
      "\n",
      "\n",
      "Stage  5\n",
      "Epoch 150/200\n",
      "Learning rate :  0.000951229424500714\n",
      "Average loss :  7.072949301800691e-06\n",
      "\n",
      "\n",
      "Stage  5\n",
      "Epoch 200/200\n",
      "Learning rate :  0.000951229424500714\n",
      "Average loss :  1.0103944987349678e-05\n",
      "expression length:\t 5\n",
      "Result stage 7: -1.807*sin(x0) + 24.95*cos(x0) + 1.416*x0_t**2 + 20.235*x0_t*sin(x0) + -12.949*x0_t*cos(x0) + \n",
      "exp([0.13946865]*t)\n",
      "\n",
      "\n",
      "Stage  6\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0009417645335842487\n",
      "Average loss :  7.75137868913589e-06\n",
      "\n",
      "\n",
      "Stage  6\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0009417645335842487\n",
      "Average loss :  6.599956122954609e-06\n",
      "\n",
      "\n",
      "Stage  6\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0009417645335842487\n",
      "Average loss :  1.7817725165514275e-05\n",
      "\n",
      "\n",
      "Stage  6\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0009417645335842487\n",
      "Average loss :  1.0593762453936506e-05\n",
      "expression length:\t 5\n",
      "Result stage 8: -1.805*sin(x0) + 24.953*cos(x0) + 1.415*x0_t**2 + 20.227*x0_t*sin(x0) + -12.939*x0_t*cos(x0) + \n",
      "exp([0.13961434]*t)\n",
      "\n",
      "\n",
      "Stage  7\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0009323938199059483\n",
      "Average loss :  8.636621714686044e-06\n",
      "\n",
      "\n",
      "Stage  7\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0009323938199059483\n",
      "Average loss :  1.0214432222710457e-05\n",
      "\n",
      "\n",
      "Stage  7\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0009323938199059483\n",
      "Average loss :  1.2060171684424859e-05\n",
      "\n",
      "\n",
      "Stage  7\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0009323938199059483\n",
      "Average loss :  1.3849560673406813e-05\n",
      "expression length:\t 5\n",
      "Result stage 9: -1.804*sin(x0) + 24.955*cos(x0) + 1.416*x0_t**2 + 20.219*x0_t*sin(x0) + -12.928*x0_t*cos(x0) + \n",
      "exp([0.13958299]*t)\n",
      "\n",
      "\n",
      "Stage  8\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0009231163463866358\n",
      "Average loss :  6.659636255790247e-06\n",
      "\n",
      "\n",
      "Stage  8\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0009231163463866358\n",
      "Average loss :  1.0116530575032812e-05\n",
      "\n",
      "\n",
      "Stage  8\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0009231163463866358\n",
      "Average loss :  6.475619557022583e-06\n",
      "\n",
      "\n",
      "Stage  8\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0009231163463866358\n",
      "Average loss :  9.333918569609523e-06\n",
      "expression length:\t 5\n",
      "Result stage 10: -1.802*sin(x0) + 24.958*cos(x0) + 1.416*x0_t**2 + 20.211*x0_t*sin(x0) + -12.918*x0_t*cos(x0) + \n",
      "exp([0.13965437]*t)\n",
      "\n",
      "\n",
      "Stage  9\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0009139311852712283\n",
      "Average loss :  1.1712414561770856e-05\n",
      "\n",
      "\n",
      "Stage  9\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0009139311852712283\n",
      "Average loss :  6.8630788518930785e-06\n",
      "\n",
      "\n",
      "Stage  9\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0009139311852712283\n",
      "Average loss :  6.323099114524666e-06\n",
      "\n",
      "\n",
      "Stage  9\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0009139311852712283\n",
      "Average loss :  6.5190220084332395e-06\n",
      "expression length:\t 5\n",
      "Result stage 11: -1.802*sin(x0) + 24.961*cos(x0) + 1.416*x0_t**2 + 20.204*x0_t*sin(x0) + -12.907*x0_t*cos(x0) + \n",
      "exp([0.13982977]*t)\n",
      "\n",
      "\n",
      "Stage  10\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0009048374180359595\n",
      "Average loss :  6.395768195943674e-06\n",
      "\n",
      "\n",
      "Stage  10\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0009048374180359595\n",
      "Average loss :  6.329541974992026e-06\n",
      "\n",
      "\n",
      "Stage  10\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0009048374180359595\n",
      "Average loss :  5.674971362168435e-06\n",
      "\n",
      "\n",
      "Stage  10\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0009048374180359595\n",
      "Average loss :  6.132407634140691e-06\n",
      "expression length:\t 5\n",
      "Result stage 12: -1.801*sin(x0) + 24.963*cos(x0) + 1.416*x0_t**2 + 20.196*x0_t*sin(x0) + -12.897*x0_t*cos(x0) + \n",
      "exp([0.13961302]*t)\n",
      "\n",
      "\n",
      "Stage  11\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0008958341352965282\n",
      "Average loss :  4.426184204930905e-06\n",
      "\n",
      "\n",
      "Stage  11\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0008958341352965282\n",
      "Average loss :  4.41398242401192e-06\n",
      "\n",
      "\n",
      "Stage  11\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0008958341352965282\n",
      "Average loss :  6.09387143413187e-06\n",
      "\n",
      "\n",
      "Stage  11\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0008958341352965282\n",
      "Average loss :  7.63871594244847e-06\n",
      "expression length:\t 5\n",
      "Result stage 13: -1.799*sin(x0) + 24.966*cos(x0) + 1.416*x0_t**2 + 20.189*x0_t*sin(x0) + -12.889*x0_t*cos(x0) + \n",
      "exp([0.13968271]*t)\n",
      "\n",
      "\n",
      "Stage  12\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0008869204367171575\n",
      "Average loss :  6.203357770573348e-06\n",
      "\n",
      "\n",
      "Stage  12\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0008869204367171575\n",
      "Average loss :  8.688151865499094e-06\n",
      "\n",
      "\n",
      "Stage  12\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0008869204367171575\n",
      "Average loss :  7.739279681118205e-06\n",
      "\n",
      "\n",
      "Stage  12\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0008869204367171575\n",
      "Average loss :  5.283349764795275e-06\n",
      "expression length:\t 5\n",
      "Result stage 14: -1.799*sin(x0) + 24.967*cos(x0) + 1.417*x0_t**2 + 20.181*x0_t*sin(x0) + -12.878*x0_t*cos(x0) + \n",
      "exp([0.13959041]*t)\n",
      "\n",
      "\n",
      "Stage  13\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0008780954309205613\n",
      "Average loss :  7.114515483408468e-06\n",
      "\n",
      "\n",
      "Stage  13\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0008780954309205613\n",
      "Average loss :  3.5071645925199846e-06\n",
      "\n",
      "\n",
      "Stage  13\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0008780954309205613\n",
      "Average loss :  1.10665314423386e-05\n",
      "\n",
      "\n",
      "Stage  13\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0008780954309205613\n",
      "Average loss :  6.000228495395277e-06\n",
      "expression length:\t 5\n",
      "Result stage 15: -1.797*sin(x0) + 24.97*cos(x0) + 1.416*x0_t**2 + 20.175*x0_t*sin(x0) + -12.869*x0_t*cos(x0) + \n",
      "exp([0.13984878]*t)\n",
      "\n",
      "\n",
      "Stage  14\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0008693582353988059\n",
      "Average loss :  9.006186701299157e-06\n",
      "\n",
      "\n",
      "Stage  14\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0008693582353988059\n",
      "Average loss :  1.1371003893145826e-05\n",
      "\n",
      "\n",
      "Stage  14\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0008693582353988059\n",
      "Average loss :  5.876859177078586e-06\n",
      "\n",
      "\n",
      "Stage  14\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0008693582353988059\n",
      "Average loss :  7.608446594531415e-06\n",
      "expression length:\t 5\n",
      "Result stage 16: -1.795*sin(x0) + 24.972*cos(x0) + 1.417*x0_t**2 + 20.168*x0_t*sin(x0) + -12.86*x0_t*cos(x0) + \n",
      "exp([0.1395345]*t)\n",
      "\n",
      "\n",
      "Stage  15\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0008607079764250578\n",
      "Average loss :  5.4959559747658204e-06\n",
      "\n",
      "\n",
      "Stage  15\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0008607079764250578\n",
      "Average loss :  1.0392582225904334e-05\n",
      "\n",
      "\n",
      "Stage  15\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0008607079764250578\n",
      "Average loss :  5.895042249903781e-06\n",
      "\n",
      "\n",
      "Stage  15\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0008607079764250578\n",
      "Average loss :  5.642620180879021e-06\n",
      "expression length:\t 5\n",
      "Result stage 17: -1.795*sin(x0) + 24.975*cos(x0) + 1.416*x0_t**2 + 20.162*x0_t*sin(x0) + -12.852*x0_t*cos(x0) + \n",
      "exp([0.1398223]*t)\n",
      "\n",
      "\n",
      "Stage  16\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0008521437889662113\n",
      "Average loss :  5.098823748994619e-06\n",
      "\n",
      "\n",
      "Stage  16\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0008521437889662113\n",
      "Average loss :  5.34788114237017e-06\n",
      "\n",
      "\n",
      "Stage  16\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0008521437889662113\n",
      "Average loss :  5.599647920462303e-06\n",
      "\n",
      "\n",
      "Stage  16\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0008521437889662113\n",
      "Average loss :  5.611149845208274e-06\n",
      "expression length:\t 5\n",
      "Result stage 18: -1.794*sin(x0) + 24.977*cos(x0) + 1.416*x0_t**2 + 20.155*x0_t*sin(x0) + -12.843*x0_t*cos(x0) + \n",
      "exp([0.13982344]*t)\n",
      "\n",
      "\n",
      "Stage  17\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0008436648165963838\n",
      "Average loss :  9.172485988528933e-06\n",
      "\n",
      "\n",
      "Stage  17\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0008436648165963838\n",
      "Average loss :  5.45350576430792e-06\n",
      "\n",
      "\n",
      "Stage  17\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0008436648165963838\n",
      "Average loss :  5.334294201020384e-06\n",
      "\n",
      "\n",
      "Stage  17\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0008436648165963838\n",
      "Average loss :  5.786073415947612e-06\n",
      "expression length:\t 5\n",
      "Result stage 19: -1.792*sin(x0) + 24.979*cos(x0) + 1.417*x0_t**2 + 20.148*x0_t*sin(x0) + -12.835*x0_t*cos(x0) + \n",
      "exp([0.13966605]*t)\n",
      "\n",
      "\n",
      "Stage  18\n",
      "Epoch 50/200\n",
      "Learning rate :  0.000835270211411272\n",
      "Average loss :  5.132806563779013e-06\n",
      "\n",
      "\n",
      "Stage  18\n",
      "Epoch 100/200\n",
      "Learning rate :  0.000835270211411272\n",
      "Average loss :  5.484422672452638e-06\n",
      "\n",
      "\n",
      "Stage  18\n",
      "Epoch 150/200\n",
      "Learning rate :  0.000835270211411272\n",
      "Average loss :  5.135583705850877e-06\n",
      "\n",
      "\n",
      "Stage  18\n",
      "Epoch 200/200\n",
      "Learning rate :  0.000835270211411272\n",
      "Average loss :  9.06476634554565e-06\n",
      "expression length:\t 5\n",
      "Result stage 20: -1.791*sin(x0) + 24.981*cos(x0) + 1.417*x0_t**2 + 20.142*x0_t*sin(x0) + -12.827*x0_t*cos(x0) + \n",
      "exp([0.1395534]*t)\n",
      "\n",
      "\n",
      "Stage  19\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0008269591339433623\n",
      "Average loss :  5.32032345290645e-06\n",
      "\n",
      "\n",
      "Stage  19\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0008269591339433623\n",
      "Average loss :  1.3436693734547589e-05\n",
      "\n",
      "\n",
      "Stage  19\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0008269591339433623\n",
      "Average loss :  4.708524556917837e-06\n",
      "\n",
      "\n",
      "Stage  19\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0008269591339433623\n",
      "Average loss :  7.349171028181445e-06\n",
      "expression length:\t 5\n",
      "Result stage 21: -1.79*sin(x0) + 24.983*cos(x0) + 1.417*x0_t**2 + 20.136*x0_t*sin(x0) + -12.819*x0_t*cos(x0) + \n",
      "exp([0.13954863]*t)\n",
      "\n",
      "\n",
      "Stage  20\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0008187307530779819\n",
      "Average loss :  9.588400644133799e-06\n",
      "\n",
      "\n",
      "Stage  20\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0008187307530779819\n",
      "Average loss :  8.836929737299215e-06\n",
      "\n",
      "\n",
      "Stage  20\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0008187307530779819\n",
      "Average loss :  4.725126018456649e-06\n",
      "\n",
      "\n",
      "Stage  20\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0008187307530779819\n",
      "Average loss :  6.437247975554783e-06\n",
      "expression length:\t 5\n",
      "Result stage 22: -1.789*sin(x0) + 24.986*cos(x0) + 1.417*x0_t**2 + 20.13*x0_t*sin(x0) + -12.811*x0_t*cos(x0) + \n",
      "exp([0.13971253]*t)\n",
      "\n",
      "\n",
      "Stage  21\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0008105842459701871\n",
      "Average loss :  1.2119618986616842e-05\n",
      "\n",
      "\n",
      "Stage  21\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0008105842459701871\n",
      "Average loss :  8.865297786542214e-06\n",
      "\n",
      "\n",
      "Stage  21\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0008105842459701871\n",
      "Average loss :  9.837189281824976e-06\n",
      "\n",
      "\n",
      "Stage  21\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0008105842459701871\n",
      "Average loss :  4.904441084363498e-06\n",
      "expression length:\t 5\n",
      "Result stage 23: -1.788*sin(x0) + 24.987*cos(x0) + 1.417*x0_t**2 + 20.124*x0_t*sin(x0) + -12.803*x0_t*cos(x0) + \n",
      "exp([0.1397883]*t)\n",
      "\n",
      "\n",
      "Stage  22\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0008025187979624785\n",
      "Average loss :  4.146592345932731e-06\n",
      "\n",
      "\n",
      "Stage  22\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0008025187979624785\n",
      "Average loss :  4.438048563315533e-06\n",
      "\n",
      "\n",
      "Stage  22\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0008025187979624785\n",
      "Average loss :  4.394987627165392e-06\n",
      "\n",
      "\n",
      "Stage  22\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0008025187979624785\n",
      "Average loss :  6.6094021349272225e-06\n",
      "expression length:\t 5\n",
      "Result stage 24: -1.786*sin(x0) + 24.989*cos(x0) + 1.417*x0_t**2 + 20.118*x0_t*sin(x0) + -12.796*x0_t*cos(x0) + \n",
      "exp([0.13971302]*t)\n",
      "\n",
      "\n",
      "Stage  23\n",
      "Epoch 50/200\n",
      "Learning rate :  0.000794533602503334\n",
      "Average loss :  4.856525720242644e-06\n",
      "\n",
      "\n",
      "Stage  23\n",
      "Epoch 100/200\n",
      "Learning rate :  0.000794533602503334\n",
      "Average loss :  4.341723524703411e-06\n",
      "\n",
      "\n",
      "Stage  23\n",
      "Epoch 150/200\n",
      "Learning rate :  0.000794533602503334\n",
      "Average loss :  8.132102266245056e-06\n",
      "\n",
      "\n",
      "Stage  23\n",
      "Epoch 200/200\n",
      "Learning rate :  0.000794533602503334\n",
      "Average loss :  4.399470526550431e-06\n",
      "expression length:\t 5\n",
      "Result stage 25: -1.787*sin(x0) + 24.991*cos(x0) + 1.417*x0_t**2 + 20.112*x0_t*sin(x0) + -12.787*x0_t*cos(x0) + \n",
      "exp([0.13961446]*t)\n",
      "\n",
      "\n",
      "Stage  24\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0007866278610665535\n",
      "Average loss :  4.65960738438298e-06\n",
      "\n",
      "\n",
      "Stage  24\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0007866278610665535\n",
      "Average loss :  4.256936790625332e-06\n",
      "\n",
      "\n",
      "Stage  24\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0007866278610665535\n",
      "Average loss :  4.823167273571016e-06\n",
      "\n",
      "\n",
      "Stage  24\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0007866278610665535\n",
      "Average loss :  4.540514510154026e-06\n",
      "expression length:\t 5\n",
      "Result stage 26: -1.785*sin(x0) + 24.993*cos(x0) + 1.417*x0_t**2 + 20.107*x0_t*sin(x0) + -12.78*x0_t*cos(x0) + \n",
      "exp([0.13980556]*t)\n",
      "\n",
      "\n",
      "Stage  25\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0007788007830714049\n",
      "Average loss :  4.170608463027747e-06\n",
      "\n",
      "\n",
      "Stage  25\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0007788007830714049\n",
      "Average loss :  4.91479931952199e-06\n",
      "\n",
      "\n",
      "Stage  25\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0007788007830714049\n",
      "Average loss :  4.593981429934502e-06\n",
      "\n",
      "\n",
      "Stage  25\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0007788007830714049\n",
      "Average loss :  4.1788907765294425e-06\n",
      "expression length:\t 5\n",
      "Result stage 27: -1.785*sin(x0) + 24.994*cos(x0) + 1.417*x0_t**2 + 20.101*x0_t*sin(x0) + -12.773*x0_t*cos(x0) + \n",
      "exp([0.13964252]*t)\n",
      "\n",
      "\n",
      "Stage  26\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0007710515858035663\n",
      "Average loss :  4.4003850234730635e-06\n",
      "\n",
      "\n",
      "Stage  26\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0007710515858035663\n",
      "Average loss :  4.066202109243022e-06\n",
      "\n",
      "\n",
      "Stage  26\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0007710515858035663\n",
      "Average loss :  3.2590887713013217e-06\n",
      "\n",
      "\n",
      "Stage  26\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0007710515858035663\n",
      "Average loss :  2.5629153697082074e-06\n",
      "expression length:\t 5\n",
      "Result stage 28: -1.785*sin(x0) + 24.996*cos(x0) + 1.417*x0_t**2 + 20.096*x0_t*sin(x0) + -12.765*x0_t*cos(x0) + \n",
      "exp([0.14005823]*t)\n",
      "\n",
      "\n",
      "Stage  27\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0007633794943368531\n",
      "Average loss :  4.3858458411705215e-06\n",
      "\n",
      "\n",
      "Stage  27\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0007633794943368531\n",
      "Average loss :  4.071947387274122e-06\n",
      "\n",
      "\n",
      "Stage  27\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0007633794943368531\n",
      "Average loss :  7.55544169805944e-06\n",
      "\n",
      "\n",
      "Stage  27\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0007633794943368531\n",
      "Average loss :  6.9974012149032205e-06\n",
      "expression length:\t 5\n",
      "Result stage 29: -1.782*sin(x0) + 24.998*cos(x0) + 1.417*x0_t**2 + 20.091*x0_t*sin(x0) + -12.76*x0_t*cos(x0) + \n",
      "exp([0.13958856]*t)\n",
      "\n",
      "\n",
      "Stage  28\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0007557837414557255\n",
      "Average loss :  4.1672592487884685e-06\n",
      "\n",
      "\n",
      "Stage  28\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0007557837414557255\n",
      "Average loss :  9.448417586099822e-06\n",
      "\n",
      "\n",
      "Stage  28\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0007557837414557255\n",
      "Average loss :  8.18316220829729e-06\n",
      "\n",
      "\n",
      "Stage  28\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0007557837414557255\n",
      "Average loss :  4.260041350789834e-06\n",
      "expression length:\t 5\n",
      "Result stage 30: -1.781*sin(x0) + 25.0*cos(x0) + 1.417*x0_t**2 + 20.086*x0_t*sin(x0) + -12.753*x0_t*cos(x0) + \n",
      "exp([0.13981599]*t)\n",
      "\n",
      "\n",
      "Stage  29\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0007482635675785653\n",
      "Average loss :  4.323223947721999e-06\n",
      "\n",
      "\n",
      "Stage  29\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0007482635675785653\n",
      "Average loss :  4.41843030785094e-06\n",
      "\n",
      "\n",
      "Stage  29\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0007482635675785653\n",
      "Average loss :  3.819286121142795e-06\n",
      "\n",
      "\n",
      "Stage  29\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0007482635675785653\n",
      "Average loss :  1.1398387869121507e-06\n",
      "expression length:\t 5\n",
      "Result stage 31: -1.784*sin(x0) + 25.001*cos(x0) + 1.418*x0_t**2 + 20.08*x0_t*sin(x0) + -12.743*x0_t*cos(x0) + \n",
      "exp([0.13998415]*t)\n",
      "\n",
      "\n",
      "Stage  30\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0007408182206817179\n",
      "Average loss :  4.248759978509042e-06\n",
      "\n",
      "\n",
      "Stage  30\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0007408182206817179\n",
      "Average loss :  6.598623258469161e-06\n",
      "\n",
      "\n",
      "Stage  30\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0007408182206817179\n",
      "Average loss :  5.755198344559176e-06\n",
      "\n",
      "\n",
      "Stage  30\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0007408182206817179\n",
      "Average loss :  4.233500476402696e-06\n",
      "expression length:\t 5\n",
      "Result stage 32: -1.78*sin(x0) + 25.003*cos(x0) + 1.417*x0_t**2 + 20.076*x0_t*sin(x0) + -12.74*x0_t*cos(x0) + \n",
      "exp([0.13986462]*t)\n",
      "\n",
      "\n",
      "Stage  31\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0007334469562242892\n",
      "Average loss :  3.6854446534562157e-06\n",
      "\n",
      "\n",
      "Stage  31\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0007334469562242892\n",
      "Average loss :  3.726442400875385e-06\n",
      "\n",
      "\n",
      "Stage  31\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0007334469562242892\n",
      "Average loss :  3.6872690998279722e-06\n",
      "\n",
      "\n",
      "Stage  31\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0007334469562242892\n",
      "Average loss :  4.118175183975836e-06\n",
      "expression length:\t 5\n",
      "Result stage 33: -1.779*sin(x0) + 25.005*cos(x0) + 1.417*x0_t**2 + 20.071*x0_t*sin(x0) + -12.734*x0_t*cos(x0) + \n",
      "exp([0.13971162]*t)\n",
      "\n",
      "\n",
      "Stage  32\n",
      "Epoch 50/200\n",
      "Learning rate :  0.000726149037073691\n",
      "Average loss :  6.066715286578983e-06\n",
      "\n",
      "\n",
      "Stage  32\n",
      "Epoch 100/200\n",
      "Learning rate :  0.000726149037073691\n",
      "Average loss :  3.61479533239617e-06\n",
      "\n",
      "\n",
      "Stage  32\n",
      "Epoch 150/200\n",
      "Learning rate :  0.000726149037073691\n",
      "Average loss :  7.137172815419035e-06\n",
      "\n",
      "\n",
      "Stage  32\n",
      "Epoch 200/200\n",
      "Learning rate :  0.000726149037073691\n",
      "Average loss :  5.8435011851543095e-06\n",
      "expression length:\t 5\n",
      "Result stage 34: -1.778*sin(x0) + 25.006*cos(x0) + 1.418*x0_t**2 + 20.066*x0_t*sin(x0) + -12.728*x0_t*cos(x0) + \n",
      "exp([0.13960183]*t)\n",
      "\n",
      "\n",
      "Stage  33\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0007189237334319262\n",
      "Average loss :  7.55054270484834e-06\n",
      "\n",
      "\n",
      "Stage  33\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0007189237334319262\n",
      "Average loss :  3.8624384615104645e-06\n",
      "\n",
      "\n",
      "Stage  33\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0007189237334319262\n",
      "Average loss :  3.7573529425571905e-06\n",
      "\n",
      "\n",
      "Stage  33\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0007189237334319262\n",
      "Average loss :  5.950605554971844e-06\n",
      "expression length:\t 5\n",
      "Result stage 35: -1.777*sin(x0) + 25.008*cos(x0) + 1.418*x0_t**2 + 20.061*x0_t*sin(x0) + -12.722*x0_t*cos(x0) + \n",
      "exp([0.13961574]*t)\n",
      "\n",
      "\n",
      "Stage  34\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0007117703227626096\n",
      "Average loss :  7.338804607570637e-06\n",
      "\n",
      "\n",
      "Stage  34\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0007117703227626096\n",
      "Average loss :  3.465621830400778e-06\n",
      "\n",
      "\n",
      "Stage  34\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0007117703227626096\n",
      "Average loss :  3.878813458868535e-06\n",
      "\n",
      "\n",
      "Stage  34\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0007117703227626096\n",
      "Average loss :  3.476228357612854e-06\n",
      "expression length:\t 5\n",
      "Result stage 36: -1.777*sin(x0) + 25.009*cos(x0) + 1.418*x0_t**2 + 20.057*x0_t*sin(x0) + -12.715*x0_t*cos(x0) + \n",
      "exp([0.13966]*t)\n",
      "\n",
      "\n",
      "Stage  35\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0007046880897187134\n",
      "Average loss :  3.4711679290921893e-06\n",
      "\n",
      "\n",
      "Stage  35\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0007046880897187134\n",
      "Average loss :  4.765318408317398e-06\n",
      "\n",
      "\n",
      "Stage  35\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0007046880897187134\n",
      "Average loss :  5.133216291142162e-06\n",
      "\n",
      "\n",
      "Stage  35\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0007046880897187134\n",
      "Average loss :  3.842575551971095e-06\n",
      "expression length:\t 5\n",
      "Result stage 37: -1.776*sin(x0) + 25.011*cos(x0) + 1.418*x0_t**2 + 20.052*x0_t*sin(x0) + -12.71*x0_t*cos(x0) + \n",
      "exp([0.13972051]*t)\n",
      "\n",
      "\n",
      "Stage  36\n",
      "Epoch 50/200\n",
      "Learning rate :  0.000697676326071031\n",
      "Average loss :  4.859088221564889e-06\n",
      "\n",
      "\n",
      "Stage  36\n",
      "Epoch 100/200\n",
      "Learning rate :  0.000697676326071031\n",
      "Average loss :  5.31410569237778e-06\n",
      "\n",
      "\n",
      "Stage  36\n",
      "Epoch 150/200\n",
      "Learning rate :  0.000697676326071031\n",
      "Average loss :  3.7086454085510923e-06\n",
      "\n",
      "\n",
      "Stage  36\n",
      "Epoch 200/200\n",
      "Learning rate :  0.000697676326071031\n",
      "Average loss :  3.7526199321291642e-06\n",
      "expression length:\t 5\n",
      "Result stage 38: -1.775*sin(x0) + 25.012*cos(x0) + 1.417*x0_t**2 + 20.048*x0_t*sin(x0) + -12.704*x0_t*cos(x0) + \n",
      "exp([0.13988131]*t)\n",
      "\n",
      "\n",
      "Stage  37\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0006907343306373547\n",
      "Average loss :  3.3085157156165224e-06\n",
      "\n",
      "\n",
      "Stage  37\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0006907343306373547\n",
      "Average loss :  3.60639751306735e-06\n",
      "\n",
      "\n",
      "Stage  37\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0006907343306373547\n",
      "Average loss :  3.667657892947318e-06\n",
      "\n",
      "\n",
      "Stage  37\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0006907343306373547\n",
      "Average loss :  1.8371318901699851e-06\n",
      "expression length:\t 5\n",
      "Result stage 39: -1.776*sin(x0) + 25.013*cos(x0) + 1.418*x0_t**2 + 20.044*x0_t*sin(x0) + -12.698*x0_t*cos(x0) + \n",
      "exp([0.13998398]*t)\n",
      "\n",
      "\n",
      "Stage  38\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0006838614092123559\n",
      "Average loss :  3.5970292628917377e-06\n",
      "\n",
      "\n",
      "Stage  38\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0006838614092123559\n",
      "Average loss :  3.1690240120951785e-06\n",
      "\n",
      "\n",
      "Stage  38\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0006838614092123559\n",
      "Average loss :  3.234813220842625e-06\n",
      "\n",
      "\n",
      "Stage  38\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0006838614092123559\n",
      "Average loss :  3.1974677767721005e-06\n",
      "expression length:\t 5\n",
      "Result stage 40: -1.774*sin(x0) + 25.014*cos(x0) + 1.418*x0_t**2 + 20.039*x0_t*sin(x0) + -12.693*x0_t*cos(x0) + \n",
      "exp([0.1396633]*t)\n",
      "\n",
      "\n",
      "Stage  39\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0006770568744981646\n",
      "Average loss :  3.5041839510085993e-06\n",
      "\n",
      "\n",
      "Stage  39\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0006770568744981646\n",
      "Average loss :  3.2233631372946547e-06\n",
      "\n",
      "\n",
      "Stage  39\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0006770568744981646\n",
      "Average loss :  5.134842012921581e-06\n",
      "\n",
      "\n",
      "Stage  39\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0006770568744981646\n",
      "Average loss :  3.6907806588715175e-06\n",
      "expression length:\t 5\n",
      "Result stage 41: -1.773*sin(x0) + 25.016*cos(x0) + 1.418*x0_t**2 + 20.035*x0_t*sin(x0) + -12.689*x0_t*cos(x0) + \n",
      "exp([0.13973282]*t)\n",
      "\n",
      "\n",
      "Stage  40\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0006703200460356394\n",
      "Average loss :  3.3793576221796684e-06\n",
      "\n",
      "\n",
      "Stage  40\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0006703200460356394\n",
      "Average loss :  3.457341108514811e-06\n",
      "\n",
      "\n",
      "Stage  40\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0006703200460356394\n",
      "Average loss :  3.031118694707402e-06\n",
      "\n",
      "\n",
      "Stage  40\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0006703200460356394\n",
      "Average loss :  3.0669029911223333e-06\n",
      "expression length:\t 5\n",
      "Result stage 42: -1.773*sin(x0) + 25.017*cos(x0) + 1.418*x0_t**2 + 20.031*x0_t*sin(x0) + -12.683*x0_t*cos(x0) + \n",
      "exp([0.13966854]*t)\n",
      "\n",
      "\n",
      "Stage  41\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0006636502501363194\n",
      "Average loss :  3.394903160369722e-06\n",
      "\n",
      "\n",
      "Stage  41\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0006636502501363194\n",
      "Average loss :  3.18679212796269e-06\n",
      "\n",
      "\n",
      "Stage  41\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0006636502501363194\n",
      "Average loss :  8.482160410494544e-06\n",
      "\n",
      "\n",
      "Stage  41\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0006636502501363194\n",
      "Average loss :  2.973567234221264e-06\n",
      "expression length:\t 5\n",
      "Result stage 43: -1.772*sin(x0) + 25.019*cos(x0) + 1.418*x0_t**2 + 20.027*x0_t*sin(x0) + -12.678*x0_t*cos(x0) + \n",
      "exp([0.13967703]*t)\n",
      "\n",
      "\n",
      "Stage  42\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0006570468198150568\n",
      "Average loss :  3.7217150747892447e-06\n",
      "\n",
      "\n",
      "Stage  42\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0006570468198150568\n",
      "Average loss :  3.1496585961576784e-06\n",
      "\n",
      "\n",
      "Stage  42\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0006570468198150568\n",
      "Average loss :  3.186591129633598e-06\n",
      "\n",
      "\n",
      "Stage  42\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0006570468198150568\n",
      "Average loss :  3.3209805678779958e-06\n",
      "expression length:\t 5\n",
      "Result stage 44: -1.771*sin(x0) + 25.02*cos(x0) + 1.418*x0_t**2 + 20.024*x0_t*sin(x0) + -12.673*x0_t*cos(x0) + \n",
      "exp([0.13988908]*t)\n",
      "\n",
      "\n",
      "Stage  43\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0006505090947233165\n",
      "Average loss :  3.2536156595597276e-06\n",
      "\n",
      "\n",
      "Stage  43\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0006505090947233165\n",
      "Average loss :  3.2313666906702565e-06\n",
      "\n",
      "\n",
      "Stage  43\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0006505090947233165\n",
      "Average loss :  6.169585503812414e-06\n",
      "\n",
      "\n",
      "Stage  43\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0006505090947233165\n",
      "Average loss :  7.938672752061393e-06\n",
      "expression length:\t 5\n",
      "Result stage 45: -1.769*sin(x0) + 25.021*cos(x0) + 1.418*x0_t**2 + 20.02*x0_t*sin(x0) + -12.669*x0_t*cos(x0) + \n",
      "exp([0.13980755]*t)\n",
      "\n",
      "\n",
      "Stage  44\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0006440364210831414\n",
      "Average loss :  3.1894189760350855e-06\n",
      "\n",
      "\n",
      "Stage  44\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0006440364210831414\n",
      "Average loss :  3.1737070003146073e-06\n",
      "\n",
      "\n",
      "Stage  44\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0006440364210831414\n",
      "Average loss :  3.115044364676578e-06\n",
      "\n",
      "\n",
      "Stage  44\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0006440364210831414\n",
      "Average loss :  3.193203610862838e-06\n",
      "expression length:\t 5\n",
      "Result stage 46: -1.77*sin(x0) + 25.023*cos(x0) + 1.418*x0_t**2 + 20.016*x0_t*sin(x0) + -12.663*x0_t*cos(x0) + \n",
      "exp([0.13989043]*t)\n",
      "\n",
      "\n",
      "Stage  45\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0006376281516217733\n",
      "Average loss :  3.125377588730771e-06\n",
      "\n",
      "\n",
      "Stage  45\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0006376281516217733\n",
      "Average loss :  3.599637466322747e-06\n",
      "\n",
      "\n",
      "Stage  45\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0006376281516217733\n",
      "Average loss :  3.2710120194678893e-06\n",
      "\n",
      "\n",
      "Stage  45\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0006376281516217733\n",
      "Average loss :  2.8153813218523283e-06\n",
      "expression length:\t 5\n",
      "Result stage 47: -1.769*sin(x0) + 25.024*cos(x0) + 1.418*x0_t**2 + 20.012*x0_t*sin(x0) + -12.658*x0_t*cos(x0) + \n",
      "exp([0.13970207]*t)\n",
      "\n",
      "\n",
      "Stage  46\n",
      "Epoch 50/200\n",
      "Learning rate :  0.000631283645506926\n",
      "Average loss :  3.7441484437295003e-06\n",
      "\n",
      "\n",
      "Stage  46\n",
      "Epoch 100/200\n",
      "Learning rate :  0.000631283645506926\n",
      "Average loss :  4.476800768316025e-06\n",
      "\n",
      "\n",
      "Stage  46\n",
      "Epoch 150/200\n",
      "Learning rate :  0.000631283645506926\n",
      "Average loss :  5.816223165311385e-06\n",
      "\n",
      "\n",
      "Stage  46\n",
      "Epoch 200/200\n",
      "Learning rate :  0.000631283645506926\n",
      "Average loss :  5.36232164449757e-06\n",
      "expression length:\t 5\n",
      "Result stage 48: -1.767*sin(x0) + 25.025*cos(x0) + 1.418*x0_t**2 + 20.009*x0_t*sin(x0) + -12.655*x0_t*cos(x0) + \n",
      "exp([0.13969022]*t)\n",
      "\n",
      "\n",
      "Stage  47\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0006250022682827008\n",
      "Average loss :  2.6578047709335806e-06\n",
      "\n",
      "\n",
      "Stage  47\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0006250022682827008\n",
      "Average loss :  4.44969191448763e-06\n",
      "\n",
      "\n",
      "Stage  47\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0006250022682827008\n",
      "Average loss :  2.940814511021017e-06\n",
      "\n",
      "\n",
      "Stage  47\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0006250022682827008\n",
      "Average loss :  2.6658703973225784e-06\n",
      "expression length:\t 5\n",
      "Result stage 49: -1.768*sin(x0) + 25.026*cos(x0) + 1.418*x0_t**2 + 20.005*x0_t*sin(x0) + -12.649*x0_t*cos(x0) + \n",
      "exp([0.13970456]*t)\n",
      "\n",
      "\n",
      "Stage  48\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0006187833918061408\n",
      "Average loss :  2.8463505259423982e-06\n",
      "\n",
      "\n",
      "Stage  48\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0006187833918061408\n",
      "Average loss :  3.862886842398439e-06\n",
      "\n",
      "\n",
      "Stage  48\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0006187833918061408\n",
      "Average loss :  2.0892350676149363e-06\n",
      "\n",
      "\n",
      "Stage  48\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0006187833918061408\n",
      "Average loss :  5.070257429906633e-06\n",
      "expression length:\t 5\n",
      "Result stage 50: -1.766*sin(x0) + 25.027*cos(x0) + 1.418*x0_t**2 + 20.002*x0_t*sin(x0) + -12.646*x0_t*cos(x0) + \n",
      "exp([0.13970202]*t)\n",
      "\n",
      "\n",
      "Stage  49\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0006126263941844161\n",
      "Average loss :  3.416008439671714e-06\n",
      "\n",
      "\n",
      "Stage  49\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0006126263941844161\n",
      "Average loss :  2.701833864193759e-06\n",
      "\n",
      "\n",
      "Stage  49\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0006126263941844161\n",
      "Average loss :  4.286530838726321e-06\n",
      "\n",
      "\n",
      "Stage  49\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0006126263941844161\n",
      "Average loss :  5.399653218773892e-06\n",
      "expression length:\t 5\n",
      "Result stage 51: -1.766*sin(x0) + 25.028*cos(x0) + 1.418*x0_t**2 + 19.998*x0_t*sin(x0) + -12.641*x0_t*cos(x0) + \n",
      "exp([0.13971992]*t)\n",
      "\n",
      "\n",
      "Stage  50\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0006065306597126335\n",
      "Average loss :  4.417513537191553e-06\n",
      "\n",
      "\n",
      "Stage  50\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0006065306597126335\n",
      "Average loss :  3.800290414801566e-06\n",
      "\n",
      "\n",
      "Stage  50\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0006065306597126335\n",
      "Average loss :  3.4422414501023013e-06\n",
      "\n",
      "\n",
      "Stage  50\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0006065306597126335\n",
      "Average loss :  4.2468650462978985e-06\n",
      "expression length:\t 5\n",
      "Result stage 52: -1.766*sin(x0) + 25.029*cos(x0) + 1.418*x0_t**2 + 19.995*x0_t*sin(x0) + -12.637*x0_t*cos(x0) + \n",
      "exp([0.13967045]*t)\n",
      "\n",
      "\n",
      "Stage  51\n",
      "Epoch 50/200\n",
      "Learning rate :  0.000600495578812266\n",
      "Average loss :  2.8830834253312787e-06\n",
      "\n",
      "\n",
      "Stage  51\n",
      "Epoch 100/200\n",
      "Learning rate :  0.000600495578812266\n",
      "Average loss :  5.395092557591852e-06\n",
      "\n",
      "\n",
      "Stage  51\n",
      "Epoch 150/200\n",
      "Learning rate :  0.000600495578812266\n",
      "Average loss :  2.747242206169176e-06\n",
      "\n",
      "\n",
      "Stage  51\n",
      "Epoch 200/200\n",
      "Learning rate :  0.000600495578812266\n",
      "Average loss :  2.6637483188096667e-06\n",
      "expression length:\t 5\n",
      "Result stage 53: -1.767*sin(x0) + 25.03*cos(x0) + 1.418*x0_t**2 + 19.992*x0_t*sin(x0) + -12.631*x0_t*cos(x0) + \n",
      "exp([0.13998257]*t)\n",
      "\n",
      "\n",
      "Stage  52\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005945205479701944\n",
      "Average loss :  2.369706180616049e-06\n",
      "\n",
      "\n",
      "Stage  52\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005945205479701944\n",
      "Average loss :  2.857187837435049e-06\n",
      "\n",
      "\n",
      "Stage  52\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005945205479701944\n",
      "Average loss :  3.139922455375199e-06\n",
      "\n",
      "\n",
      "Stage  52\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005945205479701944\n",
      "Average loss :  2.5547567474859534e-06\n",
      "expression length:\t 5\n",
      "Result stage 54: -1.765*sin(x0) + 25.031*cos(x0) + 1.418*x0_t**2 + 19.989*x0_t*sin(x0) + -12.628*x0_t*cos(x0) + \n",
      "exp([0.13982971]*t)\n",
      "\n",
      "\n",
      "Stage  53\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005886049696783552\n",
      "Average loss :  2.357477569603361e-06\n",
      "\n",
      "\n",
      "Stage  53\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005886049696783552\n",
      "Average loss :  2.3547117962152697e-06\n",
      "\n",
      "\n",
      "Stage  53\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005886049696783552\n",
      "Average loss :  5.480082108988427e-06\n",
      "\n",
      "\n",
      "Stage  53\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005886049696783552\n",
      "Average loss :  4.615786110662157e-06\n",
      "expression length:\t 5\n",
      "Result stage 55: -1.764*sin(x0) + 25.032*cos(x0) + 1.418*x0_t**2 + 19.986*x0_t*sin(x0) + -12.624*x0_t*cos(x0) + \n",
      "exp([0.13970926]*t)\n",
      "\n",
      "\n",
      "Stage  54\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005827482523739897\n",
      "Average loss :  6.618940915359417e-06\n",
      "\n",
      "\n",
      "Stage  54\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005827482523739897\n",
      "Average loss :  2.3244133444677573e-06\n",
      "\n",
      "\n",
      "Stage  54\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005827482523739897\n",
      "Average loss :  2.510202875782852e-06\n",
      "\n",
      "\n",
      "Stage  54\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005827482523739897\n",
      "Average loss :  3.721487473740126e-06\n",
      "expression length:\t 5\n",
      "Result stage 56: -1.763*sin(x0) + 25.034*cos(x0) + 1.418*x0_t**2 + 19.983*x0_t*sin(x0) + -12.621*x0_t*cos(x0) + \n",
      "exp([0.13978346]*t)\n",
      "\n",
      "\n",
      "Stage  55\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005769498103804867\n",
      "Average loss :  4.010408702015411e-06\n",
      "\n",
      "\n",
      "Stage  55\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005769498103804867\n",
      "Average loss :  2.69932843366405e-06\n",
      "\n",
      "\n",
      "Stage  55\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005769498103804867\n",
      "Average loss :  2.413683660051902e-06\n",
      "\n",
      "\n",
      "Stage  55\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005769498103804867\n",
      "Average loss :  2.9340658329601865e-06\n",
      "expression length:\t 5\n",
      "Result stage 57: -1.763*sin(x0) + 25.034*cos(x0) + 1.418*x0_t**2 + 19.98*x0_t*sin(x0) + -12.616*x0_t*cos(x0) + \n",
      "exp([0.13972397]*t)\n",
      "\n",
      "\n",
      "Stage  56\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005712090638488148\n",
      "Average loss :  2.8657955226663034e-06\n",
      "\n",
      "\n",
      "Stage  56\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005712090638488148\n",
      "Average loss :  4.328178420109907e-06\n",
      "\n",
      "\n",
      "Stage  56\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005712090638488148\n",
      "Average loss :  4.754292604047805e-06\n",
      "\n",
      "\n",
      "Stage  56\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005712090638488148\n",
      "Average loss :  3.836869836959522e-06\n",
      "expression length:\t 5\n",
      "Result stage 58: -1.762*sin(x0) + 25.036*cos(x0) + 1.418*x0_t**2 + 19.977*x0_t*sin(x0) + -12.613*x0_t*cos(x0) + \n",
      "exp([0.13977107]*t)\n",
      "\n",
      "\n",
      "Stage  57\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005655254386995371\n",
      "Average loss :  2.189039832956041e-06\n",
      "\n",
      "\n",
      "Stage  57\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005655254386995371\n",
      "Average loss :  2.3234829313878436e-06\n",
      "\n",
      "\n",
      "Stage  57\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005655254386995371\n",
      "Average loss :  6.560054316651076e-06\n",
      "\n",
      "\n",
      "Stage  57\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005655254386995371\n",
      "Average loss :  2.3743934889353113e-06\n",
      "expression length:\t 5\n",
      "Result stage 59: -1.762*sin(x0) + 25.036*cos(x0) + 1.418*x0_t**2 + 19.974*x0_t*sin(x0) + -12.608*x0_t*cos(x0) + \n",
      "exp([0.13986365]*t)\n",
      "\n",
      "\n",
      "Stage  58\n",
      "Epoch 50/200\n",
      "Learning rate :  0.000559898366565402\n",
      "Average loss :  2.360420467084623e-06\n",
      "\n",
      "\n",
      "Stage  58\n",
      "Epoch 100/200\n",
      "Learning rate :  0.000559898366565402\n",
      "Average loss :  2.352489218537812e-06\n",
      "\n",
      "\n",
      "Stage  58\n",
      "Epoch 150/200\n",
      "Learning rate :  0.000559898366565402\n",
      "Average loss :  2.4763312467257492e-06\n",
      "\n",
      "\n",
      "Stage  58\n",
      "Epoch 200/200\n",
      "Learning rate :  0.000559898366565402\n",
      "Average loss :  2.7955661607848015e-06\n",
      "expression length:\t 5\n",
      "Result stage 60: -1.762*sin(x0) + 25.037*cos(x0) + 1.419*x0_t**2 + 19.97*x0_t*sin(x0) + -12.605*x0_t*cos(x0) + \n",
      "exp([0.13972868]*t)\n",
      "\n",
      "\n",
      "Stage  59\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005543272847345071\n",
      "Average loss :  2.332157919227029e-06\n",
      "\n",
      "\n",
      "Stage  59\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005543272847345071\n",
      "Average loss :  4.02313025915646e-06\n",
      "\n",
      "\n",
      "Stage  59\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005543272847345071\n",
      "Average loss :  2.087752363877371e-06\n",
      "\n",
      "\n",
      "Stage  59\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005543272847345071\n",
      "Average loss :  3.895147983712377e-06\n",
      "expression length:\t 5\n",
      "Result stage 61: -1.761*sin(x0) + 25.038*cos(x0) + 1.419*x0_t**2 + 19.968*x0_t*sin(x0) + -12.601*x0_t*cos(x0) + \n",
      "exp([0.13971695]*t)\n",
      "\n",
      "\n",
      "Stage  60\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005488116360940264\n",
      "Average loss :  4.2000347093562596e-06\n",
      "\n",
      "\n",
      "Stage  60\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005488116360940264\n",
      "Average loss :  1.645239194658643e-06\n",
      "\n",
      "\n",
      "Stage  60\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005488116360940264\n",
      "Average loss :  2.4847608983691316e-06\n",
      "\n",
      "\n",
      "Stage  60\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005488116360940264\n",
      "Average loss :  2.3017798866931116e-06\n",
      "expression length:\t 5\n",
      "Result stage 62: -1.761*sin(x0) + 25.039*cos(x0) + 1.418*x0_t**2 + 19.965*x0_t*sin(x0) + -12.597*x0_t*cos(x0) + \n",
      "exp([0.13990851]*t)\n",
      "\n",
      "\n",
      "Stage  61\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005433508690744998\n",
      "Average loss :  3.494325255815056e-06\n",
      "\n",
      "\n",
      "Stage  61\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005433508690744998\n",
      "Average loss :  2.2674530555377714e-06\n",
      "\n",
      "\n",
      "Stage  61\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005433508690744998\n",
      "Average loss :  1.9889748728019185e-06\n",
      "\n",
      "\n",
      "Stage  61\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005433508690744998\n",
      "Average loss :  1.5889273754510214e-06\n",
      "expression length:\t 5\n",
      "Result stage 63: -1.761*sin(x0) + 25.04*cos(x0) + 1.419*x0_t**2 + 19.962*x0_t*sin(x0) + -12.593*x0_t*cos(x0) + \n",
      "exp([0.1398553]*t)\n",
      "\n",
      "\n",
      "Stage  62\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005379444375946745\n",
      "Average loss :  2.6579277800919954e-06\n",
      "\n",
      "\n",
      "Stage  62\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005379444375946745\n",
      "Average loss :  2.8442987058951985e-06\n",
      "\n",
      "\n",
      "Stage  62\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005379444375946745\n",
      "Average loss :  1.5517819065280491e-06\n",
      "\n",
      "\n",
      "Stage  62\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005379444375946745\n",
      "Average loss :  5.299543772707693e-06\n",
      "expression length:\t 5\n",
      "Result stage 64: -1.759*sin(x0) + 25.041*cos(x0) + 1.418*x0_t**2 + 19.96*x0_t*sin(x0) + -12.591*x0_t*cos(x0) + \n",
      "exp([0.13985206]*t)\n",
      "\n",
      "\n",
      "Stage  63\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005325918010068972\n",
      "Average loss :  2.0447639599296963e-06\n",
      "\n",
      "\n",
      "Stage  63\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005325918010068972\n",
      "Average loss :  1.55125394485367e-06\n",
      "\n",
      "\n",
      "Stage  63\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005325918010068972\n",
      "Average loss :  1.9597969185269903e-06\n",
      "\n",
      "\n",
      "Stage  63\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005325918010068972\n",
      "Average loss :  1.9482649804558605e-06\n",
      "expression length:\t 5\n",
      "Result stage 65: -1.76*sin(x0) + 25.041*cos(x0) + 1.419*x0_t**2 + 19.957*x0_t*sin(x0) + -12.587*x0_t*cos(x0) + \n",
      "exp([0.13974895]*t)\n",
      "\n",
      "\n",
      "Stage  64\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005272924240430486\n",
      "Average loss :  1.9068473875449854e-06\n",
      "\n",
      "\n",
      "Stage  64\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005272924240430486\n",
      "Average loss :  3.3681151307973778e-06\n",
      "\n",
      "\n",
      "Stage  64\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005272924240430486\n",
      "Average loss :  1.864555542852031e-06\n",
      "\n",
      "\n",
      "Stage  64\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005272924240430486\n",
      "Average loss :  1.987383257073816e-06\n",
      "expression length:\t 5\n",
      "Result stage 66: -1.759*sin(x0) + 25.042*cos(x0) + 1.419*x0_t**2 + 19.955*x0_t*sin(x0) + -12.584*x0_t*cos(x0) + \n",
      "exp([0.1397833]*t)\n",
      "\n",
      "\n",
      "Stage  65\n",
      "Epoch 50/200\n",
      "Learning rate :  0.000522045776761016\n",
      "Average loss :  5.358178441383643e-06\n",
      "\n",
      "\n",
      "Stage  65\n",
      "Epoch 100/200\n",
      "Learning rate :  0.000522045776761016\n",
      "Average loss :  2.8668960112554487e-06\n",
      "\n",
      "\n",
      "Stage  65\n",
      "Epoch 150/200\n",
      "Learning rate :  0.000522045776761016\n",
      "Average loss :  2.0800746369786793e-06\n",
      "\n",
      "\n",
      "Stage  65\n",
      "Epoch 200/200\n",
      "Learning rate :  0.000522045776761016\n",
      "Average loss :  3.27660654875217e-06\n",
      "expression length:\t 5\n",
      "Result stage 67: -1.758*sin(x0) + 25.043*cos(x0) + 1.419*x0_t**2 + 19.952*x0_t*sin(x0) + -12.581*x0_t*cos(x0) + \n",
      "exp([0.13972646]*t)\n",
      "\n",
      "\n",
      "Stage  66\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005168513344916992\n",
      "Average loss :  3.93584514313261e-06\n",
      "\n",
      "\n",
      "Stage  66\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005168513344916992\n",
      "Average loss :  2.2066392375563737e-06\n",
      "\n",
      "\n",
      "Stage  66\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005168513344916992\n",
      "Average loss :  1.9986518964287825e-06\n",
      "\n",
      "\n",
      "Stage  66\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005168513344916992\n",
      "Average loss :  2.0085378764633788e-06\n",
      "expression length:\t 5\n",
      "Result stage 68: -1.758*sin(x0) + 25.044*cos(x0) + 1.419*x0_t**2 + 19.95*x0_t*sin(x0) + -12.577*x0_t*cos(x0) + \n",
      "exp([0.1397947]*t)\n",
      "\n",
      "\n",
      "Stage  67\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005117085777865425\n",
      "Average loss :  1.7487193417764502e-06\n",
      "\n",
      "\n",
      "Stage  67\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005117085777865425\n",
      "Average loss :  1.8858687553802156e-06\n",
      "\n",
      "\n",
      "Stage  67\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005117085777865425\n",
      "Average loss :  1.944449195434572e-06\n",
      "\n",
      "\n",
      "Stage  67\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005117085777865425\n",
      "Average loss :  2.62527578342997e-06\n",
      "expression length:\t 5\n",
      "Result stage 69: -1.757*sin(x0) + 25.045*cos(x0) + 1.418*x0_t**2 + 19.948*x0_t*sin(x0) + -12.575*x0_t*cos(x0) + \n",
      "exp([0.13982244]*t)\n",
      "\n",
      "\n",
      "Stage  68\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005066169923655895\n",
      "Average loss :  2.828517835951061e-06\n",
      "\n",
      "\n",
      "Stage  68\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005066169923655895\n",
      "Average loss :  3.4660733945202082e-06\n",
      "\n",
      "\n",
      "Stage  68\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005066169923655895\n",
      "Average loss :  2.2242475097300485e-06\n",
      "\n",
      "\n",
      "Stage  68\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005066169923655895\n",
      "Average loss :  1.8834156207958586e-06\n",
      "expression length:\t 5\n",
      "Result stage 70: -1.757*sin(x0) + 25.045*cos(x0) + 1.419*x0_t**2 + 19.945*x0_t*sin(x0) + -12.571*x0_t*cos(x0) + \n",
      "exp([0.13986512]*t)\n",
      "\n",
      "\n",
      "Stage  69\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0005015760690660555\n",
      "Average loss :  1.9463443550193915e-06\n",
      "\n",
      "\n",
      "Stage  69\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0005015760690660555\n",
      "Average loss :  1.8438018969391123e-06\n",
      "\n",
      "\n",
      "Stage  69\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0005015760690660555\n",
      "Average loss :  1.9367041659279494e-06\n",
      "\n",
      "\n",
      "Stage  69\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0005015760690660555\n",
      "Average loss :  1.7233093103641295e-06\n",
      "expression length:\t 5\n",
      "Result stage 71: -1.757*sin(x0) + 25.046*cos(x0) + 1.419*x0_t**2 + 19.943*x0_t*sin(x0) + -12.568*x0_t*cos(x0) + \n",
      "exp([0.13978295]*t)\n",
      "\n",
      "\n",
      "Stage  70\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0004965853037914095\n",
      "Average loss :  3.0083924684731755e-06\n",
      "\n",
      "\n",
      "Stage  70\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0004965853037914095\n",
      "Average loss :  1.6981049384412472e-06\n",
      "\n",
      "\n",
      "Stage  70\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0004965853037914095\n",
      "Average loss :  1.7554472151459777e-06\n",
      "\n",
      "\n",
      "Stage  70\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0004965853037914095\n",
      "Average loss :  1.799944698177569e-06\n",
      "expression length:\t 5\n",
      "Result stage 72: -1.757*sin(x0) + 25.047*cos(x0) + 1.419*x0_t**2 + 19.941*x0_t*sin(x0) + -12.566*x0_t*cos(x0) + \n",
      "exp([0.13987154]*t)\n",
      "\n",
      "\n",
      "Stage  71\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0004916441974609651\n",
      "Average loss :  1.748006411617098e-06\n",
      "\n",
      "\n",
      "Stage  71\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0004916441974609651\n",
      "Average loss :  1.6386413790314691e-06\n",
      "\n",
      "\n",
      "Stage  71\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0004916441974609651\n",
      "Average loss :  1.7603142623556778e-06\n",
      "\n",
      "\n",
      "Stage  71\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0004916441974609651\n",
      "Average loss :  1.6029481457735528e-06\n",
      "expression length:\t 5\n",
      "Result stage 73: -1.757*sin(x0) + 25.047*cos(x0) + 1.419*x0_t**2 + 19.939*x0_t*sin(x0) + -12.562*x0_t*cos(x0) + \n",
      "exp([0.1397746]*t)\n",
      "\n",
      "\n",
      "Stage  72\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0004867522559599717\n",
      "Average loss :  3.4238933039887343e-06\n",
      "\n",
      "\n",
      "Stage  72\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0004867522559599717\n",
      "Average loss :  1.7042970057445928e-06\n",
      "\n",
      "\n",
      "Stage  72\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0004867522559599717\n",
      "Average loss :  1.580973844284017e-06\n",
      "\n",
      "\n",
      "Stage  72\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0004867522559599717\n",
      "Average loss :  1.7260184677070356e-06\n",
      "expression length:\t 5\n",
      "Result stage 74: -1.756*sin(x0) + 25.048*cos(x0) + 1.419*x0_t**2 + 19.937*x0_t*sin(x0) + -12.56*x0_t*cos(x0) + \n",
      "exp([0.13989003]*t)\n",
      "\n",
      "\n",
      "Stage  73\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00048190899009020245\n",
      "Average loss :  1.7328519561488065e-06\n",
      "\n",
      "\n",
      "Stage  73\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00048190899009020245\n",
      "Average loss :  2.866118393285433e-06\n",
      "\n",
      "\n",
      "Stage  73\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00048190899009020245\n",
      "Average loss :  1.7903366824612021e-06\n",
      "\n",
      "\n",
      "Stage  73\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00048190899009020245\n",
      "Average loss :  1.2734670917780022e-06\n",
      "expression length:\t 5\n",
      "Result stage 75: -1.756*sin(x0) + 25.049*cos(x0) + 1.419*x0_t**2 + 19.934*x0_t*sin(x0) + -12.556*x0_t*cos(x0) + \n",
      "exp([0.13986424]*t)\n",
      "\n",
      "\n",
      "Stage  74\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0004771139155210344\n",
      "Average loss :  1.8912071482191095e-06\n",
      "\n",
      "\n",
      "Stage  74\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0004771139155210344\n",
      "Average loss :  3.906433903466677e-06\n",
      "\n",
      "\n",
      "Stage  74\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0004771139155210344\n",
      "Average loss :  2.6572008664516034e-06\n",
      "\n",
      "\n",
      "Stage  74\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0004771139155210344\n",
      "Average loss :  2.1042872049292782e-06\n",
      "expression length:\t 5\n",
      "Result stage 76: -1.755*sin(x0) + 25.05*cos(x0) + 1.419*x0_t**2 + 19.933*x0_t*sin(x0) + -12.555*x0_t*cos(x0) + \n",
      "exp([0.13983755]*t)\n",
      "\n",
      "\n",
      "Stage  75\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0004723665527410147\n",
      "Average loss :  1.4474069303105352e-06\n",
      "\n",
      "\n",
      "Stage  75\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0004723665527410147\n",
      "Average loss :  1.515354369985289e-06\n",
      "\n",
      "\n",
      "Stage  75\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0004723665527410147\n",
      "Average loss :  1.6425627791250008e-06\n",
      "\n",
      "\n",
      "Stage  75\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0004723665527410147\n",
      "Average loss :  1.5173078509178595e-06\n",
      "expression length:\t 5\n",
      "Result stage 77: -1.755*sin(x0) + 25.05*cos(x0) + 1.419*x0_t**2 + 19.93*x0_t*sin(x0) + -12.552*x0_t*cos(x0) + \n",
      "exp([0.13977657]*t)\n",
      "\n",
      "\n",
      "Stage  76\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00046766642700990925\n",
      "Average loss :  1.4807593515797635e-06\n",
      "\n",
      "\n",
      "Stage  76\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00046766642700990925\n",
      "Average loss :  1.4643560461991e-06\n",
      "\n",
      "\n",
      "Stage  76\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00046766642700990925\n",
      "Average loss :  1.4932579688320402e-06\n",
      "\n",
      "\n",
      "Stage  76\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00046766642700990925\n",
      "Average loss :  1.6578258055233164e-06\n",
      "expression length:\t 5\n",
      "Result stage 78: -1.755*sin(x0) + 25.051*cos(x0) + 1.419*x0_t**2 + 19.929*x0_t*sin(x0) + -12.549*x0_t*cos(x0) + \n",
      "exp([0.13984002]*t)\n",
      "\n",
      "\n",
      "Stage  77\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00046301306831122806\n",
      "Average loss :  1.6203408677029074e-06\n",
      "\n",
      "\n",
      "Stage  77\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00046301306831122806\n",
      "Average loss :  1.4678947763968608e-06\n",
      "\n",
      "\n",
      "Stage  77\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00046301306831122806\n",
      "Average loss :  1.4584009022655664e-06\n",
      "\n",
      "\n",
      "Stage  77\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00046301306831122806\n",
      "Average loss :  1.5838433000681107e-06\n",
      "expression length:\t 5\n",
      "Result stage 79: -1.754*sin(x0) + 25.051*cos(x0) + 1.419*x0_t**2 + 19.927*x0_t*sin(x0) + -12.547*x0_t*cos(x0) + \n",
      "exp([0.13984409]*t)\n",
      "\n",
      "\n",
      "Stage  78\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00045840601130522354\n",
      "Average loss :  2.71926319328486e-06\n",
      "\n",
      "\n",
      "Stage  78\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00045840601130522354\n",
      "Average loss :  1.4203498039933038e-06\n",
      "\n",
      "\n",
      "Stage  78\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00045840601130522354\n",
      "Average loss :  1.8438344113747007e-06\n",
      "\n",
      "\n",
      "Stage  78\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00045840601130522354\n",
      "Average loss :  1.8191116168964072e-06\n",
      "expression length:\t 5\n",
      "Result stage 80: -1.754*sin(x0) + 25.052*cos(x0) + 1.419*x0_t**2 + 19.924*x0_t*sin(x0) + -12.545*x0_t*cos(x0) + \n",
      "exp([0.13978508]*t)\n",
      "\n",
      "\n",
      "Stage  79\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0004538447952823558\n",
      "Average loss :  1.5227269614115357e-06\n",
      "\n",
      "\n",
      "Stage  79\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0004538447952823558\n",
      "Average loss :  1.9857091047015274e-06\n",
      "\n",
      "\n",
      "Stage  79\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0004538447952823558\n",
      "Average loss :  2.3306022285396466e-06\n",
      "\n",
      "\n",
      "Stage  79\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0004538447952823558\n",
      "Average loss :  1.9699266431416618e-06\n",
      "expression length:\t 5\n",
      "Result stage 81: -1.754*sin(x0) + 25.053*cos(x0) + 1.419*x0_t**2 + 19.923*x0_t*sin(x0) + -12.542*x0_t*cos(x0) + \n",
      "exp([0.13976762]*t)\n",
      "\n",
      "\n",
      "Stage  80\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0004493289641172216\n",
      "Average loss :  1.531921157038596e-06\n",
      "\n",
      "\n",
      "Stage  80\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0004493289641172216\n",
      "Average loss :  1.3511242968888837e-06\n",
      "\n",
      "\n",
      "Stage  80\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0004493289641172216\n",
      "Average loss :  1.5138812159420922e-06\n",
      "\n",
      "\n",
      "Stage  80\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0004493289641172216\n",
      "Average loss :  1.515727603873529e-06\n",
      "expression length:\t 5\n",
      "Result stage 82: -1.753*sin(x0) + 25.053*cos(x0) + 1.419*x0_t**2 + 19.921*x0_t*sin(x0) + -12.54*x0_t*cos(x0) + \n",
      "exp([0.13990822]*t)\n",
      "\n",
      "\n",
      "Stage  81\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0004448580662229411\n",
      "Average loss :  1.545968643767992e-06\n",
      "\n",
      "\n",
      "Stage  81\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0004448580662229411\n",
      "Average loss :  1.7523774431538186e-06\n",
      "\n",
      "\n",
      "Stage  81\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0004448580662229411\n",
      "Average loss :  1.569186338201689e-06\n",
      "\n",
      "\n",
      "Stage  81\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0004448580662229411\n",
      "Average loss :  2.1577670850092545e-06\n",
      "expression length:\t 5\n",
      "Result stage 83: -1.753*sin(x0) + 25.054*cos(x0) + 1.419*x0_t**2 + 19.919*x0_t*sin(x0) + -12.538*x0_t*cos(x0) + \n",
      "exp([0.13976304]*t)\n",
      "\n",
      "\n",
      "Stage  82\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0004404316545059993\n",
      "Average loss :  1.0990410146405338e-06\n",
      "\n",
      "\n",
      "Stage  82\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0004404316545059993\n",
      "Average loss :  1.4137391417534673e-06\n",
      "\n",
      "\n",
      "Stage  82\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0004404316545059993\n",
      "Average loss :  2.423813839413924e-06\n",
      "\n",
      "\n",
      "Stage  82\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0004404316545059993\n",
      "Average loss :  1.3039942814430105e-06\n",
      "expression length:\t 5\n",
      "Result stage 84: -1.753*sin(x0) + 25.054*cos(x0) + 1.419*x0_t**2 + 19.918*x0_t*sin(x0) + -12.535*x0_t*cos(x0) + \n",
      "exp([0.13980374]*t)\n",
      "\n",
      "\n",
      "Stage  83\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0004360492863215356\n",
      "Average loss :  2.0226823380653514e-06\n",
      "\n",
      "\n",
      "Stage  83\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0004360492863215356\n",
      "Average loss :  1.2671024478549953e-06\n",
      "\n",
      "\n",
      "Stage  83\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0004360492863215356\n",
      "Average loss :  1.428335622222221e-06\n",
      "\n",
      "\n",
      "Stage  83\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0004360492863215356\n",
      "Average loss :  2.050264583886019e-06\n",
      "expression length:\t 5\n",
      "Result stage 85: -1.752*sin(x0) + 25.055*cos(x0) + 1.419*x0_t**2 + 19.916*x0_t*sin(x0) + -12.534*x0_t*cos(x0) + \n",
      "exp([0.13976856]*t)\n",
      "\n",
      "\n",
      "Stage  84\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00043171052342907973\n",
      "Average loss :  1.4847848888166482e-06\n",
      "\n",
      "\n",
      "Stage  84\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00043171052342907973\n",
      "Average loss :  1.570679387441487e-06\n",
      "\n",
      "\n",
      "Stage  84\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00043171052342907973\n",
      "Average loss :  1.3994948631079751e-06\n",
      "\n",
      "\n",
      "Stage  84\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00043171052342907973\n",
      "Average loss :  2.5558927063684678e-06\n",
      "expression length:\t 5\n",
      "Result stage 86: -1.751*sin(x0) + 25.056*cos(x0) + 1.419*x0_t**2 + 19.915*x0_t*sin(x0) + -12.532*x0_t*cos(x0) + \n",
      "exp([0.13977945]*t)\n",
      "\n",
      "\n",
      "Stage  85\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0004274149319487267\n",
      "Average loss :  1.60343529387319e-06\n",
      "\n",
      "\n",
      "Stage  85\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0004274149319487267\n",
      "Average loss :  2.046745066763833e-06\n",
      "\n",
      "\n",
      "Stage  85\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0004274149319487267\n",
      "Average loss :  1.370091013086494e-06\n",
      "\n",
      "\n",
      "Stage  85\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0004274149319487267\n",
      "Average loss :  3.2931338864727877e-06\n",
      "expression length:\t 5\n",
      "Result stage 87: -1.752*sin(x0) + 25.056*cos(x0) + 1.419*x0_t**2 + 19.913*x0_t*sin(x0) + -12.529*x0_t*cos(x0) + \n",
      "exp([0.13987865]*t)\n",
      "\n",
      "\n",
      "Stage  86\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00042316208231774885\n",
      "Average loss :  2.3492702894145623e-06\n",
      "\n",
      "\n",
      "Stage  86\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00042316208231774885\n",
      "Average loss :  1.3551803021982778e-06\n",
      "\n",
      "\n",
      "Stage  86\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00042316208231774885\n",
      "Average loss :  2.5103950065386016e-06\n",
      "\n",
      "\n",
      "Stage  86\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00042316208231774885\n",
      "Average loss :  1.2958923889527796e-06\n",
      "expression length:\t 5\n",
      "Result stage 88: -1.752*sin(x0) + 25.057*cos(x0) + 1.419*x0_t**2 + 19.911*x0_t*sin(x0) + -12.527*x0_t*cos(x0) + \n",
      "exp([0.13990381]*t)\n",
      "\n",
      "\n",
      "Stage  87\n",
      "Epoch 50/200\n",
      "Learning rate :  0.000418951549247639\n",
      "Average loss :  1.200777319354529e-06\n",
      "\n",
      "\n",
      "Stage  87\n",
      "Epoch 100/200\n",
      "Learning rate :  0.000418951549247639\n",
      "Average loss :  1.2993833706786972e-06\n",
      "\n",
      "\n",
      "Stage  87\n",
      "Epoch 150/200\n",
      "Learning rate :  0.000418951549247639\n",
      "Average loss :  1.3284384294820484e-06\n",
      "\n",
      "\n",
      "Stage  87\n",
      "Epoch 200/200\n",
      "Learning rate :  0.000418951549247639\n",
      "Average loss :  1.9507263004925335e-06\n",
      "expression length:\t 5\n",
      "Result stage 89: -1.751*sin(x0) + 25.057*cos(x0) + 1.419*x0_t**2 + 19.91*x0_t*sin(x0) + -12.525*x0_t*cos(x0) + \n",
      "exp([0.13977721]*t)\n",
      "\n",
      "\n",
      "Stage  88\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0004147829116815814\n",
      "Average loss :  1.166370793725946e-06\n",
      "\n",
      "\n",
      "Stage  88\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0004147829116815814\n",
      "Average loss :  1.523459104646463e-06\n",
      "\n",
      "\n",
      "Stage  88\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0004147829116815814\n",
      "Average loss :  1.184200300485827e-06\n",
      "\n",
      "\n",
      "Stage  88\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0004147829116815814\n",
      "Average loss :  1.1741414027710562e-06\n",
      "expression length:\t 5\n",
      "Result stage 90: -1.751*sin(x0) + 25.058*cos(x0) + 1.419*x0_t**2 + 19.908*x0_t*sin(x0) + -12.522*x0_t*cos(x0) + \n",
      "exp([0.13980484]*t)\n",
      "\n",
      "\n",
      "Stage  89\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0004106557527523455\n",
      "Average loss :  1.1207973784621572e-06\n",
      "\n",
      "\n",
      "Stage  89\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0004106557527523455\n",
      "Average loss :  1.3526978364097886e-06\n",
      "\n",
      "\n",
      "Stage  89\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0004106557527523455\n",
      "Average loss :  1.292377305617265e-06\n",
      "\n",
      "\n",
      "Stage  89\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0004106557527523455\n",
      "Average loss :  1.1902106962224934e-06\n",
      "expression length:\t 5\n",
      "Result stage 91: -1.751*sin(x0) + 25.058*cos(x0) + 1.419*x0_t**2 + 19.906*x0_t*sin(x0) + -12.521*x0_t*cos(x0) + \n",
      "exp([0.13983105]*t)\n",
      "\n",
      "\n",
      "Stage  90\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00040656965974059914\n",
      "Average loss :  1.1880870260938536e-06\n",
      "\n",
      "\n",
      "Stage  90\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00040656965974059914\n",
      "Average loss :  1.7481316945122671e-06\n",
      "\n",
      "\n",
      "Stage  90\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00040656965974059914\n",
      "Average loss :  1.2575793562064064e-06\n",
      "\n",
      "\n",
      "Stage  90\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00040656965974059914\n",
      "Average loss :  1.942504468388506e-06\n",
      "expression length:\t 5\n",
      "Result stage 92: -1.75*sin(x0) + 25.059*cos(x0) + 1.419*x0_t**2 + 19.905*x0_t*sin(x0) + -12.519*x0_t*cos(x0) + \n",
      "exp([0.13983586]*t)\n",
      "\n",
      "\n",
      "Stage  91\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00040252422403363596\n",
      "Average loss :  2.012582399402163e-06\n",
      "\n",
      "\n",
      "Stage  91\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00040252422403363596\n",
      "Average loss :  1.1888818107763655e-06\n",
      "\n",
      "\n",
      "Stage  91\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00040252422403363596\n",
      "Average loss :  1.2858041600338765e-06\n",
      "\n",
      "\n",
      "Stage  91\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00040252422403363596\n",
      "Average loss :  2.1816308617417235e-06\n",
      "expression length:\t 5\n",
      "Result stage 93: -1.75*sin(x0) + 25.059*cos(x0) + 1.419*x0_t**2 + 19.904*x0_t*sin(x0) + -12.517*x0_t*cos(x0) + \n",
      "exp([0.13980599]*t)\n",
      "\n",
      "\n",
      "Stage  92\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00039851904108451417\n",
      "Average loss :  1.0722570777943474e-06\n",
      "\n",
      "\n",
      "Stage  92\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00039851904108451417\n",
      "Average loss :  8.565004350202798e-07\n",
      "\n",
      "\n",
      "Stage  92\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00039851904108451417\n",
      "Average loss :  1.3385221109274426e-06\n",
      "\n",
      "\n",
      "Stage  92\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00039851904108451417\n",
      "Average loss :  1.630082579140435e-06\n",
      "expression length:\t 5\n",
      "Result stage 94: -1.75*sin(x0) + 25.06*cos(x0) + 1.419*x0_t**2 + 19.902*x0_t*sin(x0) + -12.515*x0_t*cos(x0) + \n",
      "exp([0.13986292]*t)\n",
      "\n",
      "\n",
      "Stage  93\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0003945537103716011\n",
      "Average loss :  1.0974171118505183e-06\n",
      "\n",
      "\n",
      "Stage  93\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0003945537103716011\n",
      "Average loss :  1.1734748568414943e-06\n",
      "\n",
      "\n",
      "Stage  93\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0003945537103716011\n",
      "Average loss :  1.1166367812620592e-06\n",
      "\n",
      "\n",
      "Stage  93\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0003945537103716011\n",
      "Average loss :  1.0516957900108537e-06\n",
      "expression length:\t 5\n",
      "Result stage 95: -1.75*sin(x0) + 25.06*cos(x0) + 1.419*x0_t**2 + 19.901*x0_t*sin(x0) + -12.513*x0_t*cos(x0) + \n",
      "exp([0.13980813]*t)\n",
      "\n",
      "\n",
      "Stage  94\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00039062783535852107\n",
      "Average loss :  1.0303215276508126e-06\n",
      "\n",
      "\n",
      "Stage  94\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00039062783535852107\n",
      "Average loss :  2.1017942799517186e-06\n",
      "\n",
      "\n",
      "Stage  94\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00039062783535852107\n",
      "Average loss :  1.0711682989494875e-06\n",
      "\n",
      "\n",
      "Stage  94\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00039062783535852107\n",
      "Average loss :  1.0919793567154557e-06\n",
      "expression length:\t 5\n",
      "Result stage 96: -1.75*sin(x0) + 25.061*cos(x0) + 1.419*x0_t**2 + 19.899*x0_t*sin(x0) + -12.511*x0_t*cos(x0) + \n",
      "exp([0.13984253]*t)\n",
      "\n",
      "\n",
      "Stage  95\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00038674102345450116\n",
      "Average loss :  1.0124533673661062e-06\n",
      "\n",
      "\n",
      "Stage  95\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00038674102345450116\n",
      "Average loss :  9.110248697652423e-07\n",
      "\n",
      "\n",
      "Stage  95\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00038674102345450116\n",
      "Average loss :  2.5514548269711668e-06\n",
      "\n",
      "\n",
      "Stage  95\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00038674102345450116\n",
      "Average loss :  1.2663357438214007e-06\n",
      "expression length:\t 5\n",
      "Result stage 97: -1.749*sin(x0) + 25.061*cos(x0) + 1.419*x0_t**2 + 19.898*x0_t*sin(x0) + -12.51*x0_t*cos(x0) + \n",
      "exp([0.13982366]*t)\n",
      "\n",
      "\n",
      "Stage  96\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0003828928859751121\n",
      "Average loss :  1.060630665961071e-06\n",
      "\n",
      "\n",
      "Stage  96\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0003828928859751121\n",
      "Average loss :  1.1145617690999643e-06\n",
      "\n",
      "\n",
      "Stage  96\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0003828928859751121\n",
      "Average loss :  9.964634273273987e-07\n",
      "\n",
      "\n",
      "Stage  96\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0003828928859751121\n",
      "Average loss :  1.517397890893335e-06\n",
      "expression length:\t 5\n",
      "Result stage 98: -1.749*sin(x0) + 25.062*cos(x0) + 1.419*x0_t**2 + 19.897*x0_t*sin(x0) + -12.508*x0_t*cos(x0) + \n",
      "exp([0.13979548]*t)\n",
      "\n",
      "\n",
      "Stage  97\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00037908303810339886\n",
      "Average loss :  9.714585758047178e-07\n",
      "\n",
      "\n",
      "Stage  97\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00037908303810339886\n",
      "Average loss :  1.2780138831658405e-06\n",
      "\n",
      "\n",
      "Stage  97\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00037908303810339886\n",
      "Average loss :  1.1271744142504758e-06\n",
      "\n",
      "\n",
      "Stage  97\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00037908303810339886\n",
      "Average loss :  1.3721510185860097e-06\n",
      "expression length:\t 5\n",
      "Result stage 99: -1.749*sin(x0) + 25.062*cos(x0) + 1.419*x0_t**2 + 19.896*x0_t*sin(x0) + -12.506*x0_t*cos(x0) + \n",
      "exp([0.13987114]*t)\n",
      "\n",
      "\n",
      "Stage  98\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0003753110988513996\n",
      "Average loss :  1.6973202718872926e-06\n",
      "\n",
      "\n",
      "Stage  98\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0003753110988513996\n",
      "Average loss :  1.0120425031345803e-06\n",
      "\n",
      "\n",
      "Stage  98\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0003753110988513996\n",
      "Average loss :  1.0062090041174088e-06\n",
      "\n",
      "\n",
      "Stage  98\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0003753110988513996\n",
      "Average loss :  9.501801514488761e-07\n",
      "expression length:\t 5\n",
      "Result stage 100: -1.749*sin(x0) + 25.062*cos(x0) + 1.419*x0_t**2 + 19.894*x0_t*sin(x0) + -12.504*x0_t*cos(x0) + \n",
      "exp([0.13981774]*t)\n",
      "\n",
      "\n",
      "Stage  99\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0003715766910220457\n",
      "Average loss :  1.020093918668863e-06\n",
      "\n",
      "\n",
      "Stage  99\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0003715766910220457\n",
      "Average loss :  9.823118034546496e-07\n",
      "\n",
      "\n",
      "Stage  99\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0003715766910220457\n",
      "Average loss :  1.8386222109256778e-06\n",
      "\n",
      "\n",
      "Stage  99\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0003715766910220457\n",
      "Average loss :  1.0445370435263612e-06\n",
      "expression length:\t 5\n",
      "Result stage 101: -1.748*sin(x0) + 25.063*cos(x0) + 1.419*x0_t**2 + 19.893*x0_t*sin(x0) + -12.503*x0_t*cos(x0) + \n",
      "exp([0.13987334]*t)\n",
      "\n",
      "\n",
      "Stage  100\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00036787944117144236\n",
      "Average loss :  1.789294515219808e-06\n",
      "\n",
      "\n",
      "Stage  100\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00036787944117144236\n",
      "Average loss :  1.0221334605375887e-06\n",
      "\n",
      "\n",
      "Stage  100\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00036787944117144236\n",
      "Average loss :  1.556749111841782e-06\n",
      "\n",
      "\n",
      "Stage  100\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00036787944117144236\n",
      "Average loss :  8.999963938549627e-07\n",
      "expression length:\t 5\n",
      "Result stage 102: -1.749*sin(x0) + 25.063*cos(x0) + 1.419*x0_t**2 + 19.892*x0_t*sin(x0) + -12.501*x0_t*cos(x0) + \n",
      "exp([0.13982499]*t)\n",
      "\n",
      "\n",
      "Stage  101\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0003642189795715233\n",
      "Average loss :  1.5213512369882665e-06\n",
      "\n",
      "\n",
      "Stage  101\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0003642189795715233\n",
      "Average loss :  9.771312079465133e-07\n",
      "\n",
      "\n",
      "Stage  101\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0003642189795715233\n",
      "Average loss :  1.0010809319282998e-06\n",
      "\n",
      "\n",
      "Stage  101\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0003642189795715233\n",
      "Average loss :  9.932153943736921e-07\n",
      "expression length:\t 5\n",
      "Result stage 103: -1.748*sin(x0) + 25.064*cos(x0) + 1.419*x0_t**2 + 19.891*x0_t*sin(x0) + -12.499*x0_t*cos(x0) + \n",
      "exp([0.13992639]*t)\n",
      "\n",
      "\n",
      "Stage  102\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00036059494017307833\n",
      "Average loss :  7.798362275934778e-07\n",
      "\n",
      "\n",
      "Stage  102\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00036059494017307833\n",
      "Average loss :  1.8286989416083088e-06\n",
      "\n",
      "\n",
      "Stage  102\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00036059494017307833\n",
      "Average loss :  1.1209233434783528e-06\n",
      "\n",
      "\n",
      "Stage  102\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00036059494017307833\n",
      "Average loss :  8.886426599019615e-07\n",
      "expression length:\t 5\n",
      "Result stage 104: -1.748*sin(x0) + 25.064*cos(x0) + 1.419*x0_t**2 + 19.889*x0_t*sin(x0) + -12.498*x0_t*cos(x0) + \n",
      "exp([0.13983417]*t)\n",
      "\n",
      "\n",
      "Stage  103\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0003570069605691474\n",
      "Average loss :  1.0876347005250864e-06\n",
      "\n",
      "\n",
      "Stage  103\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0003570069605691474\n",
      "Average loss :  9.676504078015569e-07\n",
      "\n",
      "\n",
      "Stage  103\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0003570069605691474\n",
      "Average loss :  8.517779974681616e-07\n",
      "\n",
      "\n",
      "Stage  103\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0003570069605691474\n",
      "Average loss :  9.130315561378666e-07\n",
      "expression length:\t 5\n",
      "Result stage 105: -1.748*sin(x0) + 25.065*cos(x0) + 1.419*x0_t**2 + 19.888*x0_t*sin(x0) + -12.496*x0_t*cos(x0) + \n",
      "exp([0.13991144]*t)\n",
      "\n",
      "\n",
      "Stage  104\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00035345468195878014\n",
      "Average loss :  9.422269044989662e-07\n",
      "\n",
      "\n",
      "Stage  104\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00035345468195878014\n",
      "Average loss :  1.3387358421823592e-06\n",
      "\n",
      "\n",
      "Stage  104\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00035345468195878014\n",
      "Average loss :  1.3810262089464231e-06\n",
      "\n",
      "\n",
      "Stage  104\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00035345468195878014\n",
      "Average loss :  9.956299891200615e-07\n",
      "expression length:\t 5\n",
      "Result stage 106: -1.748*sin(x0) + 25.065*cos(x0) + 1.419*x0_t**2 + 19.887*x0_t*sin(x0) + -12.495*x0_t*cos(x0) + \n",
      "exp([0.13986667]*t)\n",
      "\n",
      "\n",
      "Stage  105\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00034993774911115536\n",
      "Average loss :  2.2338374492392177e-06\n",
      "\n",
      "\n",
      "Stage  105\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00034993774911115536\n",
      "Average loss :  9.680981065685046e-07\n",
      "\n",
      "\n",
      "Stage  105\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00034993774911115536\n",
      "Average loss :  9.025740723700437e-07\n",
      "\n",
      "\n",
      "Stage  105\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00034993774911115536\n",
      "Average loss :  2.000163476623129e-06\n",
      "expression length:\t 5\n",
      "Result stage 107: -1.747*sin(x0) + 25.065*cos(x0) + 1.419*x0_t**2 + 19.886*x0_t*sin(x0) + -12.494*x0_t*cos(x0) + \n",
      "exp([0.13987416]*t)\n",
      "\n",
      "\n",
      "Stage  106\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0003464558103300574\n",
      "Average loss :  8.028401907722582e-07\n",
      "\n",
      "\n",
      "Stage  106\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0003464558103300574\n",
      "Average loss :  7.612056265315914e-07\n",
      "\n",
      "\n",
      "Stage  106\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0003464558103300574\n",
      "Average loss :  1.0508725836189114e-06\n",
      "\n",
      "\n",
      "Stage  106\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0003464558103300574\n",
      "Average loss :  1.4687883549413527e-06\n",
      "expression length:\t 5\n",
      "Result stage 108: -1.747*sin(x0) + 25.065*cos(x0) + 1.419*x0_t**2 + 19.885*x0_t*sin(x0) + -12.492*x0_t*cos(x0) + \n",
      "exp([0.1398274]*t)\n",
      "\n",
      "\n",
      "Stage  107\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00034300851741870663\n",
      "Average loss :  1.2347984466032358e-06\n",
      "\n",
      "\n",
      "Stage  107\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00034300851741870663\n",
      "Average loss :  7.932112566777505e-07\n",
      "\n",
      "\n",
      "Stage  107\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00034300851741870663\n",
      "Average loss :  9.998326504501165e-07\n",
      "\n",
      "\n",
      "Stage  107\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00034300851741870663\n",
      "Average loss :  1.7865839936348493e-06\n",
      "expression length:\t 5\n",
      "Result stage 109: -1.747*sin(x0) + 25.066*cos(x0) + 1.419*x0_t**2 + 19.884*x0_t*sin(x0) + -12.491*x0_t*cos(x0) + \n",
      "exp([0.13985558]*t)\n",
      "\n",
      "\n",
      "Stage  108\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00033959552564493913\n",
      "Average loss :  1.864589876277023e-06\n",
      "\n",
      "\n",
      "Stage  108\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00033959552564493913\n",
      "Average loss :  1.3559887293013162e-06\n",
      "\n",
      "\n",
      "Stage  108\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00033959552564493913\n",
      "Average loss :  1.1997791489193332e-06\n",
      "\n",
      "\n",
      "Stage  108\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00033959552564493913\n",
      "Average loss :  7.803326411703893e-07\n",
      "expression length:\t 5\n",
      "Result stage 110: -1.747*sin(x0) + 25.066*cos(x0) + 1.419*x0_t**2 + 19.883*x0_t*sin(x0) + -12.489*x0_t*cos(x0) + \n",
      "exp([0.13984041]*t)\n",
      "\n",
      "\n",
      "Stage  109\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00033621649370673334\n",
      "Average loss :  8.358019272236561e-07\n",
      "\n",
      "\n",
      "Stage  109\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00033621649370673334\n",
      "Average loss :  1.2385860372887691e-06\n",
      "\n",
      "\n",
      "Stage  109\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00033621649370673334\n",
      "Average loss :  1.4743685596840805e-06\n",
      "\n",
      "\n",
      "Stage  109\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00033621649370673334\n",
      "Average loss :  7.503106189687969e-07\n",
      "expression length:\t 5\n",
      "Result stage 111: -1.747*sin(x0) + 25.066*cos(x0) + 1.419*x0_t**2 + 19.882*x0_t*sin(x0) + -12.488*x0_t*cos(x0) + \n",
      "exp([0.13984121]*t)\n",
      "\n",
      "\n",
      "Stage  110\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00033287108369807955\n",
      "Average loss :  8.435334848400089e-07\n",
      "\n",
      "\n",
      "Stage  110\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00033287108369807955\n",
      "Average loss :  1.195775098494778e-06\n",
      "\n",
      "\n",
      "Stage  110\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00033287108369807955\n",
      "Average loss :  8.759346314946015e-07\n",
      "\n",
      "\n",
      "Stage  110\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00033287108369807955\n",
      "Average loss :  1.3180209634811035e-06\n",
      "expression length:\t 5\n",
      "Result stage 112: -1.746*sin(x0) + 25.067*cos(x0) + 1.419*x0_t**2 + 19.881*x0_t*sin(x0) + -12.487*x0_t*cos(x0) + \n",
      "exp([0.13986424]*t)\n",
      "\n",
      "\n",
      "Stage  111\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0003295589610751891\n",
      "Average loss :  9.10960068267741e-07\n",
      "\n",
      "\n",
      "Stage  111\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0003295589610751891\n",
      "Average loss :  1.767951744113816e-06\n",
      "\n",
      "\n",
      "Stage  111\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0003295589610751891\n",
      "Average loss :  7.469042202501441e-07\n",
      "\n",
      "\n",
      "Stage  111\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0003295589610751891\n",
      "Average loss :  7.852092949178768e-07\n",
      "expression length:\t 5\n",
      "Result stage 113: -1.746*sin(x0) + 25.067*cos(x0) + 1.419*x0_t**2 + 19.88*x0_t*sin(x0) + -12.486*x0_t*cos(x0) + \n",
      "exp([0.13992612]*t)\n",
      "\n",
      "\n",
      "Stage  112\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00032627979462303947\n",
      "Average loss :  6.105748298068647e-07\n",
      "\n",
      "\n",
      "Stage  112\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00032627979462303947\n",
      "Average loss :  1.3647160130858538e-06\n",
      "\n",
      "\n",
      "Stage  112\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00032627979462303947\n",
      "Average loss :  1.131620365413255e-06\n",
      "\n",
      "\n",
      "Stage  112\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00032627979462303947\n",
      "Average loss :  7.18679814326606e-07\n",
      "expression length:\t 5\n",
      "Result stage 114: -1.746*sin(x0) + 25.068*cos(x0) + 1.419*x0_t**2 + 19.879*x0_t*sin(x0) + -12.484*x0_t*cos(x0) + \n",
      "exp([0.13984716]*t)\n",
      "\n",
      "\n",
      "Stage  113\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0003230332564222529\n",
      "Average loss :  9.709336836749571e-07\n",
      "\n",
      "\n",
      "Stage  113\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0003230332564222529\n",
      "Average loss :  7.140610591704899e-07\n",
      "\n",
      "\n",
      "Stage  113\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0003230332564222529\n",
      "Average loss :  7.907628969405778e-07\n",
      "\n",
      "\n",
      "Stage  113\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0003230332564222529\n",
      "Average loss :  6.803853125347814e-07\n",
      "expression length:\t 5\n",
      "Result stage 115: -1.746*sin(x0) + 25.068*cos(x0) + 1.42*x0_t**2 + 19.878*x0_t*sin(x0) + -12.483*x0_t*cos(x0) + \n",
      "exp([0.13985704]*t)\n",
      "\n",
      "\n",
      "Stage  114\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00031981902181630386\n",
      "Average loss :  1.2746802440233296e-06\n",
      "\n",
      "\n",
      "Stage  114\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00031981902181630386\n",
      "Average loss :  8.614574085186177e-07\n",
      "\n",
      "\n",
      "Stage  114\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00031981902181630386\n",
      "Average loss :  6.929373057573684e-07\n",
      "\n",
      "\n",
      "Stage  114\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00031981902181630386\n",
      "Average loss :  7.772374601699994e-07\n",
      "expression length:\t 5\n",
      "Result stage 116: -1.746*sin(x0) + 25.068*cos(x0) + 1.419*x0_t**2 + 19.877*x0_t*sin(x0) + -12.482*x0_t*cos(x0) + \n",
      "exp([0.13994455]*t)\n",
      "\n",
      "\n",
      "Stage  115\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00031663676937905317\n",
      "Average loss :  1.2170215768492199e-06\n",
      "\n",
      "\n",
      "Stage  115\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00031663676937905317\n",
      "Average loss :  7.62646152452362e-07\n",
      "\n",
      "\n",
      "Stage  115\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00031663676937905317\n",
      "Average loss :  1.06852507997246e-06\n",
      "\n",
      "\n",
      "Stage  115\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00031663676937905317\n",
      "Average loss :  7.214897550511523e-07\n",
      "expression length:\t 5\n",
      "Result stage 117: -1.746*sin(x0) + 25.069*cos(x0) + 1.419*x0_t**2 + 19.877*x0_t*sin(x0) + -12.481*x0_t*cos(x0) + \n",
      "exp([0.13990387]*t)\n",
      "\n",
      "\n",
      "Stage  116\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0003134861808826053\n",
      "Average loss :  7.458195909748611e-07\n",
      "\n",
      "\n",
      "Stage  116\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0003134861808826053\n",
      "Average loss :  1.2629458296942175e-06\n",
      "\n",
      "\n",
      "Stage  116\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0003134861808826053\n",
      "Average loss :  6.642336529694148e-07\n",
      "\n",
      "\n",
      "Stage  116\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0003134861808826053\n",
      "Average loss :  1.3463092045640224e-06\n",
      "expression length:\t 5\n",
      "Result stage 118: -1.745*sin(x0) + 25.069*cos(x0) + 1.419*x0_t**2 + 19.876*x0_t*sin(x0) + -12.481*x0_t*cos(x0) + \n",
      "exp([0.13983849]*t)\n",
      "\n",
      "\n",
      "Stage  117\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00031036694126548506\n",
      "Average loss :  1.0990992223014473e-06\n",
      "\n",
      "\n",
      "Stage  117\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00031036694126548506\n",
      "Average loss :  9.36585593080963e-07\n",
      "\n",
      "\n",
      "Stage  117\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00031036694126548506\n",
      "Average loss :  8.817299317342986e-07\n",
      "\n",
      "\n",
      "Stage  117\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00031036694126548506\n",
      "Average loss :  9.532935223433014e-07\n",
      "expression length:\t 5\n",
      "Result stage 119: -1.745*sin(x0) + 25.069*cos(x0) + 1.419*x0_t**2 + 19.875*x0_t*sin(x0) + -12.479*x0_t*cos(x0) + \n",
      "exp([0.13989377]*t)\n",
      "\n",
      "\n",
      "Stage  118\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00030727873860113123\n",
      "Average loss :  6.549414024448197e-07\n",
      "\n",
      "\n",
      "Stage  118\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00030727873860113123\n",
      "Average loss :  7.842713785066735e-07\n",
      "\n",
      "\n",
      "Stage  118\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00030727873860113123\n",
      "Average loss :  1.0019203955380362e-06\n",
      "\n",
      "\n",
      "Stage  118\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00030727873860113123\n",
      "Average loss :  9.731049885886023e-07\n",
      "expression length:\t 5\n",
      "Result stage 120: -1.745*sin(x0) + 25.069*cos(x0) + 1.42*x0_t**2 + 19.874*x0_t*sin(x0) + -12.478*x0_t*cos(x0) + \n",
      "exp([0.13983743]*t)\n",
      "\n",
      "\n",
      "Stage  119\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0003042212640667041\n",
      "Average loss :  7.127665071493539e-07\n",
      "\n",
      "\n",
      "Stage  119\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0003042212640667041\n",
      "Average loss :  6.738439992659551e-07\n",
      "\n",
      "\n",
      "Stage  119\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0003042212640667041\n",
      "Average loss :  7.016160452621989e-07\n",
      "\n",
      "\n",
      "Stage  119\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0003042212640667041\n",
      "Average loss :  5.147593356014113e-07\n",
      "expression length:\t 5\n",
      "Result stage 121: -1.746*sin(x0) + 25.07*cos(x0) + 1.42*x0_t**2 + 19.873*x0_t*sin(x0) + -12.476*x0_t*cos(x0) + \n",
      "exp([0.13991025]*t)\n",
      "\n",
      "\n",
      "Stage  120\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00030119421191220216\n",
      "Average loss :  8.584529496147297e-07\n",
      "\n",
      "\n",
      "Stage  120\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00030119421191220216\n",
      "Average loss :  6.900513653818052e-07\n",
      "\n",
      "\n",
      "Stage  120\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00030119421191220216\n",
      "Average loss :  6.060798796170275e-07\n",
      "\n",
      "\n",
      "Stage  120\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00030119421191220216\n",
      "Average loss :  1.0105258070325362e-06\n",
      "expression length:\t 5\n",
      "Result stage 122: -1.745*sin(x0) + 25.07*cos(x0) + 1.42*x0_t**2 + 19.872*x0_t*sin(x0) + -12.476*x0_t*cos(x0) + \n",
      "exp([0.13983841]*t)\n",
      "\n",
      "\n",
      "Stage  121\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00029819727942988737\n",
      "Average loss :  6.343204859149409e-07\n",
      "\n",
      "\n",
      "Stage  121\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00029819727942988737\n",
      "Average loss :  1.0592013950372348e-06\n",
      "\n",
      "\n",
      "Stage  121\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00029819727942988737\n",
      "Average loss :  6.764963131900004e-07\n",
      "\n",
      "\n",
      "Stage  121\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00029819727942988737\n",
      "Average loss :  5.065145955995831e-07\n",
      "expression length:\t 5\n",
      "Result stage 123: -1.745*sin(x0) + 25.07*cos(x0) + 1.42*x0_t**2 + 19.871*x0_t*sin(x0) + -12.474*x0_t*cos(x0) + \n",
      "exp([0.13990608]*t)\n",
      "\n",
      "\n",
      "Stage  122\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002952301669240142\n",
      "Average loss :  5.872792030459095e-07\n",
      "\n",
      "\n",
      "Stage  122\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002952301669240142\n",
      "Average loss :  5.293285312291118e-07\n",
      "\n",
      "\n",
      "Stage  122\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002952301669240142\n",
      "Average loss :  6.624116508646694e-07\n",
      "\n",
      "\n",
      "Stage  122\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002952301669240142\n",
      "Average loss :  5.586738325291662e-07\n",
      "expression length:\t 5\n",
      "Result stage 124: -1.745*sin(x0) + 25.07*cos(x0) + 1.42*x0_t**2 + 19.87*x0_t*sin(x0) + -12.473*x0_t*cos(x0) + \n",
      "exp([0.13988714]*t)\n",
      "\n",
      "\n",
      "Stage  123\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002922925776808594\n",
      "Average loss :  4.952233894073288e-07\n",
      "\n",
      "\n",
      "Stage  123\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002922925776808594\n",
      "Average loss :  5.754268954660802e-07\n",
      "\n",
      "\n",
      "Stage  123\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002922925776808594\n",
      "Average loss :  1.0715003782024723e-06\n",
      "\n",
      "\n",
      "Stage  123\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002922925776808594\n",
      "Average loss :  5.751757612415531e-07\n",
      "expression length:\t 5\n",
      "Result stage 125: -1.745*sin(x0) + 25.071*cos(x0) + 1.42*x0_t**2 + 19.869*x0_t*sin(x0) + -12.472*x0_t*cos(x0) + \n",
      "exp([0.13985787]*t)\n",
      "\n",
      "\n",
      "Stage  124\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002893842179390506\n",
      "Average loss :  5.614759857053286e-07\n",
      "\n",
      "\n",
      "Stage  124\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002893842179390506\n",
      "Average loss :  9.109240295401833e-07\n",
      "\n",
      "\n",
      "Stage  124\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002893842179390506\n",
      "Average loss :  6.342921210489294e-07\n",
      "\n",
      "\n",
      "Stage  124\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002893842179390506\n",
      "Average loss :  6.36811193999165e-07\n",
      "expression length:\t 5\n",
      "Result stage 126: -1.745*sin(x0) + 25.071*cos(x0) + 1.419*x0_t**2 + 19.869*x0_t*sin(x0) + -12.471*x0_t*cos(x0) + \n",
      "exp([0.13995214]*t)\n",
      "\n",
      "\n",
      "Stage  125\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002865047968601901\n",
      "Average loss :  6.172557505124132e-07\n",
      "\n",
      "\n",
      "Stage  125\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002865047968601901\n",
      "Average loss :  6.032316832715878e-07\n",
      "\n",
      "\n",
      "Stage  125\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002865047968601901\n",
      "Average loss :  5.483087193169922e-07\n",
      "\n",
      "\n",
      "Stage  125\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002865047968601901\n",
      "Average loss :  6.086809207772603e-07\n",
      "expression length:\t 5\n",
      "Result stage 127: -1.744*sin(x0) + 25.071*cos(x0) + 1.419*x0_t**2 + 19.868*x0_t*sin(x0) + -12.47*x0_t*cos(x0) + \n",
      "exp([0.13994473]*t)\n",
      "\n",
      "\n",
      "Stage  126\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002836540264997704\n",
      "Average loss :  9.351963967674237e-07\n",
      "\n",
      "\n",
      "Stage  126\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002836540264997704\n",
      "Average loss :  7.918296205389197e-07\n",
      "\n",
      "\n",
      "Stage  126\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002836540264997704\n",
      "Average loss :  8.520133292222454e-07\n",
      "\n",
      "\n",
      "Stage  126\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002836540264997704\n",
      "Average loss :  5.46481714991387e-07\n",
      "expression length:\t 5\n",
      "Result stage 128: -1.744*sin(x0) + 25.071*cos(x0) + 1.42*x0_t**2 + 19.867*x0_t*sin(x0) + -12.469*x0_t*cos(x0) + \n",
      "exp([0.13987404]*t)\n",
      "\n",
      "\n",
      "Stage  127\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002808316217783798\n",
      "Average loss :  4.6116133489704225e-07\n",
      "\n",
      "\n",
      "Stage  127\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002808316217783798\n",
      "Average loss :  7.581616614515951e-07\n",
      "\n",
      "\n",
      "Stage  127\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002808316217783798\n",
      "Average loss :  5.632123816212697e-07\n",
      "\n",
      "\n",
      "Stage  127\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002808316217783798\n",
      "Average loss :  9.095696213989868e-07\n",
      "expression length:\t 5\n",
      "Result stage 129: -1.744*sin(x0) + 25.072*cos(x0) + 1.42*x0_t**2 + 19.866*x0_t*sin(x0) + -12.469*x0_t*cos(x0) + \n",
      "exp([0.13985154]*t)\n",
      "\n",
      "\n",
      "Stage  128\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00027803730045319414\n",
      "Average loss :  5.561514058172179e-07\n",
      "\n",
      "\n",
      "Stage  128\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00027803730045319414\n",
      "Average loss :  5.624186769637163e-07\n",
      "\n",
      "\n",
      "Stage  128\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00027803730045319414\n",
      "Average loss :  5.613015332528448e-07\n",
      "\n",
      "\n",
      "Stage  128\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00027803730045319414\n",
      "Average loss :  1.1568303079911857e-06\n",
      "expression length:\t 5\n",
      "Result stage 130: -1.744*sin(x0) + 25.072*cos(x0) + 1.42*x0_t**2 + 19.866*x0_t*sin(x0) + -12.468*x0_t*cos(x0) + \n",
      "exp([0.13987426]*t)\n",
      "\n",
      "\n",
      "Stage  129\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002752707830897523\n",
      "Average loss :  5.854593041476619e-07\n",
      "\n",
      "\n",
      "Stage  129\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002752707830897523\n",
      "Average loss :  5.09924632297043e-07\n",
      "\n",
      "\n",
      "Stage  129\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002752707830897523\n",
      "Average loss :  5.107706328999484e-07\n",
      "\n",
      "\n",
      "Stage  129\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002752707830897523\n",
      "Average loss :  6.776357963644841e-07\n",
      "expression length:\t 5\n",
      "Result stage 131: -1.744*sin(x0) + 25.072*cos(x0) + 1.42*x0_t**2 + 19.865*x0_t*sin(x0) + -12.467*x0_t*cos(x0) + \n",
      "exp([0.13986911]*t)\n",
      "\n",
      "\n",
      "Stage  130\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002725317930340126\n",
      "Average loss :  5.452293407870457e-07\n",
      "\n",
      "\n",
      "Stage  130\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002725317930340126\n",
      "Average loss :  9.553122026773053e-07\n",
      "\n",
      "\n",
      "Stage  130\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002725317930340126\n",
      "Average loss :  1.1325179229970672e-06\n",
      "\n",
      "\n",
      "Stage  130\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002725317930340126\n",
      "Average loss :  5.018281399316038e-07\n",
      "expression length:\t 5\n",
      "Result stage 132: -1.744*sin(x0) + 25.072*cos(x0) + 1.42*x0_t**2 + 19.864*x0_t*sin(x0) + -12.465*x0_t*cos(x0) + \n",
      "exp([0.13987286]*t)\n",
      "\n",
      "\n",
      "Stage  131\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00026982005638468684\n",
      "Average loss :  4.915127078675141e-07\n",
      "\n",
      "\n",
      "Stage  131\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00026982005638468684\n",
      "Average loss :  4.901962142866978e-07\n",
      "\n",
      "\n",
      "Stage  131\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00026982005638468684\n",
      "Average loss :  7.697026376263238e-07\n",
      "\n",
      "\n",
      "Stage  131\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00026982005638468684\n",
      "Average loss :  6.947767587917042e-07\n",
      "expression length:\t 5\n",
      "Result stage 133: -1.744*sin(x0) + 25.073*cos(x0) + 1.419*x0_t**2 + 19.864*x0_t*sin(x0) + -12.465*x0_t*cos(x0) + \n",
      "exp([0.13990875]*t)\n",
      "\n",
      "\n",
      "Stage  132\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002671353019658503\n",
      "Average loss :  5.320524678609218e-07\n",
      "\n",
      "\n",
      "Stage  132\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002671353019658503\n",
      "Average loss :  4.508819131388009e-07\n",
      "\n",
      "\n",
      "Stage  132\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002671353019658503\n",
      "Average loss :  8.945476679400599e-07\n",
      "\n",
      "\n",
      "Stage  132\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002671353019658503\n",
      "Average loss :  8.767169106249639e-07\n",
      "expression length:\t 5\n",
      "Result stage 134: -1.744*sin(x0) + 25.073*cos(x0) + 1.42*x0_t**2 + 19.863*x0_t*sin(x0) + -12.464*x0_t*cos(x0) + \n",
      "exp([0.13986303]*t)\n",
      "\n",
      "\n",
      "Stage  133\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00026447726129982395\n",
      "Average loss :  3.957847525271063e-07\n",
      "\n",
      "\n",
      "Stage  133\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00026447726129982395\n",
      "Average loss :  5.235452817942132e-07\n",
      "\n",
      "\n",
      "Stage  133\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00026447726129982395\n",
      "Average loss :  4.885113185082446e-07\n",
      "\n",
      "\n",
      "Stage  133\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00026447726129982395\n",
      "Average loss :  5.05453272126033e-07\n",
      "expression length:\t 5\n",
      "Result stage 135: -1.743*sin(x0) + 25.073*cos(x0) + 1.42*x0_t**2 + 19.862*x0_t*sin(x0) + -12.463*x0_t*cos(x0) + \n",
      "exp([0.13991718]*t)\n",
      "\n",
      "\n",
      "Stage  134\n",
      "Epoch 50/200\n",
      "Learning rate :  0.000261845668580326\n",
      "Average loss :  5.18111448855052e-07\n",
      "\n",
      "\n",
      "Stage  134\n",
      "Epoch 100/200\n",
      "Learning rate :  0.000261845668580326\n",
      "Average loss :  2.408060595371353e-07\n",
      "\n",
      "\n",
      "Stage  134\n",
      "Epoch 150/200\n",
      "Learning rate :  0.000261845668580326\n",
      "Average loss :  4.636610526631557e-07\n",
      "\n",
      "\n",
      "Stage  134\n",
      "Epoch 200/200\n",
      "Learning rate :  0.000261845668580326\n",
      "Average loss :  4.863721869696747e-07\n",
      "expression length:\t 5\n",
      "Result stage 136: -1.744*sin(x0) + 25.073*cos(x0) + 1.42*x0_t**2 + 19.862*x0_t*sin(x0) + -12.462*x0_t*cos(x0) + \n",
      "exp([0.13989519]*t)\n",
      "\n",
      "\n",
      "Stage  135\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002592402606458915\n",
      "Average loss :  4.744554473745666e-07\n",
      "\n",
      "\n",
      "Stage  135\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002592402606458915\n",
      "Average loss :  4.991588298253191e-07\n",
      "\n",
      "\n",
      "Stage  135\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002592402606458915\n",
      "Average loss :  5.090207650937373e-07\n",
      "\n",
      "\n",
      "Stage  135\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002592402606458915\n",
      "Average loss :  4.459178342131054e-07\n",
      "expression length:\t 5\n",
      "Result stage 137: -1.743*sin(x0) + 25.073*cos(x0) + 1.42*x0_t**2 + 19.861*x0_t*sin(x0) + -12.461*x0_t*cos(x0) + \n",
      "exp([0.13988233]*t)\n",
      "\n",
      "\n",
      "Stage  136\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002566607769535559\n",
      "Average loss :  3.9724616840430826e-07\n",
      "\n",
      "\n",
      "Stage  136\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002566607769535559\n",
      "Average loss :  4.653098528706323e-07\n",
      "\n",
      "\n",
      "Stage  136\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002566607769535559\n",
      "Average loss :  5.162194725016889e-07\n",
      "\n",
      "\n",
      "Stage  136\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002566607769535559\n",
      "Average loss :  6.283361813075317e-07\n",
      "expression length:\t 5\n",
      "Result stage 138: -1.743*sin(x0) + 25.073*cos(x0) + 1.42*x0_t**2 + 19.861*x0_t*sin(x0) + -12.461*x0_t*cos(x0) + \n",
      "exp([0.13987017]*t)\n",
      "\n",
      "\n",
      "Stage  137\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00025410695955280026\n",
      "Average loss :  4.7086081167435623e-07\n",
      "\n",
      "\n",
      "Stage  137\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00025410695955280026\n",
      "Average loss :  4.560047273116652e-07\n",
      "\n",
      "\n",
      "Stage  137\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00025410695955280026\n",
      "Average loss :  4.39927447359878e-07\n",
      "\n",
      "\n",
      "Stage  137\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00025410695955280026\n",
      "Average loss :  8.413720706812455e-07\n",
      "expression length:\t 5\n",
      "Result stage 139: -1.743*sin(x0) + 25.074*cos(x0) + 1.419*x0_t**2 + 19.86*x0_t*sin(x0) + -12.46*x0_t*cos(x0) + \n",
      "exp([0.13988033]*t)\n",
      "\n",
      "\n",
      "Stage  138\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002515785530597565\n",
      "Average loss :  2.423024056952272e-07\n",
      "\n",
      "\n",
      "Stage  138\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002515785530597565\n",
      "Average loss :  4.89272792947304e-07\n",
      "\n",
      "\n",
      "Stage  138\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002515785530597565\n",
      "Average loss :  3.7506725902858307e-07\n",
      "\n",
      "\n",
      "Stage  138\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002515785530597565\n",
      "Average loss :  1.0995998991347733e-06\n",
      "expression length:\t 5\n",
      "Result stage 140: -1.743*sin(x0) + 25.074*cos(x0) + 1.42*x0_t**2 + 19.859*x0_t*sin(x0) + -12.459*x0_t*cos(x0) + \n",
      "exp([0.13992263]*t)\n",
      "\n",
      "\n",
      "Stage  139\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00024907530463166817\n",
      "Average loss :  5.918035412832978e-07\n",
      "\n",
      "\n",
      "Stage  139\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00024907530463166817\n",
      "Average loss :  8.066596706157725e-07\n",
      "\n",
      "\n",
      "Stage  139\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00024907530463166817\n",
      "Average loss :  4.420680568273383e-07\n",
      "\n",
      "\n",
      "Stage  139\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00024907530463166817\n",
      "Average loss :  9.803892453419394e-07\n",
      "expression length:\t 5\n",
      "Result stage 141: -1.743*sin(x0) + 25.074*cos(x0) + 1.42*x0_t**2 + 19.859*x0_t*sin(x0) + -12.459*x0_t*cos(x0) + \n",
      "exp([0.1399025]*t)\n",
      "\n",
      "\n",
      "Stage  140\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00024659696394160646\n",
      "Average loss :  4.333995491379028e-07\n",
      "\n",
      "\n",
      "Stage  140\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00024659696394160646\n",
      "Average loss :  4.2386389509374567e-07\n",
      "\n",
      "\n",
      "Stage  140\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00024659696394160646\n",
      "Average loss :  5.4659483339492e-07\n",
      "\n",
      "\n",
      "Stage  140\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00024659696394160646\n",
      "Average loss :  6.854332355032966e-07\n",
      "expression length:\t 5\n",
      "Result stage 142: -1.743*sin(x0) + 25.074*cos(x0) + 1.42*x0_t**2 + 19.858*x0_t*sin(x0) + -12.458*x0_t*cos(x0) + \n",
      "exp([0.1398698]*t)\n",
      "\n",
      "\n",
      "Stage  141\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002441432831534371\n",
      "Average loss :  1.0458732049301034e-06\n",
      "\n",
      "\n",
      "Stage  141\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002441432831534371\n",
      "Average loss :  1.1270423101450433e-06\n",
      "\n",
      "\n",
      "Stage  141\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002441432831534371\n",
      "Average loss :  3.995472184215032e-07\n",
      "\n",
      "\n",
      "Stage  141\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002441432831534371\n",
      "Average loss :  4.008832092949888e-07\n",
      "expression length:\t 5\n",
      "Result stage 143: -1.743*sin(x0) + 25.074*cos(x0) + 1.42*x0_t**2 + 19.857*x0_t*sin(x0) + -12.457*x0_t*cos(x0) + \n",
      "exp([0.13988239]*t)\n",
      "\n",
      "\n",
      "Stage  142\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00024171401689703645\n",
      "Average loss :  4.32607407674368e-07\n",
      "\n",
      "\n",
      "Stage  142\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00024171401689703645\n",
      "Average loss :  6.523574143102451e-07\n",
      "\n",
      "\n",
      "Stage  142\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00024171401689703645\n",
      "Average loss :  4.919351113130688e-07\n",
      "\n",
      "\n",
      "Stage  142\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00024171401689703645\n",
      "Average loss :  3.9385648165080056e-07\n",
      "expression length:\t 5\n",
      "Result stage 144: -1.743*sin(x0) + 25.074*cos(x0) + 1.42*x0_t**2 + 19.857*x0_t*sin(x0) + -12.456*x0_t*cos(x0) + \n",
      "exp([0.1398877]*t)\n",
      "\n",
      "\n",
      "Stage  143\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00023930892224375457\n",
      "Average loss :  5.021597075938189e-07\n",
      "\n",
      "\n",
      "Stage  143\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00023930892224375457\n",
      "Average loss :  4.1959398799917835e-07\n",
      "\n",
      "\n",
      "Stage  143\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00023930892224375457\n",
      "Average loss :  5.295834739627026e-07\n",
      "\n",
      "\n",
      "Stage  143\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00023930892224375457\n",
      "Average loss :  3.864764721583924e-07\n",
      "expression length:\t 5\n",
      "Result stage 145: -1.743*sin(x0) + 25.075*cos(x0) + 1.42*x0_t**2 + 19.857*x0_t*sin(x0) + -12.456*x0_t*cos(x0) + \n",
      "exp([0.13988848]*t)\n",
      "\n",
      "\n",
      "Stage  144\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00023692775868212177\n",
      "Average loss :  7.591243615934218e-07\n",
      "\n",
      "\n",
      "Stage  144\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00023692775868212177\n",
      "Average loss :  3.8087776488282543e-07\n",
      "\n",
      "\n",
      "Stage  144\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00023692775868212177\n",
      "Average loss :  8.068540751082764e-07\n",
      "\n",
      "\n",
      "Stage  144\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00023692775868212177\n",
      "Average loss :  6.97860116360971e-07\n",
      "expression length:\t 5\n",
      "Result stage 146: -1.742*sin(x0) + 25.075*cos(x0) + 1.42*x0_t**2 + 19.856*x0_t*sin(x0) + -12.455*x0_t*cos(x0) + \n",
      "exp([0.13987657]*t)\n",
      "\n",
      "\n",
      "Stage  145\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00023457028809379765\n",
      "Average loss :  3.678530617889919e-07\n",
      "\n",
      "\n",
      "Stage  145\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00023457028809379765\n",
      "Average loss :  3.6976794604015595e-07\n",
      "\n",
      "\n",
      "Stage  145\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00023457028809379765\n",
      "Average loss :  5.086131977805053e-07\n",
      "\n",
      "\n",
      "Stage  145\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00023457028809379765\n",
      "Average loss :  4.0139516954695864e-07\n",
      "expression length:\t 5\n",
      "Result stage 147: -1.742*sin(x0) + 25.075*cos(x0) + 1.42*x0_t**2 + 19.856*x0_t*sin(x0) + -12.454*x0_t*cos(x0) + \n",
      "exp([0.13993394]*t)\n",
      "\n",
      "\n",
      "Stage  146\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00023223627472975883\n",
      "Average loss :  1.100606709769636e-06\n",
      "\n",
      "\n",
      "Stage  146\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00023223627472975883\n",
      "Average loss :  3.8732565599275404e-07\n",
      "\n",
      "\n",
      "Stage  146\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00023223627472975883\n",
      "Average loss :  4.0295694248015934e-07\n",
      "\n",
      "\n",
      "Stage  146\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00023223627472975883\n",
      "Average loss :  8.799593729236221e-07\n",
      "expression length:\t 5\n",
      "Result stage 148: -1.742*sin(x0) + 25.075*cos(x0) + 1.42*x0_t**2 + 19.855*x0_t*sin(x0) + -12.454*x0_t*cos(x0) + \n",
      "exp([0.13991703]*t)\n",
      "\n",
      "\n",
      "Stage  147\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00022992548518672385\n",
      "Average loss :  8.322010671690805e-07\n",
      "\n",
      "\n",
      "Stage  147\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00022992548518672385\n",
      "Average loss :  3.5834327150041645e-07\n",
      "\n",
      "\n",
      "Stage  147\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00022992548518672385\n",
      "Average loss :  3.5249891539024247e-07\n",
      "\n",
      "\n",
      "Stage  147\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00022992548518672385\n",
      "Average loss :  3.874676224313589e-07\n",
      "expression length:\t 5\n",
      "Result stage 149: -1.742*sin(x0) + 25.075*cos(x0) + 1.42*x0_t**2 + 19.855*x0_t*sin(x0) + -12.453*x0_t*cos(x0) + \n",
      "exp([0.13993458]*t)\n",
      "\n",
      "\n",
      "Stage  148\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00022763768838381275\n",
      "Average loss :  3.4426992101543874e-07\n",
      "\n",
      "\n",
      "Stage  148\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00022763768838381275\n",
      "Average loss :  3.8408040836657165e-07\n",
      "\n",
      "\n",
      "Stage  148\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00022763768838381275\n",
      "Average loss :  3.7060158319945913e-07\n",
      "\n",
      "\n",
      "Stage  148\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00022763768838381275\n",
      "Average loss :  3.8526030721186544e-07\n",
      "expression length:\t 5\n",
      "Result stage 150: -1.742*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.854*x0_t*sin(x0) + -12.453*x0_t*cos(x0) + \n",
      "exp([0.13996056]*t)\n",
      "\n",
      "\n",
      "Stage  149\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00022537265553943873\n",
      "Average loss :  3.4559650430310285e-07\n",
      "\n",
      "\n",
      "Stage  149\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00022537265553943873\n",
      "Average loss :  5.097957682664855e-07\n",
      "\n",
      "\n",
      "Stage  149\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00022537265553943873\n",
      "Average loss :  3.6673685599453165e-07\n",
      "\n",
      "\n",
      "Stage  149\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00022537265553943873\n",
      "Average loss :  2.9592769124064944e-07\n",
      "expression length:\t 5\n",
      "Result stage 151: -1.742*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.854*x0_t*sin(x0) + -12.452*x0_t*cos(x0) + \n",
      "exp([0.13992421]*t)\n",
      "\n",
      "\n",
      "Stage  150\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00022313016014842982\n",
      "Average loss :  1.8726855444128887e-07\n",
      "\n",
      "\n",
      "Stage  150\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00022313016014842982\n",
      "Average loss :  3.6328995633994055e-07\n",
      "\n",
      "\n",
      "Stage  150\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00022313016014842982\n",
      "Average loss :  3.7050156720397354e-07\n",
      "\n",
      "\n",
      "Stage  150\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00022313016014842982\n",
      "Average loss :  2.776058352083055e-07\n",
      "expression length:\t 5\n",
      "Result stage 152: -1.742*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.853*x0_t*sin(x0) + -12.451*x0_t*cos(x0) + \n",
      "exp([0.13993347]*t)\n",
      "\n",
      "\n",
      "Stage  151\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0002209099779593782\n",
      "Average loss :  3.4426713568791456e-07\n",
      "\n",
      "\n",
      "Stage  151\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0002209099779593782\n",
      "Average loss :  3.5608132975539775e-07\n",
      "\n",
      "\n",
      "Stage  151\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0002209099779593782\n",
      "Average loss :  6.076472232052765e-07\n",
      "\n",
      "\n",
      "Stage  151\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0002209099779593782\n",
      "Average loss :  3.8218792042243876e-07\n",
      "expression length:\t 5\n",
      "Result stage 153: -1.742*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.853*x0_t*sin(x0) + -12.451*x0_t*cos(x0) + \n",
      "exp([0.13990629]*t)\n",
      "\n",
      "\n",
      "Stage  152\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00021871188695221476\n",
      "Average loss :  3.5672576359502273e-07\n",
      "\n",
      "\n",
      "Stage  152\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00021871188695221476\n",
      "Average loss :  4.7603543862351216e-07\n",
      "\n",
      "\n",
      "Stage  152\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00021871188695221476\n",
      "Average loss :  3.504129324483074e-07\n",
      "\n",
      "\n",
      "Stage  152\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00021871188695221476\n",
      "Average loss :  3.404974791010318e-07\n",
      "expression length:\t 5\n",
      "Result stage 154: -1.742*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.853*x0_t*sin(x0) + -12.45*x0_t*cos(x0) + \n",
      "exp([0.13994423]*t)\n",
      "\n",
      "\n",
      "Stage  153\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00021653566731600707\n",
      "Average loss :  3.1441965120393434e-07\n",
      "\n",
      "\n",
      "Stage  153\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00021653566731600707\n",
      "Average loss :  3.1190450044960016e-07\n",
      "\n",
      "\n",
      "Stage  153\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00021653566731600707\n",
      "Average loss :  3.7475194858416216e-07\n",
      "\n",
      "\n",
      "Stage  153\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00021653566731600707\n",
      "Average loss :  2.6826171506399987e-07\n",
      "expression length:\t 5\n",
      "Result stage 155: -1.742*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.852*x0_t*sin(x0) + -12.449*x0_t*cos(x0) + \n",
      "exp([0.13993095]*t)\n",
      "\n",
      "\n",
      "Stage  154\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00021438110142697796\n",
      "Average loss :  3.7070790881443827e-07\n",
      "\n",
      "\n",
      "Stage  154\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00021438110142697796\n",
      "Average loss :  9.254688961846114e-07\n",
      "\n",
      "\n",
      "Stage  154\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00021438110142697796\n",
      "Average loss :  3.4259599601682567e-07\n",
      "\n",
      "\n",
      "Stage  154\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00021438110142697796\n",
      "Average loss :  3.760318350032321e-07\n",
      "expression length:\t 5\n",
      "Result stage 156: -1.742*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.852*x0_t*sin(x0) + -12.449*x0_t*cos(x0) + \n",
      "exp([0.13992465]*t)\n",
      "\n",
      "\n",
      "Stage  155\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00021224797382674306\n",
      "Average loss :  3.334918119435315e-07\n",
      "\n",
      "\n",
      "Stage  155\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00021224797382674306\n",
      "Average loss :  5.394412596615439e-07\n",
      "\n",
      "\n",
      "Stage  155\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00021224797382674306\n",
      "Average loss :  9.172837849291682e-07\n",
      "\n",
      "\n",
      "Stage  155\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00021224797382674306\n",
      "Average loss :  1.6107864553305262e-07\n",
      "expression length:\t 5\n",
      "Result stage 157: -1.742*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.851*x0_t*sin(x0) + -12.448*x0_t*cos(x0) + \n",
      "exp([0.14000396]*t)\n",
      "\n",
      "\n",
      "Stage  156\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00021013607120076472\n",
      "Average loss :  6.226989057722676e-07\n",
      "\n",
      "\n",
      "Stage  156\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00021013607120076472\n",
      "Average loss :  2.9071628659949056e-07\n",
      "\n",
      "\n",
      "Stage  156\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00021013607120076472\n",
      "Average loss :  5.889605745323934e-07\n",
      "\n",
      "\n",
      "Stage  156\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00021013607120076472\n",
      "Average loss :  4.5786700297867355e-07\n",
      "expression length:\t 5\n",
      "Result stage 158: -1.742*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.851*x0_t*sin(x0) + -12.448*x0_t*cos(x0) + \n",
      "exp([0.13988876]*t)\n",
      "\n",
      "\n",
      "Stage  157\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00020804518235702048\n",
      "Average loss :  3.381546207492647e-07\n",
      "\n",
      "\n",
      "Stage  157\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00020804518235702048\n",
      "Average loss :  6.350209673655627e-07\n",
      "\n",
      "\n",
      "Stage  157\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00020804518235702048\n",
      "Average loss :  2.547127451180131e-07\n",
      "\n",
      "\n",
      "Stage  157\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00020804518235702048\n",
      "Average loss :  2.9092089448568004e-07\n",
      "expression length:\t 5\n",
      "Result stage 159: -1.742*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.851*x0_t*sin(x0) + -12.447*x0_t*cos(x0) + \n",
      "exp([0.1399053]*t)\n",
      "\n",
      "\n",
      "Stage  158\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00020597509820488344\n",
      "Average loss :  5.452996560961765e-07\n",
      "\n",
      "\n",
      "Stage  158\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00020597509820488344\n",
      "Average loss :  5.606567583527067e-07\n",
      "\n",
      "\n",
      "Stage  158\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00020597509820488344\n",
      "Average loss :  3.130402319584391e-07\n",
      "\n",
      "\n",
      "Stage  158\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00020597509820488344\n",
      "Average loss :  3.2146013495548686e-07\n",
      "expression length:\t 5\n",
      "Result stage 160: -1.742*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.85*x0_t*sin(x0) + -12.447*x0_t*cos(x0) + \n",
      "exp([0.13996634]*t)\n",
      "\n",
      "\n",
      "Stage  159\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00020392561173421343\n",
      "Average loss :  3.5748053051065654e-07\n",
      "\n",
      "\n",
      "Stage  159\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00020392561173421343\n",
      "Average loss :  1.5370260086911003e-07\n",
      "\n",
      "\n",
      "Stage  159\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00020392561173421343\n",
      "Average loss :  3.065155169679201e-07\n",
      "\n",
      "\n",
      "Stage  159\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00020392561173421343\n",
      "Average loss :  3.1558630553263356e-07\n",
      "expression length:\t 5\n",
      "Result stage 161: -1.741*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.85*x0_t*sin(x0) + -12.446*x0_t*cos(x0) + \n",
      "exp([0.1399651]*t)\n",
      "\n",
      "\n",
      "Stage  160\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00020189651799465538\n",
      "Average loss :  3.3108696584349673e-07\n",
      "\n",
      "\n",
      "Stage  160\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00020189651799465538\n",
      "Average loss :  3.5629653893920477e-07\n",
      "\n",
      "\n",
      "Stage  160\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00020189651799465538\n",
      "Average loss :  3.0323010946631257e-07\n",
      "\n",
      "\n",
      "Stage  160\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00020189651799465538\n",
      "Average loss :  2.895494048971159e-07\n",
      "expression length:\t 5\n",
      "Result stage 162: -1.741*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.849*x0_t*sin(x0) + -12.446*x0_t*cos(x0) + \n",
      "exp([0.13994795]*t)\n",
      "\n",
      "\n",
      "Stage  161\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00019988761407514449\n",
      "Average loss :  5.241144549472665e-07\n",
      "\n",
      "\n",
      "Stage  161\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00019988761407514449\n",
      "Average loss :  3.3516036523906223e-07\n",
      "\n",
      "\n",
      "Stage  161\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00019988761407514449\n",
      "Average loss :  3.5494758776621893e-07\n",
      "\n",
      "\n",
      "Stage  161\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00019988761407514449\n",
      "Average loss :  2.948638666566694e-07\n",
      "expression length:\t 5\n",
      "Result stage 163: -1.741*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.849*x0_t*sin(x0) + -12.445*x0_t*cos(x0) + \n",
      "exp([0.13995788]*t)\n",
      "\n",
      "\n",
      "Stage  162\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00019789869908361465\n",
      "Average loss :  5.048745492786111e-07\n",
      "\n",
      "\n",
      "Stage  162\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00019789869908361465\n",
      "Average loss :  2.975045561015577e-07\n",
      "\n",
      "\n",
      "Stage  162\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00019789869908361465\n",
      "Average loss :  3.3736893101377063e-07\n",
      "\n",
      "\n",
      "Stage  162\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00019789869908361465\n",
      "Average loss :  2.8071923452444025e-07\n",
      "expression length:\t 5\n",
      "Result stage 164: -1.741*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.849*x0_t*sin(x0) + -12.445*x0_t*cos(x0) + \n",
      "exp([0.13995412]*t)\n",
      "\n",
      "\n",
      "Stage  163\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00019592957412690933\n",
      "Average loss :  2.2013661293840414e-07\n",
      "\n",
      "\n",
      "Stage  163\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00019592957412690933\n",
      "Average loss :  3.0316661536744505e-07\n",
      "\n",
      "\n",
      "Stage  163\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00019592957412690933\n",
      "Average loss :  2.799006892928446e-07\n",
      "\n",
      "\n",
      "Stage  163\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00019592957412690933\n",
      "Average loss :  3.0186228627826495e-07\n",
      "expression length:\t 5\n",
      "Result stage 165: -1.741*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.848*x0_t*sin(x0) + -12.444*x0_t*cos(x0) + \n",
      "exp([0.13992769]*t)\n",
      "\n",
      "\n",
      "Stage  164\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00019398004229089188\n",
      "Average loss :  4.4541636157191533e-07\n",
      "\n",
      "\n",
      "Stage  164\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00019398004229089188\n",
      "Average loss :  4.004465665730095e-07\n",
      "\n",
      "\n",
      "Stage  164\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00019398004229089188\n",
      "Average loss :  4.3348373424123565e-07\n",
      "\n",
      "\n",
      "Stage  164\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00019398004229089188\n",
      "Average loss :  2.677682573448692e-07\n",
      "expression length:\t 5\n",
      "Result stage 166: -1.741*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.848*x0_t*sin(x0) + -12.444*x0_t*cos(x0) + \n",
      "exp([0.13992251]*t)\n",
      "\n",
      "\n",
      "Stage  165\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001920499086207541\n",
      "Average loss :  1.944419665278474e-07\n",
      "\n",
      "\n",
      "Stage  165\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001920499086207541\n",
      "Average loss :  3.0640663339909224e-07\n",
      "\n",
      "\n",
      "Stage  165\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001920499086207541\n",
      "Average loss :  2.510244598852296e-07\n",
      "\n",
      "\n",
      "Stage  165\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001920499086207541\n",
      "Average loss :  2.508183456484403e-07\n",
      "expression length:\t 5\n",
      "Result stage 167: -1.741*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.848*x0_t*sin(x0) + -12.444*x0_t*cos(x0) + \n",
      "exp([0.13991223]*t)\n",
      "\n",
      "\n",
      "Stage  166\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001901389801015205\n",
      "Average loss :  2.454972900522989e-07\n",
      "\n",
      "\n",
      "Stage  166\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001901389801015205\n",
      "Average loss :  2.644647736360639e-07\n",
      "\n",
      "\n",
      "Stage  166\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001901389801015205\n",
      "Average loss :  2.6915151352113753e-07\n",
      "\n",
      "\n",
      "Stage  166\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001901389801015205\n",
      "Average loss :  2.6605539460433647e-07\n",
      "expression length:\t 5\n",
      "Result stage 168: -1.741*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.848*x0_t*sin(x0) + -12.443*x0_t*cos(x0) + \n",
      "exp([0.13992502]*t)\n",
      "\n",
      "\n",
      "Stage  167\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001882470656387468\n",
      "Average loss :  6.928378866177809e-07\n",
      "\n",
      "\n",
      "Stage  167\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001882470656387468\n",
      "Average loss :  2.6748270443022193e-07\n",
      "\n",
      "\n",
      "Stage  167\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001882470656387468\n",
      "Average loss :  4.805552862308105e-07\n",
      "\n",
      "\n",
      "Stage  167\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001882470656387468\n",
      "Average loss :  2.8398440576893336e-07\n",
      "expression length:\t 5\n",
      "Result stage 169: -1.741*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.847*x0_t*sin(x0) + -12.443*x0_t*cos(x0) + \n",
      "exp([0.13993305]*t)\n",
      "\n",
      "\n",
      "Stage  168\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00018637397603940998\n",
      "Average loss :  2.327450800976294e-07\n",
      "\n",
      "\n",
      "Stage  168\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00018637397603940998\n",
      "Average loss :  2.495768569588108e-07\n",
      "\n",
      "\n",
      "Stage  168\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00018637397603940998\n",
      "Average loss :  2.467561444063904e-07\n",
      "\n",
      "\n",
      "Stage  168\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00018637397603940998\n",
      "Average loss :  2.4801511244731955e-07\n",
      "expression length:\t 5\n",
      "Result stage 170: -1.741*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.847*x0_t*sin(x0) + -12.442*x0_t*cos(x0) + \n",
      "exp([0.13995548]*t)\n",
      "\n",
      "\n",
      "Stage  169\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00018451952399298926\n",
      "Average loss :  2.4689188649063e-07\n",
      "\n",
      "\n",
      "Stage  169\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00018451952399298926\n",
      "Average loss :  2.952958482183021e-07\n",
      "\n",
      "\n",
      "Stage  169\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00018451952399298926\n",
      "Average loss :  2.5075163989640714e-07\n",
      "\n",
      "\n",
      "Stage  169\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00018451952399298926\n",
      "Average loss :  2.0325329330717068e-07\n",
      "expression length:\t 5\n",
      "Result stage 171: -1.741*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.847*x0_t*sin(x0) + -12.442*x0_t*cos(x0) + \n",
      "exp([0.13993385]*t)\n",
      "\n",
      "\n",
      "Stage  170\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00018268352405273466\n",
      "Average loss :  2.2416618605802796e-07\n",
      "\n",
      "\n",
      "Stage  170\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00018268352405273466\n",
      "Average loss :  4.959036914442549e-07\n",
      "\n",
      "\n",
      "Stage  170\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00018268352405273466\n",
      "Average loss :  5.616390126306214e-07\n",
      "\n",
      "\n",
      "Stage  170\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00018268352405273466\n",
      "Average loss :  4.277283949249977e-07\n",
      "expression length:\t 5\n",
      "Result stage 172: -1.741*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.846*x0_t*sin(x0) + -12.442*x0_t*cos(x0) + \n",
      "exp([0.13990912]*t)\n",
      "\n",
      "\n",
      "Stage  171\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001808657926171221\n",
      "Average loss :  2.3271408622349554e-07\n",
      "\n",
      "\n",
      "Stage  171\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001808657926171221\n",
      "Average loss :  4.5283618987923546e-07\n",
      "\n",
      "\n",
      "Stage  171\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001808657926171221\n",
      "Average loss :  2.1885128376197827e-07\n",
      "\n",
      "\n",
      "Stage  171\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001808657926171221\n",
      "Average loss :  1.6919200618303876e-07\n",
      "expression length:\t 5\n",
      "Result stage 173: -1.741*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.846*x0_t*sin(x0) + -12.441*x0_t*cos(x0) + \n",
      "exp([0.13995625]*t)\n",
      "\n",
      "\n",
      "Stage  172\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00017906614791149322\n",
      "Average loss :  2.3739218590890232e-07\n",
      "\n",
      "\n",
      "Stage  172\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00017906614791149322\n",
      "Average loss :  2.3821631600640103e-07\n",
      "\n",
      "\n",
      "Stage  172\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00017906614791149322\n",
      "Average loss :  4.462403637717216e-07\n",
      "\n",
      "\n",
      "Stage  172\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00017906614791149322\n",
      "Average loss :  2.282808395648317e-07\n",
      "expression length:\t 5\n",
      "Result stage 174: -1.741*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.846*x0_t*sin(x0) + -12.441*x0_t*cos(x0) + \n",
      "exp([0.13995574]*t)\n",
      "\n",
      "\n",
      "Stage  173\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00017728440996987783\n",
      "Average loss :  2.336600601893224e-07\n",
      "\n",
      "\n",
      "Stage  173\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00017728440996987783\n",
      "Average loss :  3.3096497986662143e-07\n",
      "\n",
      "\n",
      "Stage  173\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00017728440996987783\n",
      "Average loss :  1.7624917347802693e-07\n",
      "\n",
      "\n",
      "Stage  173\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00017728440996987783\n",
      "Average loss :  2.9218156782917504e-07\n",
      "expression length:\t 5\n",
      "Result stage 175: -1.741*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.845*x0_t*sin(x0) + -12.441*x0_t*cos(x0) + \n",
      "exp([0.13991068]*t)\n",
      "\n",
      "\n",
      "Stage  174\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00017552040061699688\n",
      "Average loss :  2.2605458127600286e-07\n",
      "\n",
      "\n",
      "Stage  174\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00017552040061699688\n",
      "Average loss :  4.514679403655464e-07\n",
      "\n",
      "\n",
      "Stage  174\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00017552040061699688\n",
      "Average loss :  2.1842163278051885e-07\n",
      "\n",
      "\n",
      "Stage  174\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00017552040061699688\n",
      "Average loss :  2.0367896524930984e-07\n",
      "expression length:\t 5\n",
      "Result stage 176: -1.741*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.845*x0_t*sin(x0) + -12.44*x0_t*cos(x0) + \n",
      "exp([0.13991857]*t)\n",
      "\n",
      "\n",
      "Stage  175\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00017377394345044513\n",
      "Average loss :  2.2870800364671595e-07\n",
      "\n",
      "\n",
      "Stage  175\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00017377394345044513\n",
      "Average loss :  2.298329775385355e-07\n",
      "\n",
      "\n",
      "Stage  175\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00017377394345044513\n",
      "Average loss :  5.017724902245391e-07\n",
      "\n",
      "\n",
      "Stage  175\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00017377394345044513\n",
      "Average loss :  2.1848165943083586e-07\n",
      "expression length:\t 5\n",
      "Result stage 177: -1.741*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.845*x0_t*sin(x0) + -12.44*x0_t*cos(x0) + \n",
      "exp([0.13994527]*t)\n",
      "\n",
      "\n",
      "Stage  176\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00017204486382305055\n",
      "Average loss :  2.573680433215486e-07\n",
      "\n",
      "\n",
      "Stage  176\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00017204486382305055\n",
      "Average loss :  4.848174626204127e-07\n",
      "\n",
      "\n",
      "Stage  176\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00017204486382305055\n",
      "Average loss :  2.010964550436256e-07\n",
      "\n",
      "\n",
      "Stage  176\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00017204486382305055\n",
      "Average loss :  3.527635783484584e-07\n",
      "expression length:\t 5\n",
      "Result stage 178: -1.74*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.845*x0_t*sin(x0) + -12.44*x0_t*cos(x0) + \n",
      "exp([0.13992903]*t)\n",
      "\n",
      "\n",
      "Stage  177\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00017033298882540942\n",
      "Average loss :  1.9313290522404714e-07\n",
      "\n",
      "\n",
      "Stage  177\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00017033298882540942\n",
      "Average loss :  2.0625387264772144e-07\n",
      "\n",
      "\n",
      "Stage  177\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00017033298882540942\n",
      "Average loss :  2.1917992398812203e-07\n",
      "\n",
      "\n",
      "Stage  177\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00017033298882540942\n",
      "Average loss :  2.774792449145025e-07\n",
      "expression length:\t 5\n",
      "Result stage 179: -1.741*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.844*x0_t*sin(x0) + -12.439*x0_t*cos(x0) + \n",
      "exp([0.13994306]*t)\n",
      "\n",
      "\n",
      "Stage  178\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001686381472685955\n",
      "Average loss :  3.152699150632543e-07\n",
      "\n",
      "\n",
      "Stage  178\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001686381472685955\n",
      "Average loss :  1.5444759071669978e-07\n",
      "\n",
      "\n",
      "Stage  178\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001686381472685955\n",
      "Average loss :  2.019527158836354e-07\n",
      "\n",
      "\n",
      "Stage  178\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001686381472685955\n",
      "Average loss :  1.635348212403187e-07\n",
      "expression length:\t 5\n",
      "Result stage 180: -1.741*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.844*x0_t*sin(x0) + -12.439*x0_t*cos(x0) + \n",
      "exp([0.1399454]*t)\n",
      "\n",
      "\n",
      "Stage  179\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00016696016966704069\n",
      "Average loss :  2.0526600508219417e-07\n",
      "\n",
      "\n",
      "Stage  179\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00016696016966704069\n",
      "Average loss :  2.929758409209171e-07\n",
      "\n",
      "\n",
      "Stage  179\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00016696016966704069\n",
      "Average loss :  5.275765602164029e-07\n",
      "\n",
      "\n",
      "Stage  179\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00016696016966704069\n",
      "Average loss :  3.800406034315529e-07\n",
      "expression length:\t 5\n",
      "Result stage 181: -1.74*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.844*x0_t*sin(x0) + -12.438*x0_t*cos(x0) + \n",
      "exp([0.13992149]*t)\n",
      "\n",
      "\n",
      "Stage  180\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00016529888822158653\n",
      "Average loss :  2.007242159152156e-07\n",
      "\n",
      "\n",
      "Stage  180\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00016529888822158653\n",
      "Average loss :  1.848272574989096e-07\n",
      "\n",
      "\n",
      "Stage  180\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00016529888822158653\n",
      "Average loss :  2.0362327290968096e-07\n",
      "\n",
      "\n",
      "Stage  180\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00016529888822158653\n",
      "Average loss :  1.0017731710831868e-07\n",
      "expression length:\t 5\n",
      "Result stage 182: -1.741*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.844*x0_t*sin(x0) + -12.438*x0_t*cos(x0) + \n",
      "exp([0.14000945]*t)\n",
      "\n",
      "\n",
      "Stage  181\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00016365413680270404\n",
      "Average loss :  1.9628637915047875e-07\n",
      "\n",
      "\n",
      "Stage  181\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00016365413680270404\n",
      "Average loss :  1.8304500315480254e-07\n",
      "\n",
      "\n",
      "Stage  181\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00016365413680270404\n",
      "Average loss :  1.8148307390219998e-07\n",
      "\n",
      "\n",
      "Stage  181\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00016365413680270404\n",
      "Average loss :  1.983703725727537e-07\n",
      "expression length:\t 5\n",
      "Result stage 183: -1.74*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.843*x0_t*sin(x0) + -12.438*x0_t*cos(x0) + \n",
      "exp([0.13994989]*t)\n",
      "\n",
      "\n",
      "Stage  182\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00016202575093388075\n",
      "Average loss :  1.9675528051266156e-07\n",
      "\n",
      "\n",
      "Stage  182\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00016202575093388075\n",
      "Average loss :  2.3287469730348676e-07\n",
      "\n",
      "\n",
      "Stage  182\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00016202575093388075\n",
      "Average loss :  1.97320304096138e-07\n",
      "\n",
      "\n",
      "Stage  182\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00016202575093388075\n",
      "Average loss :  3.7200811675575096e-07\n",
      "expression length:\t 5\n",
      "Result stage 184: -1.74*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.843*x0_t*sin(x0) + -12.438*x0_t*cos(x0) + \n",
      "exp([0.13991222]*t)\n",
      "\n",
      "\n",
      "Stage  183\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00016041356777517275\n",
      "Average loss :  1.9435009335211362e-07\n",
      "\n",
      "\n",
      "Stage  183\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00016041356777517275\n",
      "Average loss :  1.7351956671518565e-07\n",
      "\n",
      "\n",
      "Stage  183\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00016041356777517275\n",
      "Average loss :  1.7462448909100203e-07\n",
      "\n",
      "\n",
      "Stage  183\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00016041356777517275\n",
      "Average loss :  1.8991532613199524e-07\n",
      "expression length:\t 5\n",
      "Result stage 185: -1.74*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.843*x0_t*sin(x0) + -12.437*x0_t*cos(x0) + \n",
      "exp([0.13996553]*t)\n",
      "\n",
      "\n",
      "Stage  184\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00015881742610692067\n",
      "Average loss :  2.927893376636348e-07\n",
      "\n",
      "\n",
      "Stage  184\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00015881742610692067\n",
      "Average loss :  3.7962806231917057e-07\n",
      "\n",
      "\n",
      "Stage  184\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00015881742610692067\n",
      "Average loss :  1.8012386249210977e-07\n",
      "\n",
      "\n",
      "Stage  184\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00015881742610692067\n",
      "Average loss :  1.8604036711167282e-07\n",
      "expression length:\t 5\n",
      "Result stage 186: -1.74*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.843*x0_t*sin(x0) + -12.437*x0_t*cos(x0) + \n",
      "exp([0.13996656]*t)\n",
      "\n",
      "\n",
      "Stage  185\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00015723716631362762\n",
      "Average loss :  4.2241970277245855e-07\n",
      "\n",
      "\n",
      "Stage  185\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00015723716631362762\n",
      "Average loss :  1.6809283920338203e-07\n",
      "\n",
      "\n",
      "Stage  185\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00015723716631362762\n",
      "Average loss :  1.8825328140792408e-07\n",
      "\n",
      "\n",
      "Stage  185\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00015723716631362762\n",
      "Average loss :  1.6536601776806492e-07\n",
      "expression length:\t 5\n",
      "Result stage 187: -1.74*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.842*x0_t*sin(x0) + -12.436*x0_t*cos(x0) + \n",
      "exp([0.13993095]*t)\n",
      "\n",
      "\n",
      "Stage  186\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001556726303679973\n",
      "Average loss :  2.1052460397186223e-07\n",
      "\n",
      "\n",
      "Stage  186\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001556726303679973\n",
      "Average loss :  1.6546614745038823e-07\n",
      "\n",
      "\n",
      "Stage  186\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001556726303679973\n",
      "Average loss :  3.4872547871600545e-07\n",
      "\n",
      "\n",
      "Stage  186\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001556726303679973\n",
      "Average loss :  1.8680741220578057e-07\n",
      "expression length:\t 5\n",
      "Result stage 188: -1.74*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.842*x0_t*sin(x0) + -12.436*x0_t*cos(x0) + \n",
      "exp([0.13994364]*t)\n",
      "\n",
      "\n",
      "Stage  187\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001541236618151314\n",
      "Average loss :  1.7020308007431595e-07\n",
      "\n",
      "\n",
      "Stage  187\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001541236618151314\n",
      "Average loss :  8.371975468435267e-08\n",
      "\n",
      "\n",
      "Stage  187\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001541236618151314\n",
      "Average loss :  3.7237447259030887e-07\n",
      "\n",
      "\n",
      "Stage  187\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001541236618151314\n",
      "Average loss :  1.721376889918247e-07\n",
      "expression length:\t 5\n",
      "Result stage 189: -1.74*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.842*x0_t*sin(x0) + -12.436*x0_t*cos(x0) + \n",
      "exp([0.13996033]*t)\n",
      "\n",
      "\n",
      "Stage  188\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00015259010575688386\n",
      "Average loss :  1.6613556397260254e-07\n",
      "\n",
      "\n",
      "Stage  188\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00015259010575688386\n",
      "Average loss :  1.6681237013926875e-07\n",
      "\n",
      "\n",
      "Stage  188\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00015259010575688386\n",
      "Average loss :  3.1245573950400285e-07\n",
      "\n",
      "\n",
      "Stage  188\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00015259010575688386\n",
      "Average loss :  1.566253189366762e-07\n",
      "expression length:\t 5\n",
      "Result stage 190: -1.74*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.841*x0_t*sin(x0) + -12.435*x0_t*cos(x0) + \n",
      "exp([0.13992633]*t)\n",
      "\n",
      "\n",
      "Stage  189\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00015107180883637084\n",
      "Average loss :  2.124593407870634e-07\n",
      "\n",
      "\n",
      "Stage  189\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00015107180883637084\n",
      "Average loss :  1.6351357601251948e-07\n",
      "\n",
      "\n",
      "Stage  189\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00015107180883637084\n",
      "Average loss :  1.6193632745853392e-07\n",
      "\n",
      "\n",
      "Stage  189\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00015107180883637084\n",
      "Average loss :  1.674934253514948e-07\n",
      "expression length:\t 5\n",
      "Result stage 191: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.841*x0_t*sin(x0) + -12.435*x0_t*cos(x0) + \n",
      "exp([0.13996997]*t)\n",
      "\n",
      "\n",
      "Stage  190\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00014956861922263504\n",
      "Average loss :  3.5664240272126335e-07\n",
      "\n",
      "\n",
      "Stage  190\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00014956861922263504\n",
      "Average loss :  1.5016188115168916e-07\n",
      "\n",
      "\n",
      "Stage  190\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00014956861922263504\n",
      "Average loss :  1.4059050101877801e-07\n",
      "\n",
      "\n",
      "Stage  190\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00014956861922263504\n",
      "Average loss :  1.4923809033007274e-07\n",
      "expression length:\t 5\n",
      "Result stage 192: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.841*x0_t*sin(x0) + -12.435*x0_t*cos(x0) + \n",
      "exp([0.13993376]*t)\n",
      "\n",
      "\n",
      "Stage  191\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00014808038659546244\n",
      "Average loss :  3.9362734582937264e-07\n",
      "\n",
      "\n",
      "Stage  191\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00014808038659546244\n",
      "Average loss :  1.450212607778667e-07\n",
      "\n",
      "\n",
      "Stage  191\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00014808038659546244\n",
      "Average loss :  1.4632936995440105e-07\n",
      "\n",
      "\n",
      "Stage  191\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00014808038659546244\n",
      "Average loss :  1.4767186939934618e-07\n",
      "expression length:\t 5\n",
      "Result stage 193: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.841*x0_t*sin(x0) + -12.435*x0_t*cos(x0) + \n",
      "exp([0.13993344]*t)\n",
      "\n",
      "\n",
      "Stage  192\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00014660696213035016\n",
      "Average loss :  1.4435130424317322e-07\n",
      "\n",
      "\n",
      "Stage  192\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00014660696213035016\n",
      "Average loss :  1.596221181898727e-07\n",
      "\n",
      "\n",
      "Stage  192\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00014660696213035016\n",
      "Average loss :  1.440852344103405e-07\n",
      "\n",
      "\n",
      "Stage  192\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00014660696213035016\n",
      "Average loss :  1.624456729132362e-07\n",
      "expression length:\t 5\n",
      "Result stage 194: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.841*x0_t*sin(x0) + -12.434*x0_t*cos(x0) + \n",
      "exp([0.13997616]*t)\n",
      "\n",
      "\n",
      "Stage  193\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00014514819848362374\n",
      "Average loss :  4.1931167515940615e-07\n",
      "\n",
      "\n",
      "Stage  193\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00014514819848362374\n",
      "Average loss :  1.3979511948036816e-07\n",
      "\n",
      "\n",
      "Stage  193\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00014514819848362374\n",
      "Average loss :  1.429799425523015e-07\n",
      "\n",
      "\n",
      "Stage  193\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00014514819848362374\n",
      "Average loss :  1.426112561375703e-07\n",
      "expression length:\t 5\n",
      "Result stage 195: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.84*x0_t*sin(x0) + -12.434*x0_t*cos(x0) + \n",
      "exp([0.13993208]*t)\n",
      "\n",
      "\n",
      "Stage  194\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00014370394977770293\n",
      "Average loss :  2.1778895131774334e-07\n",
      "\n",
      "\n",
      "Stage  194\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00014370394977770293\n",
      "Average loss :  1.0848025766563296e-07\n",
      "\n",
      "\n",
      "Stage  194\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00014370394977770293\n",
      "Average loss :  1.5419752230627637e-07\n",
      "\n",
      "\n",
      "Stage  194\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00014370394977770293\n",
      "Average loss :  1.3871992621261597e-07\n",
      "expression length:\t 5\n",
      "Result stage 196: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.84*x0_t*sin(x0) + -12.434*x0_t*cos(x0) + \n",
      "exp([0.13993049]*t)\n",
      "\n",
      "\n",
      "Stage  195\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00014227407158651359\n",
      "Average loss :  1.5086187943325058e-07\n",
      "\n",
      "\n",
      "Stage  195\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00014227407158651359\n",
      "Average loss :  1.302634444755313e-07\n",
      "\n",
      "\n",
      "Stage  195\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00014227407158651359\n",
      "Average loss :  1.4930780878330552e-07\n",
      "\n",
      "\n",
      "Stage  195\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00014227407158651359\n",
      "Average loss :  1.3566925360919413e-07\n",
      "expression length:\t 5\n",
      "Result stage 197: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.84*x0_t*sin(x0) + -12.434*x0_t*cos(x0) + \n",
      "exp([0.13993135]*t)\n",
      "\n",
      "\n",
      "Stage  196\n",
      "Epoch 50/200\n",
      "Learning rate :  0.000140858420921045\n",
      "Average loss :  1.3079640837077022e-07\n",
      "\n",
      "\n",
      "Stage  196\n",
      "Epoch 100/200\n",
      "Learning rate :  0.000140858420921045\n",
      "Average loss :  1.492311270112623e-07\n",
      "\n",
      "\n",
      "Stage  196\n",
      "Epoch 150/200\n",
      "Learning rate :  0.000140858420921045\n",
      "Average loss :  1.5189266378001776e-07\n",
      "\n",
      "\n",
      "Stage  196\n",
      "Epoch 200/200\n",
      "Learning rate :  0.000140858420921045\n",
      "Average loss :  2.7636855293167173e-07\n",
      "expression length:\t 5\n",
      "Result stage 198: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.84*x0_t*sin(x0) + -12.434*x0_t*cos(x0) + \n",
      "exp([0.13992533]*t)\n",
      "\n",
      "\n",
      "Stage  197\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00013945685621505094\n",
      "Average loss :  2.5083585342144943e-07\n",
      "\n",
      "\n",
      "Stage  197\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00013945685621505094\n",
      "Average loss :  1.4310218432456168e-07\n",
      "\n",
      "\n",
      "Stage  197\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00013945685621505094\n",
      "Average loss :  1.407545369147556e-07\n",
      "\n",
      "\n",
      "Stage  197\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00013945685621505094\n",
      "Average loss :  1.2815750949357607e-07\n",
      "expression length:\t 5\n",
      "Result stage 199: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.84*x0_t*sin(x0) + -12.433*x0_t*cos(x0) + \n",
      "exp([0.13993572]*t)\n",
      "\n",
      "\n",
      "Stage  198\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00013806923731089283\n",
      "Average loss :  1.0499346814185628e-07\n",
      "\n",
      "\n",
      "Stage  198\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00013806923731089283\n",
      "Average loss :  1.4273076942572516e-07\n",
      "\n",
      "\n",
      "Stage  198\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00013806923731089283\n",
      "Average loss :  1.9824899766263115e-07\n",
      "\n",
      "\n",
      "Stage  198\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00013806923731089283\n",
      "Average loss :  2.614988261484541e-07\n",
      "expression length:\t 5\n",
      "Result stage 200: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.84*x0_t*sin(x0) + -12.433*x0_t*cos(x0) + \n",
      "exp([0.13993554]*t)\n",
      "\n",
      "\n",
      "Stage  199\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00013669542544552385\n",
      "Average loss :  1.6849867279233877e-07\n",
      "\n",
      "\n",
      "Stage  199\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00013669542544552385\n",
      "Average loss :  1.583079551892297e-07\n",
      "\n",
      "\n",
      "Stage  199\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00013669542544552385\n",
      "Average loss :  1.2541447347302892e-07\n",
      "\n",
      "\n",
      "Stage  199\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00013669542544552385\n",
      "Average loss :  1.337228638931265e-07\n",
      "expression length:\t 5\n",
      "Result stage 201: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.84*x0_t*sin(x0) + -12.433*x0_t*cos(x0) + \n",
      "exp([0.1399591]*t)\n",
      "\n",
      "\n",
      "Stage  200\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001353352832366127\n",
      "Average loss :  1.315362823106625e-07\n",
      "\n",
      "\n",
      "Stage  200\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001353352832366127\n",
      "Average loss :  2.8149074182692857e-07\n",
      "\n",
      "\n",
      "Stage  200\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001353352832366127\n",
      "Average loss :  1.2530364301710506e-07\n",
      "\n",
      "\n",
      "Stage  200\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001353352832366127\n",
      "Average loss :  1.7764175197498844e-07\n",
      "expression length:\t 5\n",
      "Result stage 202: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.839*x0_t*sin(x0) + -12.432*x0_t*cos(x0) + \n",
      "exp([0.13993025]*t)\n",
      "\n",
      "\n",
      "Stage  201\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00013398867466880493\n",
      "Average loss :  1.2288238337987423e-07\n",
      "\n",
      "\n",
      "Stage  201\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00013398867466880493\n",
      "Average loss :  1.1891750517634136e-07\n",
      "\n",
      "\n",
      "Stage  201\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00013398867466880493\n",
      "Average loss :  1.1575708924738137e-07\n",
      "\n",
      "\n",
      "Stage  201\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00013398867466880493\n",
      "Average loss :  1.0719126208869056e-07\n",
      "expression length:\t 5\n",
      "Result stage 203: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.839*x0_t*sin(x0) + -12.432*x0_t*cos(x0) + \n",
      "exp([0.13995181]*t)\n",
      "\n",
      "\n",
      "Stage  202\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001326554650801217\n",
      "Average loss :  1.1902666585683619e-07\n",
      "\n",
      "\n",
      "Stage  202\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001326554650801217\n",
      "Average loss :  1.1912315756035241e-07\n",
      "\n",
      "\n",
      "Stage  202\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001326554650801217\n",
      "Average loss :  1.6897062948828534e-07\n",
      "\n",
      "\n",
      "Stage  202\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001326554650801217\n",
      "Average loss :  1.5965648003657407e-07\n",
      "expression length:\t 5\n",
      "Result stage 204: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.839*x0_t*sin(x0) + -12.432*x0_t*cos(x0) + \n",
      "exp([0.13993455]*t)\n",
      "\n",
      "\n",
      "Stage  203\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00013133552114849304\n",
      "Average loss :  1.2764037649048987e-07\n",
      "\n",
      "\n",
      "Stage  203\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00013133552114849304\n",
      "Average loss :  1.1695058077521026e-07\n",
      "\n",
      "\n",
      "Stage  203\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00013133552114849304\n",
      "Average loss :  1.2650809821934672e-07\n",
      "\n",
      "\n",
      "Stage  203\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00013133552114849304\n",
      "Average loss :  1.6501719812822557e-07\n",
      "expression length:\t 5\n",
      "Result stage 205: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.839*x0_t*sin(x0) + -12.432*x0_t*cos(x0) + \n",
      "exp([0.13993248]*t)\n",
      "\n",
      "\n",
      "Stage  204\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00013002871087842592\n",
      "Average loss :  1.1435362523570802e-07\n",
      "\n",
      "\n",
      "Stage  204\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00013002871087842592\n",
      "Average loss :  1.1351900042200214e-07\n",
      "\n",
      "\n",
      "Stage  204\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00013002871087842592\n",
      "Average loss :  3.186667925092479e-07\n",
      "\n",
      "\n",
      "Stage  204\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00013002871087842592\n",
      "Average loss :  2.272863213192977e-07\n",
      "expression length:\t 5\n",
      "Result stage 206: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.839*x0_t*sin(x0) + -12.432*x0_t*cos(x0) + \n",
      "exp([0.1399343]*t)\n",
      "\n",
      "\n",
      "Stage  205\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00012873490358780425\n",
      "Average loss :  1.2445296704299835e-07\n",
      "\n",
      "\n",
      "Stage  205\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00012873490358780425\n",
      "Average loss :  1.2084471734397084e-07\n",
      "\n",
      "\n",
      "Stage  205\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00012873490358780425\n",
      "Average loss :  2.134042347279319e-07\n",
      "\n",
      "\n",
      "Stage  205\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00012873490358780425\n",
      "Average loss :  2.0419102497726271e-07\n",
      "expression length:\t 5\n",
      "Result stage 207: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.839*x0_t*sin(x0) + -12.432*x0_t*cos(x0) + \n",
      "exp([0.13994412]*t)\n",
      "\n",
      "\n",
      "Stage  206\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00012745396989482074\n",
      "Average loss :  1.923659596059224e-07\n",
      "\n",
      "\n",
      "Stage  206\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00012745396989482074\n",
      "Average loss :  1.281483861248489e-07\n",
      "\n",
      "\n",
      "Stage  206\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00012745396989482074\n",
      "Average loss :  1.9303581666463288e-07\n",
      "\n",
      "\n",
      "Stage  206\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00012745396989482074\n",
      "Average loss :  1.2156776563188032e-07\n",
      "expression length:\t 5\n",
      "Result stage 208: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.838*x0_t*sin(x0) + -12.431*x0_t*cos(x0) + \n",
      "exp([0.13997534]*t)\n",
      "\n",
      "\n",
      "Stage  207\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00012618578170503877\n",
      "Average loss :  1.2589863729317585e-07\n",
      "\n",
      "\n",
      "Stage  207\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00012618578170503877\n",
      "Average loss :  1.0848236087213081e-07\n",
      "\n",
      "\n",
      "Stage  207\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00012618578170503877\n",
      "Average loss :  1.067224886242002e-07\n",
      "\n",
      "\n",
      "Stage  207\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00012618578170503877\n",
      "Average loss :  1.1302888935915689e-07\n",
      "expression length:\t 5\n",
      "Result stage 209: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.838*x0_t*sin(x0) + -12.431*x0_t*cos(x0) + \n",
      "exp([0.13996819]*t)\n",
      "\n",
      "\n",
      "Stage  208\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00012493021219858242\n",
      "Average loss :  1.0433839747747697e-07\n",
      "\n",
      "\n",
      "Stage  208\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00012493021219858242\n",
      "Average loss :  1.1597452242995132e-07\n",
      "\n",
      "\n",
      "Stage  208\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00012493021219858242\n",
      "Average loss :  1.3926837993949448e-07\n",
      "\n",
      "\n",
      "Stage  208\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00012493021219858242\n",
      "Average loss :  1.0463558197670864e-07\n",
      "expression length:\t 5\n",
      "Result stage 210: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.838*x0_t*sin(x0) + -12.431*x0_t*cos(x0) + \n",
      "exp([0.13993973]*t)\n",
      "\n",
      "\n",
      "Stage  209\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00012368713581745484\n",
      "Average loss :  2.357075601366887e-07\n",
      "\n",
      "\n",
      "Stage  209\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00012368713581745484\n",
      "Average loss :  1.129010200884295e-07\n",
      "\n",
      "\n",
      "Stage  209\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00012368713581745484\n",
      "Average loss :  1.207823316917711e-07\n",
      "\n",
      "\n",
      "Stage  209\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00012368713581745484\n",
      "Average loss :  1.040882722236347e-07\n",
      "expression length:\t 5\n",
      "Result stage 211: -1.74*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.838*x0_t*sin(x0) + -12.431*x0_t*cos(x0) + \n",
      "exp([0.13994206]*t)\n",
      "\n",
      "\n",
      "Stage  210\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001224564282529819\n",
      "Average loss :  1.0242929704418202e-07\n",
      "\n",
      "\n",
      "Stage  210\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001224564282529819\n",
      "Average loss :  1.0664314231689787e-07\n",
      "\n",
      "\n",
      "Stage  210\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001224564282529819\n",
      "Average loss :  1.900291408674093e-07\n",
      "\n",
      "\n",
      "Stage  210\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001224564282529819\n",
      "Average loss :  1.122628248140245e-07\n",
      "expression length:\t 5\n",
      "Result stage 212: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.838*x0_t*sin(x0) + -12.431*x0_t*cos(x0) + \n",
      "exp([0.13997625]*t)\n",
      "\n",
      "\n",
      "Stage  211\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00012123796643338168\n",
      "Average loss :  8.286111352617809e-08\n",
      "\n",
      "\n",
      "Stage  211\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00012123796643338168\n",
      "Average loss :  1.1208840078325011e-07\n",
      "\n",
      "\n",
      "Stage  211\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00012123796643338168\n",
      "Average loss :  1.0708789233149218e-07\n",
      "\n",
      "\n",
      "Stage  211\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00012123796643338168\n",
      "Average loss :  9.692844571418391e-08\n",
      "expression length:\t 5\n",
      "Result stage 213: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.838*x0_t*sin(x0) + -12.43*x0_t*cos(x0) + \n",
      "exp([0.13994399]*t)\n",
      "\n",
      "\n",
      "Stage  212\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00012003162851145672\n",
      "Average loss :  1.6613675768439862e-07\n",
      "\n",
      "\n",
      "Stage  212\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00012003162851145672\n",
      "Average loss :  1.0979856313042546e-07\n",
      "\n",
      "\n",
      "Stage  212\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00012003162851145672\n",
      "Average loss :  1.0291876861856508e-07\n",
      "\n",
      "\n",
      "Stage  212\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00012003162851145672\n",
      "Average loss :  1.170335437450376e-07\n",
      "expression length:\t 5\n",
      "Result stage 214: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.837*x0_t*sin(x0) + -12.43*x0_t*cos(x0) + \n",
      "exp([0.13995135]*t)\n",
      "\n",
      "\n",
      "Stage  213\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00011883729385240965\n",
      "Average loss :  7.72238095692046e-08\n",
      "\n",
      "\n",
      "Stage  213\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00011883729385240965\n",
      "Average loss :  1.0715309883835289e-07\n",
      "\n",
      "\n",
      "Stage  213\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00011883729385240965\n",
      "Average loss :  8.809688978317354e-08\n",
      "\n",
      "\n",
      "Stage  213\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00011883729385240965\n",
      "Average loss :  1.221945211682396e-07\n",
      "expression length:\t 5\n",
      "Result stage 215: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.837*x0_t*sin(x0) + -12.43*x0_t*cos(x0) + \n",
      "exp([0.13995929]*t)\n",
      "\n",
      "\n",
      "Stage  214\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00011765484302177918\n",
      "Average loss :  1.542138221566347e-07\n",
      "\n",
      "\n",
      "Stage  214\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00011765484302177918\n",
      "Average loss :  1.0405697992155183e-07\n",
      "\n",
      "\n",
      "Stage  214\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00011765484302177918\n",
      "Average loss :  9.177617954492234e-08\n",
      "\n",
      "\n",
      "Stage  214\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00011765484302177918\n",
      "Average loss :  1.0343401157797416e-07\n",
      "expression length:\t 5\n",
      "Result stage 216: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.837*x0_t*sin(x0) + -12.43*x0_t*cos(x0) + \n",
      "exp([0.13996287]*t)\n",
      "\n",
      "\n",
      "Stage  215\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00011648415777349696\n",
      "Average loss :  9.088098096299291e-08\n",
      "\n",
      "\n",
      "Stage  215\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00011648415777349696\n",
      "Average loss :  9.10123176822708e-08\n",
      "\n",
      "\n",
      "Stage  215\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00011648415777349696\n",
      "Average loss :  9.998681349543403e-08\n",
      "\n",
      "\n",
      "Stage  215\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00011648415777349696\n",
      "Average loss :  1.7519040795832552e-07\n",
      "expression length:\t 5\n",
      "Result stage 217: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.837*x0_t*sin(x0) + -12.43*x0_t*cos(x0) + \n",
      "exp([0.13994065]*t)\n",
      "\n",
      "\n",
      "Stage  216\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00011532512103806252\n",
      "Average loss :  1.0190187538228201e-07\n",
      "\n",
      "\n",
      "Stage  216\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00011532512103806252\n",
      "Average loss :  1.6135331293298805e-07\n",
      "\n",
      "\n",
      "Stage  216\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00011532512103806252\n",
      "Average loss :  9.366425501866615e-08\n",
      "\n",
      "\n",
      "Stage  216\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00011532512103806252\n",
      "Average loss :  9.018928892601252e-08\n",
      "expression length:\t 5\n",
      "Result stage 218: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.837*x0_t*sin(x0) + -12.429*x0_t*cos(x0) + \n",
      "exp([0.13994665]*t)\n",
      "\n",
      "\n",
      "Stage  217\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001141776169108365\n",
      "Average loss :  9.789815180738515e-08\n",
      "\n",
      "\n",
      "Stage  217\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001141776169108365\n",
      "Average loss :  1.8248405808662937e-07\n",
      "\n",
      "\n",
      "Stage  217\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001141776169108365\n",
      "Average loss :  4.6898982475340745e-08\n",
      "\n",
      "\n",
      "Stage  217\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001141776169108365\n",
      "Average loss :  9.521046706595371e-08\n",
      "expression length:\t 5\n",
      "Result stage 219: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.837*x0_t*sin(x0) + -12.429*x0_t*cos(x0) + \n",
      "exp([0.13996206]*t)\n",
      "\n",
      "\n",
      "Stage  218\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00011304153064044985\n",
      "Average loss :  9.429412273220805e-08\n",
      "\n",
      "\n",
      "Stage  218\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00011304153064044985\n",
      "Average loss :  9.687418867088127e-08\n",
      "\n",
      "\n",
      "Stage  218\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00011304153064044985\n",
      "Average loss :  8.520131444811341e-08\n",
      "\n",
      "\n",
      "Stage  218\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00011304153064044985\n",
      "Average loss :  9.134978995462006e-08\n",
      "expression length:\t 5\n",
      "Result stage 220: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.837*x0_t*sin(x0) + -12.429*x0_t*cos(x0) + \n",
      "exp([0.13997363]*t)\n",
      "\n",
      "\n",
      "Stage  219\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00011191674861732888\n",
      "Average loss :  8.971517218014924e-08\n",
      "\n",
      "\n",
      "Stage  219\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00011191674861732888\n",
      "Average loss :  9.310271309459495e-08\n",
      "\n",
      "\n",
      "Stage  219\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00011191674861732888\n",
      "Average loss :  8.459674916139193e-08\n",
      "\n",
      "\n",
      "Stage  219\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00011191674861732888\n",
      "Average loss :  7.080929265157465e-08\n",
      "expression length:\t 5\n",
      "Result stage 221: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.837*x0_t*sin(x0) + -12.429*x0_t*cos(x0) + \n",
      "exp([0.13996524]*t)\n",
      "\n",
      "\n",
      "Stage  220\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00011080315836233387\n",
      "Average loss :  8.252519023699278e-08\n",
      "\n",
      "\n",
      "Stage  220\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00011080315836233387\n",
      "Average loss :  8.330424350333487e-08\n",
      "\n",
      "\n",
      "Stage  220\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00011080315836233387\n",
      "Average loss :  1.9854414290421118e-07\n",
      "\n",
      "\n",
      "Stage  220\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00011080315836233387\n",
      "Average loss :  9.175315796028372e-08\n",
      "expression length:\t 5\n",
      "Result stage 222: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.429*x0_t*cos(x0) + \n",
      "exp([0.13997845]*t)\n",
      "\n",
      "\n",
      "Stage  221\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00010970064851551142\n",
      "Average loss :  8.12616320899906e-08\n",
      "\n",
      "\n",
      "Stage  221\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00010970064851551142\n",
      "Average loss :  8.613168489546297e-08\n",
      "\n",
      "\n",
      "Stage  221\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00010970064851551142\n",
      "Average loss :  8.114010796589355e-08\n",
      "\n",
      "\n",
      "Stage  221\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00010970064851551142\n",
      "Average loss :  5.3155137180738166e-08\n",
      "expression length:\t 5\n",
      "Result stage 223: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.429*x0_t*cos(x0) + \n",
      "exp([0.13997884]*t)\n",
      "\n",
      "\n",
      "Stage  222\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00010860910882495796\n",
      "Average loss :  8.954426533591686e-08\n",
      "\n",
      "\n",
      "Stage  222\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00010860910882495796\n",
      "Average loss :  1.0036548303560267e-07\n",
      "\n",
      "\n",
      "Stage  222\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00010860910882495796\n",
      "Average loss :  8.270701101764644e-08\n",
      "\n",
      "\n",
      "Stage  222\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00010860910882495796\n",
      "Average loss :  8.320240851844574e-08\n",
      "expression length:\t 5\n",
      "Result stage 224: -1.74*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.429*x0_t*cos(x0) + \n",
      "exp([0.13998011]*t)\n",
      "\n",
      "\n",
      "Stage  223\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00010752843013579496\n",
      "Average loss :  8.131635809149884e-08\n",
      "\n",
      "\n",
      "Stage  223\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00010752843013579496\n",
      "Average loss :  1.6888871812170692e-07\n",
      "\n",
      "\n",
      "Stage  223\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00010752843013579496\n",
      "Average loss :  1.373387874537002e-07\n",
      "\n",
      "\n",
      "Stage  223\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00010752843013579496\n",
      "Average loss :  1.0308640696621296e-07\n",
      "expression length:\t 5\n",
      "Result stage 225: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.429*x0_t*cos(x0) + \n",
      "exp([0.13996357]*t)\n",
      "\n",
      "\n",
      "Stage  224\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001064585043792528\n",
      "Average loss :  8.22653802856621e-08\n",
      "\n",
      "\n",
      "Stage  224\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001064585043792528\n",
      "Average loss :  8.398244233376317e-08\n",
      "\n",
      "\n",
      "Stage  224\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001064585043792528\n",
      "Average loss :  1.2999690568449296e-07\n",
      "\n",
      "\n",
      "Stage  224\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001064585043792528\n",
      "Average loss :  1.1582508108176626e-07\n",
      "expression length:\t 5\n",
      "Result stage 226: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.429*x0_t*cos(x0) + \n",
      "exp([0.13996378]*t)\n",
      "\n",
      "\n",
      "Stage  225\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00010539922456186434\n",
      "Average loss :  9.017973923164391e-08\n",
      "\n",
      "\n",
      "Stage  225\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00010539922456186434\n",
      "Average loss :  7.899718923454202e-08\n",
      "\n",
      "\n",
      "Stage  225\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00010539922456186434\n",
      "Average loss :  8.339818435842972e-08\n",
      "\n",
      "\n",
      "Stage  225\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00010539922456186434\n",
      "Average loss :  1.2640175839351286e-07\n",
      "expression length:\t 5\n",
      "Result stage 227: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.428*x0_t*cos(x0) + \n",
      "exp([0.13996093]*t)\n",
      "\n",
      "\n",
      "Stage  226\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00010435048475476499\n",
      "Average loss :  1.393036370700429e-07\n",
      "\n",
      "\n",
      "Stage  226\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00010435048475476499\n",
      "Average loss :  7.915384969692241e-08\n",
      "\n",
      "\n",
      "Stage  226\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00010435048475476499\n",
      "Average loss :  7.382763556051941e-08\n",
      "\n",
      "\n",
      "Stage  226\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00010435048475476499\n",
      "Average loss :  1.5904088002116623e-07\n",
      "expression length:\t 5\n",
      "Result stage 228: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.428*x0_t*cos(x0) + \n",
      "exp([0.13995515]*t)\n",
      "\n",
      "\n",
      "Stage  227\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001033121800831002\n",
      "Average loss :  7.772141685791212e-08\n",
      "\n",
      "\n",
      "Stage  227\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001033121800831002\n",
      "Average loss :  7.881744323867679e-08\n",
      "\n",
      "\n",
      "Stage  227\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001033121800831002\n",
      "Average loss :  5.80832804075726e-08\n",
      "\n",
      "\n",
      "Stage  227\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001033121800831002\n",
      "Average loss :  1.0427660157574792e-07\n",
      "expression length:\t 5\n",
      "Result stage 229: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.428*x0_t*cos(x0) + \n",
      "exp([0.13994707]*t)\n",
      "\n",
      "\n",
      "Stage  228\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00010228420671553744\n",
      "Average loss :  8.510987470344844e-08\n",
      "\n",
      "\n",
      "Stage  228\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00010228420671553744\n",
      "Average loss :  3.642222878852408e-08\n",
      "\n",
      "\n",
      "Stage  228\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00010228420671553744\n",
      "Average loss :  1.0278166939770017e-07\n",
      "\n",
      "\n",
      "Stage  228\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00010228420671553744\n",
      "Average loss :  8.3258505867434e-08\n",
      "expression length:\t 5\n",
      "Result stage 230: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.428*x0_t*cos(x0) + \n",
      "exp([0.13996017]*t)\n",
      "\n",
      "\n",
      "Stage  229\n",
      "Epoch 50/200\n",
      "Learning rate :  0.0001012664618538834\n",
      "Average loss :  1.467212058514633e-07\n",
      "\n",
      "\n",
      "Stage  229\n",
      "Epoch 100/200\n",
      "Learning rate :  0.0001012664618538834\n",
      "Average loss :  7.7820345723012e-08\n",
      "\n",
      "\n",
      "Stage  229\n",
      "Epoch 150/200\n",
      "Learning rate :  0.0001012664618538834\n",
      "Average loss :  6.89347814386565e-08\n",
      "\n",
      "\n",
      "Stage  229\n",
      "Epoch 200/200\n",
      "Learning rate :  0.0001012664618538834\n",
      "Average loss :  9.04396486589576e-08\n",
      "expression length:\t 5\n",
      "Result stage 231: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.428*x0_t*cos(x0) + \n",
      "exp([0.1399513]*t)\n",
      "\n",
      "\n",
      "Stage  230\n",
      "Epoch 50/200\n",
      "Learning rate :  0.00010025884372280371\n",
      "Average loss :  6.762116555592002e-08\n",
      "\n",
      "\n",
      "Stage  230\n",
      "Epoch 100/200\n",
      "Learning rate :  0.00010025884372280371\n",
      "Average loss :  6.754702042144345e-08\n",
      "\n",
      "\n",
      "Stage  230\n",
      "Epoch 150/200\n",
      "Learning rate :  0.00010025884372280371\n",
      "Average loss :  7.470472240811432e-08\n",
      "\n",
      "\n",
      "Stage  230\n",
      "Epoch 200/200\n",
      "Learning rate :  0.00010025884372280371\n",
      "Average loss :  9.320290672576448e-08\n",
      "expression length:\t 5\n",
      "Result stage 232: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.428*x0_t*cos(x0) + \n",
      "exp([0.13995053]*t)\n",
      "\n",
      "\n",
      "Stage  231\n",
      "Epoch 50/200\n",
      "Learning rate :  9.926125155964566e-05\n",
      "Average loss :  7.50654010062135e-08\n",
      "\n",
      "\n",
      "Stage  231\n",
      "Epoch 100/200\n",
      "Learning rate :  9.926125155964566e-05\n",
      "Average loss :  1.3616531191473769e-07\n",
      "\n",
      "\n",
      "Stage  231\n",
      "Epoch 150/200\n",
      "Learning rate :  9.926125155964566e-05\n",
      "Average loss :  6.997181145607101e-08\n",
      "\n",
      "\n",
      "Stage  231\n",
      "Epoch 200/200\n",
      "Learning rate :  9.926125155964566e-05\n",
      "Average loss :  1.621702807597103e-07\n",
      "expression length:\t 5\n",
      "Result stage 233: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.428*x0_t*cos(x0) + \n",
      "exp([0.13996549]*t)\n",
      "\n",
      "\n",
      "Stage  232\n",
      "Epoch 50/200\n",
      "Learning rate :  9.827358560436155e-05\n",
      "Average loss :  7.275994562405685e-08\n",
      "\n",
      "\n",
      "Stage  232\n",
      "Epoch 100/200\n",
      "Learning rate :  9.827358560436155e-05\n",
      "Average loss :  7.186440598161425e-08\n",
      "\n",
      "\n",
      "Stage  232\n",
      "Epoch 150/200\n",
      "Learning rate :  9.827358560436155e-05\n",
      "Average loss :  6.458217427507407e-08\n",
      "\n",
      "\n",
      "Stage  232\n",
      "Epoch 200/200\n",
      "Learning rate :  9.827358560436155e-05\n",
      "Average loss :  1.7581795930254884e-07\n",
      "expression length:\t 5\n",
      "Result stage 234: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.428*x0_t*cos(x0) + \n",
      "exp([0.13997091]*t)\n",
      "\n",
      "\n",
      "Stage  233\n",
      "Epoch 50/200\n",
      "Learning rate :  9.729574708953276e-05\n",
      "Average loss :  6.278283848359933e-08\n",
      "\n",
      "\n",
      "Stage  233\n",
      "Epoch 100/200\n",
      "Learning rate :  9.729574708953276e-05\n",
      "Average loss :  8.52566017783829e-08\n",
      "\n",
      "\n",
      "Stage  233\n",
      "Epoch 150/200\n",
      "Learning rate :  9.729574708953276e-05\n",
      "Average loss :  6.876781100118023e-08\n",
      "\n",
      "\n",
      "Stage  233\n",
      "Epoch 200/200\n",
      "Learning rate :  9.729574708953276e-05\n",
      "Average loss :  6.822328657563048e-08\n",
      "expression length:\t 5\n",
      "Result stage 235: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.427*x0_t*cos(x0) + \n",
      "exp([0.13997832]*t)\n",
      "\n",
      "\n",
      "Stage  234\n",
      "Epoch 50/200\n",
      "Learning rate :  9.632763823049303e-05\n",
      "Average loss :  6.324015089376189e-08\n",
      "\n",
      "\n",
      "Stage  234\n",
      "Epoch 100/200\n",
      "Learning rate :  9.632763823049303e-05\n",
      "Average loss :  6.903459137674872e-08\n",
      "\n",
      "\n",
      "Stage  234\n",
      "Epoch 150/200\n",
      "Learning rate :  9.632763823049303e-05\n",
      "Average loss :  6.198883539809685e-08\n",
      "\n",
      "\n",
      "Stage  234\n",
      "Epoch 200/200\n",
      "Learning rate :  9.632763823049303e-05\n",
      "Average loss :  6.863691481839851e-08\n",
      "expression length:\t 5\n",
      "Result stage 236: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.427*x0_t*cos(x0) + \n",
      "exp([0.13998018]*t)\n",
      "\n",
      "\n",
      "Stage  235\n",
      "Epoch 50/200\n",
      "Learning rate :  9.536916221554961e-05\n",
      "Average loss :  6.118887085904134e-08\n",
      "\n",
      "\n",
      "Stage  235\n",
      "Epoch 100/200\n",
      "Learning rate :  9.536916221554961e-05\n",
      "Average loss :  6.159914534009658e-08\n",
      "\n",
      "\n",
      "Stage  235\n",
      "Epoch 150/200\n",
      "Learning rate :  9.536916221554961e-05\n",
      "Average loss :  4.770997108494157e-08\n",
      "\n",
      "\n",
      "Stage  235\n",
      "Epoch 200/200\n",
      "Learning rate :  9.536916221554961e-05\n",
      "Average loss :  6.108169969820665e-08\n",
      "expression length:\t 5\n",
      "Result stage 237: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.427*x0_t*cos(x0) + \n",
      "exp([0.13995631]*t)\n",
      "\n",
      "\n",
      "Stage  236\n",
      "Epoch 50/200\n",
      "Learning rate :  9.442022319630235e-05\n",
      "Average loss :  5.129551183813419e-08\n",
      "\n",
      "\n",
      "Stage  236\n",
      "Epoch 100/200\n",
      "Learning rate :  9.442022319630235e-05\n",
      "Average loss :  1.745103190842201e-07\n",
      "\n",
      "\n",
      "Stage  236\n",
      "Epoch 150/200\n",
      "Learning rate :  9.442022319630235e-05\n",
      "Average loss :  5.931908120260232e-08\n",
      "\n",
      "\n",
      "Stage  236\n",
      "Epoch 200/200\n",
      "Learning rate :  9.442022319630235e-05\n",
      "Average loss :  4.9493070974904185e-08\n",
      "expression length:\t 5\n",
      "Result stage 238: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.427*x0_t*cos(x0) + \n",
      "exp([0.1399721]*t)\n",
      "\n",
      "\n",
      "Stage  237\n",
      "Epoch 50/200\n",
      "Learning rate :  9.348072627805847e-05\n",
      "Average loss :  4.934149799851184e-08\n",
      "\n",
      "\n",
      "Stage  237\n",
      "Epoch 100/200\n",
      "Learning rate :  9.348072627805847e-05\n",
      "Average loss :  5.8872867469972334e-08\n",
      "\n",
      "\n",
      "Stage  237\n",
      "Epoch 150/200\n",
      "Learning rate :  9.348072627805847e-05\n",
      "Average loss :  5.8616844711423255e-08\n",
      "\n",
      "\n",
      "Stage  237\n",
      "Epoch 200/200\n",
      "Learning rate :  9.348072627805847e-05\n",
      "Average loss :  6.558709486625958e-08\n",
      "expression length:\t 5\n",
      "Result stage 239: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.427*x0_t*cos(x0) + \n",
      "exp([0.13998316]*t)\n",
      "\n",
      "\n",
      "Stage  238\n",
      "Epoch 50/200\n",
      "Learning rate :  9.25505775103433e-05\n",
      "Average loss :  6.206151681453775e-08\n",
      "\n",
      "\n",
      "Stage  238\n",
      "Epoch 100/200\n",
      "Learning rate :  9.25505775103433e-05\n",
      "Average loss :  9.262560496381411e-08\n",
      "\n",
      "\n",
      "Stage  238\n",
      "Epoch 150/200\n",
      "Learning rate :  9.25505775103433e-05\n",
      "Average loss :  1.5345216297646402e-07\n",
      "\n",
      "\n",
      "Stage  238\n",
      "Epoch 200/200\n",
      "Learning rate :  9.25505775103433e-05\n",
      "Average loss :  6.091580928568874e-08\n",
      "expression length:\t 5\n",
      "Result stage 240: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.427*x0_t*cos(x0) + \n",
      "exp([0.13997215]*t)\n",
      "\n",
      "\n",
      "Stage  239\n",
      "Epoch 50/200\n",
      "Learning rate :  9.162968387750484e-05\n",
      "Average loss :  5.680544035158164e-08\n",
      "\n",
      "\n",
      "Stage  239\n",
      "Epoch 100/200\n",
      "Learning rate :  9.162968387750484e-05\n",
      "Average loss :  5.6895842703852395e-08\n",
      "\n",
      "\n",
      "Stage  239\n",
      "Epoch 150/200\n",
      "Learning rate :  9.162968387750484e-05\n",
      "Average loss :  7.01790980883743e-08\n",
      "\n",
      "\n",
      "Stage  239\n",
      "Epoch 200/200\n",
      "Learning rate :  9.162968387750484e-05\n",
      "Average loss :  5.80134482675021e-08\n",
      "expression length:\t 5\n",
      "Result stage 241: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.427*x0_t*cos(x0) + \n",
      "exp([0.13995993]*t)\n",
      "\n",
      "\n",
      "Stage  240\n",
      "Epoch 50/200\n",
      "Learning rate :  9.071795328941252e-05\n",
      "Average loss :  5.59241186692816e-08\n",
      "\n",
      "\n",
      "Stage  240\n",
      "Epoch 100/200\n",
      "Learning rate :  9.071795328941252e-05\n",
      "Average loss :  7.556847236855901e-08\n",
      "\n",
      "\n",
      "Stage  240\n",
      "Epoch 150/200\n",
      "Learning rate :  9.071795328941252e-05\n",
      "Average loss :  6.172430033757337e-08\n",
      "\n",
      "\n",
      "Stage  240\n",
      "Epoch 200/200\n",
      "Learning rate :  9.071795328941252e-05\n",
      "Average loss :  5.451801143863122e-08\n",
      "expression length:\t 5\n",
      "Result stage 242: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.426*x0_t*cos(x0) + \n",
      "exp([0.13995925]*t)\n",
      "\n",
      "\n",
      "Stage  241\n",
      "Epoch 50/200\n",
      "Learning rate :  8.981529457224764e-05\n",
      "Average loss :  7.099642829189179e-08\n",
      "\n",
      "\n",
      "Stage  241\n",
      "Epoch 100/200\n",
      "Learning rate :  8.981529457224764e-05\n",
      "Average loss :  1.5348443582752225e-07\n",
      "\n",
      "\n",
      "Stage  241\n",
      "Epoch 150/200\n",
      "Learning rate :  8.981529457224764e-05\n",
      "Average loss :  6.693764476040087e-08\n",
      "\n",
      "\n",
      "Stage  241\n",
      "Epoch 200/200\n",
      "Learning rate :  8.981529457224764e-05\n",
      "Average loss :  6.313963041293391e-08\n",
      "expression length:\t 5\n",
      "Result stage 243: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.426*x0_t*cos(x0) + \n",
      "exp([0.13996561]*t)\n",
      "\n",
      "\n",
      "Stage  242\n",
      "Epoch 50/200\n",
      "Learning rate :  8.892161745938634e-05\n",
      "Average loss :  1.3436857670967584e-07\n",
      "\n",
      "\n",
      "Stage  242\n",
      "Epoch 100/200\n",
      "Learning rate :  8.892161745938634e-05\n",
      "Average loss :  1.548828549857717e-07\n",
      "\n",
      "\n",
      "Stage  242\n",
      "Epoch 150/200\n",
      "Learning rate :  8.892161745938634e-05\n",
      "Average loss :  6.285109321879645e-08\n",
      "\n",
      "\n",
      "Stage  242\n",
      "Epoch 200/200\n",
      "Learning rate :  8.892161745938634e-05\n",
      "Average loss :  9.165996317506142e-08\n",
      "expression length:\t 5\n",
      "Result stage 244: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.426*x0_t*cos(x0) + \n",
      "exp([0.13996474]*t)\n",
      "\n",
      "\n",
      "Stage  243\n",
      "Epoch 50/200\n",
      "Learning rate :  8.803683258237255e-05\n",
      "Average loss :  5.519888190974598e-08\n",
      "\n",
      "\n",
      "Stage  243\n",
      "Epoch 100/200\n",
      "Learning rate :  8.803683258237255e-05\n",
      "Average loss :  5.2216030610452435e-08\n",
      "\n",
      "\n",
      "Stage  243\n",
      "Epoch 150/200\n",
      "Learning rate :  8.803683258237255e-05\n",
      "Average loss :  5.189430396512762e-08\n",
      "\n",
      "\n",
      "Stage  243\n",
      "Epoch 200/200\n",
      "Learning rate :  8.803683258237255e-05\n",
      "Average loss :  5.917503642649535e-08\n",
      "expression length:\t 5\n",
      "Result stage 245: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.426*x0_t*cos(x0) + \n",
      "exp([0.13996947]*t)\n",
      "\n",
      "\n",
      "Stage  244\n",
      "Epoch 50/200\n",
      "Learning rate :  8.71608514619813e-05\n",
      "Average loss :  4.8581476619347086e-08\n",
      "\n",
      "\n",
      "Stage  244\n",
      "Epoch 100/200\n",
      "Learning rate :  8.71608514619813e-05\n",
      "Average loss :  5.716799122978955e-08\n",
      "\n",
      "\n",
      "Stage  244\n",
      "Epoch 150/200\n",
      "Learning rate :  8.71608514619813e-05\n",
      "Average loss :  5.5572556334482215e-08\n",
      "\n",
      "\n",
      "Stage  244\n",
      "Epoch 200/200\n",
      "Learning rate :  8.71608514619813e-05\n",
      "Average loss :  8.86100579577942e-08\n",
      "expression length:\t 5\n",
      "Result stage 246: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.426*x0_t*cos(x0) + \n",
      "exp([0.13995437]*t)\n",
      "\n",
      "\n",
      "Stage  245\n",
      "Epoch 50/200\n",
      "Learning rate :  8.62935864993705e-05\n",
      "Average loss :  5.0804981555074846e-08\n",
      "\n",
      "\n",
      "Stage  245\n",
      "Epoch 100/200\n",
      "Learning rate :  8.62935864993705e-05\n",
      "Average loss :  1.4762105138288462e-07\n",
      "\n",
      "\n",
      "Stage  245\n",
      "Epoch 150/200\n",
      "Learning rate :  8.62935864993705e-05\n",
      "Average loss :  6.481672443214848e-08\n",
      "\n",
      "\n",
      "Stage  245\n",
      "Epoch 200/200\n",
      "Learning rate :  8.62935864993705e-05\n",
      "Average loss :  6.216038883621877e-08\n",
      "expression length:\t 5\n",
      "Result stage 247: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.426*x0_t*cos(x0) + \n",
      "exp([0.13997017]*t)\n",
      "\n",
      "\n",
      "Stage  246\n",
      "Epoch 50/200\n",
      "Learning rate :  8.543495096732123e-05\n",
      "Average loss :  5.381375345336892e-08\n",
      "\n",
      "\n",
      "Stage  246\n",
      "Epoch 100/200\n",
      "Learning rate :  8.543495096732123e-05\n",
      "Average loss :  1.447720308078715e-07\n",
      "\n",
      "\n",
      "Stage  246\n",
      "Epoch 150/200\n",
      "Learning rate :  8.543495096732123e-05\n",
      "Average loss :  4.9509662147784184e-08\n",
      "\n",
      "\n",
      "Stage  246\n",
      "Epoch 200/200\n",
      "Learning rate :  8.543495096732123e-05\n",
      "Average loss :  4.20741734785679e-08\n",
      "expression length:\t 5\n",
      "Result stage 248: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.426*x0_t*cos(x0) + \n",
      "exp([0.13997197]*t)\n",
      "\n",
      "\n",
      "Stage  247\n",
      "Epoch 50/200\n",
      "Learning rate :  8.458485900156469e-05\n",
      "Average loss :  5.397129143602797e-08\n",
      "\n",
      "\n",
      "Stage  247\n",
      "Epoch 100/200\n",
      "Learning rate :  8.458485900156469e-05\n",
      "Average loss :  9.03603307733647e-08\n",
      "\n",
      "\n",
      "Stage  247\n",
      "Epoch 150/200\n",
      "Learning rate :  8.458485900156469e-05\n",
      "Average loss :  5.6004065385195645e-08\n",
      "\n",
      "\n",
      "Stage  247\n",
      "Epoch 200/200\n",
      "Learning rate :  8.458485900156469e-05\n",
      "Average loss :  7.996059991910442e-08\n",
      "expression length:\t 5\n",
      "Result stage 249: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.426*x0_t*cos(x0) + \n",
      "exp([0.1399555]*t)\n",
      "\n",
      "\n",
      "Stage  248\n",
      "Epoch 50/200\n",
      "Learning rate :  8.374322559219597e-05\n",
      "Average loss :  5.2573195574723286e-08\n",
      "\n",
      "\n",
      "Stage  248\n",
      "Epoch 100/200\n",
      "Learning rate :  8.374322559219597e-05\n",
      "Average loss :  1.1501728636176267e-07\n",
      "\n",
      "\n",
      "Stage  248\n",
      "Epoch 150/200\n",
      "Learning rate :  8.374322559219597e-05\n",
      "Average loss :  5.118997137287806e-08\n",
      "\n",
      "\n",
      "Stage  248\n",
      "Epoch 200/200\n",
      "Learning rate :  8.374322559219597e-05\n",
      "Average loss :  5.0766093551146696e-08\n",
      "expression length:\t 5\n",
      "Result stage 250: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.426*x0_t*cos(x0) + \n",
      "exp([0.13997722]*t)\n",
      "\n",
      "\n",
      "Stage  249\n",
      "Epoch 50/200\n",
      "Learning rate :  8.290996657517266e-05\n",
      "Average loss :  5.1786955168608984e-08\n",
      "\n",
      "\n",
      "Stage  249\n",
      "Epoch 100/200\n",
      "Learning rate :  8.290996657517266e-05\n",
      "Average loss :  4.63554457041937e-08\n",
      "\n",
      "\n",
      "Stage  249\n",
      "Epoch 150/200\n",
      "Learning rate :  8.290996657517266e-05\n",
      "Average loss :  1.235957967082868e-07\n",
      "\n",
      "\n",
      "Stage  249\n",
      "Epoch 200/200\n",
      "Learning rate :  8.290996657517266e-05\n",
      "Average loss :  4.622181037916562e-08\n",
      "expression length:\t 5\n",
      "Result stage 251: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.426*x0_t*cos(x0) + \n",
      "exp([0.13996004]*t)\n",
      "\n",
      "\n",
      "Stage  250\n",
      "Epoch 50/200\n",
      "Learning rate :  8.20849986238988e-05\n",
      "Average loss :  3.790317038010471e-08\n",
      "\n",
      "\n",
      "Stage  250\n",
      "Epoch 100/200\n",
      "Learning rate :  8.20849986238988e-05\n",
      "Average loss :  5.1080967011785106e-08\n",
      "\n",
      "\n",
      "Stage  250\n",
      "Epoch 150/200\n",
      "Learning rate :  8.20849986238988e-05\n",
      "Average loss :  4.729427516281248e-08\n",
      "\n",
      "\n",
      "Stage  250\n",
      "Epoch 200/200\n",
      "Learning rate :  8.20849986238988e-05\n",
      "Average loss :  4.641026052354391e-08\n",
      "expression length:\t 5\n",
      "Result stage 252: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.426*x0_t*cos(x0) + \n",
      "exp([0.13996595]*t)\n",
      "\n",
      "\n",
      "Stage  251\n",
      "Epoch 50/200\n",
      "Learning rate :  8.126823924089167e-05\n",
      "Average loss :  5.387490276120843e-08\n",
      "\n",
      "\n",
      "Stage  251\n",
      "Epoch 100/200\n",
      "Learning rate :  8.126823924089167e-05\n",
      "Average loss :  4.918350882121558e-08\n",
      "\n",
      "\n",
      "Stage  251\n",
      "Epoch 150/200\n",
      "Learning rate :  8.126823924089167e-05\n",
      "Average loss :  4.048982304993842e-08\n",
      "\n",
      "\n",
      "Stage  251\n",
      "Epoch 200/200\n",
      "Learning rate :  8.126823924089167e-05\n",
      "Average loss :  9.692153923879232e-08\n",
      "expression length:\t 5\n",
      "Result stage 253: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.426*x0_t*cos(x0) + \n",
      "exp([0.1399653]*t)\n",
      "\n",
      "\n",
      "Stage  252\n",
      "Epoch 50/200\n",
      "Learning rate :  8.045960674953244e-05\n",
      "Average loss :  5.335741448675435e-08\n",
      "\n",
      "\n",
      "Stage  252\n",
      "Epoch 100/200\n",
      "Learning rate :  8.045960674953244e-05\n",
      "Average loss :  5.623204657467795e-08\n",
      "\n",
      "\n",
      "Stage  252\n",
      "Epoch 150/200\n",
      "Learning rate :  8.045960674953244e-05\n",
      "Average loss :  4.828757127484096e-08\n",
      "\n",
      "\n",
      "Stage  252\n",
      "Epoch 200/200\n",
      "Learning rate :  8.045960674953244e-05\n",
      "Average loss :  4.590166469142787e-08\n",
      "expression length:\t 5\n",
      "Result stage 254: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.13997957]*t)\n",
      "\n",
      "\n",
      "Stage  253\n",
      "Epoch 50/200\n",
      "Learning rate :  7.9659020285898e-05\n",
      "Average loss :  4.209329773630088e-08\n",
      "\n",
      "\n",
      "Stage  253\n",
      "Epoch 100/200\n",
      "Learning rate :  7.9659020285898e-05\n",
      "Average loss :  4.6939977238480424e-08\n",
      "\n",
      "\n",
      "Stage  253\n",
      "Epoch 150/200\n",
      "Learning rate :  7.9659020285898e-05\n",
      "Average loss :  5.603737918136176e-08\n",
      "\n",
      "\n",
      "Stage  253\n",
      "Epoch 200/200\n",
      "Learning rate :  7.9659020285898e-05\n",
      "Average loss :  4.41738094991706e-08\n",
      "expression length:\t 5\n",
      "Result stage 255: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.13996576]*t)\n",
      "\n",
      "\n",
      "Stage  254\n",
      "Epoch 50/200\n",
      "Learning rate :  7.886639979067494e-05\n",
      "Average loss :  1.2670406590586936e-07\n",
      "\n",
      "\n",
      "Stage  254\n",
      "Epoch 100/200\n",
      "Learning rate :  7.886639979067494e-05\n",
      "Average loss :  1.033715619769282e-07\n",
      "\n",
      "\n",
      "Stage  254\n",
      "Epoch 150/200\n",
      "Learning rate :  7.886639979067494e-05\n",
      "Average loss :  4.452208912653077e-08\n",
      "\n",
      "\n",
      "Stage  254\n",
      "Epoch 200/200\n",
      "Learning rate :  7.886639979067494e-05\n",
      "Average loss :  5.576317363420458e-08\n",
      "expression length:\t 5\n",
      "Result stage 256: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.13997328]*t)\n",
      "\n",
      "\n",
      "Stage  255\n",
      "Epoch 50/200\n",
      "Learning rate :  7.808166600115313e-05\n",
      "Average loss :  4.205299575232857e-08\n",
      "\n",
      "\n",
      "Stage  255\n",
      "Epoch 100/200\n",
      "Learning rate :  7.808166600115313e-05\n",
      "Average loss :  4.5436696183287495e-08\n",
      "\n",
      "\n",
      "Stage  255\n",
      "Epoch 150/200\n",
      "Learning rate :  7.808166600115313e-05\n",
      "Average loss :  4.5584673813436893e-08\n",
      "\n",
      "\n",
      "Stage  255\n",
      "Epoch 200/200\n",
      "Learning rate :  7.808166600115313e-05\n",
      "Average loss :  7.731112816600216e-08\n",
      "expression length:\t 5\n",
      "Result stage 257: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.13996002]*t)\n",
      "\n",
      "\n",
      "Stage  256\n",
      "Epoch 50/200\n",
      "Learning rate :  7.730474044329974e-05\n",
      "Average loss :  8.153262598398214e-08\n",
      "\n",
      "\n",
      "Stage  256\n",
      "Epoch 100/200\n",
      "Learning rate :  7.730474044329974e-05\n",
      "Average loss :  5.49441665498307e-08\n",
      "\n",
      "\n",
      "Stage  256\n",
      "Epoch 150/200\n",
      "Learning rate :  7.730474044329974e-05\n",
      "Average loss :  4.2503479846800474e-08\n",
      "\n",
      "\n",
      "Stage  256\n",
      "Epoch 200/200\n",
      "Learning rate :  7.730474044329974e-05\n",
      "Average loss :  4.293872990501768e-08\n",
      "expression length:\t 5\n",
      "Result stage 258: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.13998246]*t)\n",
      "\n",
      "\n",
      "Stage  257\n",
      "Epoch 50/200\n",
      "Learning rate :  7.653554542391152e-05\n",
      "Average loss :  3.935553039013939e-08\n",
      "\n",
      "\n",
      "Stage  257\n",
      "Epoch 100/200\n",
      "Learning rate :  7.653554542391152e-05\n",
      "Average loss :  5.725599550032712e-08\n",
      "\n",
      "\n",
      "Stage  257\n",
      "Epoch 150/200\n",
      "Learning rate :  7.653554542391152e-05\n",
      "Average loss :  9.897186714624695e-08\n",
      "\n",
      "\n",
      "Stage  257\n",
      "Epoch 200/200\n",
      "Learning rate :  7.653554542391152e-05\n",
      "Average loss :  4.10801774819447e-08\n",
      "expression length:\t 5\n",
      "Result stage 259: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.1399672]*t)\n",
      "\n",
      "\n",
      "Stage  258\n",
      "Epoch 50/200\n",
      "Learning rate :  7.577400402284549e-05\n",
      "Average loss :  3.8327442553054425e-08\n",
      "\n",
      "\n",
      "Stage  258\n",
      "Epoch 100/200\n",
      "Learning rate :  7.577400402284549e-05\n",
      "Average loss :  4.349046278662172e-08\n",
      "\n",
      "\n",
      "Stage  258\n",
      "Epoch 150/200\n",
      "Learning rate :  7.577400402284549e-05\n",
      "Average loss :  4.217270799244943e-08\n",
      "\n",
      "\n",
      "Stage  258\n",
      "Epoch 200/200\n",
      "Learning rate :  7.577400402284549e-05\n",
      "Average loss :  6.901829152639039e-08\n",
      "expression length:\t 5\n",
      "Result stage 260: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.13995993]*t)\n",
      "\n",
      "\n",
      "Stage  259\n",
      "Epoch 50/200\n",
      "Learning rate :  7.502004008532698e-05\n",
      "Average loss :  3.759041433681887e-08\n",
      "\n",
      "\n",
      "Stage  259\n",
      "Epoch 100/200\n",
      "Learning rate :  7.502004008532698e-05\n",
      "Average loss :  3.7764809945883826e-08\n",
      "\n",
      "\n",
      "Stage  259\n",
      "Epoch 150/200\n",
      "Learning rate :  7.502004008532698e-05\n",
      "Average loss :  3.796532155320165e-08\n",
      "\n",
      "\n",
      "Stage  259\n",
      "Epoch 200/200\n",
      "Learning rate :  7.502004008532698e-05\n",
      "Average loss :  3.1408454503889516e-08\n",
      "expression length:\t 5\n",
      "Result stage 261: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.13997734]*t)\n",
      "\n",
      "\n",
      "Stage  260\n",
      "Epoch 50/200\n",
      "Learning rate :  7.427357821433387e-05\n",
      "Average loss :  7.172177163283777e-08\n",
      "\n",
      "\n",
      "Stage  260\n",
      "Epoch 100/200\n",
      "Learning rate :  7.427357821433387e-05\n",
      "Average loss :  4.136310494118334e-08\n",
      "\n",
      "\n",
      "Stage  260\n",
      "Epoch 150/200\n",
      "Learning rate :  7.427357821433387e-05\n",
      "Average loss :  2.994197600969528e-08\n",
      "\n",
      "\n",
      "Stage  260\n",
      "Epoch 200/200\n",
      "Learning rate :  7.427357821433387e-05\n",
      "Average loss :  3.010698179650717e-08\n",
      "expression length:\t 5\n",
      "Result stage 262: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.13997921]*t)\n",
      "\n",
      "\n",
      "Stage  261\n",
      "Epoch 50/200\n",
      "Learning rate :  7.35345437630571e-05\n",
      "Average loss :  3.909403645252496e-08\n",
      "\n",
      "\n",
      "Stage  261\n",
      "Epoch 100/200\n",
      "Learning rate :  7.35345437630571e-05\n",
      "Average loss :  4.6878273707307017e-08\n",
      "\n",
      "\n",
      "Stage  261\n",
      "Epoch 150/200\n",
      "Learning rate :  7.35345437630571e-05\n",
      "Average loss :  4.1030407516018386e-08\n",
      "\n",
      "\n",
      "Stage  261\n",
      "Epoch 200/200\n",
      "Learning rate :  7.35345437630571e-05\n",
      "Average loss :  4.1328725330913585e-08\n",
      "expression length:\t 5\n",
      "Result stage 263: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.13997158]*t)\n",
      "\n",
      "\n",
      "Stage  262\n",
      "Epoch 50/200\n",
      "Learning rate :  7.28028628274356e-05\n",
      "Average loss :  4.337261927389591e-08\n",
      "\n",
      "\n",
      "Stage  262\n",
      "Epoch 100/200\n",
      "Learning rate :  7.28028628274356e-05\n",
      "Average loss :  3.944682447354353e-08\n",
      "\n",
      "\n",
      "Stage  262\n",
      "Epoch 150/200\n",
      "Learning rate :  7.28028628274356e-05\n",
      "Average loss :  5.055999352521212e-08\n",
      "\n",
      "\n",
      "Stage  262\n",
      "Epoch 200/200\n",
      "Learning rate :  7.28028628274356e-05\n",
      "Average loss :  3.998421505002625e-08\n",
      "expression length:\t 5\n",
      "Result stage 264: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.13997537]*t)\n",
      "\n",
      "\n",
      "Stage  263\n",
      "Epoch 50/200\n",
      "Learning rate :  7.20784622387661e-05\n",
      "Average loss :  4.621987415021067e-08\n",
      "\n",
      "\n",
      "Stage  263\n",
      "Epoch 100/200\n",
      "Learning rate :  7.20784622387661e-05\n",
      "Average loss :  3.6787469070986845e-08\n",
      "\n",
      "\n",
      "Stage  263\n",
      "Epoch 150/200\n",
      "Learning rate :  7.20784622387661e-05\n",
      "Average loss :  3.698434625221125e-08\n",
      "\n",
      "\n",
      "Stage  263\n",
      "Epoch 200/200\n",
      "Learning rate :  7.20784622387661e-05\n",
      "Average loss :  3.515533819609118e-08\n",
      "expression length:\t 5\n",
      "Result stage 265: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.1399666]*t)\n",
      "\n",
      "\n",
      "Stage  264\n",
      "Epoch 50/200\n",
      "Learning rate :  7.136126955638605e-05\n",
      "Average loss :  5.159723670544736e-08\n",
      "\n",
      "\n",
      "Stage  264\n",
      "Epoch 100/200\n",
      "Learning rate :  7.136126955638605e-05\n",
      "Average loss :  4.7725215779337304e-08\n",
      "\n",
      "\n",
      "Stage  264\n",
      "Epoch 150/200\n",
      "Learning rate :  7.136126955638605e-05\n",
      "Average loss :  3.753934763039979e-08\n",
      "\n",
      "\n",
      "Stage  264\n",
      "Epoch 200/200\n",
      "Learning rate :  7.136126955638605e-05\n",
      "Average loss :  6.476572167457562e-08\n",
      "expression length:\t 5\n",
      "Result stage 266: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.1399645]*t)\n",
      "\n",
      "\n",
      "Stage  265\n",
      "Epoch 50/200\n",
      "Learning rate :  7.06512130604296e-05\n",
      "Average loss :  3.545566684692858e-08\n",
      "\n",
      "\n",
      "Stage  265\n",
      "Epoch 100/200\n",
      "Learning rate :  7.06512130604296e-05\n",
      "Average loss :  3.8623451104058404e-08\n",
      "\n",
      "\n",
      "Stage  265\n",
      "Epoch 150/200\n",
      "Learning rate :  7.06512130604296e-05\n",
      "Average loss :  3.581439855793178e-08\n",
      "\n",
      "\n",
      "Stage  265\n",
      "Epoch 200/200\n",
      "Learning rate :  7.06512130604296e-05\n",
      "Average loss :  3.6928899049826214e-08\n",
      "expression length:\t 5\n",
      "Result stage 267: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.13998519]*t)\n",
      "\n",
      "\n",
      "Stage  266\n",
      "Epoch 50/200\n",
      "Learning rate :  6.994822174465535e-05\n",
      "Average loss :  4.985819757052923e-08\n",
      "\n",
      "\n",
      "Stage  266\n",
      "Epoch 100/200\n",
      "Learning rate :  6.994822174465535e-05\n",
      "Average loss :  3.007766125051603e-08\n",
      "\n",
      "\n",
      "Stage  266\n",
      "Epoch 150/200\n",
      "Learning rate :  6.994822174465535e-05\n",
      "Average loss :  3.312793239729217e-08\n",
      "\n",
      "\n",
      "Stage  266\n",
      "Epoch 200/200\n",
      "Learning rate :  6.994822174465535e-05\n",
      "Average loss :  3.636550260921467e-08\n",
      "expression length:\t 5\n",
      "Result stage 268: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.425*x0_t*cos(x0) + \n",
      "exp([0.13997279]*t)\n",
      "\n",
      "\n",
      "Stage  267\n",
      "Epoch 50/200\n",
      "Learning rate :  6.925222530934599e-05\n",
      "Average loss :  3.584173313697647e-08\n",
      "\n",
      "\n",
      "Stage  267\n",
      "Epoch 100/200\n",
      "Learning rate :  6.925222530934599e-05\n",
      "Average loss :  3.234472956137324e-08\n",
      "\n",
      "\n",
      "Stage  267\n",
      "Epoch 150/200\n",
      "Learning rate :  6.925222530934599e-05\n",
      "Average loss :  4.565496070085828e-08\n",
      "\n",
      "\n",
      "Stage  267\n",
      "Epoch 200/200\n",
      "Learning rate :  6.925222530934599e-05\n",
      "Average loss :  3.6320983554105624e-08\n",
      "expression length:\t 5\n",
      "Result stage 269: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.139988]*t)\n",
      "\n",
      "\n",
      "Stage  268\n",
      "Epoch 50/200\n",
      "Learning rate :  6.856315415427791e-05\n",
      "Average loss :  6.263098129011269e-08\n",
      "\n",
      "\n",
      "Stage  268\n",
      "Epoch 100/200\n",
      "Learning rate :  6.856315415427791e-05\n",
      "Average loss :  3.7654192652780694e-08\n",
      "\n",
      "\n",
      "Stage  268\n",
      "Epoch 150/200\n",
      "Learning rate :  6.856315415427791e-05\n",
      "Average loss :  3.2631366053692545e-08\n",
      "\n",
      "\n",
      "Stage  268\n",
      "Epoch 200/200\n",
      "Learning rate :  6.856315415427791e-05\n",
      "Average loss :  5.134154079655673e-08\n",
      "expression length:\t 5\n",
      "Result stage 270: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13996343]*t)\n",
      "\n",
      "\n",
      "Stage  269\n",
      "Epoch 50/200\n",
      "Learning rate :  6.788093937176144e-05\n",
      "Average loss :  3.8349593722841746e-08\n",
      "\n",
      "\n",
      "Stage  269\n",
      "Epoch 100/200\n",
      "Learning rate :  6.788093937176144e-05\n",
      "Average loss :  7.528529266664918e-08\n",
      "\n",
      "\n",
      "Stage  269\n",
      "Epoch 150/200\n",
      "Learning rate :  6.788093937176144e-05\n",
      "Average loss :  5.5165571666293545e-08\n",
      "\n",
      "\n",
      "Stage  269\n",
      "Epoch 200/200\n",
      "Learning rate :  6.788093937176144e-05\n",
      "Average loss :  3.298039530363894e-08\n",
      "expression length:\t 5\n",
      "Result stage 271: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13997948]*t)\n",
      "\n",
      "\n",
      "Stage  270\n",
      "Epoch 50/200\n",
      "Learning rate :  6.720551273974975e-05\n",
      "Average loss :  3.406517024018285e-08\n",
      "\n",
      "\n",
      "Stage  270\n",
      "Epoch 100/200\n",
      "Learning rate :  6.720551273974975e-05\n",
      "Average loss :  3.017871463839583e-08\n",
      "\n",
      "\n",
      "Stage  270\n",
      "Epoch 150/200\n",
      "Learning rate :  6.720551273974975e-05\n",
      "Average loss :  4.301081446556054e-08\n",
      "\n",
      "\n",
      "Stage  270\n",
      "Epoch 200/200\n",
      "Learning rate :  6.720551273974975e-05\n",
      "Average loss :  6.576915012601603e-08\n",
      "expression length:\t 5\n",
      "Result stage 272: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13996123]*t)\n",
      "\n",
      "\n",
      "Stage  271\n",
      "Epoch 50/200\n",
      "Learning rate :  6.653680671501685e-05\n",
      "Average loss :  6.666101626251475e-08\n",
      "\n",
      "\n",
      "Stage  271\n",
      "Epoch 100/200\n",
      "Learning rate :  6.653680671501685e-05\n",
      "Average loss :  6.316057010735676e-08\n",
      "\n",
      "\n",
      "Stage  271\n",
      "Epoch 150/200\n",
      "Learning rate :  6.653680671501685e-05\n",
      "Average loss :  2.983225400043921e-08\n",
      "\n",
      "\n",
      "Stage  271\n",
      "Epoch 200/200\n",
      "Learning rate :  6.653680671501685e-05\n",
      "Average loss :  5.263905222818721e-08\n",
      "expression length:\t 5\n",
      "Result stage 273: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13996467]*t)\n",
      "\n",
      "\n",
      "Stage  272\n",
      "Epoch 50/200\n",
      "Learning rate :  6.587475442640295e-05\n",
      "Average loss :  3.6019311977497637e-08\n",
      "\n",
      "\n",
      "Stage  272\n",
      "Epoch 100/200\n",
      "Learning rate :  6.587475442640295e-05\n",
      "Average loss :  3.1390658961072404e-08\n",
      "\n",
      "\n",
      "Stage  272\n",
      "Epoch 150/200\n",
      "Learning rate :  6.587475442640295e-05\n",
      "Average loss :  2.8608692304032957e-08\n",
      "\n",
      "\n",
      "Stage  272\n",
      "Epoch 200/200\n",
      "Learning rate :  6.587475442640295e-05\n",
      "Average loss :  2.9511975085938502e-08\n",
      "expression length:\t 5\n",
      "Result stage 274: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13997029]*t)\n",
      "\n",
      "\n",
      "Stage  273\n",
      "Epoch 50/200\n",
      "Learning rate :  6.521928966812752e-05\n",
      "Average loss :  5.5077379101931e-08\n",
      "\n",
      "\n",
      "Stage  273\n",
      "Epoch 100/200\n",
      "Learning rate :  6.521928966812752e-05\n",
      "Average loss :  3.129125047962589e-08\n",
      "\n",
      "\n",
      "Stage  273\n",
      "Epoch 150/200\n",
      "Learning rate :  6.521928966812752e-05\n",
      "Average loss :  3.227472689104616e-08\n",
      "\n",
      "\n",
      "Stage  273\n",
      "Epoch 200/200\n",
      "Learning rate :  6.521928966812752e-05\n",
      "Average loss :  3.124896963413448e-08\n",
      "expression length:\t 5\n",
      "Result stage 275: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13998072]*t)\n",
      "\n",
      "\n",
      "Stage  274\n",
      "Epoch 50/200\n",
      "Learning rate :  6.457034689316847e-05\n",
      "Average loss :  4.482897608681924e-08\n",
      "\n",
      "\n",
      "Stage  274\n",
      "Epoch 100/200\n",
      "Learning rate :  6.457034689316847e-05\n",
      "Average loss :  2.673123944418876e-08\n",
      "\n",
      "\n",
      "Stage  274\n",
      "Epoch 150/200\n",
      "Learning rate :  6.457034689316847e-05\n",
      "Average loss :  3.139274795671554e-08\n",
      "\n",
      "\n",
      "Stage  274\n",
      "Epoch 200/200\n",
      "Learning rate :  6.457034689316847e-05\n",
      "Average loss :  3.395793157778826e-08\n",
      "expression length:\t 5\n",
      "Result stage 276: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13997725]*t)\n",
      "\n",
      "\n",
      "Stage  275\n",
      "Epoch 50/200\n",
      "Learning rate :  6.392786120670758e-05\n",
      "Average loss :  5.6429144024150446e-08\n",
      "\n",
      "\n",
      "Stage  275\n",
      "Epoch 100/200\n",
      "Learning rate :  6.392786120670758e-05\n",
      "Average loss :  3.0218185287367305e-08\n",
      "\n",
      "\n",
      "Stage  275\n",
      "Epoch 150/200\n",
      "Learning rate :  6.392786120670758e-05\n",
      "Average loss :  5.387294521597141e-08\n",
      "\n",
      "\n",
      "Stage  275\n",
      "Epoch 200/200\n",
      "Learning rate :  6.392786120670758e-05\n",
      "Average loss :  2.9292317904605625e-08\n",
      "expression length:\t 5\n",
      "Result stage 277: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13998516]*t)\n",
      "\n",
      "\n",
      "Stage  276\n",
      "Epoch 50/200\n",
      "Learning rate :  6.329176835964071e-05\n",
      "Average loss :  4.244381202056502e-08\n",
      "\n",
      "\n",
      "Stage  276\n",
      "Epoch 100/200\n",
      "Learning rate :  6.329176835964071e-05\n",
      "Average loss :  3.02921243644505e-08\n",
      "\n",
      "\n",
      "Stage  276\n",
      "Epoch 150/200\n",
      "Learning rate :  6.329176835964071e-05\n",
      "Average loss :  2.172852298087946e-08\n",
      "\n",
      "\n",
      "Stage  276\n",
      "Epoch 200/200\n",
      "Learning rate :  6.329176835964071e-05\n",
      "Average loss :  2.878277882700786e-08\n",
      "expression length:\t 5\n",
      "Result stage 278: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13998534]*t)\n",
      "\n",
      "\n",
      "Stage  277\n",
      "Epoch 50/200\n",
      "Learning rate :  6.266200474215315e-05\n",
      "Average loss :  3.2300174979127405e-08\n",
      "\n",
      "\n",
      "Stage  277\n",
      "Epoch 100/200\n",
      "Learning rate :  6.266200474215315e-05\n",
      "Average loss :  4.195085168134938e-08\n",
      "\n",
      "\n",
      "Stage  277\n",
      "Epoch 150/200\n",
      "Learning rate :  6.266200474215315e-05\n",
      "Average loss :  2.6217991333510327e-08\n",
      "\n",
      "\n",
      "Stage  277\n",
      "Epoch 200/200\n",
      "Learning rate :  6.266200474215315e-05\n",
      "Average loss :  2.6600659452924447e-08\n",
      "expression length:\t 5\n",
      "Result stage 279: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13997233]*t)\n",
      "\n",
      "\n",
      "Stage  278\n",
      "Epoch 50/200\n",
      "Learning rate :  6.203850737735829e-05\n",
      "Average loss :  2.5734321340564748e-08\n",
      "\n",
      "\n",
      "Stage  278\n",
      "Epoch 100/200\n",
      "Learning rate :  6.203850737735829e-05\n",
      "Average loss :  2.7716678729916566e-08\n",
      "\n",
      "\n",
      "Stage  278\n",
      "Epoch 150/200\n",
      "Learning rate :  6.203850737735829e-05\n",
      "Average loss :  2.597505144308343e-08\n",
      "\n",
      "\n",
      "Stage  278\n",
      "Epoch 200/200\n",
      "Learning rate :  6.203850737735829e-05\n",
      "Average loss :  2.719873037904108e-08\n",
      "expression length:\t 5\n",
      "Result stage 280: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13997436]*t)\n",
      "\n",
      "\n",
      "Stage  279\n",
      "Epoch 50/200\n",
      "Learning rate :  6.142121391500013e-05\n",
      "Average loss :  2.7727933726851006e-08\n",
      "\n",
      "\n",
      "Stage  279\n",
      "Epoch 100/200\n",
      "Learning rate :  6.142121391500013e-05\n",
      "Average loss :  3.6177681295157527e-08\n",
      "\n",
      "\n",
      "Stage  279\n",
      "Epoch 150/200\n",
      "Learning rate :  6.142121391500013e-05\n",
      "Average loss :  5.031276373301807e-08\n",
      "\n",
      "\n",
      "Stage  279\n",
      "Epoch 200/200\n",
      "Learning rate :  6.142121391500013e-05\n",
      "Average loss :  3.144694105117196e-08\n",
      "expression length:\t 5\n",
      "Result stage 281: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.1399788]*t)\n",
      "\n",
      "\n",
      "Stage  280\n",
      "Epoch 50/200\n",
      "Learning rate :  6.0810062625217954e-05\n",
      "Average loss :  2.6826677768099216e-08\n",
      "\n",
      "\n",
      "Stage  280\n",
      "Epoch 100/200\n",
      "Learning rate :  6.0810062625217954e-05\n",
      "Average loss :  2.469572280006105e-08\n",
      "\n",
      "\n",
      "Stage  280\n",
      "Epoch 150/200\n",
      "Learning rate :  6.0810062625217954e-05\n",
      "Average loss :  2.6899925842371886e-08\n",
      "\n",
      "\n",
      "Stage  280\n",
      "Epoch 200/200\n",
      "Learning rate :  6.0810062625217954e-05\n",
      "Average loss :  3.2870477895130534e-08\n",
      "expression length:\t 5\n",
      "Result stage 282: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13997059]*t)\n",
      "\n",
      "\n",
      "Stage  281\n",
      "Epoch 50/200\n",
      "Learning rate :  6.020499239237354e-05\n",
      "Average loss :  2.443679925079323e-08\n",
      "\n",
      "\n",
      "Stage  281\n",
      "Epoch 100/200\n",
      "Learning rate :  6.020499239237354e-05\n",
      "Average loss :  3.333467191168893e-08\n",
      "\n",
      "\n",
      "Stage  281\n",
      "Epoch 150/200\n",
      "Learning rate :  6.020499239237354e-05\n",
      "Average loss :  3.311584961807057e-08\n",
      "\n",
      "\n",
      "Stage  281\n",
      "Epoch 200/200\n",
      "Learning rate :  6.020499239237354e-05\n",
      "Average loss :  2.7402428770528786e-08\n",
      "expression length:\t 5\n",
      "Result stage 283: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13998963]*t)\n",
      "\n",
      "\n",
      "Stage  282\n",
      "Epoch 50/200\n",
      "Learning rate :  5.960594270893937e-05\n",
      "Average loss :  2.3793205627953284e-08\n",
      "\n",
      "\n",
      "Stage  282\n",
      "Epoch 100/200\n",
      "Learning rate :  5.960594270893937e-05\n",
      "Average loss :  2.1737315947234492e-08\n",
      "\n",
      "\n",
      "Stage  282\n",
      "Epoch 150/200\n",
      "Learning rate :  5.960594270893937e-05\n",
      "Average loss :  2.5847478823948222e-08\n",
      "\n",
      "\n",
      "Stage  282\n",
      "Epoch 200/200\n",
      "Learning rate :  5.960594270893937e-05\n",
      "Average loss :  2.585358771511892e-08\n",
      "expression length:\t 5\n",
      "Result stage 284: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.424*x0_t*cos(x0) + \n",
      "exp([0.13998483]*t)\n",
      "\n",
      "\n",
      "Stage  283\n",
      "Epoch 50/200\n",
      "Learning rate :  5.9012853669447845e-05\n",
      "Average loss :  2.415776023667604e-08\n",
      "\n",
      "\n",
      "Stage  283\n",
      "Epoch 100/200\n",
      "Learning rate :  5.9012853669447845e-05\n",
      "Average loss :  3.673149606697734e-08\n",
      "\n",
      "\n",
      "Stage  283\n",
      "Epoch 150/200\n",
      "Learning rate :  5.9012853669447845e-05\n",
      "Average loss :  2.3501783630308637e-08\n",
      "\n",
      "\n",
      "Stage  283\n",
      "Epoch 200/200\n",
      "Learning rate :  5.9012853669447845e-05\n",
      "Average loss :  2.538721233236174e-08\n",
      "expression length:\t 5\n",
      "Result stage 285: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13998833]*t)\n",
      "\n",
      "\n",
      "Stage  284\n",
      "Epoch 50/200\n",
      "Learning rate :  5.842566596450083e-05\n",
      "Average loss :  2.6619272119887682e-08\n",
      "\n",
      "\n",
      "Stage  284\n",
      "Epoch 100/200\n",
      "Learning rate :  5.842566596450083e-05\n",
      "Average loss :  4.212804682879323e-08\n",
      "\n",
      "\n",
      "Stage  284\n",
      "Epoch 150/200\n",
      "Learning rate :  5.842566596450083e-05\n",
      "Average loss :  2.105929830520381e-08\n",
      "\n",
      "\n",
      "Stage  284\n",
      "Epoch 200/200\n",
      "Learning rate :  5.842566596450083e-05\n",
      "Average loss :  2.5631285538452175e-08\n",
      "expression length:\t 5\n",
      "Result stage 286: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13997841]*t)\n",
      "\n",
      "\n",
      "Stage  285\n",
      "Epoch 50/200\n",
      "Learning rate :  5.7844320874838456e-05\n",
      "Average loss :  2.3788345515640685e-08\n",
      "\n",
      "\n",
      "Stage  285\n",
      "Epoch 100/200\n",
      "Learning rate :  5.7844320874838456e-05\n",
      "Average loss :  2.411217892017703e-08\n",
      "\n",
      "\n",
      "Stage  285\n",
      "Epoch 150/200\n",
      "Learning rate :  5.7844320874838456e-05\n",
      "Average loss :  4.616073923102704e-08\n",
      "\n",
      "\n",
      "Stage  285\n",
      "Epoch 200/200\n",
      "Learning rate :  5.7844320874838456e-05\n",
      "Average loss :  2.4282350352677895e-08\n",
      "expression length:\t 5\n",
      "Result stage 287: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13998426]*t)\n",
      "\n",
      "\n",
      "Stage  286\n",
      "Epoch 50/200\n",
      "Learning rate :  5.7268760265467356e-05\n",
      "Average loss :  2.1988352472135375e-08\n",
      "\n",
      "\n",
      "Stage  286\n",
      "Epoch 100/200\n",
      "Learning rate :  5.7268760265467356e-05\n",
      "Average loss :  2.2012756062395056e-08\n",
      "\n",
      "\n",
      "Stage  286\n",
      "Epoch 150/200\n",
      "Learning rate :  5.7268760265467356e-05\n",
      "Average loss :  2.2286545942051816e-08\n",
      "\n",
      "\n",
      "Stage  286\n",
      "Epoch 200/200\n",
      "Learning rate :  5.7268760265467356e-05\n",
      "Average loss :  2.1924412507701163e-08\n",
      "expression length:\t 5\n",
      "Result stage 288: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13997248]*t)\n",
      "\n",
      "\n",
      "Stage  287\n",
      "Epoch 50/200\n",
      "Learning rate :  5.6698926579846905e-05\n",
      "Average loss :  2.426903655816659e-08\n",
      "\n",
      "\n",
      "Stage  287\n",
      "Epoch 100/200\n",
      "Learning rate :  5.6698926579846905e-05\n",
      "Average loss :  2.3987212216525222e-08\n",
      "\n",
      "\n",
      "Stage  287\n",
      "Epoch 150/200\n",
      "Learning rate :  5.6698926579846905e-05\n",
      "Average loss :  2.1632043711861115e-08\n",
      "\n",
      "\n",
      "Stage  287\n",
      "Epoch 200/200\n",
      "Learning rate :  5.6698926579846905e-05\n",
      "Average loss :  2.470514104402355e-08\n",
      "expression length:\t 5\n",
      "Result stage 289: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13997996]*t)\n",
      "\n",
      "\n",
      "Stage  288\n",
      "Epoch 50/200\n",
      "Learning rate :  5.6134762834133726e-05\n",
      "Average loss :  2.089669770555247e-08\n",
      "\n",
      "\n",
      "Stage  288\n",
      "Epoch 100/200\n",
      "Learning rate :  5.6134762834133726e-05\n",
      "Average loss :  2.1121577375993184e-08\n",
      "\n",
      "\n",
      "Stage  288\n",
      "Epoch 150/200\n",
      "Learning rate :  5.6134762834133726e-05\n",
      "Average loss :  2.1322584586869198e-08\n",
      "\n",
      "\n",
      "Stage  288\n",
      "Epoch 200/200\n",
      "Learning rate :  5.6134762834133726e-05\n",
      "Average loss :  2.3517761960079042e-08\n",
      "expression length:\t 5\n",
      "Result stage 290: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13997868]*t)\n",
      "\n",
      "\n",
      "Stage  289\n",
      "Epoch 50/200\n",
      "Learning rate :  5.557621261148306e-05\n",
      "Average loss :  2.7182668560499224e-08\n",
      "\n",
      "\n",
      "Stage  289\n",
      "Epoch 100/200\n",
      "Learning rate :  5.557621261148306e-05\n",
      "Average loss :  3.336769793804706e-08\n",
      "\n",
      "\n",
      "Stage  289\n",
      "Epoch 150/200\n",
      "Learning rate :  5.557621261148306e-05\n",
      "Average loss :  2.1944511985338977e-08\n",
      "\n",
      "\n",
      "Stage  289\n",
      "Epoch 200/200\n",
      "Learning rate :  5.557621261148306e-05\n",
      "Average loss :  2.085605821378067e-08\n",
      "expression length:\t 5\n",
      "Result stage 291: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13997608]*t)\n",
      "\n",
      "\n",
      "Stage  290\n",
      "Epoch 50/200\n",
      "Learning rate :  5.502322005640723e-05\n",
      "Average loss :  2.2295171930863944e-08\n",
      "\n",
      "\n",
      "Stage  290\n",
      "Epoch 100/200\n",
      "Learning rate :  5.502322005640723e-05\n",
      "Average loss :  2.305560009574492e-08\n",
      "\n",
      "\n",
      "Stage  290\n",
      "Epoch 150/200\n",
      "Learning rate :  5.502322005640723e-05\n",
      "Average loss :  2.867223969360566e-08\n",
      "\n",
      "\n",
      "Stage  290\n",
      "Epoch 200/200\n",
      "Learning rate :  5.502322005640723e-05\n",
      "Average loss :  2.2954834477673103e-08\n",
      "expression length:\t 5\n",
      "Result stage 292: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13999058]*t)\n",
      "\n",
      "\n",
      "Stage  291\n",
      "Epoch 50/200\n",
      "Learning rate :  5.447572986918986e-05\n",
      "Average loss :  1.9978662280095705e-08\n",
      "\n",
      "\n",
      "Stage  291\n",
      "Epoch 100/200\n",
      "Learning rate :  5.447572986918986e-05\n",
      "Average loss :  2.6670067043710333e-08\n",
      "\n",
      "\n",
      "Stage  291\n",
      "Epoch 150/200\n",
      "Learning rate :  5.447572986918986e-05\n",
      "Average loss :  1.6673460834226717e-08\n",
      "\n",
      "\n",
      "Stage  291\n",
      "Epoch 200/200\n",
      "Learning rate :  5.447572986918986e-05\n",
      "Average loss :  2.169085000502946e-08\n",
      "expression length:\t 5\n",
      "Result stage 293: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13998151]*t)\n",
      "\n",
      "\n",
      "Stage  292\n",
      "Epoch 50/200\n",
      "Learning rate :  5.393368730035602e-05\n",
      "Average loss :  2.192788350896535e-08\n",
      "\n",
      "\n",
      "Stage  292\n",
      "Epoch 100/200\n",
      "Learning rate :  5.393368730035602e-05\n",
      "Average loss :  1.9751665192302426e-08\n",
      "\n",
      "\n",
      "Stage  292\n",
      "Epoch 150/200\n",
      "Learning rate :  5.393368730035602e-05\n",
      "Average loss :  4.808905273989694e-08\n",
      "\n",
      "\n",
      "Stage  292\n",
      "Epoch 200/200\n",
      "Learning rate :  5.393368730035602e-05\n",
      "Average loss :  1.9491123381953912e-08\n",
      "expression length:\t 5\n",
      "Result stage 294: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.139974]*t)\n",
      "\n",
      "\n",
      "Stage  293\n",
      "Epoch 50/200\n",
      "Learning rate :  5.339703814519709e-05\n",
      "Average loss :  1.9290656183557076e-08\n",
      "\n",
      "\n",
      "Stage  293\n",
      "Epoch 100/200\n",
      "Learning rate :  5.339703814519709e-05\n",
      "Average loss :  2.154181366620378e-08\n",
      "\n",
      "\n",
      "Stage  293\n",
      "Epoch 150/200\n",
      "Learning rate :  5.339703814519709e-05\n",
      "Average loss :  2.099804952138129e-08\n",
      "\n",
      "\n",
      "Stage  293\n",
      "Epoch 200/200\n",
      "Learning rate :  5.339703814519709e-05\n",
      "Average loss :  3.8866588170094474e-08\n",
      "expression length:\t 5\n",
      "Result stage 295: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.1399727]*t)\n",
      "\n",
      "\n",
      "Stage  294\n",
      "Epoch 50/200\n",
      "Learning rate :  5.286572873835037e-05\n",
      "Average loss :  2.3729489484480837e-08\n",
      "\n",
      "\n",
      "Stage  294\n",
      "Epoch 100/200\n",
      "Learning rate :  5.286572873835037e-05\n",
      "Average loss :  1.99635135089693e-08\n",
      "\n",
      "\n",
      "Stage  294\n",
      "Epoch 150/200\n",
      "Learning rate :  5.286572873835037e-05\n",
      "Average loss :  1.867834242830213e-08\n",
      "\n",
      "\n",
      "Stage  294\n",
      "Epoch 200/200\n",
      "Learning rate :  5.286572873835037e-05\n",
      "Average loss :  3.103220791444983e-08\n",
      "expression length:\t 5\n",
      "Result stage 296: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13997163]*t)\n",
      "\n",
      "\n",
      "Stage  295\n",
      "Epoch 50/200\n",
      "Learning rate :  5.233970594843238e-05\n",
      "Average loss :  2.0805929423772795e-08\n",
      "\n",
      "\n",
      "Stage  295\n",
      "Epoch 100/200\n",
      "Learning rate :  5.233970594843238e-05\n",
      "Average loss :  1.9486254387857116e-08\n",
      "\n",
      "\n",
      "Stage  295\n",
      "Epoch 150/200\n",
      "Learning rate :  5.233970594843238e-05\n",
      "Average loss :  2.3654108005644048e-08\n",
      "\n",
      "\n",
      "Stage  295\n",
      "Epoch 200/200\n",
      "Learning rate :  5.233970594843238e-05\n",
      "Average loss :  3.18295469980967e-08\n",
      "expression length:\t 5\n",
      "Result stage 297: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.1399725]*t)\n",
      "\n",
      "\n",
      "Stage  296\n",
      "Epoch 50/200\n",
      "Learning rate :  5.181891717272583e-05\n",
      "Average loss :  1.7819809627894756e-08\n",
      "\n",
      "\n",
      "Stage  296\n",
      "Epoch 100/200\n",
      "Learning rate :  5.181891717272583e-05\n",
      "Average loss :  2.5134673009574726e-08\n",
      "\n",
      "\n",
      "Stage  296\n",
      "Epoch 150/200\n",
      "Learning rate :  5.181891717272583e-05\n",
      "Average loss :  3.140845095117584e-08\n",
      "\n",
      "\n",
      "Stage  296\n",
      "Epoch 200/200\n",
      "Learning rate :  5.181891717272583e-05\n",
      "Average loss :  4.4315875413758476e-08\n",
      "expression length:\t 5\n",
      "Result stage 298: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13998206]*t)\n",
      "\n",
      "\n",
      "Stage  297\n",
      "Epoch 50/200\n",
      "Learning rate :  5.130331033191911e-05\n",
      "Average loss :  1.787544690046161e-08\n",
      "\n",
      "\n",
      "Stage  297\n",
      "Epoch 100/200\n",
      "Learning rate :  5.130331033191911e-05\n",
      "Average loss :  3.209581578289544e-08\n",
      "\n",
      "\n",
      "Stage  297\n",
      "Epoch 150/200\n",
      "Learning rate :  5.130331033191911e-05\n",
      "Average loss :  2.2479342831616123e-08\n",
      "\n",
      "\n",
      "Stage  297\n",
      "Epoch 200/200\n",
      "Learning rate :  5.130331033191911e-05\n",
      "Average loss :  2.8020449960308724e-08\n",
      "expression length:\t 5\n",
      "Result stage 299: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13997258]*t)\n",
      "\n",
      "\n",
      "Stage  298\n",
      "Epoch 50/200\n",
      "Learning rate :  5.07928338648985e-05\n",
      "Average loss :  3.692843364433429e-08\n",
      "\n",
      "\n",
      "Stage  298\n",
      "Epoch 100/200\n",
      "Learning rate :  5.07928338648985e-05\n",
      "Average loss :  2.485586314548982e-08\n",
      "\n",
      "\n",
      "Stage  298\n",
      "Epoch 150/200\n",
      "Learning rate :  5.07928338648985e-05\n",
      "Average loss :  1.6992098395007815e-08\n",
      "\n",
      "\n",
      "Stage  298\n",
      "Epoch 200/200\n",
      "Learning rate :  5.07928338648985e-05\n",
      "Average loss :  3.6800823721705456e-08\n",
      "expression length:\t 5\n",
      "Result stage 300: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.1399774]*t)\n",
      "\n",
      "\n",
      "Stage  299\n",
      "Epoch 50/200\n",
      "Learning rate :  5.028743672359187e-05\n",
      "Average loss :  1.8074747032414962e-08\n",
      "\n",
      "\n",
      "Stage  299\n",
      "Epoch 100/200\n",
      "Learning rate :  5.028743672359187e-05\n",
      "Average loss :  1.6970087557410807e-08\n",
      "\n",
      "\n",
      "Stage  299\n",
      "Epoch 150/200\n",
      "Learning rate :  5.028743672359187e-05\n",
      "Average loss :  1.943861782649492e-08\n",
      "\n",
      "\n",
      "Stage  299\n",
      "Epoch 200/200\n",
      "Learning rate :  5.028743672359187e-05\n",
      "Average loss :  5.207851927480078e-08\n",
      "expression length:\t 5\n",
      "Result stage 301: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.1399905]*t)\n",
      "\n",
      "\n",
      "Stage  300\n",
      "Epoch 50/200\n",
      "Learning rate :  4.9787068367863945e-05\n",
      "Average loss :  3.34297141080242e-08\n",
      "\n",
      "\n",
      "Stage  300\n",
      "Epoch 100/200\n",
      "Learning rate :  4.9787068367863945e-05\n",
      "Average loss :  2.750952177166255e-08\n",
      "\n",
      "\n",
      "Stage  300\n",
      "Epoch 150/200\n",
      "Learning rate :  4.9787068367863945e-05\n",
      "Average loss :  1.6618111331467844e-08\n",
      "\n",
      "\n",
      "Stage  300\n",
      "Epoch 200/200\n",
      "Learning rate :  4.9787068367863945e-05\n",
      "Average loss :  1.654834136388672e-08\n",
      "expression length:\t 5\n",
      "Result stage 302: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13997826]*t)\n",
      "\n",
      "\n",
      "Stage  301\n",
      "Epoch 50/200\n",
      "Learning rate :  4.929167876046215e-05\n",
      "Average loss :  2.0713468273925173e-08\n",
      "\n",
      "\n",
      "Stage  301\n",
      "Epoch 100/200\n",
      "Learning rate :  4.929167876046215e-05\n",
      "Average loss :  1.6349613218835657e-08\n",
      "\n",
      "\n",
      "Stage  301\n",
      "Epoch 150/200\n",
      "Learning rate :  4.929167876046215e-05\n",
      "Average loss :  1.8220665864987495e-08\n",
      "\n",
      "\n",
      "Stage  301\n",
      "Epoch 200/200\n",
      "Learning rate :  4.929167876046215e-05\n",
      "Average loss :  1.7627325377134184e-08\n",
      "expression length:\t 5\n",
      "Result stage 303: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13998693]*t)\n",
      "\n",
      "\n",
      "Stage  302\n",
      "Epoch 50/200\n",
      "Learning rate :  4.880121836201296e-05\n",
      "Average loss :  2.5844306250633053e-08\n",
      "\n",
      "\n",
      "Stage  302\n",
      "Epoch 100/200\n",
      "Learning rate :  4.880121836201296e-05\n",
      "Average loss :  1.713931752078679e-08\n",
      "\n",
      "\n",
      "Stage  302\n",
      "Epoch 150/200\n",
      "Learning rate :  4.880121836201296e-05\n",
      "Average loss :  2.007665500514122e-08\n",
      "\n",
      "\n",
      "Stage  302\n",
      "Epoch 200/200\n",
      "Learning rate :  4.880121836201296e-05\n",
      "Average loss :  3.245674307095214e-08\n",
      "expression length:\t 5\n",
      "Result stage 304: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13997722]*t)\n",
      "\n",
      "\n",
      "Stage  303\n",
      "Epoch 50/200\n",
      "Learning rate :  4.831563812606777e-05\n",
      "Average loss :  1.6764278853997894e-08\n",
      "\n",
      "\n",
      "Stage  303\n",
      "Epoch 100/200\n",
      "Learning rate :  4.831563812606777e-05\n",
      "Average loss :  2.2643103392283592e-08\n",
      "\n",
      "\n",
      "Stage  303\n",
      "Epoch 150/200\n",
      "Learning rate :  4.831563812606777e-05\n",
      "Average loss :  1.6264376512253875e-08\n",
      "\n",
      "\n",
      "Stage  303\n",
      "Epoch 200/200\n",
      "Learning rate :  4.831563812606777e-05\n",
      "Average loss :  2.569000479013539e-08\n",
      "expression length:\t 5\n",
      "Result stage 305: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13997418]*t)\n",
      "\n",
      "\n",
      "Stage  304\n",
      "Epoch 50/200\n",
      "Learning rate :  4.7834889494198366e-05\n",
      "Average loss :  1.5197887393014753e-08\n",
      "\n",
      "\n",
      "Stage  304\n",
      "Epoch 100/200\n",
      "Learning rate :  4.7834889494198366e-05\n",
      "Average loss :  1.5486383730944908e-08\n",
      "\n",
      "\n",
      "Stage  304\n",
      "Epoch 150/200\n",
      "Learning rate :  4.7834889494198366e-05\n",
      "Average loss :  1.547562789028234e-08\n",
      "\n",
      "\n",
      "Stage  304\n",
      "Epoch 200/200\n",
      "Learning rate :  4.7834889494198366e-05\n",
      "Average loss :  1.7314500055931603e-08\n",
      "expression length:\t 5\n",
      "Result stage 306: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13999224]*t)\n",
      "\n",
      "\n",
      "Stage  305\n",
      "Epoch 50/200\n",
      "Learning rate :  4.7358924391140906e-05\n",
      "Average loss :  1.5091353944285402e-08\n",
      "\n",
      "\n",
      "Stage  305\n",
      "Epoch 100/200\n",
      "Learning rate :  4.7358924391140906e-05\n",
      "Average loss :  3.16409973777354e-08\n",
      "\n",
      "\n",
      "Stage  305\n",
      "Epoch 150/200\n",
      "Learning rate :  4.7358924391140906e-05\n",
      "Average loss :  2.7448196604495934e-08\n",
      "\n",
      "\n",
      "Stage  305\n",
      "Epoch 200/200\n",
      "Learning rate :  4.7358924391140906e-05\n",
      "Average loss :  1.3870327997267395e-08\n",
      "expression length:\t 5\n",
      "Result stage 307: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13998008]*t)\n",
      "\n",
      "\n",
      "Stage  306\n",
      "Epoch 50/200\n",
      "Learning rate :  4.6887695219988485e-05\n",
      "Average loss :  1.472246324851767e-08\n",
      "\n",
      "\n",
      "Stage  306\n",
      "Epoch 100/200\n",
      "Learning rate :  4.6887695219988485e-05\n",
      "Average loss :  1.8503497400956803e-08\n",
      "\n",
      "\n",
      "Stage  306\n",
      "Epoch 150/200\n",
      "Learning rate :  4.6887695219988485e-05\n",
      "Average loss :  1.4498350964231577e-08\n",
      "\n",
      "\n",
      "Stage  306\n",
      "Epoch 200/200\n",
      "Learning rate :  4.6887695219988485e-05\n",
      "Average loss :  2.6253186291569364e-08\n",
      "expression length:\t 5\n",
      "Result stage 308: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.423*x0_t*cos(x0) + \n",
      "exp([0.13998045]*t)\n",
      "\n",
      "\n",
      "Stage  307\n",
      "Epoch 50/200\n",
      "Learning rate :  4.642115485743125e-05\n",
      "Average loss :  1.643058489264604e-08\n",
      "\n",
      "\n",
      "Stage  307\n",
      "Epoch 100/200\n",
      "Learning rate :  4.642115485743125e-05\n",
      "Average loss :  3.1583859083639254e-08\n",
      "\n",
      "\n",
      "Stage  307\n",
      "Epoch 150/200\n",
      "Learning rate :  4.642115485743125e-05\n",
      "Average loss :  1.6257839519084882e-08\n",
      "\n",
      "\n",
      "Stage  307\n",
      "Epoch 200/200\n",
      "Learning rate :  4.642115485743125e-05\n",
      "Average loss :  1.5289616683844542e-08\n",
      "expression length:\t 5\n",
      "Result stage 309: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13998124]*t)\n",
      "\n",
      "\n",
      "Stage  308\n",
      "Epoch 50/200\n",
      "Learning rate :  4.5959256649044205e-05\n",
      "Average loss :  2.5490152211204986e-08\n",
      "\n",
      "\n",
      "Stage  308\n",
      "Epoch 100/200\n",
      "Learning rate :  4.5959256649044205e-05\n",
      "Average loss :  1.5900139871405372e-08\n",
      "\n",
      "\n",
      "Stage  308\n",
      "Epoch 150/200\n",
      "Learning rate :  4.5959256649044205e-05\n",
      "Average loss :  1.4383645385862565e-08\n",
      "\n",
      "\n",
      "Stage  308\n",
      "Epoch 200/200\n",
      "Learning rate :  4.5959256649044205e-05\n",
      "Average loss :  1.5770227790312674e-08\n",
      "expression length:\t 5\n",
      "Result stage 310: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13998477]*t)\n",
      "\n",
      "\n",
      "Stage  309\n",
      "Epoch 50/200\n",
      "Learning rate :  4.550195440462157e-05\n",
      "Average loss :  1.623240031278783e-08\n",
      "\n",
      "\n",
      "Stage  309\n",
      "Epoch 100/200\n",
      "Learning rate :  4.550195440462157e-05\n",
      "Average loss :  1.5172441081290344e-08\n",
      "\n",
      "\n",
      "Stage  309\n",
      "Epoch 150/200\n",
      "Learning rate :  4.550195440462157e-05\n",
      "Average loss :  1.1893153128994527e-08\n",
      "\n",
      "\n",
      "Stage  309\n",
      "Epoch 200/200\n",
      "Learning rate :  4.550195440462157e-05\n",
      "Average loss :  1.512026415184664e-08\n",
      "expression length:\t 5\n",
      "Result stage 311: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13999173]*t)\n",
      "\n",
      "\n",
      "Stage  310\n",
      "Epoch 50/200\n",
      "Learning rate :  4.50492023935578e-05\n",
      "Average loss :  1.3181852054344745e-08\n",
      "\n",
      "\n",
      "Stage  310\n",
      "Epoch 100/200\n",
      "Learning rate :  4.50492023935578e-05\n",
      "Average loss :  1.566104046446526e-08\n",
      "\n",
      "\n",
      "Stage  310\n",
      "Epoch 150/200\n",
      "Learning rate :  4.50492023935578e-05\n",
      "Average loss :  2.1222245294438835e-08\n",
      "\n",
      "\n",
      "Stage  310\n",
      "Epoch 200/200\n",
      "Learning rate :  4.50492023935578e-05\n",
      "Average loss :  1.51665915382182e-08\n",
      "expression length:\t 5\n",
      "Result stage 312: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.1399917]*t)\n",
      "\n",
      "\n",
      "Stage  311\n",
      "Epoch 50/200\n",
      "Learning rate :  4.460095534027453e-05\n",
      "Average loss :  1.4671481807226883e-08\n",
      "\n",
      "\n",
      "Stage  311\n",
      "Epoch 100/200\n",
      "Learning rate :  4.460095534027453e-05\n",
      "Average loss :  1.349442779741139e-08\n",
      "\n",
      "\n",
      "Stage  311\n",
      "Epoch 150/200\n",
      "Learning rate :  4.460095534027453e-05\n",
      "Average loss :  2.0452695537187537e-08\n",
      "\n",
      "\n",
      "Stage  311\n",
      "Epoch 200/200\n",
      "Learning rate :  4.460095534027453e-05\n",
      "Average loss :  2.9351618024975323e-08\n",
      "expression length:\t 5\n",
      "Result stage 313: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13997377]*t)\n",
      "\n",
      "\n",
      "Stage  312\n",
      "Epoch 50/200\n",
      "Learning rate :  4.415716841969286e-05\n",
      "Average loss :  1.4208846543795062e-08\n",
      "\n",
      "\n",
      "Stage  312\n",
      "Epoch 100/200\n",
      "Learning rate :  4.415716841969286e-05\n",
      "Average loss :  1.0525735838484707e-08\n",
      "\n",
      "\n",
      "Stage  312\n",
      "Epoch 150/200\n",
      "Learning rate :  4.415716841969286e-05\n",
      "Average loss :  2.6749061632358462e-08\n",
      "\n",
      "\n",
      "Stage  312\n",
      "Epoch 200/200\n",
      "Learning rate :  4.415716841969286e-05\n",
      "Average loss :  2.5743748466311445e-08\n",
      "expression length:\t 5\n",
      "Result stage 314: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13997984]*t)\n",
      "\n",
      "\n",
      "Stage  313\n",
      "Epoch 50/200\n",
      "Learning rate :  4.371779725275094e-05\n",
      "Average loss :  2.3322749953536004e-08\n",
      "\n",
      "\n",
      "Stage  313\n",
      "Epoch 100/200\n",
      "Learning rate :  4.371779725275094e-05\n",
      "Average loss :  1.2839350915783143e-08\n",
      "\n",
      "\n",
      "Stage  313\n",
      "Epoch 150/200\n",
      "Learning rate :  4.371779725275094e-05\n",
      "Average loss :  1.3933527220899578e-08\n",
      "\n",
      "\n",
      "Stage  313\n",
      "Epoch 200/200\n",
      "Learning rate :  4.371779725275094e-05\n",
      "Average loss :  1.5042619594396456e-08\n",
      "expression length:\t 5\n",
      "Result stage 315: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13998431]*t)\n",
      "\n",
      "\n",
      "Stage  314\n",
      "Epoch 50/200\n",
      "Learning rate :  4.32827979019659e-05\n",
      "Average loss :  3.674654891483442e-08\n",
      "\n",
      "\n",
      "Stage  314\n",
      "Epoch 100/200\n",
      "Learning rate :  4.32827979019659e-05\n",
      "Average loss :  1.942751381989183e-08\n",
      "\n",
      "\n",
      "Stage  314\n",
      "Epoch 150/200\n",
      "Learning rate :  4.32827979019659e-05\n",
      "Average loss :  2.3813809590933488e-08\n",
      "\n",
      "\n",
      "Stage  314\n",
      "Epoch 200/200\n",
      "Learning rate :  4.32827979019659e-05\n",
      "Average loss :  1.2921803183019165e-08\n",
      "expression length:\t 5\n",
      "Result stage 316: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13998134]*t)\n",
      "\n",
      "\n",
      "Stage  315\n",
      "Epoch 50/200\n",
      "Learning rate :  4.285212686704019e-05\n",
      "Average loss :  1.012060835137163e-08\n",
      "\n",
      "\n",
      "Stage  315\n",
      "Epoch 100/200\n",
      "Learning rate :  4.285212686704019e-05\n",
      "Average loss :  1.6117168044615937e-08\n",
      "\n",
      "\n",
      "Stage  315\n",
      "Epoch 150/200\n",
      "Learning rate :  4.285212686704019e-05\n",
      "Average loss :  1.3993354031072158e-08\n",
      "\n",
      "\n",
      "Stage  315\n",
      "Epoch 200/200\n",
      "Learning rate :  4.285212686704019e-05\n",
      "Average loss :  1.3754434036172825e-08\n",
      "expression length:\t 5\n",
      "Result stage 317: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13999175]*t)\n",
      "\n",
      "\n",
      "Stage  316\n",
      "Epoch 50/200\n",
      "Learning rate :  4.2425741080511384e-05\n",
      "Average loss :  1.5808785391868696e-08\n",
      "\n",
      "\n",
      "Stage  316\n",
      "Epoch 100/200\n",
      "Learning rate :  4.2425741080511384e-05\n",
      "Average loss :  1.357442958038746e-08\n",
      "\n",
      "\n",
      "Stage  316\n",
      "Epoch 150/200\n",
      "Learning rate :  4.2425741080511384e-05\n",
      "Average loss :  1.6007826175723494e-08\n",
      "\n",
      "\n",
      "Stage  316\n",
      "Epoch 200/200\n",
      "Learning rate :  4.2425741080511384e-05\n",
      "Average loss :  1.3482684302346115e-08\n",
      "expression length:\t 5\n",
      "Result stage 318: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13998401]*t)\n",
      "\n",
      "\n",
      "Stage  317\n",
      "Epoch 50/200\n",
      "Learning rate :  4.200359790344555e-05\n",
      "Average loss :  1.2537336502305152e-08\n",
      "\n",
      "\n",
      "Stage  317\n",
      "Epoch 100/200\n",
      "Learning rate :  4.200359790344555e-05\n",
      "Average loss :  1.4648705359832093e-08\n",
      "\n",
      "\n",
      "Stage  317\n",
      "Epoch 150/200\n",
      "Learning rate :  4.200359790344555e-05\n",
      "Average loss :  1.2015394901254695e-08\n",
      "\n",
      "\n",
      "Stage  317\n",
      "Epoch 200/200\n",
      "Learning rate :  4.200359790344555e-05\n",
      "Average loss :  1.2609488564407911e-08\n",
      "expression length:\t 5\n",
      "Result stage 319: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13998766]*t)\n",
      "\n",
      "\n",
      "Stage  318\n",
      "Epoch 50/200\n",
      "Learning rate :  4.158565512117316e-05\n",
      "Average loss :  1.2509665303639395e-08\n",
      "\n",
      "\n",
      "Stage  318\n",
      "Epoch 100/200\n",
      "Learning rate :  4.158565512117316e-05\n",
      "Average loss :  1.1765473928448955e-08\n",
      "\n",
      "\n",
      "Stage  318\n",
      "Epoch 150/200\n",
      "Learning rate :  4.158565512117316e-05\n",
      "Average loss :  1.9310173016151566e-08\n",
      "\n",
      "\n",
      "Stage  318\n",
      "Epoch 200/200\n",
      "Learning rate :  4.158565512117316e-05\n",
      "Average loss :  1.1378697095665302e-08\n",
      "expression length:\t 5\n",
      "Result stage 320: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13998097]*t)\n",
      "\n",
      "\n",
      "Stage  319\n",
      "Epoch 50/200\n",
      "Learning rate :  4.117187093906774e-05\n",
      "Average loss :  1.612160005493024e-08\n",
      "\n",
      "\n",
      "Stage  319\n",
      "Epoch 100/200\n",
      "Learning rate :  4.117187093906774e-05\n",
      "Average loss :  2.6621345128319263e-08\n",
      "\n",
      "\n",
      "Stage  319\n",
      "Epoch 150/200\n",
      "Learning rate :  4.117187093906774e-05\n",
      "Average loss :  1.2088631429207908e-08\n",
      "\n",
      "\n",
      "Stage  319\n",
      "Epoch 200/200\n",
      "Learning rate :  4.117187093906774e-05\n",
      "Average loss :  1.3832029743809926e-08\n",
      "expression length:\t 5\n",
      "Result stage 321: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13998212]*t)\n",
      "\n",
      "\n",
      "Stage  320\n",
      "Epoch 50/200\n",
      "Learning rate :  4.0762203978366214e-05\n",
      "Average loss :  2.795500186891786e-08\n",
      "\n",
      "\n",
      "Stage  320\n",
      "Epoch 100/200\n",
      "Learning rate :  4.0762203978366214e-05\n",
      "Average loss :  1.1207736072549324e-08\n",
      "\n",
      "\n",
      "Stage  320\n",
      "Epoch 150/200\n",
      "Learning rate :  4.0762203978366214e-05\n",
      "Average loss :  2.105657159745533e-08\n",
      "\n",
      "\n",
      "Stage  320\n",
      "Epoch 200/200\n",
      "Learning rate :  4.0762203978366214e-05\n",
      "Average loss :  8.969443854311976e-09\n",
      "expression length:\t 5\n",
      "Result stage 322: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.1399889]*t)\n",
      "\n",
      "\n",
      "Stage  321\n",
      "Epoch 50/200\n",
      "Learning rate :  4.035661327203115e-05\n",
      "Average loss :  1.217623424309977e-08\n",
      "\n",
      "\n",
      "Stage  321\n",
      "Epoch 100/200\n",
      "Learning rate :  4.035661327203115e-05\n",
      "Average loss :  1.2203479116124072e-08\n",
      "\n",
      "\n",
      "Stage  321\n",
      "Epoch 150/200\n",
      "Learning rate :  4.035661327203115e-05\n",
      "Average loss :  1.0491805646495322e-08\n",
      "\n",
      "\n",
      "Stage  321\n",
      "Epoch 200/200\n",
      "Learning rate :  4.035661327203115e-05\n",
      "Average loss :  8.669379880643646e-09\n",
      "expression length:\t 5\n",
      "Result stage 323: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.1399894]*t)\n",
      "\n",
      "\n",
      "Stage  322\n",
      "Epoch 50/200\n",
      "Learning rate :  3.9955058260653896e-05\n",
      "Average loss :  1.0849372067411878e-08\n",
      "\n",
      "\n",
      "Stage  322\n",
      "Epoch 100/200\n",
      "Learning rate :  3.9955058260653896e-05\n",
      "Average loss :  1.180754516383331e-08\n",
      "\n",
      "\n",
      "Stage  322\n",
      "Epoch 150/200\n",
      "Learning rate :  3.9955058260653896e-05\n",
      "Average loss :  1.1698624291511805e-08\n",
      "\n",
      "\n",
      "Stage  322\n",
      "Epoch 200/200\n",
      "Learning rate :  3.9955058260653896e-05\n",
      "Average loss :  8.70310490341808e-09\n",
      "expression length:\t 5\n",
      "Result stage 324: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13998882]*t)\n",
      "\n",
      "\n",
      "Stage  323\n",
      "Epoch 50/200\n",
      "Learning rate :  3.955749878839873e-05\n",
      "Average loss :  1.0416948192926156e-08\n",
      "\n",
      "\n",
      "Stage  323\n",
      "Epoch 100/200\n",
      "Learning rate :  3.955749878839873e-05\n",
      "Average loss :  1.0689286789045127e-08\n",
      "\n",
      "\n",
      "Stage  323\n",
      "Epoch 150/200\n",
      "Learning rate :  3.955749878839873e-05\n",
      "Average loss :  1.1120598664149384e-08\n",
      "\n",
      "\n",
      "Stage  323\n",
      "Epoch 200/200\n",
      "Learning rate :  3.955749878839873e-05\n",
      "Average loss :  3.235531398360081e-09\n",
      "expression length:\t 5\n",
      "Result stage 325: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13999455]*t)\n",
      "\n",
      "\n",
      "Stage  324\n",
      "Epoch 50/200\n",
      "Learning rate :  3.916389509898707e-05\n",
      "Average loss :  1.1431342983314607e-08\n",
      "\n",
      "\n",
      "Stage  324\n",
      "Epoch 100/200\n",
      "Learning rate :  3.916389509898707e-05\n",
      "Average loss :  1.1048208570230145e-08\n",
      "\n",
      "\n",
      "Stage  324\n",
      "Epoch 150/200\n",
      "Learning rate :  3.916389509898707e-05\n",
      "Average loss :  1.2515526393030996e-08\n",
      "\n",
      "\n",
      "Stage  324\n",
      "Epoch 200/200\n",
      "Learning rate :  3.916389509898707e-05\n",
      "Average loss :  5.329810370824362e-09\n",
      "expression length:\t 5\n",
      "Result stage 326: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.14000024]*t)\n",
      "\n",
      "\n",
      "Stage  325\n",
      "Epoch 50/200\n",
      "Learning rate :  3.877420783172201e-05\n",
      "Average loss :  1.681961414590205e-08\n",
      "\n",
      "\n",
      "Stage  325\n",
      "Epoch 100/200\n",
      "Learning rate :  3.877420783172201e-05\n",
      "Average loss :  1.4732727926514144e-08\n",
      "\n",
      "\n",
      "Stage  325\n",
      "Epoch 150/200\n",
      "Learning rate :  3.877420783172201e-05\n",
      "Average loss :  1.3119434427721899e-08\n",
      "\n",
      "\n",
      "Stage  325\n",
      "Epoch 200/200\n",
      "Learning rate :  3.877420783172201e-05\n",
      "Average loss :  1.0162120034351574e-08\n",
      "expression length:\t 5\n",
      "Result stage 327: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.1399821]*t)\n",
      "\n",
      "\n",
      "Stage  326\n",
      "Epoch 50/200\n",
      "Learning rate :  3.8388398017552055e-05\n",
      "Average loss :  1.011050532184754e-08\n",
      "\n",
      "\n",
      "Stage  326\n",
      "Epoch 100/200\n",
      "Learning rate :  3.8388398017552055e-05\n",
      "Average loss :  9.924895572055448e-09\n",
      "\n",
      "\n",
      "Stage  326\n",
      "Epoch 150/200\n",
      "Learning rate :  3.8388398017552055e-05\n",
      "Average loss :  1.2466121468435176e-08\n",
      "\n",
      "\n",
      "Stage  326\n",
      "Epoch 200/200\n",
      "Learning rate :  3.8388398017552055e-05\n",
      "Average loss :  1.4608265708204726e-08\n",
      "expression length:\t 5\n",
      "Result stage 328: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13998698]*t)\n",
      "\n",
      "\n",
      "Stage  327\n",
      "Epoch 50/200\n",
      "Learning rate :  3.800642707517431e-05\n",
      "Average loss :  9.731712324878572e-09\n",
      "\n",
      "\n",
      "Stage  327\n",
      "Epoch 100/200\n",
      "Learning rate :  3.800642707517431e-05\n",
      "Average loss :  2.1992178744767443e-08\n",
      "\n",
      "\n",
      "Stage  327\n",
      "Epoch 150/200\n",
      "Learning rate :  3.800642707517431e-05\n",
      "Average loss :  9.683537527394037e-09\n",
      "\n",
      "\n",
      "Stage  327\n",
      "Epoch 200/200\n",
      "Learning rate :  3.800642707517431e-05\n",
      "Average loss :  2.6753172122084834e-08\n",
      "expression length:\t 5\n",
      "Result stage 329: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13998929]*t)\n",
      "\n",
      "\n",
      "Stage  328\n",
      "Epoch 50/200\n",
      "Learning rate :  3.76282568071762e-05\n",
      "Average loss :  7.683572889050083e-09\n",
      "\n",
      "\n",
      "Stage  328\n",
      "Epoch 100/200\n",
      "Learning rate :  3.76282568071762e-05\n",
      "Average loss :  2.6659249030558385e-08\n",
      "\n",
      "\n",
      "Stage  328\n",
      "Epoch 150/200\n",
      "Learning rate :  3.76282568071762e-05\n",
      "Average loss :  9.55448342665477e-09\n",
      "\n",
      "\n",
      "Stage  328\n",
      "Epoch 200/200\n",
      "Learning rate :  3.76282568071762e-05\n",
      "Average loss :  1.3245507801684653e-08\n",
      "expression length:\t 5\n",
      "Result stage 330: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.422*x0_t*cos(x0) + \n",
      "exp([0.13998729]*t)\n",
      "\n",
      "\n",
      "Stage  329\n",
      "Epoch 50/200\n",
      "Learning rate :  3.725384939621581e-05\n",
      "Average loss :  1.0385290849512785e-08\n",
      "\n",
      "\n",
      "Stage  329\n",
      "Epoch 100/200\n",
      "Learning rate :  3.725384939621581e-05\n",
      "Average loss :  1.0375580394850203e-08\n",
      "\n",
      "\n",
      "Stage  329\n",
      "Epoch 150/200\n",
      "Learning rate :  3.725384939621581e-05\n",
      "Average loss :  1.0167222619372751e-08\n",
      "\n",
      "\n",
      "Stage  329\n",
      "Epoch 200/200\n",
      "Learning rate :  3.725384939621581e-05\n",
      "Average loss :  1.0441999265253799e-08\n",
      "expression length:\t 5\n",
      "Result stage 331: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999353]*t)\n",
      "\n",
      "\n",
      "Stage  330\n",
      "Epoch 50/200\n",
      "Learning rate :  3.688316740124e-05\n",
      "Average loss :  4.711268264401269e-09\n",
      "\n",
      "\n",
      "Stage  330\n",
      "Epoch 100/200\n",
      "Learning rate :  3.688316740124e-05\n",
      "Average loss :  1.0116560034134636e-08\n",
      "\n",
      "\n",
      "Stage  330\n",
      "Epoch 150/200\n",
      "Learning rate :  3.688316740124e-05\n",
      "Average loss :  9.097433917304443e-09\n",
      "\n",
      "\n",
      "Stage  330\n",
      "Epoch 200/200\n",
      "Learning rate :  3.688316740124e-05\n",
      "Average loss :  1.087433165736229e-08\n",
      "expression length:\t 5\n",
      "Result stage 332: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399845]*t)\n",
      "\n",
      "\n",
      "Stage  331\n",
      "Epoch 50/200\n",
      "Learning rate :  3.65161737537404e-05\n",
      "Average loss :  2.122119191483307e-08\n",
      "\n",
      "\n",
      "Stage  331\n",
      "Epoch 100/200\n",
      "Learning rate :  3.65161737537404e-05\n",
      "Average loss :  9.955684276974353e-09\n",
      "\n",
      "\n",
      "Stage  331\n",
      "Epoch 150/200\n",
      "Learning rate :  3.65161737537404e-05\n",
      "Average loss :  9.847072490742903e-09\n",
      "\n",
      "\n",
      "Stage  331\n",
      "Epoch 200/200\n",
      "Learning rate :  3.65161737537404e-05\n",
      "Average loss :  1.2780371427822956e-08\n",
      "expression length:\t 5\n",
      "Result stage 333: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998766]*t)\n",
      "\n",
      "\n",
      "Stage  332\n",
      "Epoch 50/200\n",
      "Learning rate :  3.615283175404641e-05\n",
      "Average loss :  8.971960063774986e-09\n",
      "\n",
      "\n",
      "Stage  332\n",
      "Epoch 100/200\n",
      "Learning rate :  3.615283175404641e-05\n",
      "Average loss :  1.2749608480078223e-08\n",
      "\n",
      "\n",
      "Stage  332\n",
      "Epoch 150/200\n",
      "Learning rate :  3.615283175404641e-05\n",
      "Average loss :  8.862080846938625e-09\n",
      "\n",
      "\n",
      "Stage  332\n",
      "Epoch 200/200\n",
      "Learning rate :  3.615283175404641e-05\n",
      "Average loss :  9.726548455546435e-09\n",
      "expression length:\t 5\n",
      "Result stage 334: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999315]*t)\n",
      "\n",
      "\n",
      "Stage  333\n",
      "Epoch 50/200\n",
      "Learning rate :  3.5793105067655295e-05\n",
      "Average loss :  9.075334261865464e-09\n",
      "\n",
      "\n",
      "Stage  333\n",
      "Epoch 100/200\n",
      "Learning rate :  3.5793105067655295e-05\n",
      "Average loss :  1.4228198175203488e-08\n",
      "\n",
      "\n",
      "Stage  333\n",
      "Epoch 150/200\n",
      "Learning rate :  3.5793105067655295e-05\n",
      "Average loss :  1.1925580523097778e-08\n",
      "\n",
      "\n",
      "Stage  333\n",
      "Epoch 200/200\n",
      "Learning rate :  3.5793105067655295e-05\n",
      "Average loss :  9.078745755175532e-09\n",
      "expression length:\t 5\n",
      "Result stage 335: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999061]*t)\n",
      "\n",
      "\n",
      "Stage  334\n",
      "Epoch 50/200\n",
      "Learning rate :  3.543695772159864e-05\n",
      "Average loss :  9.286484470294454e-09\n",
      "\n",
      "\n",
      "Stage  334\n",
      "Epoch 100/200\n",
      "Learning rate :  3.543695772159864e-05\n",
      "Average loss :  1.2829877604758622e-08\n",
      "\n",
      "\n",
      "Stage  334\n",
      "Epoch 150/200\n",
      "Learning rate :  3.543695772159864e-05\n",
      "Average loss :  1.0119165949618036e-08\n",
      "\n",
      "\n",
      "Stage  334\n",
      "Epoch 200/200\n",
      "Learning rate :  3.543695772159864e-05\n",
      "Average loss :  1.0934702920906147e-08\n",
      "expression length:\t 5\n",
      "Result stage 336: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998368]*t)\n",
      "\n",
      "\n",
      "Stage  335\n",
      "Epoch 50/200\n",
      "Learning rate :  3.5084354100845025e-05\n",
      "Average loss :  1.722008491356064e-08\n",
      "\n",
      "\n",
      "Stage  335\n",
      "Epoch 100/200\n",
      "Learning rate :  3.5084354100845025e-05\n",
      "Average loss :  8.304675169767961e-09\n",
      "\n",
      "\n",
      "Stage  335\n",
      "Epoch 150/200\n",
      "Learning rate :  3.5084354100845025e-05\n",
      "Average loss :  1.0366687064333746e-08\n",
      "\n",
      "\n",
      "Stage  335\n",
      "Epoch 200/200\n",
      "Learning rate :  3.5084354100845025e-05\n",
      "Average loss :  6.48700160255089e-09\n",
      "expression length:\t 5\n",
      "Result stage 337: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999113]*t)\n",
      "\n",
      "\n",
      "Stage  336\n",
      "Epoch 50/200\n",
      "Learning rate :  3.473525894473856e-05\n",
      "Average loss :  1.0729444888113449e-08\n",
      "\n",
      "\n",
      "Stage  336\n",
      "Epoch 100/200\n",
      "Learning rate :  3.473525894473856e-05\n",
      "Average loss :  9.219097485413386e-09\n",
      "\n",
      "\n",
      "Stage  336\n",
      "Epoch 150/200\n",
      "Learning rate :  3.473525894473856e-05\n",
      "Average loss :  8.747663926556015e-09\n",
      "\n",
      "\n",
      "Stage  336\n",
      "Epoch 200/200\n",
      "Learning rate :  3.473525894473856e-05\n",
      "Average loss :  8.80116868273717e-09\n",
      "expression length:\t 5\n",
      "Result stage 338: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999158]*t)\n",
      "\n",
      "\n",
      "Stage  337\n",
      "Epoch 50/200\n",
      "Learning rate :  3.438963734347271e-05\n",
      "Average loss :  1.3039377577683808e-08\n",
      "\n",
      "\n",
      "Stage  337\n",
      "Epoch 100/200\n",
      "Learning rate :  3.438963734347271e-05\n",
      "Average loss :  8.624574832083454e-09\n",
      "\n",
      "\n",
      "Stage  337\n",
      "Epoch 150/200\n",
      "Learning rate :  3.438963734347271e-05\n",
      "Average loss :  8.44770475794121e-09\n",
      "\n",
      "\n",
      "Stage  337\n",
      "Epoch 200/200\n",
      "Learning rate :  3.438963734347271e-05\n",
      "Average loss :  7.292807246983557e-09\n",
      "expression length:\t 5\n",
      "Result stage 339: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.14000252]*t)\n",
      "\n",
      "\n",
      "Stage  338\n",
      "Epoch 50/200\n",
      "Learning rate :  3.404745473459934e-05\n",
      "Average loss :  8.48591241719987e-09\n",
      "\n",
      "\n",
      "Stage  338\n",
      "Epoch 100/200\n",
      "Learning rate :  3.404745473459934e-05\n",
      "Average loss :  6.107352401585331e-09\n",
      "\n",
      "\n",
      "Stage  338\n",
      "Epoch 150/200\n",
      "Learning rate :  3.404745473459934e-05\n",
      "Average loss :  3.0768647629741963e-09\n",
      "\n",
      "\n",
      "Stage  338\n",
      "Epoch 200/200\n",
      "Learning rate :  3.404745473459934e-05\n",
      "Average loss :  7.816248093206468e-09\n",
      "expression length:\t 5\n",
      "Result stage 340: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998589]*t)\n",
      "\n",
      "\n",
      "Stage  339\n",
      "Epoch 50/200\n",
      "Learning rate :  3.3708676899572394e-05\n",
      "Average loss :  8.3281932461432e-09\n",
      "\n",
      "\n",
      "Stage  339\n",
      "Epoch 100/200\n",
      "Learning rate :  3.3708676899572394e-05\n",
      "Average loss :  1.3208066640402194e-08\n",
      "\n",
      "\n",
      "Stage  339\n",
      "Epoch 150/200\n",
      "Learning rate :  3.3708676899572394e-05\n",
      "Average loss :  9.723576610554119e-09\n",
      "\n",
      "\n",
      "Stage  339\n",
      "Epoch 200/200\n",
      "Learning rate :  3.3708676899572394e-05\n",
      "Average loss :  8.250674810028613e-09\n",
      "expression length:\t 5\n",
      "Result stage 341: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999116]*t)\n",
      "\n",
      "\n",
      "Stage  340\n",
      "Epoch 50/200\n",
      "Learning rate :  3.337326996032608e-05\n",
      "Average loss :  8.088648861814818e-09\n",
      "\n",
      "\n",
      "Stage  340\n",
      "Epoch 100/200\n",
      "Learning rate :  3.337326996032608e-05\n",
      "Average loss :  1.0037301656495856e-08\n",
      "\n",
      "\n",
      "Stage  340\n",
      "Epoch 150/200\n",
      "Learning rate :  3.337326996032608e-05\n",
      "Average loss :  9.601917483337274e-09\n",
      "\n",
      "\n",
      "Stage  340\n",
      "Epoch 200/200\n",
      "Learning rate :  3.337326996032608e-05\n",
      "Average loss :  7.878361962809777e-09\n",
      "expression length:\t 5\n",
      "Result stage 342: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998653]*t)\n",
      "\n",
      "\n",
      "Stage  341\n",
      "Epoch 50/200\n",
      "Learning rate :  3.3041200375886935e-05\n",
      "Average loss :  1.5737176894958793e-08\n",
      "\n",
      "\n",
      "Stage  341\n",
      "Epoch 100/200\n",
      "Learning rate :  3.3041200375886935e-05\n",
      "Average loss :  1.4312126594973051e-08\n",
      "\n",
      "\n",
      "Stage  341\n",
      "Epoch 150/200\n",
      "Learning rate :  3.3041200375886935e-05\n",
      "Average loss :  8.236602511146884e-09\n",
      "\n",
      "\n",
      "Stage  341\n",
      "Epoch 200/200\n",
      "Learning rate :  3.3041200375886935e-05\n",
      "Average loss :  7.190870121576154e-09\n",
      "expression length:\t 5\n",
      "Result stage 343: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998511]*t)\n",
      "\n",
      "\n",
      "Stage  342\n",
      "Epoch 50/200\n",
      "Learning rate :  3.271243493901982e-05\n",
      "Average loss :  1.0123054394739484e-08\n",
      "\n",
      "\n",
      "Stage  342\n",
      "Epoch 100/200\n",
      "Learning rate :  3.271243493901982e-05\n",
      "Average loss :  7.979259031287711e-09\n",
      "\n",
      "\n",
      "Stage  342\n",
      "Epoch 150/200\n",
      "Learning rate :  3.271243493901982e-05\n",
      "Average loss :  1.027393814467814e-08\n",
      "\n",
      "\n",
      "Stage  342\n",
      "Epoch 200/200\n",
      "Learning rate :  3.271243493901982e-05\n",
      "Average loss :  8.287696751096973e-09\n",
      "expression length:\t 5\n",
      "Result stage 344: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998714]*t)\n",
      "\n",
      "\n",
      "Stage  343\n",
      "Epoch 50/200\n",
      "Learning rate :  3.2386940772907044e-05\n",
      "Average loss :  7.610052144002566e-09\n",
      "\n",
      "\n",
      "Stage  343\n",
      "Epoch 100/200\n",
      "Learning rate :  3.2386940772907044e-05\n",
      "Average loss :  9.65189439483538e-09\n",
      "\n",
      "\n",
      "Stage  343\n",
      "Epoch 150/200\n",
      "Learning rate :  3.2386940772907044e-05\n",
      "Average loss :  1.1259614574044008e-08\n",
      "\n",
      "\n",
      "Stage  343\n",
      "Epoch 200/200\n",
      "Learning rate :  3.2386940772907044e-05\n",
      "Average loss :  1.1454459603044143e-08\n",
      "expression length:\t 5\n",
      "Result stage 345: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998859]*t)\n",
      "\n",
      "\n",
      "Stage  344\n",
      "Epoch 50/200\n",
      "Learning rate :  3.206468532786077e-05\n",
      "Average loss :  7.584946004612902e-09\n",
      "\n",
      "\n",
      "Stage  344\n",
      "Epoch 100/200\n",
      "Learning rate :  3.206468532786077e-05\n",
      "Average loss :  1.7241154282032767e-08\n",
      "\n",
      "\n",
      "Stage  344\n",
      "Epoch 150/200\n",
      "Learning rate :  3.206468532786077e-05\n",
      "Average loss :  9.952684010272606e-09\n",
      "\n",
      "\n",
      "Stage  344\n",
      "Epoch 200/200\n",
      "Learning rate :  3.206468532786077e-05\n",
      "Average loss :  7.3066996897352965e-09\n",
      "expression length:\t 5\n",
      "Result stage 346: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999233]*t)\n",
      "\n",
      "\n",
      "Stage  345\n",
      "Epoch 50/200\n",
      "Learning rate :  3.174563637806794e-05\n",
      "Average loss :  6.728347212714425e-09\n",
      "\n",
      "\n",
      "Stage  345\n",
      "Epoch 100/200\n",
      "Learning rate :  3.174563637806794e-05\n",
      "Average loss :  7.789596523366527e-09\n",
      "\n",
      "\n",
      "Stage  345\n",
      "Epoch 150/200\n",
      "Learning rate :  3.174563637806794e-05\n",
      "Average loss :  5.366428190711758e-09\n",
      "\n",
      "\n",
      "Stage  345\n",
      "Epoch 200/200\n",
      "Learning rate :  3.174563637806794e-05\n",
      "Average loss :  7.177869409957793e-09\n",
      "expression length:\t 5\n",
      "Result stage 347: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999334]*t)\n",
      "\n",
      "\n",
      "Stage  346\n",
      "Epoch 50/200\n",
      "Learning rate :  3.142976201836771e-05\n",
      "Average loss :  7.529532553007812e-09\n",
      "\n",
      "\n",
      "Stage  346\n",
      "Epoch 100/200\n",
      "Learning rate :  3.142976201836771e-05\n",
      "Average loss :  6.547138831081156e-09\n",
      "\n",
      "\n",
      "Stage  346\n",
      "Epoch 150/200\n",
      "Learning rate :  3.142976201836771e-05\n",
      "Average loss :  7.2088823799276724e-09\n",
      "\n",
      "\n",
      "Stage  346\n",
      "Epoch 200/200\n",
      "Learning rate :  3.142976201836771e-05\n",
      "Average loss :  7.268922352920981e-09\n",
      "expression length:\t 5\n",
      "Result stage 348: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998917]*t)\n",
      "\n",
      "\n",
      "Stage  347\n",
      "Epoch 50/200\n",
      "Learning rate :  3.111703066106086e-05\n",
      "Average loss :  1.3354388705977271e-08\n",
      "\n",
      "\n",
      "Stage  347\n",
      "Epoch 100/200\n",
      "Learning rate :  3.111703066106086e-05\n",
      "Average loss :  7.403178070575223e-09\n",
      "\n",
      "\n",
      "Stage  347\n",
      "Epoch 150/200\n",
      "Learning rate :  3.111703066106086e-05\n",
      "Average loss :  7.81665665527953e-09\n",
      "\n",
      "\n",
      "Stage  347\n",
      "Epoch 200/200\n",
      "Learning rate :  3.111703066106086e-05\n",
      "Average loss :  7.0870620483276525e-09\n",
      "expression length:\t 5\n",
      "Result stage 349: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999261]*t)\n",
      "\n",
      "\n",
      "Stage  348\n",
      "Epoch 50/200\n",
      "Learning rate :  3.0807411032751074e-05\n",
      "Average loss :  6.766769367061443e-09\n",
      "\n",
      "\n",
      "Stage  348\n",
      "Epoch 100/200\n",
      "Learning rate :  3.0807411032751074e-05\n",
      "Average loss :  6.683057218737076e-09\n",
      "\n",
      "\n",
      "Stage  348\n",
      "Epoch 150/200\n",
      "Learning rate :  3.0807411032751074e-05\n",
      "Average loss :  8.093093306626997e-09\n",
      "\n",
      "\n",
      "Stage  348\n",
      "Epoch 200/200\n",
      "Learning rate :  3.0807411032751074e-05\n",
      "Average loss :  6.729715007480763e-09\n",
      "expression length:\t 5\n",
      "Result stage 350: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999248]*t)\n",
      "\n",
      "\n",
      "Stage  349\n",
      "Epoch 50/200\n",
      "Learning rate :  3.0500872171217483e-05\n",
      "Average loss :  6.299333943360352e-09\n",
      "\n",
      "\n",
      "Stage  349\n",
      "Epoch 100/200\n",
      "Learning rate :  3.0500872171217483e-05\n",
      "Average loss :  6.340182157060781e-09\n",
      "\n",
      "\n",
      "Stage  349\n",
      "Epoch 150/200\n",
      "Learning rate :  3.0500872171217483e-05\n",
      "Average loss :  6.810699115789021e-09\n",
      "\n",
      "\n",
      "Stage  349\n",
      "Epoch 200/200\n",
      "Learning rate :  3.0500872171217483e-05\n",
      "Average loss :  6.898860593906875e-09\n",
      "expression length:\t 5\n",
      "Result stage 351: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999368]*t)\n",
      "\n",
      "\n",
      "Stage  350\n",
      "Epoch 50/200\n",
      "Learning rate :  3.01973834223185e-05\n",
      "Average loss :  5.604622987931407e-09\n",
      "\n",
      "\n",
      "Stage  350\n",
      "Epoch 100/200\n",
      "Learning rate :  3.01973834223185e-05\n",
      "Average loss :  6.116137818423795e-09\n",
      "\n",
      "\n",
      "Stage  350\n",
      "Epoch 150/200\n",
      "Learning rate :  3.01973834223185e-05\n",
      "Average loss :  8.9597742558567e-09\n",
      "\n",
      "\n",
      "Stage  350\n",
      "Epoch 200/200\n",
      "Learning rate :  3.01973834223185e-05\n",
      "Average loss :  8.332390777354703e-09\n",
      "expression length:\t 5\n",
      "Result stage 352: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998531]*t)\n",
      "\n",
      "\n",
      "Stage  351\n",
      "Epoch 50/200\n",
      "Learning rate :  2.989691443692631e-05\n",
      "Average loss :  1.0795911720151707e-08\n",
      "\n",
      "\n",
      "Stage  351\n",
      "Epoch 100/200\n",
      "Learning rate :  2.989691443692631e-05\n",
      "Average loss :  5.610887754414762e-09\n",
      "\n",
      "\n",
      "Stage  351\n",
      "Epoch 150/200\n",
      "Learning rate :  2.989691443692631e-05\n",
      "Average loss :  6.627181914353741e-09\n",
      "\n",
      "\n",
      "Stage  351\n",
      "Epoch 200/200\n",
      "Learning rate :  2.989691443692631e-05\n",
      "Average loss :  6.027124133112238e-09\n",
      "expression length:\t 5\n",
      "Result stage 353: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998604]*t)\n",
      "\n",
      "\n",
      "Stage  352\n",
      "Epoch 50/200\n",
      "Learning rate :  2.9599435167892e-05\n",
      "Average loss :  5.981087181083922e-09\n",
      "\n",
      "\n",
      "Stage  352\n",
      "Epoch 100/200\n",
      "Learning rate :  2.9599435167892e-05\n",
      "Average loss :  6.7207488463338905e-09\n",
      "\n",
      "\n",
      "Stage  352\n",
      "Epoch 150/200\n",
      "Learning rate :  2.9599435167892e-05\n",
      "Average loss :  6.642578931348453e-09\n",
      "\n",
      "\n",
      "Stage  352\n",
      "Epoch 200/200\n",
      "Learning rate :  2.9599435167892e-05\n",
      "Average loss :  6.543197983432947e-09\n",
      "expression length:\t 5\n",
      "Result stage 354: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.139994]*t)\n",
      "\n",
      "\n",
      "Stage  353\n",
      "Epoch 50/200\n",
      "Learning rate :  2.9304915867040745e-05\n",
      "Average loss :  7.940534452188786e-09\n",
      "\n",
      "\n",
      "Stage  353\n",
      "Epoch 100/200\n",
      "Learning rate :  2.9304915867040745e-05\n",
      "Average loss :  1.2109488523037726e-08\n",
      "\n",
      "\n",
      "Stage  353\n",
      "Epoch 150/200\n",
      "Learning rate :  2.9304915867040745e-05\n",
      "Average loss :  5.710846906481493e-09\n",
      "\n",
      "\n",
      "Stage  353\n",
      "Epoch 200/200\n",
      "Learning rate :  2.9304915867040745e-05\n",
      "Average loss :  6.4193259596834196e-09\n",
      "expression length:\t 5\n",
      "Result stage 355: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999496]*t)\n",
      "\n",
      "\n",
      "Stage  354\n",
      "Epoch 50/200\n",
      "Learning rate :  2.9013327082197052e-05\n",
      "Average loss :  6.871677005193533e-09\n",
      "\n",
      "\n",
      "Stage  354\n",
      "Epoch 100/200\n",
      "Learning rate :  2.9013327082197052e-05\n",
      "Average loss :  5.725228291453277e-09\n",
      "\n",
      "\n",
      "Stage  354\n",
      "Epoch 150/200\n",
      "Learning rate :  2.9013327082197052e-05\n",
      "Average loss :  5.690083959564163e-09\n",
      "\n",
      "\n",
      "Stage  354\n",
      "Epoch 200/200\n",
      "Learning rate :  2.9013327082197052e-05\n",
      "Average loss :  5.5624034267509614e-09\n",
      "expression length:\t 5\n",
      "Result stage 356: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399862]*t)\n",
      "\n",
      "\n",
      "Stage  355\n",
      "Epoch 50/200\n",
      "Learning rate :  2.8724639654239422e-05\n",
      "Average loss :  5.510626177596123e-09\n",
      "\n",
      "\n",
      "Stage  355\n",
      "Epoch 100/200\n",
      "Learning rate :  2.8724639654239422e-05\n",
      "Average loss :  6.004482688837243e-09\n",
      "\n",
      "\n",
      "Stage  355\n",
      "Epoch 150/200\n",
      "Learning rate :  2.8724639654239422e-05\n",
      "Average loss :  5.571479722021877e-09\n",
      "\n",
      "\n",
      "Stage  355\n",
      "Epoch 200/200\n",
      "Learning rate :  2.8724639654239422e-05\n",
      "Average loss :  6.221285708818414e-09\n",
      "expression length:\t 5\n",
      "Result stage 357: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999495]*t)\n",
      "\n",
      "\n",
      "Stage  356\n",
      "Epoch 50/200\n",
      "Learning rate :  2.8438824714184505e-05\n",
      "Average loss :  7.043397420858355e-09\n",
      "\n",
      "\n",
      "Stage  356\n",
      "Epoch 100/200\n",
      "Learning rate :  2.8438824714184505e-05\n",
      "Average loss :  1.5785380114152758e-08\n",
      "\n",
      "\n",
      "Stage  356\n",
      "Epoch 150/200\n",
      "Learning rate :  2.8438824714184505e-05\n",
      "Average loss :  4.228062344679984e-09\n",
      "\n",
      "\n",
      "Stage  356\n",
      "Epoch 200/200\n",
      "Learning rate :  2.8438824714184505e-05\n",
      "Average loss :  6.519054629450238e-09\n",
      "expression length:\t 5\n",
      "Result stage 358: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998993]*t)\n",
      "\n",
      "\n",
      "Stage  357\n",
      "Epoch 50/200\n",
      "Learning rate :  2.8155853680300096e-05\n",
      "Average loss :  5.638120192941187e-09\n",
      "\n",
      "\n",
      "Stage  357\n",
      "Epoch 100/200\n",
      "Learning rate :  2.8155853680300096e-05\n",
      "Average loss :  5.308421258121143e-09\n",
      "\n",
      "\n",
      "Stage  357\n",
      "Epoch 150/200\n",
      "Learning rate :  2.8155853680300096e-05\n",
      "Average loss :  1.0167141795136558e-08\n",
      "\n",
      "\n",
      "Stage  357\n",
      "Epoch 200/200\n",
      "Learning rate :  2.8155853680300096e-05\n",
      "Average loss :  5.614585241175973e-09\n",
      "expression length:\t 5\n",
      "Result stage 359: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999258]*t)\n",
      "\n",
      "\n",
      "Stage  358\n",
      "Epoch 50/200\n",
      "Learning rate :  2.7875698255247015e-05\n",
      "Average loss :  5.1055111249809215e-09\n",
      "\n",
      "\n",
      "Stage  358\n",
      "Epoch 100/200\n",
      "Learning rate :  2.7875698255247015e-05\n",
      "Average loss :  5.520042645201784e-09\n",
      "\n",
      "\n",
      "Stage  358\n",
      "Epoch 150/200\n",
      "Learning rate :  2.7875698255247015e-05\n",
      "Average loss :  7.336109497657617e-09\n",
      "\n",
      "\n",
      "Stage  358\n",
      "Epoch 200/200\n",
      "Learning rate :  2.7875698255247015e-05\n",
      "Average loss :  5.135216252227792e-09\n",
      "expression length:\t 5\n",
      "Result stage 360: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998747]*t)\n",
      "\n",
      "\n",
      "Stage  359\n",
      "Epoch 50/200\n",
      "Learning rate :  2.7598330423249287e-05\n",
      "Average loss :  5.929728263964762e-09\n",
      "\n",
      "\n",
      "Stage  359\n",
      "Epoch 100/200\n",
      "Learning rate :  2.7598330423249287e-05\n",
      "Average loss :  5.716121354026882e-09\n",
      "\n",
      "\n",
      "Stage  359\n",
      "Epoch 150/200\n",
      "Learning rate :  2.7598330423249287e-05\n",
      "Average loss :  5.10074826820528e-09\n",
      "\n",
      "\n",
      "Stage  359\n",
      "Epoch 200/200\n",
      "Learning rate :  2.7598330423249287e-05\n",
      "Average loss :  6.097858662457156e-09\n",
      "expression length:\t 5\n",
      "Result stage 361: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998888]*t)\n",
      "\n",
      "\n",
      "Stage  360\n",
      "Epoch 50/200\n",
      "Learning rate :  2.732372244729256e-05\n",
      "Average loss :  4.926179020259269e-09\n",
      "\n",
      "\n",
      "Stage  360\n",
      "Epoch 100/200\n",
      "Learning rate :  2.732372244729256e-05\n",
      "Average loss :  9.522127975003514e-09\n",
      "\n",
      "\n",
      "Stage  360\n",
      "Epoch 150/200\n",
      "Learning rate :  2.732372244729256e-05\n",
      "Average loss :  5.614493758798744e-09\n",
      "\n",
      "\n",
      "Stage  360\n",
      "Epoch 200/200\n",
      "Learning rate :  2.732372244729256e-05\n",
      "Average loss :  5.411564529822499e-09\n",
      "expression length:\t 5\n",
      "Result stage 362: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999155]*t)\n",
      "\n",
      "\n",
      "Stage  361\n",
      "Epoch 50/200\n",
      "Learning rate :  2.7051846866350418e-05\n",
      "Average loss :  7.72297426010482e-09\n",
      "\n",
      "\n",
      "Stage  361\n",
      "Epoch 100/200\n",
      "Learning rate :  2.7051846866350418e-05\n",
      "Average loss :  4.78279371662893e-09\n",
      "\n",
      "\n",
      "Stage  361\n",
      "Epoch 150/200\n",
      "Learning rate :  2.7051846866350418e-05\n",
      "Average loss :  8.858203059958214e-09\n",
      "\n",
      "\n",
      "Stage  361\n",
      "Epoch 200/200\n",
      "Learning rate :  2.7051846866350418e-05\n",
      "Average loss :  8.499224435354336e-09\n",
      "expression length:\t 5\n",
      "Result stage 363: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998571]*t)\n",
      "\n",
      "\n",
      "Stage  362\n",
      "Epoch 50/200\n",
      "Learning rate :  2.6782676492638175e-05\n",
      "Average loss :  5.1431263692336415e-09\n",
      "\n",
      "\n",
      "Stage  362\n",
      "Epoch 100/200\n",
      "Learning rate :  2.6782676492638175e-05\n",
      "Average loss :  4.720326352014581e-09\n",
      "\n",
      "\n",
      "Stage  362\n",
      "Epoch 150/200\n",
      "Learning rate :  2.6782676492638175e-05\n",
      "Average loss :  4.834709521617242e-09\n",
      "\n",
      "\n",
      "Stage  362\n",
      "Epoch 200/200\n",
      "Learning rate :  2.6782676492638175e-05\n",
      "Average loss :  5.345385911681433e-09\n",
      "expression length:\t 5\n",
      "Result stage 364: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999505]*t)\n",
      "\n",
      "\n",
      "Stage  363\n",
      "Epoch 50/200\n",
      "Learning rate :  2.6516184408894183e-05\n",
      "Average loss :  1.1706540625766593e-08\n",
      "\n",
      "\n",
      "Stage  363\n",
      "Epoch 100/200\n",
      "Learning rate :  2.6516184408894183e-05\n",
      "Average loss :  1.01147730191542e-08\n",
      "\n",
      "\n",
      "Stage  363\n",
      "Epoch 150/200\n",
      "Learning rate :  2.6516184408894183e-05\n",
      "Average loss :  1.2907888091717723e-08\n",
      "\n",
      "\n",
      "Stage  363\n",
      "Epoch 200/200\n",
      "Learning rate :  2.6516184408894183e-05\n",
      "Average loss :  5.372103650813642e-09\n",
      "expression length:\t 5\n",
      "Result stage 365: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999547]*t)\n",
      "\n",
      "\n",
      "Stage  364\n",
      "Epoch 50/200\n",
      "Learning rate :  2.6252343965687962e-05\n",
      "Average loss :  5.108125034070099e-09\n",
      "\n",
      "\n",
      "Stage  364\n",
      "Epoch 100/200\n",
      "Learning rate :  2.6252343965687962e-05\n",
      "Average loss :  5.04234076714738e-09\n",
      "\n",
      "\n",
      "Stage  364\n",
      "Epoch 150/200\n",
      "Learning rate :  2.6252343965687962e-05\n",
      "Average loss :  5.086105758778103e-09\n",
      "\n",
      "\n",
      "Stage  364\n",
      "Epoch 200/200\n",
      "Learning rate :  2.6252343965687962e-05\n",
      "Average loss :  4.9365684873237115e-09\n",
      "expression length:\t 5\n",
      "Result stage 366: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999209]*t)\n",
      "\n",
      "\n",
      "Stage  365\n",
      "Epoch 50/200\n",
      "Learning rate :  2.599112877875535e-05\n",
      "Average loss :  5.1676889434304485e-09\n",
      "\n",
      "\n",
      "Stage  365\n",
      "Epoch 100/200\n",
      "Learning rate :  2.599112877875535e-05\n",
      "Average loss :  5.062240404640761e-09\n",
      "\n",
      "\n",
      "Stage  365\n",
      "Epoch 150/200\n",
      "Learning rate :  2.599112877875535e-05\n",
      "Average loss :  4.289451460692817e-09\n",
      "\n",
      "\n",
      "Stage  365\n",
      "Epoch 200/200\n",
      "Learning rate :  2.599112877875535e-05\n",
      "Average loss :  4.508948325820938e-09\n",
      "expression length:\t 5\n",
      "Result stage 367: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998772]*t)\n",
      "\n",
      "\n",
      "Stage  366\n",
      "Epoch 50/200\n",
      "Learning rate :  2.5732512726359942e-05\n",
      "Average loss :  4.758530014470352e-09\n",
      "\n",
      "\n",
      "Stage  366\n",
      "Epoch 100/200\n",
      "Learning rate :  2.5732512726359942e-05\n",
      "Average loss :  4.4443830837792575e-09\n",
      "\n",
      "\n",
      "Stage  366\n",
      "Epoch 150/200\n",
      "Learning rate :  2.5732512726359942e-05\n",
      "Average loss :  9.036392079053712e-09\n",
      "\n",
      "\n",
      "Stage  366\n",
      "Epoch 200/200\n",
      "Learning rate :  2.5732512726359942e-05\n",
      "Average loss :  4.4313748226443295e-09\n",
      "expression length:\t 5\n",
      "Result stage 368: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998765]*t)\n",
      "\n",
      "\n",
      "Stage  367\n",
      "Epoch 50/200\n",
      "Learning rate :  2.5476469946681018e-05\n",
      "Average loss :  4.33351488027256e-09\n",
      "\n",
      "\n",
      "Stage  367\n",
      "Epoch 100/200\n",
      "Learning rate :  2.5476469946681018e-05\n",
      "Average loss :  4.767975791963863e-09\n",
      "\n",
      "\n",
      "Stage  367\n",
      "Epoch 150/200\n",
      "Learning rate :  2.5476469946681018e-05\n",
      "Average loss :  4.033271050474241e-09\n",
      "\n",
      "\n",
      "Stage  367\n",
      "Epoch 200/200\n",
      "Learning rate :  2.5476469946681018e-05\n",
      "Average loss :  4.3521160009163395e-09\n",
      "expression length:\t 5\n",
      "Result stage 369: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998768]*t)\n",
      "\n",
      "\n",
      "Stage  368\n",
      "Epoch 50/200\n",
      "Learning rate :  2.5222974835227213e-05\n",
      "Average loss :  4.216340165896781e-09\n",
      "\n",
      "\n",
      "Stage  368\n",
      "Epoch 100/200\n",
      "Learning rate :  2.5222974835227213e-05\n",
      "Average loss :  5.493834276393272e-09\n",
      "\n",
      "\n",
      "Stage  368\n",
      "Epoch 150/200\n",
      "Learning rate :  2.5222974835227213e-05\n",
      "Average loss :  8.355220515454675e-09\n",
      "\n",
      "\n",
      "Stage  368\n",
      "Epoch 200/200\n",
      "Learning rate :  2.5222974835227213e-05\n",
      "Average loss :  4.251592411463889e-09\n",
      "expression length:\t 5\n",
      "Result stage 370: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999054]*t)\n",
      "\n",
      "\n",
      "Stage  369\n",
      "Epoch 50/200\n",
      "Learning rate :  2.4972002042276156e-05\n",
      "Average loss :  4.695635880125337e-09\n",
      "\n",
      "\n",
      "Stage  369\n",
      "Epoch 100/200\n",
      "Learning rate :  2.4972002042276156e-05\n",
      "Average loss :  3.8083269870980985e-09\n",
      "\n",
      "\n",
      "Stage  369\n",
      "Epoch 150/200\n",
      "Learning rate :  2.4972002042276156e-05\n",
      "Average loss :  4.1635246361693135e-09\n",
      "\n",
      "\n",
      "Stage  369\n",
      "Epoch 200/200\n",
      "Learning rate :  2.4972002042276156e-05\n",
      "Average loss :  5.771491284889407e-09\n",
      "expression length:\t 5\n",
      "Result stage 371: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999172]*t)\n",
      "\n",
      "\n",
      "Stage  370\n",
      "Epoch 50/200\n",
      "Learning rate :  2.472352647033939e-05\n",
      "Average loss :  4.059717451099232e-09\n",
      "\n",
      "\n",
      "Stage  370\n",
      "Epoch 100/200\n",
      "Learning rate :  2.472352647033939e-05\n",
      "Average loss :  4.426273569890782e-09\n",
      "\n",
      "\n",
      "Stage  370\n",
      "Epoch 150/200\n",
      "Learning rate :  2.472352647033939e-05\n",
      "Average loss :  8.65793658988423e-09\n",
      "\n",
      "\n",
      "Stage  370\n",
      "Epoch 200/200\n",
      "Learning rate :  2.472352647033939e-05\n",
      "Average loss :  4.587159097013682e-09\n",
      "expression length:\t 5\n",
      "Result stage 372: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399951]*t)\n",
      "\n",
      "\n",
      "Stage  371\n",
      "Epoch 50/200\n",
      "Learning rate :  2.4477523271652672e-05\n",
      "Average loss :  4.276044851536653e-09\n",
      "\n",
      "\n",
      "Stage  371\n",
      "Epoch 100/200\n",
      "Learning rate :  2.4477523271652672e-05\n",
      "Average loss :  3.097017531317192e-09\n",
      "\n",
      "\n",
      "Stage  371\n",
      "Epoch 150/200\n",
      "Learning rate :  2.4477523271652672e-05\n",
      "Average loss :  7.153645231738892e-09\n",
      "\n",
      "\n",
      "Stage  371\n",
      "Epoch 200/200\n",
      "Learning rate :  2.4477523271652672e-05\n",
      "Average loss :  2.170027491033011e-09\n",
      "expression length:\t 5\n",
      "Result stage 373: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.14000054]*t)\n",
      "\n",
      "\n",
      "Stage  372\n",
      "Epoch 50/200\n",
      "Learning rate :  2.4233967845691113e-05\n",
      "Average loss :  3.9621967928837876e-09\n",
      "\n",
      "\n",
      "Stage  372\n",
      "Epoch 100/200\n",
      "Learning rate :  2.4233967845691113e-05\n",
      "Average loss :  3.970527906460575e-09\n",
      "\n",
      "\n",
      "Stage  372\n",
      "Epoch 150/200\n",
      "Learning rate :  2.4233967845691113e-05\n",
      "Average loss :  4.175769952041719e-09\n",
      "\n",
      "\n",
      "Stage  372\n",
      "Epoch 200/200\n",
      "Learning rate :  2.4233967845691113e-05\n",
      "Average loss :  7.110717348268736e-09\n",
      "expression length:\t 5\n",
      "Result stage 374: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998713]*t)\n",
      "\n",
      "\n",
      "Stage  373\n",
      "Epoch 50/200\n",
      "Learning rate :  2.3992835836709175e-05\n",
      "Average loss :  7.743977015195469e-09\n",
      "\n",
      "\n",
      "Stage  373\n",
      "Epoch 100/200\n",
      "Learning rate :  2.3992835836709175e-05\n",
      "Average loss :  4.12902911861579e-09\n",
      "\n",
      "\n",
      "Stage  373\n",
      "Epoch 150/200\n",
      "Learning rate :  2.3992835836709175e-05\n",
      "Average loss :  3.851317487146844e-09\n",
      "\n",
      "\n",
      "Stage  373\n",
      "Epoch 200/200\n",
      "Learning rate :  2.3992835836709175e-05\n",
      "Average loss :  4.255073182690694e-09\n",
      "expression length:\t 5\n",
      "Result stage 375: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999517]*t)\n",
      "\n",
      "\n",
      "Stage  374\n",
      "Epoch 50/200\n",
      "Learning rate :  2.3754103131304996e-05\n",
      "Average loss :  3.766515987990715e-09\n",
      "\n",
      "\n",
      "Stage  374\n",
      "Epoch 100/200\n",
      "Learning rate :  2.3754103131304996e-05\n",
      "Average loss :  4.2123295962426255e-09\n",
      "\n",
      "\n",
      "Stage  374\n",
      "Epoch 150/200\n",
      "Learning rate :  2.3754103131304996e-05\n",
      "Average loss :  3.2689388973494715e-09\n",
      "\n",
      "\n",
      "Stage  374\n",
      "Epoch 200/200\n",
      "Learning rate :  2.3754103131304996e-05\n",
      "Average loss :  3.6710379180959762e-09\n",
      "expression length:\t 5\n",
      "Result stage 376: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998958]*t)\n",
      "\n",
      "\n",
      "Stage  375\n",
      "Epoch 50/200\n",
      "Learning rate :  2.3517745856009108e-05\n",
      "Average loss :  6.4420078160765115e-09\n",
      "\n",
      "\n",
      "Stage  375\n",
      "Epoch 100/200\n",
      "Learning rate :  2.3517745856009108e-05\n",
      "Average loss :  3.820429306244932e-09\n",
      "\n",
      "\n",
      "Stage  375\n",
      "Epoch 150/200\n",
      "Learning rate :  2.3517745856009108e-05\n",
      "Average loss :  5.3130464472417316e-09\n",
      "\n",
      "\n",
      "Stage  375\n",
      "Epoch 200/200\n",
      "Learning rate :  2.3517745856009108e-05\n",
      "Average loss :  3.974387041694172e-09\n",
      "expression length:\t 5\n",
      "Result stage 377: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999452]*t)\n",
      "\n",
      "\n",
      "Stage  376\n",
      "Epoch 50/200\n",
      "Learning rate :  2.3283740374897e-05\n",
      "Average loss :  6.012237818708854e-09\n",
      "\n",
      "\n",
      "Stage  376\n",
      "Epoch 100/200\n",
      "Learning rate :  2.3283740374897e-05\n",
      "Average loss :  3.740443954569628e-09\n",
      "\n",
      "\n",
      "Stage  376\n",
      "Epoch 150/200\n",
      "Learning rate :  2.3283740374897e-05\n",
      "Average loss :  3.893542377397807e-09\n",
      "\n",
      "\n",
      "Stage  376\n",
      "Epoch 200/200\n",
      "Learning rate :  2.3283740374897e-05\n",
      "Average loss :  3.6555001248217422e-09\n",
      "expression length:\t 5\n",
      "Result stage 378: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998963]*t)\n",
      "\n",
      "\n",
      "Stage  377\n",
      "Epoch 50/200\n",
      "Learning rate :  2.305206328722557e-05\n",
      "Average loss :  3.4987353014770406e-09\n",
      "\n",
      "\n",
      "Stage  377\n",
      "Epoch 100/200\n",
      "Learning rate :  2.305206328722557e-05\n",
      "Average loss :  4.876113735008403e-09\n",
      "\n",
      "\n",
      "Stage  377\n",
      "Epoch 150/200\n",
      "Learning rate :  2.305206328722557e-05\n",
      "Average loss :  1.0468498956583971e-08\n",
      "\n",
      "\n",
      "Stage  377\n",
      "Epoch 200/200\n",
      "Learning rate :  2.305206328722557e-05\n",
      "Average loss :  5.9022080556303536e-09\n",
      "expression length:\t 5\n",
      "Result stage 379: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999125]*t)\n",
      "\n",
      "\n",
      "Stage  378\n",
      "Epoch 50/200\n",
      "Learning rate :  2.282269142509297e-05\n",
      "Average loss :  3.4909954926831688e-09\n",
      "\n",
      "\n",
      "Stage  378\n",
      "Epoch 100/200\n",
      "Learning rate :  2.282269142509297e-05\n",
      "Average loss :  4.372628037430104e-09\n",
      "\n",
      "\n",
      "Stage  378\n",
      "Epoch 150/200\n",
      "Learning rate :  2.282269142509297e-05\n",
      "Average loss :  7.466062434957621e-09\n",
      "\n",
      "\n",
      "Stage  378\n",
      "Epoch 200/200\n",
      "Learning rate :  2.282269142509297e-05\n",
      "Average loss :  3.4915439428573336e-09\n",
      "expression length:\t 5\n",
      "Result stage 380: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399895]*t)\n",
      "\n",
      "\n",
      "Stage  379\n",
      "Epoch 50/200\n",
      "Learning rate :  2.2595601851121864e-05\n",
      "Average loss :  3.4641498558585226e-09\n",
      "\n",
      "\n",
      "Stage  379\n",
      "Epoch 100/200\n",
      "Learning rate :  2.2595601851121864e-05\n",
      "Average loss :  4.718390567148845e-09\n",
      "\n",
      "\n",
      "Stage  379\n",
      "Epoch 150/200\n",
      "Learning rate :  2.2595601851121864e-05\n",
      "Average loss :  3.642892210109494e-09\n",
      "\n",
      "\n",
      "Stage  379\n",
      "Epoch 200/200\n",
      "Learning rate :  2.2595601851121864e-05\n",
      "Average loss :  9.886647056589482e-09\n",
      "expression length:\t 5\n",
      "Result stage 381: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399948]*t)\n",
      "\n",
      "\n",
      "Stage  380\n",
      "Epoch 50/200\n",
      "Learning rate :  2.2370771856165592e-05\n",
      "Average loss :  3.7461820312501e-09\n",
      "\n",
      "\n",
      "Stage  380\n",
      "Epoch 100/200\n",
      "Learning rate :  2.2370771856165592e-05\n",
      "Average loss :  4.8705786070968315e-09\n",
      "\n",
      "\n",
      "Stage  380\n",
      "Epoch 150/200\n",
      "Learning rate :  2.2370771856165592e-05\n",
      "Average loss :  4.599647329683876e-09\n",
      "\n",
      "\n",
      "Stage  380\n",
      "Epoch 200/200\n",
      "Learning rate :  2.2370771856165592e-05\n",
      "Average loss :  3.680733051680818e-09\n",
      "expression length:\t 5\n",
      "Result stage 382: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999341]*t)\n",
      "\n",
      "\n",
      "Stage  381\n",
      "Epoch 50/200\n",
      "Learning rate :  2.2148178957037315e-05\n",
      "Average loss :  4.0372318821368935e-09\n",
      "\n",
      "\n",
      "Stage  381\n",
      "Epoch 100/200\n",
      "Learning rate :  2.2148178957037315e-05\n",
      "Average loss :  3.48782247527879e-09\n",
      "\n",
      "\n",
      "Stage  381\n",
      "Epoch 150/200\n",
      "Learning rate :  2.2148178957037315e-05\n",
      "Average loss :  3.49214701600431e-09\n",
      "\n",
      "\n",
      "Stage  381\n",
      "Epoch 200/200\n",
      "Learning rate :  2.2148178957037315e-05\n",
      "Average loss :  4.520098517701854e-09\n",
      "expression length:\t 5\n",
      "Result stage 383: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13998897]*t)\n",
      "\n",
      "\n",
      "Stage  382\n",
      "Epoch 50/200\n",
      "Learning rate :  2.192780089426161e-05\n",
      "Average loss :  3.502548695522023e-09\n",
      "\n",
      "\n",
      "Stage  382\n",
      "Epoch 100/200\n",
      "Learning rate :  2.192780089426161e-05\n",
      "Average loss :  4.779768136842222e-09\n",
      "\n",
      "\n",
      "Stage  382\n",
      "Epoch 150/200\n",
      "Learning rate :  2.192780089426161e-05\n",
      "Average loss :  3.3446816427584736e-09\n",
      "\n",
      "\n",
      "Stage  382\n",
      "Epoch 200/200\n",
      "Learning rate :  2.192780089426161e-05\n",
      "Average loss :  3.554692540319593e-09\n",
      "expression length:\t 5\n",
      "Result stage 384: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399955]*t)\n",
      "\n",
      "\n",
      "Stage  383\n",
      "Epoch 50/200\n",
      "Learning rate :  2.170961562984857e-05\n",
      "Average loss :  3.4598934828267147e-09\n",
      "\n",
      "\n",
      "Stage  383\n",
      "Epoch 100/200\n",
      "Learning rate :  2.170961562984857e-05\n",
      "Average loss :  5.7794018459844665e-09\n",
      "\n",
      "\n",
      "Stage  383\n",
      "Epoch 150/200\n",
      "Learning rate :  2.170961562984857e-05\n",
      "Average loss :  3.4316793851019156e-09\n",
      "\n",
      "\n",
      "Stage  383\n",
      "Epoch 200/200\n",
      "Learning rate :  2.170961562984857e-05\n",
      "Average loss :  6.639847782707875e-09\n",
      "expression length:\t 5\n",
      "Result stage 385: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999008]*t)\n",
      "\n",
      "\n",
      "Stage  384\n",
      "Epoch 50/200\n",
      "Learning rate :  2.1493601345089923e-05\n",
      "Average loss :  2.7099145150089043e-09\n",
      "\n",
      "\n",
      "Stage  384\n",
      "Epoch 100/200\n",
      "Learning rate :  2.1493601345089923e-05\n",
      "Average loss :  3.4942360116474447e-09\n",
      "\n",
      "\n",
      "Stage  384\n",
      "Epoch 150/200\n",
      "Learning rate :  2.1493601345089923e-05\n",
      "Average loss :  3.3025584489365656e-09\n",
      "\n",
      "\n",
      "Stage  384\n",
      "Epoch 200/200\n",
      "Learning rate :  2.1493601345089923e-05\n",
      "Average loss :  5.655784729441393e-09\n",
      "expression length:\t 5\n",
      "Result stage 386: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999078]*t)\n",
      "\n",
      "\n",
      "Stage  385\n",
      "Epoch 50/200\n",
      "Learning rate :  2.127973643837717e-05\n",
      "Average loss :  5.390849988629043e-09\n",
      "\n",
      "\n",
      "Stage  385\n",
      "Epoch 100/200\n",
      "Learning rate :  2.127973643837717e-05\n",
      "Average loss :  4.777069850803173e-09\n",
      "\n",
      "\n",
      "Stage  385\n",
      "Epoch 150/200\n",
      "Learning rate :  2.127973643837717e-05\n",
      "Average loss :  3.3779157249114178e-09\n",
      "\n",
      "\n",
      "Stage  385\n",
      "Epoch 200/200\n",
      "Learning rate :  2.127973643837717e-05\n",
      "Average loss :  3.0870945799676974e-09\n",
      "expression length:\t 5\n",
      "Result stage 387: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999008]*t)\n",
      "\n",
      "\n",
      "Stage  386\n",
      "Epoch 50/200\n",
      "Learning rate :  2.1067999523041435e-05\n",
      "Average loss :  3.2876896760569707e-09\n",
      "\n",
      "\n",
      "Stage  386\n",
      "Epoch 100/200\n",
      "Learning rate :  2.1067999523041435e-05\n",
      "Average loss :  2.995833137120485e-09\n",
      "\n",
      "\n",
      "Stage  386\n",
      "Epoch 150/200\n",
      "Learning rate :  2.1067999523041435e-05\n",
      "Average loss :  3.352843558346308e-09\n",
      "\n",
      "\n",
      "Stage  386\n",
      "Epoch 200/200\n",
      "Learning rate :  2.1067999523041435e-05\n",
      "Average loss :  3.238661783200314e-09\n",
      "expression length:\t 5\n",
      "Result stage 388: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999604]*t)\n",
      "\n",
      "\n",
      "Stage  387\n",
      "Epoch 50/200\n",
      "Learning rate :  2.0858369425214716e-05\n",
      "Average loss :  5.466017416466684e-09\n",
      "\n",
      "\n",
      "Stage  387\n",
      "Epoch 100/200\n",
      "Learning rate :  2.0858369425214716e-05\n",
      "Average loss :  6.055280721284362e-09\n",
      "\n",
      "\n",
      "Stage  387\n",
      "Epoch 150/200\n",
      "Learning rate :  2.0858369425214716e-05\n",
      "Average loss :  5.994943652609663e-09\n",
      "\n",
      "\n",
      "Stage  387\n",
      "Epoch 200/200\n",
      "Learning rate :  2.0858369425214716e-05\n",
      "Average loss :  4.073536619131346e-09\n",
      "expression length:\t 5\n",
      "Result stage 389: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.139993]*t)\n",
      "\n",
      "\n",
      "Stage  388\n",
      "Epoch 50/200\n",
      "Learning rate :  2.0650825181712566e-05\n",
      "Average loss :  3.1075368944755155e-09\n",
      "\n",
      "\n",
      "Stage  388\n",
      "Epoch 100/200\n",
      "Learning rate :  2.0650825181712566e-05\n",
      "Average loss :  2.8953903719042273e-09\n",
      "\n",
      "\n",
      "Stage  388\n",
      "Epoch 150/200\n",
      "Learning rate :  2.0650825181712566e-05\n",
      "Average loss :  3.9664502793357315e-09\n",
      "\n",
      "\n",
      "Stage  388\n",
      "Epoch 200/200\n",
      "Learning rate :  2.0650825181712566e-05\n",
      "Average loss :  2.271366650319351e-09\n",
      "expression length:\t 5\n",
      "Result stage 390: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999464]*t)\n",
      "\n",
      "\n",
      "Stage  389\n",
      "Epoch 50/200\n",
      "Learning rate :  2.044534603793765e-05\n",
      "Average loss :  3.7570635491590565e-09\n",
      "\n",
      "\n",
      "Stage  389\n",
      "Epoch 100/200\n",
      "Learning rate :  2.044534603793765e-05\n",
      "Average loss :  4.526974350937962e-09\n",
      "\n",
      "\n",
      "Stage  389\n",
      "Epoch 150/200\n",
      "Learning rate :  2.044534603793765e-05\n",
      "Average loss :  5.848978634759305e-09\n",
      "\n",
      "\n",
      "Stage  389\n",
      "Epoch 200/200\n",
      "Learning rate :  2.044534603793765e-05\n",
      "Average loss :  2.2123707310583995e-09\n",
      "expression length:\t 5\n",
      "Result stage 391: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999471]*t)\n",
      "\n",
      "\n",
      "Stage  390\n",
      "Epoch 50/200\n",
      "Learning rate :  2.024191144580439e-05\n",
      "Average loss :  4.331305092364346e-09\n",
      "\n",
      "\n",
      "Stage  390\n",
      "Epoch 100/200\n",
      "Learning rate :  2.024191144580439e-05\n",
      "Average loss :  4.291767385922185e-09\n",
      "\n",
      "\n",
      "Stage  390\n",
      "Epoch 150/200\n",
      "Learning rate :  2.024191144580439e-05\n",
      "Average loss :  3.0371587467215022e-09\n",
      "\n",
      "\n",
      "Stage  390\n",
      "Epoch 200/200\n",
      "Learning rate :  2.024191144580439e-05\n",
      "Average loss :  3.407673032640446e-09\n",
      "expression length:\t 5\n",
      "Result stage 392: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999103]*t)\n",
      "\n",
      "\n",
      "Stage  391\n",
      "Epoch 50/200\n",
      "Learning rate :  2.0040501061684014e-05\n",
      "Average loss :  2.6613111714368642e-09\n",
      "\n",
      "\n",
      "Stage  391\n",
      "Epoch 100/200\n",
      "Learning rate :  2.0040501061684014e-05\n",
      "Average loss :  4.376304207909243e-09\n",
      "\n",
      "\n",
      "Stage  391\n",
      "Epoch 150/200\n",
      "Learning rate :  2.0040501061684014e-05\n",
      "Average loss :  2.6935680352835334e-09\n",
      "\n",
      "\n",
      "Stage  391\n",
      "Epoch 200/200\n",
      "Learning rate :  2.0040501061684014e-05\n",
      "Average loss :  3.789907943030357e-09\n",
      "expression length:\t 5\n",
      "Result stage 393: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999327]*t)\n",
      "\n",
      "\n",
      "Stage  392\n",
      "Epoch 50/200\n",
      "Learning rate :  1.9841094744370286e-05\n",
      "Average loss :  3.0585600718779915e-09\n",
      "\n",
      "\n",
      "Stage  392\n",
      "Epoch 100/200\n",
      "Learning rate :  1.9841094744370286e-05\n",
      "Average loss :  2.6202919833906435e-09\n",
      "\n",
      "\n",
      "Stage  392\n",
      "Epoch 150/200\n",
      "Learning rate :  1.9841094744370286e-05\n",
      "Average loss :  2.6293309751679317e-09\n",
      "\n",
      "\n",
      "Stage  392\n",
      "Epoch 200/200\n",
      "Learning rate :  1.9841094744370286e-05\n",
      "Average loss :  3.7349949799647675e-09\n",
      "expression length:\t 5\n",
      "Result stage 394: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399933]*t)\n",
      "\n",
      "\n",
      "Stage  393\n",
      "Epoch 50/200\n",
      "Learning rate :  1.9643672553065294e-05\n",
      "Average loss :  2.7606734676055567e-09\n",
      "\n",
      "\n",
      "Stage  393\n",
      "Epoch 100/200\n",
      "Learning rate :  1.9643672553065294e-05\n",
      "Average loss :  2.6233628602767567e-09\n",
      "\n",
      "\n",
      "Stage  393\n",
      "Epoch 150/200\n",
      "Learning rate :  1.9643672553065294e-05\n",
      "Average loss :  2.6113795570381626e-09\n",
      "\n",
      "\n",
      "Stage  393\n",
      "Epoch 200/200\n",
      "Learning rate :  1.9643672553065294e-05\n",
      "Average loss :  2.705360380161892e-09\n",
      "expression length:\t 5\n",
      "Result stage 395: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999504]*t)\n",
      "\n",
      "\n",
      "Stage  394\n",
      "Epoch 50/200\n",
      "Learning rate :  1.944821474538539e-05\n",
      "Average loss :  2.871394233494584e-09\n",
      "\n",
      "\n",
      "Stage  394\n",
      "Epoch 100/200\n",
      "Learning rate :  1.944821474538539e-05\n",
      "Average loss :  2.92143198521444e-09\n",
      "\n",
      "\n",
      "Stage  394\n",
      "Epoch 150/200\n",
      "Learning rate :  1.944821474538539e-05\n",
      "Average loss :  2.5011046567158246e-09\n",
      "\n",
      "\n",
      "Stage  394\n",
      "Epoch 200/200\n",
      "Learning rate :  1.944821474538539e-05\n",
      "Average loss :  2.845733870771028e-09\n",
      "expression length:\t 5\n",
      "Result stage 396: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999614]*t)\n",
      "\n",
      "\n",
      "Stage  395\n",
      "Epoch 50/200\n",
      "Learning rate :  1.925470177538692e-05\n",
      "Average loss :  2.62273047724193e-09\n",
      "\n",
      "\n",
      "Stage  395\n",
      "Epoch 100/200\n",
      "Learning rate :  1.925470177538692e-05\n",
      "Average loss :  2.77560574524216e-09\n",
      "\n",
      "\n",
      "Stage  395\n",
      "Epoch 150/200\n",
      "Learning rate :  1.925470177538692e-05\n",
      "Average loss :  2.501956197775712e-09\n",
      "\n",
      "\n",
      "Stage  395\n",
      "Epoch 200/200\n",
      "Learning rate :  1.925470177538692e-05\n",
      "Average loss :  2.4727924152756486e-09\n",
      "expression length:\t 5\n",
      "Result stage 397: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999072]*t)\n",
      "\n",
      "\n",
      "Stage  396\n",
      "Epoch 50/200\n",
      "Learning rate :  1.9063114291611636e-05\n",
      "Average loss :  2.604734872235781e-09\n",
      "\n",
      "\n",
      "Stage  396\n",
      "Epoch 100/200\n",
      "Learning rate :  1.9063114291611636e-05\n",
      "Average loss :  4.752579663147571e-09\n",
      "\n",
      "\n",
      "Stage  396\n",
      "Epoch 150/200\n",
      "Learning rate :  1.9063114291611636e-05\n",
      "Average loss :  2.419570765965773e-09\n",
      "\n",
      "\n",
      "Stage  396\n",
      "Epoch 200/200\n",
      "Learning rate :  1.9063114291611636e-05\n",
      "Average loss :  2.4806889875605975e-09\n",
      "expression length:\t 5\n",
      "Result stage 398: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999265]*t)\n",
      "\n",
      "\n",
      "Stage  397\n",
      "Epoch 50/200\n",
      "Learning rate :  1.8873433135151488e-05\n",
      "Average loss :  5.300210492720225e-09\n",
      "\n",
      "\n",
      "Stage  397\n",
      "Epoch 100/200\n",
      "Learning rate :  1.8873433135151488e-05\n",
      "Average loss :  2.371866480999074e-09\n",
      "\n",
      "\n",
      "Stage  397\n",
      "Epoch 150/200\n",
      "Learning rate :  1.8873433135151488e-05\n",
      "Average loss :  3.2437725838718734e-09\n",
      "\n",
      "\n",
      "Stage  397\n",
      "Epoch 200/200\n",
      "Learning rate :  1.8873433135151488e-05\n",
      "Average loss :  3.968664508136044e-09\n",
      "expression length:\t 5\n",
      "Result stage 399: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999285]*t)\n",
      "\n",
      "\n",
      "Stage  398\n",
      "Epoch 50/200\n",
      "Learning rate :  1.8685639337732774e-05\n",
      "Average loss :  2.40188158251442e-09\n",
      "\n",
      "\n",
      "Stage  398\n",
      "Epoch 100/200\n",
      "Learning rate :  1.8685639337732774e-05\n",
      "Average loss :  5.959658544441027e-09\n",
      "\n",
      "\n",
      "Stage  398\n",
      "Epoch 150/200\n",
      "Learning rate :  1.8685639337732774e-05\n",
      "Average loss :  2.5352870913764036e-09\n",
      "\n",
      "\n",
      "Stage  398\n",
      "Epoch 200/200\n",
      "Learning rate :  1.8685639337732774e-05\n",
      "Average loss :  2.364568763013608e-09\n",
      "expression length:\t 5\n",
      "Result stage 400: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999166]*t)\n",
      "\n",
      "\n",
      "Stage  399\n",
      "Epoch 50/200\n",
      "Learning rate :  1.849971411981924e-05\n",
      "Average loss :  2.4958650701734086e-09\n",
      "\n",
      "\n",
      "Stage  399\n",
      "Epoch 100/200\n",
      "Learning rate :  1.849971411981924e-05\n",
      "Average loss :  2.5903901246238092e-09\n",
      "\n",
      "\n",
      "Stage  399\n",
      "Epoch 150/200\n",
      "Learning rate :  1.849971411981924e-05\n",
      "Average loss :  2.3444441943354377e-09\n",
      "\n",
      "\n",
      "Stage  399\n",
      "Epoch 200/200\n",
      "Learning rate :  1.849971411981924e-05\n",
      "Average loss :  4.52034631948095e-09\n",
      "expression length:\t 5\n",
      "Result stage 401: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999121]*t)\n",
      "\n",
      "\n",
      "Stage  400\n",
      "Epoch 50/200\n",
      "Learning rate :  1.831563888873418e-05\n",
      "Average loss :  2.4213910876369482e-09\n",
      "\n",
      "\n",
      "Stage  400\n",
      "Epoch 100/200\n",
      "Learning rate :  1.831563888873418e-05\n",
      "Average loss :  2.6709203737596e-09\n",
      "\n",
      "\n",
      "Stage  400\n",
      "Epoch 150/200\n",
      "Learning rate :  1.831563888873418e-05\n",
      "Average loss :  2.2568134028233544e-09\n",
      "\n",
      "\n",
      "Stage  400\n",
      "Epoch 200/200\n",
      "Learning rate :  1.831563888873418e-05\n",
      "Average loss :  3.0386952953875834e-09\n",
      "expression length:\t 5\n",
      "Result stage 402: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999382]*t)\n",
      "\n",
      "\n",
      "Stage  401\n",
      "Epoch 50/200\n",
      "Learning rate :  1.8133395236801075e-05\n",
      "Average loss :  2.2477910643914356e-09\n",
      "\n",
      "\n",
      "Stage  401\n",
      "Epoch 100/200\n",
      "Learning rate :  1.8133395236801075e-05\n",
      "Average loss :  3.052333275022079e-09\n",
      "\n",
      "\n",
      "Stage  401\n",
      "Epoch 150/200\n",
      "Learning rate :  1.8133395236801075e-05\n",
      "Average loss :  2.472231086514398e-09\n",
      "\n",
      "\n",
      "Stage  401\n",
      "Epoch 200/200\n",
      "Learning rate :  1.8133395236801075e-05\n",
      "Average loss :  2.1996851007344276e-09\n",
      "expression length:\t 5\n",
      "Result stage 403: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999183]*t)\n",
      "\n",
      "\n",
      "Stage  402\n",
      "Epoch 50/200\n",
      "Learning rate :  1.795296493950285e-05\n",
      "Average loss :  5.680273140740155e-09\n",
      "\n",
      "\n",
      "Stage  402\n",
      "Epoch 100/200\n",
      "Learning rate :  1.795296493950285e-05\n",
      "Average loss :  2.1489552359810205e-09\n",
      "\n",
      "\n",
      "Stage  402\n",
      "Epoch 150/200\n",
      "Learning rate :  1.795296493950285e-05\n",
      "Average loss :  4.546178988817928e-09\n",
      "\n",
      "\n",
      "Stage  402\n",
      "Epoch 200/200\n",
      "Learning rate :  1.795296493950285e-05\n",
      "Average loss :  2.150666089661968e-09\n",
      "expression length:\t 5\n",
      "Result stage 404: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999145]*t)\n",
      "\n",
      "\n",
      "Stage  403\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7774329953659443e-05\n",
      "Average loss :  3.751207344748764e-09\n",
      "\n",
      "\n",
      "Stage  403\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7774329953659443e-05\n",
      "Average loss :  2.5631812228255058e-09\n",
      "\n",
      "\n",
      "Stage  403\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7774329953659443e-05\n",
      "Average loss :  4.2741135075630154e-09\n",
      "\n",
      "\n",
      "Stage  403\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7774329953659443e-05\n",
      "Average loss :  2.253254915984826e-09\n",
      "expression length:\t 5\n",
      "Result stage 405: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999619]*t)\n",
      "\n",
      "\n",
      "Stage  404\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7597472415623393e-05\n",
      "Average loss :  3.91980536917913e-09\n",
      "\n",
      "\n",
      "Stage  404\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7597472415623393e-05\n",
      "Average loss :  2.295783563255327e-09\n",
      "\n",
      "\n",
      "Stage  404\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7597472415623393e-05\n",
      "Average loss :  2.4540773857495424e-09\n",
      "\n",
      "\n",
      "Stage  404\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7597472415623393e-05\n",
      "Average loss :  2.3570150275986634e-09\n",
      "expression length:\t 5\n",
      "Result stage 406: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999328]*t)\n",
      "\n",
      "\n",
      "Stage  405\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7422374639493514e-05\n",
      "Average loss :  2.2380082231876486e-09\n",
      "\n",
      "\n",
      "Stage  405\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7422374639493514e-05\n",
      "Average loss :  3.4106868440630933e-09\n",
      "\n",
      "\n",
      "Stage  405\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7422374639493514e-05\n",
      "Average loss :  2.072609417425042e-09\n",
      "\n",
      "\n",
      "Stage  405\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7422374639493514e-05\n",
      "Average loss :  4.062391312231739e-09\n",
      "expression length:\t 5\n",
      "Result stage 407: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999167]*t)\n",
      "\n",
      "\n",
      "Stage  406\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7249019115346266e-05\n",
      "Average loss :  2.0183235083237605e-09\n",
      "\n",
      "\n",
      "Stage  406\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7249019115346266e-05\n",
      "Average loss :  4.145757959150842e-09\n",
      "\n",
      "\n",
      "Stage  406\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7249019115346266e-05\n",
      "Average loss :  3.675404647296432e-09\n",
      "\n",
      "\n",
      "Stage  406\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7249019115346266e-05\n",
      "Average loss :  2.1865711463675552e-09\n",
      "expression length:\t 5\n",
      "Result stage 408: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999604]*t)\n",
      "\n",
      "\n",
      "Stage  407\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7077388507484792e-05\n",
      "Average loss :  3.231905854050865e-09\n",
      "\n",
      "\n",
      "Stage  407\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7077388507484792e-05\n",
      "Average loss :  1.9683552565652462e-09\n",
      "\n",
      "\n",
      "Stage  407\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7077388507484792e-05\n",
      "Average loss :  2.1796748850277936e-09\n",
      "\n",
      "\n",
      "Stage  407\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7077388507484792e-05\n",
      "Average loss :  2.68374478196165e-09\n",
      "expression length:\t 5\n",
      "Result stage 409: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999143]*t)\n",
      "\n",
      "\n",
      "Stage  408\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6907465652705278e-05\n",
      "Average loss :  5.413271608745163e-09\n",
      "\n",
      "\n",
      "Stage  408\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6907465652705278e-05\n",
      "Average loss :  2.169357804504557e-09\n",
      "\n",
      "\n",
      "Stage  408\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6907465652705278e-05\n",
      "Average loss :  3.1729461280605165e-09\n",
      "\n",
      "\n",
      "Stage  408\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6907465652705278e-05\n",
      "Average loss :  1.537656779682095e-09\n",
      "expression length:\t 5\n",
      "Result stage 410: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999555]*t)\n",
      "\n",
      "\n",
      "Stage  409\n",
      "Epoch 50/200\n",
      "Learning rate :  1.673923355858063e-05\n",
      "Average loss :  4.9987609607171635e-09\n",
      "\n",
      "\n",
      "Stage  409\n",
      "Epoch 100/200\n",
      "Learning rate :  1.673923355858063e-05\n",
      "Average loss :  1.4531953418384091e-09\n",
      "\n",
      "\n",
      "Stage  409\n",
      "Epoch 150/200\n",
      "Learning rate :  1.673923355858063e-05\n",
      "Average loss :  2.249907593565581e-09\n",
      "\n",
      "\n",
      "Stage  409\n",
      "Epoch 200/200\n",
      "Learning rate :  1.673923355858063e-05\n",
      "Average loss :  2.357762651783446e-09\n",
      "expression length:\t 5\n",
      "Result stage 411: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999265]*t)\n",
      "\n",
      "\n",
      "Stage  410\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6572675401761255e-05\n",
      "Average loss :  2.8383662087350103e-09\n",
      "\n",
      "\n",
      "Stage  410\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6572675401761255e-05\n",
      "Average loss :  3.836729156603269e-09\n",
      "\n",
      "\n",
      "Stage  410\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6572675401761255e-05\n",
      "Average loss :  2.6970898847622493e-09\n",
      "\n",
      "\n",
      "Stage  410\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6572675401761255e-05\n",
      "Average loss :  2.4769486461906354e-09\n",
      "expression length:\t 5\n",
      "Result stage 412: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999443]*t)\n",
      "\n",
      "\n",
      "Stage  411\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6407774526292644e-05\n",
      "Average loss :  2.0879533657591764e-09\n",
      "\n",
      "\n",
      "Stage  411\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6407774526292644e-05\n",
      "Average loss :  2.020046130368769e-09\n",
      "\n",
      "\n",
      "Stage  411\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6407774526292644e-05\n",
      "Average loss :  3.2315199405275052e-09\n",
      "\n",
      "\n",
      "Stage  411\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6407774526292644e-05\n",
      "Average loss :  1.6657116796992e-09\n",
      "expression length:\t 5\n",
      "Result stage 413: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999352]*t)\n",
      "\n",
      "\n",
      "Stage  412\n",
      "Epoch 50/200\n",
      "Learning rate :  1.624451444194987e-05\n",
      "Average loss :  1.804328353394169e-09\n",
      "\n",
      "\n",
      "Stage  412\n",
      "Epoch 100/200\n",
      "Learning rate :  1.624451444194987e-05\n",
      "Average loss :  1.7478830605099915e-09\n",
      "\n",
      "\n",
      "Stage  412\n",
      "Epoch 150/200\n",
      "Learning rate :  1.624451444194987e-05\n",
      "Average loss :  1.8687245084691995e-09\n",
      "\n",
      "\n",
      "Stage  412\n",
      "Epoch 200/200\n",
      "Learning rate :  1.624451444194987e-05\n",
      "Average loss :  1.9280859131498573e-09\n",
      "expression length:\t 5\n",
      "Result stage 414: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999659]*t)\n",
      "\n",
      "\n",
      "Stage  413\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6082878822588435e-05\n",
      "Average loss :  2.0652977106294657e-09\n",
      "\n",
      "\n",
      "Stage  413\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6082878822588435e-05\n",
      "Average loss :  1.8377502852828798e-09\n",
      "\n",
      "\n",
      "Stage  413\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6082878822588435e-05\n",
      "Average loss :  1.6755700160686615e-09\n",
      "\n",
      "\n",
      "Stage  413\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6082878822588435e-05\n",
      "Average loss :  1.4091304789687342e-09\n",
      "expression length:\t 5\n",
      "Result stage 415: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999544]*t)\n",
      "\n",
      "\n",
      "Stage  414\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5922851504511698e-05\n",
      "Average loss :  1.7103201077617314e-09\n",
      "\n",
      "\n",
      "Stage  414\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5922851504511698e-05\n",
      "Average loss :  2.961863865280634e-09\n",
      "\n",
      "\n",
      "Stage  414\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5922851504511698e-05\n",
      "Average loss :  1.7491689208171124e-09\n",
      "\n",
      "\n",
      "Stage  414\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5922851504511698e-05\n",
      "Average loss :  2.221760997400679e-09\n",
      "expression length:\t 5\n",
      "Result stage 416: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999465]*t)\n",
      "\n",
      "\n",
      "Stage  415\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5764416484854488e-05\n",
      "Average loss :  1.652519787675999e-09\n",
      "\n",
      "\n",
      "Stage  415\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5764416484854488e-05\n",
      "Average loss :  1.8617888342120636e-09\n",
      "\n",
      "\n",
      "Stage  415\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5764416484854488e-05\n",
      "Average loss :  2.1144521689109297e-09\n",
      "\n",
      "\n",
      "Stage  415\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5764416484854488e-05\n",
      "Average loss :  2.0725228200291212e-09\n",
      "expression length:\t 5\n",
      "Result stage 417: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399946]*t)\n",
      "\n",
      "\n",
      "Stage  416\n",
      "Epoch 50/200\n",
      "Learning rate :  1.560755791998283e-05\n",
      "Average loss :  2.126997911133799e-09\n",
      "\n",
      "\n",
      "Stage  416\n",
      "Epoch 100/200\n",
      "Learning rate :  1.560755791998283e-05\n",
      "Average loss :  1.6426187077200893e-09\n",
      "\n",
      "\n",
      "Stage  416\n",
      "Epoch 150/200\n",
      "Learning rate :  1.560755791998283e-05\n",
      "Average loss :  1.8623984576748853e-09\n",
      "\n",
      "\n",
      "Stage  416\n",
      "Epoch 200/200\n",
      "Learning rate :  1.560755791998283e-05\n",
      "Average loss :  3.507862667007089e-09\n",
      "expression length:\t 5\n",
      "Result stage 418: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999283]*t)\n",
      "\n",
      "\n",
      "Stage  417\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5452260123909514e-05\n",
      "Average loss :  3.0421276608905146e-09\n",
      "\n",
      "\n",
      "Stage  417\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5452260123909514e-05\n",
      "Average loss :  3.3728251302989065e-09\n",
      "\n",
      "\n",
      "Stage  417\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5452260123909514e-05\n",
      "Average loss :  1.6252994505805418e-09\n",
      "\n",
      "\n",
      "Stage  417\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5452260123909514e-05\n",
      "Average loss :  1.6135689451246549e-09\n",
      "expression length:\t 5\n",
      "Result stage 419: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999245]*t)\n",
      "\n",
      "\n",
      "Stage  418\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5298507566725518e-05\n",
      "Average loss :  3.6627672006517287e-09\n",
      "\n",
      "\n",
      "Stage  418\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5298507566725518e-05\n",
      "Average loss :  1.7636322402481142e-09\n",
      "\n",
      "\n",
      "Stage  418\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5298507566725518e-05\n",
      "Average loss :  3.6957863436271055e-09\n",
      "\n",
      "\n",
      "Stage  418\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5298507566725518e-05\n",
      "Average loss :  1.5811860709646908e-09\n",
      "expression length:\t 5\n",
      "Result stage 420: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999254]*t)\n",
      "\n",
      "\n",
      "Stage  419\n",
      "Epoch 50/200\n",
      "Learning rate :  1.514628487304698e-05\n",
      "Average loss :  1.7264597529376147e-09\n",
      "\n",
      "\n",
      "Stage  419\n",
      "Epoch 100/200\n",
      "Learning rate :  1.514628487304698e-05\n",
      "Average loss :  1.3969753132059282e-09\n",
      "\n",
      "\n",
      "Stage  419\n",
      "Epoch 150/200\n",
      "Learning rate :  1.514628487304698e-05\n",
      "Average loss :  1.5490695393083342e-09\n",
      "\n",
      "\n",
      "Stage  419\n",
      "Epoch 200/200\n",
      "Learning rate :  1.514628487304698e-05\n",
      "Average loss :  1.6719932105502266e-09\n",
      "expression length:\t 5\n",
      "Result stage 421: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399963]*t)\n",
      "\n",
      "\n",
      "Stage  420\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4995576820477704e-05\n",
      "Average loss :  1.5334259417798535e-09\n",
      "\n",
      "\n",
      "Stage  420\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4995576820477704e-05\n",
      "Average loss :  1.3472299942307586e-09\n",
      "\n",
      "\n",
      "Stage  420\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4995576820477704e-05\n",
      "Average loss :  8.07466316032901e-10\n",
      "\n",
      "\n",
      "Stage  420\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4995576820477704e-05\n",
      "Average loss :  1.7369605753714268e-09\n",
      "expression length:\t 5\n",
      "Result stage 422: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999394]*t)\n",
      "\n",
      "\n",
      "Stage  421\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4846368338086831e-05\n",
      "Average loss :  1.5005681142099547e-09\n",
      "\n",
      "\n",
      "Stage  421\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4846368338086831e-05\n",
      "Average loss :  1.6812574665792113e-09\n",
      "\n",
      "\n",
      "Stage  421\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4846368338086831e-05\n",
      "Average loss :  1.474112387711557e-09\n",
      "\n",
      "\n",
      "Stage  421\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4846368338086831e-05\n",
      "Average loss :  1.6708778804996882e-09\n",
      "expression length:\t 5\n",
      "Result stage 423: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999473]*t)\n",
      "\n",
      "\n",
      "Stage  422\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4698644504901785e-05\n",
      "Average loss :  1.5811286724343177e-09\n",
      "\n",
      "\n",
      "Stage  422\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4698644504901785e-05\n",
      "Average loss :  1.6308592254432597e-09\n",
      "\n",
      "\n",
      "Stage  422\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4698644504901785e-05\n",
      "Average loss :  1.5405313691374545e-09\n",
      "\n",
      "\n",
      "Stage  422\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4698644504901785e-05\n",
      "Average loss :  1.72320802072079e-09\n",
      "expression length:\t 5\n",
      "Result stage 424: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999449]*t)\n",
      "\n",
      "\n",
      "Stage  423\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4552390548416124e-05\n",
      "Average loss :  1.4457902652864618e-09\n",
      "\n",
      "\n",
      "Stage  423\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4552390548416124e-05\n",
      "Average loss :  1.4170736806207174e-09\n",
      "\n",
      "\n",
      "Stage  423\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4552390548416124e-05\n",
      "Average loss :  1.7150765252438305e-09\n",
      "\n",
      "\n",
      "Stage  423\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4552390548416124e-05\n",
      "Average loss :  1.4341016152386032e-09\n",
      "expression length:\t 5\n",
      "Result stage 425: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.1399931]*t)\n",
      "\n",
      "\n",
      "Stage  424\n",
      "Epoch 50/200\n",
      "Learning rate :  1.440759184311235e-05\n",
      "Average loss :  1.3967572654038918e-09\n",
      "\n",
      "\n",
      "Stage  424\n",
      "Epoch 100/200\n",
      "Learning rate :  1.440759184311235e-05\n",
      "Average loss :  3.453323627056193e-09\n",
      "\n",
      "\n",
      "Stage  424\n",
      "Epoch 150/200\n",
      "Learning rate :  1.440759184311235e-05\n",
      "Average loss :  1.2407358473964791e-09\n",
      "\n",
      "\n",
      "Stage  424\n",
      "Epoch 200/200\n",
      "Learning rate :  1.440759184311235e-05\n",
      "Average loss :  2.523672826271195e-09\n",
      "expression length:\t 5\n",
      "Result stage 426: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999242]*t)\n",
      "\n",
      "\n",
      "Stage  425\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4264233908999255e-05\n",
      "Average loss :  2.139129318123878e-09\n",
      "\n",
      "\n",
      "Stage  425\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4264233908999255e-05\n",
      "Average loss :  1.3693155498373244e-09\n",
      "\n",
      "\n",
      "Stage  425\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4264233908999255e-05\n",
      "Average loss :  1.382677305983293e-09\n",
      "\n",
      "\n",
      "Stage  425\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4264233908999255e-05\n",
      "Average loss :  1.0415599493995842e-09\n",
      "expression length:\t 5\n",
      "Result stage 427: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999669]*t)\n",
      "\n",
      "\n",
      "Stage  426\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4122302410163962e-05\n",
      "Average loss :  1.4310850282583942e-09\n",
      "\n",
      "\n",
      "Stage  426\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4122302410163962e-05\n",
      "Average loss :  1.810246286204631e-09\n",
      "\n",
      "\n",
      "Stage  426\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4122302410163962e-05\n",
      "Average loss :  1.1946331701651047e-09\n",
      "\n",
      "\n",
      "Stage  426\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4122302410163962e-05\n",
      "Average loss :  2.0014179202831883e-09\n",
      "expression length:\t 5\n",
      "Result stage 428: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999523]*t)\n",
      "\n",
      "\n",
      "Stage  427\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3981783153338297e-05\n",
      "Average loss :  1.3103917950729738e-09\n",
      "\n",
      "\n",
      "Stage  427\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3981783153338297e-05\n",
      "Average loss :  1.3127379183686116e-09\n",
      "\n",
      "\n",
      "Stage  427\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3981783153338297e-05\n",
      "Average loss :  2.6090760663066703e-09\n",
      "\n",
      "\n",
      "Stage  427\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3981783153338297e-05\n",
      "Average loss :  3.399299508544118e-09\n",
      "expression length:\t 5\n",
      "Result stage 429: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999572]*t)\n",
      "\n",
      "\n",
      "Stage  428\n",
      "Epoch 50/200\n",
      "Learning rate :  1.38426620864795e-05\n",
      "Average loss :  2.1437547292890713e-09\n",
      "\n",
      "\n",
      "Stage  428\n",
      "Epoch 100/200\n",
      "Learning rate :  1.38426620864795e-05\n",
      "Average loss :  2.2064798876897385e-09\n",
      "\n",
      "\n",
      "Stage  428\n",
      "Epoch 150/200\n",
      "Learning rate :  1.38426620864795e-05\n",
      "Average loss :  1.3947681898329733e-09\n",
      "\n",
      "\n",
      "Stage  428\n",
      "Epoch 200/200\n",
      "Learning rate :  1.38426620864795e-05\n",
      "Average loss :  2.871812565530263e-09\n",
      "expression length:\t 5\n",
      "Result stage 430: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999453]*t)\n",
      "\n",
      "\n",
      "Stage  429\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3704925297364945e-05\n",
      "Average loss :  1.4607197673655037e-09\n",
      "\n",
      "\n",
      "Stage  429\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3704925297364945e-05\n",
      "Average loss :  1.4344201382243682e-09\n",
      "\n",
      "\n",
      "Stage  429\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3704925297364945e-05\n",
      "Average loss :  1.7530609186522383e-09\n",
      "\n",
      "\n",
      "Stage  429\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3704925297364945e-05\n",
      "Average loss :  1.3937414555798e-09\n",
      "expression length:\t 5\n",
      "Result stage 431: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999556]*t)\n",
      "\n",
      "\n",
      "Stage  430\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3568559012200934e-05\n",
      "Average loss :  1.02454200678892e-09\n",
      "\n",
      "\n",
      "Stage  430\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3568559012200934e-05\n",
      "Average loss :  1.2178041908228465e-09\n",
      "\n",
      "\n",
      "Stage  430\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3568559012200934e-05\n",
      "Average loss :  9.919591814622208e-10\n",
      "\n",
      "\n",
      "Stage  430\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3568559012200934e-05\n",
      "Average loss :  1.3923603381371663e-09\n",
      "expression length:\t 5\n",
      "Result stage 432: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999493]*t)\n",
      "\n",
      "\n",
      "Stage  431\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3433549594245302e-05\n",
      "Average loss :  1.8361726583648874e-09\n",
      "\n",
      "\n",
      "Stage  431\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3433549594245302e-05\n",
      "Average loss :  1.197385524065453e-09\n",
      "\n",
      "\n",
      "Stage  431\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3433549594245302e-05\n",
      "Average loss :  2.1391513005397655e-09\n",
      "\n",
      "\n",
      "Stage  431\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3433549594245302e-05\n",
      "Average loss :  1.8787480460247252e-09\n",
      "expression length:\t 5\n",
      "Result stage 433: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999291]*t)\n",
      "\n",
      "\n",
      "Stage  432\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3299883542443767e-05\n",
      "Average loss :  1.726571441373892e-09\n",
      "\n",
      "\n",
      "Stage  432\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3299883542443767e-05\n",
      "Average loss :  1.953605943683101e-09\n",
      "\n",
      "\n",
      "Stage  432\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3299883542443767e-05\n",
      "Average loss :  1.2605766430695553e-09\n",
      "\n",
      "\n",
      "Stage  432\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3299883542443767e-05\n",
      "Average loss :  1.364858892571874e-09\n",
      "expression length:\t 5\n",
      "Result stage 434: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999479]*t)\n",
      "\n",
      "\n",
      "Stage  433\n",
      "Epoch 50/200\n",
      "Learning rate :  1.316754749007975e-05\n",
      "Average loss :  1.2335186205802984e-09\n",
      "\n",
      "\n",
      "Stage  433\n",
      "Epoch 100/200\n",
      "Learning rate :  1.316754749007975e-05\n",
      "Average loss :  1.1758576334841564e-09\n",
      "\n",
      "\n",
      "Stage  433\n",
      "Epoch 150/200\n",
      "Learning rate :  1.316754749007975e-05\n",
      "Average loss :  1.1813333644639101e-09\n",
      "\n",
      "\n",
      "Stage  433\n",
      "Epoch 200/200\n",
      "Learning rate :  1.316754749007975e-05\n",
      "Average loss :  1.2661048875983738e-09\n",
      "expression length:\t 5\n",
      "Result stage 435: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399974]*t)\n",
      "\n",
      "\n",
      "Stage  434\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3036528203437737e-05\n",
      "Average loss :  1.2401262239336575e-09\n",
      "\n",
      "\n",
      "Stage  434\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3036528203437737e-05\n",
      "Average loss :  2.691271205890189e-09\n",
      "\n",
      "\n",
      "Stage  434\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3036528203437737e-05\n",
      "Average loss :  2.8184712341783325e-09\n",
      "\n",
      "\n",
      "Stage  434\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3036528203437737e-05\n",
      "Average loss :  1.2350975797659203e-09\n",
      "expression length:\t 5\n",
      "Result stage 436: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999555]*t)\n",
      "\n",
      "\n",
      "Stage  435\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2906812580479862e-05\n",
      "Average loss :  3.0034577047644007e-09\n",
      "\n",
      "\n",
      "Stage  435\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2906812580479862e-05\n",
      "Average loss :  2.736270321435086e-09\n",
      "\n",
      "\n",
      "Stage  435\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2906812580479862e-05\n",
      "Average loss :  1.2062344456609253e-09\n",
      "\n",
      "\n",
      "Stage  435\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2906812580479862e-05\n",
      "Average loss :  3.162246464682994e-09\n",
      "expression length:\t 5\n",
      "Result stage 437: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999656]*t)\n",
      "\n",
      "\n",
      "Stage  436\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2778387649535761e-05\n",
      "Average loss :  1.9012458274403343e-09\n",
      "\n",
      "\n",
      "Stage  436\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2778387649535761e-05\n",
      "Average loss :  1.2954605166370925e-09\n",
      "\n",
      "\n",
      "Stage  436\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2778387649535761e-05\n",
      "Average loss :  1.2536764959492075e-09\n",
      "\n",
      "\n",
      "Stage  436\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2778387649535761e-05\n",
      "Average loss :  1.7370479499234648e-09\n",
      "expression length:\t 5\n",
      "Result stage 438: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999556]*t)\n",
      "\n",
      "\n",
      "Stage  437\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2651240568005305e-05\n",
      "Average loss :  2.279792132853231e-09\n",
      "\n",
      "\n",
      "Stage  437\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2651240568005305e-05\n",
      "Average loss :  1.039916819323139e-09\n",
      "\n",
      "\n",
      "Stage  437\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2651240568005305e-05\n",
      "Average loss :  9.071885465061769e-10\n",
      "\n",
      "\n",
      "Stage  437\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2651240568005305e-05\n",
      "Average loss :  1.072080979547252e-09\n",
      "expression length:\t 5\n",
      "Result stage 439: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399939]*t)\n",
      "\n",
      "\n",
      "Stage  438\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2525358621074385e-05\n",
      "Average loss :  1.0421343787925252e-09\n",
      "\n",
      "\n",
      "Stage  438\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2525358621074385e-05\n",
      "Average loss :  1.9491137592808627e-09\n",
      "\n",
      "\n",
      "Stage  438\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2525358621074385e-05\n",
      "Average loss :  1.1804083266397924e-09\n",
      "\n",
      "\n",
      "Stage  438\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2525358621074385e-05\n",
      "Average loss :  1.1513601183565925e-09\n",
      "expression length:\t 5\n",
      "Result stage 440: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999742]*t)\n",
      "\n",
      "\n",
      "Stage  439\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2400729220443407e-05\n",
      "Average loss :  1.0912739600854593e-09\n",
      "\n",
      "\n",
      "Stage  439\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2400729220443407e-05\n",
      "Average loss :  9.39100464059095e-10\n",
      "\n",
      "\n",
      "Stage  439\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2400729220443407e-05\n",
      "Average loss :  1.0054479471222066e-09\n",
      "\n",
      "\n",
      "Stage  439\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2400729220443407e-05\n",
      "Average loss :  1.090915247026203e-09\n",
      "expression length:\t 5\n",
      "Result stage 441: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999636]*t)\n",
      "\n",
      "\n",
      "Stage  440\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2277339903068436e-05\n",
      "Average loss :  1.0061467214939057e-09\n",
      "\n",
      "\n",
      "Stage  440\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2277339903068436e-05\n",
      "Average loss :  8.816913310560892e-10\n",
      "\n",
      "\n",
      "Stage  440\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2277339903068436e-05\n",
      "Average loss :  1.1318168624541158e-09\n",
      "\n",
      "\n",
      "Stage  440\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2277339903068436e-05\n",
      "Average loss :  1.1770945329558913e-09\n",
      "expression length:\t 5\n",
      "Result stage 442: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999566]*t)\n",
      "\n",
      "\n",
      "Stage  441\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2155178329914935e-05\n",
      "Average loss :  1.8359853637406331e-09\n",
      "\n",
      "\n",
      "Stage  441\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2155178329914935e-05\n",
      "Average loss :  1.1182341719262467e-09\n",
      "\n",
      "\n",
      "Stage  441\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2155178329914935e-05\n",
      "Average loss :  2.6657416274389334e-09\n",
      "\n",
      "\n",
      "Stage  441\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2155178329914935e-05\n",
      "Average loss :  1.7714267830371e-09\n",
      "expression length:\t 5\n",
      "Result stage 443: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999373]*t)\n",
      "\n",
      "\n",
      "Stage  442\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2034232284723774e-05\n",
      "Average loss :  8.822094166305305e-10\n",
      "\n",
      "\n",
      "Stage  442\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2034232284723774e-05\n",
      "Average loss :  1.0163780927996413e-09\n",
      "\n",
      "\n",
      "Stage  442\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2034232284723774e-05\n",
      "Average loss :  9.590249705482279e-10\n",
      "\n",
      "\n",
      "Stage  442\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2034232284723774e-05\n",
      "Average loss :  1.6469073882419138e-09\n",
      "expression length:\t 5\n",
      "Result stage 444: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999538]*t)\n",
      "\n",
      "\n",
      "Stage  443\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1914489672789648e-05\n",
      "Average loss :  2.016998124076963e-09\n",
      "\n",
      "\n",
      "Stage  443\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1914489672789648e-05\n",
      "Average loss :  1.0491835178427777e-09\n",
      "\n",
      "\n",
      "Stage  443\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1914489672789648e-05\n",
      "Average loss :  1.031979168786279e-09\n",
      "\n",
      "\n",
      "Stage  443\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1914489672789648e-05\n",
      "Average loss :  1.8805359491835816e-09\n",
      "expression length:\t 5\n",
      "Result stage 445: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999423]*t)\n",
      "\n",
      "\n",
      "Stage  444\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1795938519751562e-05\n",
      "Average loss :  1.0087179980189376e-09\n",
      "\n",
      "\n",
      "Stage  444\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1795938519751562e-05\n",
      "Average loss :  9.126628897071498e-10\n",
      "\n",
      "\n",
      "Stage  444\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1795938519751562e-05\n",
      "Average loss :  1.2296850204762677e-09\n",
      "\n",
      "\n",
      "Stage  444\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1795938519751562e-05\n",
      "Average loss :  4.958211619054964e-10\n",
      "expression length:\t 5\n",
      "Result stage 446: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.14000049]*t)\n",
      "\n",
      "\n",
      "Stage  445\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1678566970395443e-05\n",
      "Average loss :  9.387143284911303e-10\n",
      "\n",
      "\n",
      "Stage  445\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1678566970395443e-05\n",
      "Average loss :  9.944454149035664e-10\n",
      "\n",
      "\n",
      "Stage  445\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1678566970395443e-05\n",
      "Average loss :  1.0627279056762973e-09\n",
      "\n",
      "\n",
      "Stage  445\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1678566970395443e-05\n",
      "Average loss :  9.361682540287575e-10\n",
      "expression length:\t 5\n",
      "Result stage 447: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999422]*t)\n",
      "\n",
      "\n",
      "Stage  446\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1562363287468535e-05\n",
      "Average loss :  8.930579609156553e-10\n",
      "\n",
      "\n",
      "Stage  446\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1562363287468535e-05\n",
      "Average loss :  1.5759007432336603e-09\n",
      "\n",
      "\n",
      "Stage  446\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1562363287468535e-05\n",
      "Average loss :  1.3982220936625822e-09\n",
      "\n",
      "\n",
      "Stage  446\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1562363287468535e-05\n",
      "Average loss :  1.1354572837518617e-09\n",
      "expression length:\t 5\n",
      "Result stage 448: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999462]*t)\n",
      "\n",
      "\n",
      "Stage  447\n",
      "Epoch 50/200\n",
      "Learning rate :  1.144731585050571e-05\n",
      "Average loss :  8.653980310135978e-10\n",
      "\n",
      "\n",
      "Stage  447\n",
      "Epoch 100/200\n",
      "Learning rate :  1.144731585050571e-05\n",
      "Average loss :  8.127466477603207e-10\n",
      "\n",
      "\n",
      "Stage  447\n",
      "Epoch 150/200\n",
      "Learning rate :  1.144731585050571e-05\n",
      "Average loss :  9.49940681671535e-10\n",
      "\n",
      "\n",
      "Stage  447\n",
      "Epoch 200/200\n",
      "Learning rate :  1.144731585050571e-05\n",
      "Average loss :  9.043391591134764e-10\n",
      "expression length:\t 5\n",
      "Result stage 449: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999537]*t)\n",
      "\n",
      "\n",
      "Stage  448\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1333413154667387e-05\n",
      "Average loss :  9.104574871798832e-10\n",
      "\n",
      "\n",
      "Stage  448\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1333413154667387e-05\n",
      "Average loss :  8.573686760549037e-10\n",
      "\n",
      "\n",
      "Stage  448\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1333413154667387e-05\n",
      "Average loss :  9.43971345535033e-10\n",
      "\n",
      "\n",
      "Stage  448\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1333413154667387e-05\n",
      "Average loss :  8.644466809037965e-10\n",
      "expression length:\t 5\n",
      "Result stage 450: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999495]*t)\n",
      "\n",
      "\n",
      "Stage  449\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1220643809589085e-05\n",
      "Average loss :  8.447673671696521e-10\n",
      "\n",
      "\n",
      "Stage  449\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1220643809589085e-05\n",
      "Average loss :  9.464701244965568e-10\n",
      "\n",
      "\n",
      "Stage  449\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1220643809589085e-05\n",
      "Average loss :  9.445985105216437e-10\n",
      "\n",
      "\n",
      "Stage  449\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1220643809589085e-05\n",
      "Average loss :  7.735649343310058e-10\n",
      "expression length:\t 5\n",
      "Result stage 451: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399974]*t)\n",
      "\n",
      "\n",
      "Stage  450\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1108996538242306e-05\n",
      "Average loss :  8.783430649472734e-10\n",
      "\n",
      "\n",
      "Stage  450\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1108996538242306e-05\n",
      "Average loss :  8.183350108659226e-10\n",
      "\n",
      "\n",
      "Stage  450\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1108996538242306e-05\n",
      "Average loss :  1.244558678337171e-09\n",
      "\n",
      "\n",
      "Stage  450\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1108996538242306e-05\n",
      "Average loss :  8.313202348730897e-10\n",
      "expression length:\t 5\n",
      "Result stage 452: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999483]*t)\n",
      "\n",
      "\n",
      "Stage  451\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0998460175806881e-05\n",
      "Average loss :  8.11879452555786e-10\n",
      "\n",
      "\n",
      "Stage  451\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0998460175806881e-05\n",
      "Average loss :  8.757092828659552e-10\n",
      "\n",
      "\n",
      "Stage  451\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0998460175806881e-05\n",
      "Average loss :  8.793156758279963e-10\n",
      "\n",
      "\n",
      "Stage  451\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0998460175806881e-05\n",
      "Average loss :  9.206851392384863e-10\n",
      "expression length:\t 5\n",
      "Result stage 453: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399978]*t)\n",
      "\n",
      "\n",
      "Stage  452\n",
      "Epoch 50/200\n",
      "Learning rate :  1.088902366855444e-05\n",
      "Average loss :  1.4711721840754421e-09\n",
      "\n",
      "\n",
      "Stage  452\n",
      "Epoch 100/200\n",
      "Learning rate :  1.088902366855444e-05\n",
      "Average loss :  8.045936139566834e-10\n",
      "\n",
      "\n",
      "Stage  452\n",
      "Epoch 150/200\n",
      "Learning rate :  1.088902366855444e-05\n",
      "Average loss :  2.03679251242761e-09\n",
      "\n",
      "\n",
      "Stage  452\n",
      "Epoch 200/200\n",
      "Learning rate :  1.088902366855444e-05\n",
      "Average loss :  9.049415106154868e-10\n",
      "expression length:\t 5\n",
      "Result stage 454: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399982]*t)\n",
      "\n",
      "\n",
      "Stage  453\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0780676072743084e-05\n",
      "Average loss :  8.742919721527187e-10\n",
      "\n",
      "\n",
      "Stage  453\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0780676072743084e-05\n",
      "Average loss :  1.5512816586848999e-09\n",
      "\n",
      "\n",
      "Stage  453\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0780676072743084e-05\n",
      "Average loss :  7.76820885395324e-10\n",
      "\n",
      "\n",
      "Stage  453\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0780676072743084e-05\n",
      "Average loss :  8.673111673296319e-10\n",
      "expression length:\t 5\n",
      "Result stage 455: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399981]*t)\n",
      "\n",
      "\n",
      "Stage  454\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0673406553522926e-05\n",
      "Average loss :  8.176055943387439e-10\n",
      "\n",
      "\n",
      "Stage  454\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0673406553522926e-05\n",
      "Average loss :  2.101810503418733e-09\n",
      "\n",
      "\n",
      "Stage  454\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0673406553522926e-05\n",
      "Average loss :  7.617802499915172e-10\n",
      "\n",
      "\n",
      "Stage  454\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0673406553522926e-05\n",
      "Average loss :  1.7453362088915014e-09\n",
      "expression length:\t 5\n",
      "Result stage 456: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999544]*t)\n",
      "\n",
      "\n",
      "Stage  455\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0567204383852655e-05\n",
      "Average loss :  7.440245086698383e-10\n",
      "\n",
      "\n",
      "Stage  455\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0567204383852655e-05\n",
      "Average loss :  7.530223111729129e-10\n",
      "\n",
      "\n",
      "Stage  455\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0567204383852655e-05\n",
      "Average loss :  2.0294450564506405e-09\n",
      "\n",
      "\n",
      "Stage  455\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0567204383852655e-05\n",
      "Average loss :  7.026440540514045e-10\n",
      "expression length:\t 5\n",
      "Result stage 457: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999562]*t)\n",
      "\n",
      "\n",
      "Stage  456\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0462058943426795e-05\n",
      "Average loss :  7.981843519466736e-10\n",
      "\n",
      "\n",
      "Stage  456\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0462058943426795e-05\n",
      "Average loss :  7.165058546476644e-10\n",
      "\n",
      "\n",
      "Stage  456\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0462058943426795e-05\n",
      "Average loss :  1.215298306433965e-09\n",
      "\n",
      "\n",
      "Stage  456\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0462058943426795e-05\n",
      "Average loss :  7.432097159920659e-10\n",
      "expression length:\t 5\n",
      "Result stage 458: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399949]*t)\n",
      "\n",
      "\n",
      "Stage  457\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0357959717613697e-05\n",
      "Average loss :  9.609900653018144e-10\n",
      "\n",
      "\n",
      "Stage  457\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0357959717613697e-05\n",
      "Average loss :  5.69597147226375e-10\n",
      "\n",
      "\n",
      "Stage  457\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0357959717613697e-05\n",
      "Average loss :  5.856078955090993e-10\n",
      "\n",
      "\n",
      "Stage  457\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0357959717613697e-05\n",
      "Average loss :  1.5097841865596706e-09\n",
      "expression length:\t 5\n",
      "Result stage 459: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999513]*t)\n",
      "\n",
      "\n",
      "Stage  458\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0254896296404023e-05\n",
      "Average loss :  7.834374815551826e-10\n",
      "\n",
      "\n",
      "Stage  458\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0254896296404023e-05\n",
      "Average loss :  7.010532154794191e-10\n",
      "\n",
      "\n",
      "Stage  458\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0254896296404023e-05\n",
      "Average loss :  1.0159085794825273e-09\n",
      "\n",
      "\n",
      "Stage  458\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0254896296404023e-05\n",
      "Average loss :  7.844180305305315e-10\n",
      "expression length:\t 5\n",
      "Result stage 460: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999799]*t)\n",
      "\n",
      "\n",
      "Stage  459\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0152858373369762e-05\n",
      "Average loss :  8.587679456439901e-10\n",
      "\n",
      "\n",
      "Stage  459\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0152858373369762e-05\n",
      "Average loss :  2.010675181907118e-09\n",
      "\n",
      "\n",
      "Stage  459\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0152858373369762e-05\n",
      "Average loss :  6.908423277884879e-10\n",
      "\n",
      "\n",
      "Stage  459\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0152858373369762e-05\n",
      "Average loss :  1.500890078887096e-09\n",
      "expression length:\t 5\n",
      "Result stage 461: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399955]*t)\n",
      "\n",
      "\n",
      "Stage  460\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0051835744633576e-05\n",
      "Average loss :  8.510100402148169e-10\n",
      "\n",
      "\n",
      "Stage  460\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0051835744633576e-05\n",
      "Average loss :  8.511189530935326e-10\n",
      "\n",
      "\n",
      "Stage  460\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0051835744633576e-05\n",
      "Average loss :  9.601995865082813e-10\n",
      "\n",
      "\n",
      "Stage  460\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0051835744633576e-05\n",
      "Average loss :  7.5618128425603e-10\n",
      "expression length:\t 5\n",
      "Result stage 462: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399962]*t)\n",
      "\n",
      "\n",
      "Stage  461\n",
      "Epoch 50/200\n",
      "Learning rate :  9.95181830784842e-06\n",
      "Average loss :  6.633866789229614e-10\n",
      "\n",
      "\n",
      "Stage  461\n",
      "Epoch 100/200\n",
      "Learning rate :  9.95181830784842e-06\n",
      "Average loss :  7.389601153207082e-10\n",
      "\n",
      "\n",
      "Stage  461\n",
      "Epoch 150/200\n",
      "Learning rate :  9.95181830784842e-06\n",
      "Average loss :  1.3906217288806033e-09\n",
      "\n",
      "\n",
      "Stage  461\n",
      "Epoch 200/200\n",
      "Learning rate :  9.95181830784842e-06\n",
      "Average loss :  7.593513040582422e-10\n",
      "expression length:\t 5\n",
      "Result stage 463: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.139996]*t)\n",
      "\n",
      "\n",
      "Stage  462\n",
      "Epoch 50/200\n",
      "Learning rate :  9.852796061187257e-06\n",
      "Average loss :  6.433796828630989e-10\n",
      "\n",
      "\n",
      "Stage  462\n",
      "Epoch 100/200\n",
      "Learning rate :  9.852796061187257e-06\n",
      "Average loss :  6.553732556646708e-10\n",
      "\n",
      "\n",
      "Stage  462\n",
      "Epoch 150/200\n",
      "Learning rate :  9.852796061187257e-06\n",
      "Average loss :  7.269020940725568e-10\n",
      "\n",
      "\n",
      "Stage  462\n",
      "Epoch 200/200\n",
      "Learning rate :  9.852796061187257e-06\n",
      "Average loss :  1.138153238322559e-09\n",
      "expression length:\t 5\n",
      "Result stage 464: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999471]*t)\n",
      "\n",
      "\n",
      "Stage  463\n",
      "Epoch 50/200\n",
      "Learning rate :  9.754759102342903e-06\n",
      "Average loss :  7.251055866852596e-10\n",
      "\n",
      "\n",
      "Stage  463\n",
      "Epoch 100/200\n",
      "Learning rate :  9.754759102342903e-06\n",
      "Average loss :  6.770719540583059e-10\n",
      "\n",
      "\n",
      "Stage  463\n",
      "Epoch 150/200\n",
      "Learning rate :  9.754759102342903e-06\n",
      "Average loss :  1.0931875404907032e-09\n",
      "\n",
      "\n",
      "Stage  463\n",
      "Epoch 200/200\n",
      "Learning rate :  9.754759102342903e-06\n",
      "Average loss :  6.430085908171179e-10\n",
      "expression length:\t 5\n",
      "Result stage 465: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999549]*t)\n",
      "\n",
      "\n",
      "Stage  464\n",
      "Epoch 50/200\n",
      "Learning rate :  9.657697627537777e-06\n",
      "Average loss :  6.884085523850558e-10\n",
      "\n",
      "\n",
      "Stage  464\n",
      "Epoch 100/200\n",
      "Learning rate :  9.657697627537777e-06\n",
      "Average loss :  1.4479083487728417e-09\n",
      "\n",
      "\n",
      "Stage  464\n",
      "Epoch 150/200\n",
      "Learning rate :  9.657697627537777e-06\n",
      "Average loss :  6.235031380086298e-10\n",
      "\n",
      "\n",
      "Stage  464\n",
      "Epoch 200/200\n",
      "Learning rate :  9.657697627537777e-06\n",
      "Average loss :  1.0214328272084572e-09\n",
      "expression length:\t 5\n",
      "Result stage 466: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399948]*t)\n",
      "\n",
      "\n",
      "Stage  465\n",
      "Epoch 50/200\n",
      "Learning rate :  9.561601930543506e-06\n",
      "Average loss :  6.120713380575182e-10\n",
      "\n",
      "\n",
      "Stage  465\n",
      "Epoch 100/200\n",
      "Learning rate :  9.561601930543506e-06\n",
      "Average loss :  6.083041292903602e-10\n",
      "\n",
      "\n",
      "Stage  465\n",
      "Epoch 150/200\n",
      "Learning rate :  9.561601930543506e-06\n",
      "Average loss :  7.402592427929733e-10\n",
      "\n",
      "\n",
      "Stage  465\n",
      "Epoch 200/200\n",
      "Learning rate :  9.561601930543506e-06\n",
      "Average loss :  1.230747725955439e-09\n",
      "expression length:\t 5\n",
      "Result stage 467: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999516]*t)\n",
      "\n",
      "\n",
      "Stage  466\n",
      "Epoch 50/200\n",
      "Learning rate :  9.466462401710323e-06\n",
      "Average loss :  6.887604375727108e-10\n",
      "\n",
      "\n",
      "Stage  466\n",
      "Epoch 100/200\n",
      "Learning rate :  9.466462401710323e-06\n",
      "Average loss :  1.1903960039916228e-09\n",
      "\n",
      "\n",
      "Stage  466\n",
      "Epoch 150/200\n",
      "Learning rate :  9.466462401710323e-06\n",
      "Average loss :  1.1574728953078761e-09\n",
      "\n",
      "\n",
      "Stage  466\n",
      "Epoch 200/200\n",
      "Learning rate :  9.466462401710323e-06\n",
      "Average loss :  6.565987753504032e-10\n",
      "expression length:\t 5\n",
      "Result stage 468: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999774]*t)\n",
      "\n",
      "\n",
      "Stage  467\n",
      "Epoch 50/200\n",
      "Learning rate :  9.372269527006058e-06\n",
      "Average loss :  5.911848233175476e-10\n",
      "\n",
      "\n",
      "Stage  467\n",
      "Epoch 100/200\n",
      "Learning rate :  9.372269527006058e-06\n",
      "Average loss :  1.1593570548029675e-09\n",
      "\n",
      "\n",
      "Stage  467\n",
      "Epoch 150/200\n",
      "Learning rate :  9.372269527006058e-06\n",
      "Average loss :  9.161532088519664e-10\n",
      "\n",
      "\n",
      "Stage  467\n",
      "Epoch 200/200\n",
      "Learning rate :  9.372269527006058e-06\n",
      "Average loss :  6.339216929163172e-10\n",
      "expression length:\t 5\n",
      "Result stage 469: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999696]*t)\n",
      "\n",
      "\n",
      "Stage  468\n",
      "Epoch 50/200\n",
      "Learning rate :  9.279013887064743e-06\n",
      "Average loss :  1.687324391319578e-09\n",
      "\n",
      "\n",
      "Stage  468\n",
      "Epoch 100/200\n",
      "Learning rate :  9.279013887064743e-06\n",
      "Average loss :  9.980676285437085e-10\n",
      "\n",
      "\n",
      "Stage  468\n",
      "Epoch 150/200\n",
      "Learning rate :  9.279013887064743e-06\n",
      "Average loss :  1.1169081215456345e-09\n",
      "\n",
      "\n",
      "Stage  468\n",
      "Epoch 200/200\n",
      "Learning rate :  9.279013887064743e-06\n",
      "Average loss :  6.519430550966376e-10\n",
      "expression length:\t 5\n",
      "Result stage 470: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999848]*t)\n",
      "\n",
      "\n",
      "Stage  469\n",
      "Epoch 50/200\n",
      "Learning rate :  9.186686156244664e-06\n",
      "Average loss :  5.775162570387238e-10\n",
      "\n",
      "\n",
      "Stage  469\n",
      "Epoch 100/200\n",
      "Learning rate :  9.186686156244664e-06\n",
      "Average loss :  1.0221280488664775e-09\n",
      "\n",
      "\n",
      "Stage  469\n",
      "Epoch 150/200\n",
      "Learning rate :  9.186686156244664e-06\n",
      "Average loss :  6.287842468921667e-10\n",
      "\n",
      "\n",
      "Stage  469\n",
      "Epoch 200/200\n",
      "Learning rate :  9.186686156244664e-06\n",
      "Average loss :  4.592294045036027e-10\n",
      "expression length:\t 5\n",
      "Result stage 471: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999751]*t)\n",
      "\n",
      "\n",
      "Stage  470\n",
      "Epoch 50/200\n",
      "Learning rate :  9.095277101695815e-06\n",
      "Average loss :  1.031127738748694e-09\n",
      "\n",
      "\n",
      "Stage  470\n",
      "Epoch 100/200\n",
      "Learning rate :  9.095277101695815e-06\n",
      "Average loss :  8.493086234295788e-10\n",
      "\n",
      "\n",
      "Stage  470\n",
      "Epoch 150/200\n",
      "Learning rate :  9.095277101695815e-06\n",
      "Average loss :  6.086313120157172e-10\n",
      "\n",
      "\n",
      "Stage  470\n",
      "Epoch 200/200\n",
      "Learning rate :  9.095277101695815e-06\n",
      "Average loss :  5.959355786622211e-10\n",
      "expression length:\t 5\n",
      "Result stage 472: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399964]*t)\n",
      "\n",
      "\n",
      "Stage  471\n",
      "Epoch 50/200\n",
      "Learning rate :  9.004777582436559e-06\n",
      "Average loss :  6.720939360604916e-10\n",
      "\n",
      "\n",
      "Stage  471\n",
      "Epoch 100/200\n",
      "Learning rate :  9.004777582436559e-06\n",
      "Average loss :  5.360149546440596e-10\n",
      "\n",
      "\n",
      "Stage  471\n",
      "Epoch 150/200\n",
      "Learning rate :  9.004777582436559e-06\n",
      "Average loss :  5.692945559410134e-10\n",
      "\n",
      "\n",
      "Stage  471\n",
      "Epoch 200/200\n",
      "Learning rate :  9.004777582436559e-06\n",
      "Average loss :  9.557024061024322e-10\n",
      "expression length:\t 5\n",
      "Result stage 473: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399964]*t)\n",
      "\n",
      "\n",
      "Stage  472\n",
      "Epoch 50/200\n",
      "Learning rate :  8.915178548439555e-06\n",
      "Average loss :  5.97158544834997e-10\n",
      "\n",
      "\n",
      "Stage  472\n",
      "Epoch 100/200\n",
      "Learning rate :  8.915178548439555e-06\n",
      "Average loss :  5.328341101673573e-10\n",
      "\n",
      "\n",
      "Stage  472\n",
      "Epoch 150/200\n",
      "Learning rate :  8.915178548439555e-06\n",
      "Average loss :  5.672720626570538e-10\n",
      "\n",
      "\n",
      "Stage  472\n",
      "Epoch 200/200\n",
      "Learning rate :  8.915178548439555e-06\n",
      "Average loss :  5.239045863802971e-10\n",
      "expression length:\t 5\n",
      "Result stage 474: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399958]*t)\n",
      "\n",
      "\n",
      "Stage  473\n",
      "Epoch 50/200\n",
      "Learning rate :  8.826471039726723e-06\n",
      "Average loss :  5.352732146413075e-10\n",
      "\n",
      "\n",
      "Stage  473\n",
      "Epoch 100/200\n",
      "Learning rate :  8.826471039726723e-06\n",
      "Average loss :  5.452570617237029e-10\n",
      "\n",
      "\n",
      "Stage  473\n",
      "Epoch 150/200\n",
      "Learning rate :  8.826471039726723e-06\n",
      "Average loss :  8.331061396305017e-10\n",
      "\n",
      "\n",
      "Stage  473\n",
      "Epoch 200/200\n",
      "Learning rate :  8.826471039726723e-06\n",
      "Average loss :  6.349685777173875e-10\n",
      "expression length:\t 5\n",
      "Result stage 475: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999696]*t)\n",
      "\n",
      "\n",
      "Stage  474\n",
      "Epoch 50/200\n",
      "Learning rate :  8.73864618547329e-06\n",
      "Average loss :  6.350789893971864e-10\n",
      "\n",
      "\n",
      "Stage  474\n",
      "Epoch 100/200\n",
      "Learning rate :  8.73864618547329e-06\n",
      "Average loss :  6.334102131688724e-10\n",
      "\n",
      "\n",
      "Stage  474\n",
      "Epoch 150/200\n",
      "Learning rate :  8.73864618547329e-06\n",
      "Average loss :  6.29295116016948e-10\n",
      "\n",
      "\n",
      "Stage  474\n",
      "Epoch 200/200\n",
      "Learning rate :  8.73864618547329e-06\n",
      "Average loss :  6.350789893971864e-10\n",
      "expression length:\t 5\n",
      "Result stage 476: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999696]*t)\n",
      "\n",
      "\n",
      "Stage  475\n",
      "Epoch 50/200\n",
      "Learning rate :  8.651695203120634e-06\n",
      "Average loss :  5.467208907816712e-10\n",
      "\n",
      "\n",
      "Stage  475\n",
      "Epoch 100/200\n",
      "Learning rate :  8.651695203120634e-06\n",
      "Average loss :  7.877120622445943e-10\n",
      "\n",
      "\n",
      "Stage  475\n",
      "Epoch 150/200\n",
      "Learning rate :  8.651695203120634e-06\n",
      "Average loss :  8.742439550069037e-10\n",
      "\n",
      "\n",
      "Stage  475\n",
      "Epoch 200/200\n",
      "Learning rate :  8.651695203120634e-06\n",
      "Average loss :  5.338955944012014e-10\n",
      "expression length:\t 5\n",
      "Result stage 477: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399972]*t)\n",
      "\n",
      "\n",
      "Stage  476\n",
      "Epoch 50/200\n",
      "Learning rate :  8.56560939749806e-06\n",
      "Average loss :  8.506415571929438e-10\n",
      "\n",
      "\n",
      "Stage  476\n",
      "Epoch 100/200\n",
      "Learning rate :  8.56560939749806e-06\n",
      "Average loss :  3.9317440969632855e-10\n",
      "\n",
      "\n",
      "Stage  476\n",
      "Epoch 150/200\n",
      "Learning rate :  8.56560939749806e-06\n",
      "Average loss :  5.737968433727758e-10\n",
      "\n",
      "\n",
      "Stage  476\n",
      "Epoch 200/200\n",
      "Learning rate :  8.56560939749806e-06\n",
      "Average loss :  6.943681740700924e-10\n",
      "expression length:\t 5\n",
      "Result stage 478: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999715]*t)\n",
      "\n",
      "\n",
      "Stage  477\n",
      "Epoch 50/200\n",
      "Learning rate :  8.48038015995326e-06\n",
      "Average loss :  4.912819595581652e-10\n",
      "\n",
      "\n",
      "Stage  477\n",
      "Epoch 100/200\n",
      "Learning rate :  8.48038015995326e-06\n",
      "Average loss :  1.2779035607479727e-09\n",
      "\n",
      "\n",
      "Stage  477\n",
      "Epoch 150/200\n",
      "Learning rate :  8.48038015995326e-06\n",
      "Average loss :  2.702916501728936e-10\n",
      "\n",
      "\n",
      "Stage  477\n",
      "Epoch 200/200\n",
      "Learning rate :  8.48038015995326e-06\n",
      "Average loss :  7.746269736763622e-10\n",
      "expression length:\t 5\n",
      "Result stage 479: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999546]*t)\n",
      "\n",
      "\n",
      "Stage  478\n",
      "Epoch 50/200\n",
      "Learning rate :  8.395998967491471e-06\n",
      "Average loss :  5.255343382692956e-10\n",
      "\n",
      "\n",
      "Stage  478\n",
      "Epoch 100/200\n",
      "Learning rate :  8.395998967491471e-06\n",
      "Average loss :  4.976095646647138e-10\n",
      "\n",
      "\n",
      "Stage  478\n",
      "Epoch 150/200\n",
      "Learning rate :  8.395998967491471e-06\n",
      "Average loss :  4.82447470862013e-10\n",
      "\n",
      "\n",
      "Stage  478\n",
      "Epoch 200/200\n",
      "Learning rate :  8.395998967491471e-06\n",
      "Average loss :  5.326365459801252e-10\n",
      "expression length:\t 5\n",
      "Result stage 480: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999829]*t)\n",
      "\n",
      "\n",
      "Stage  479\n",
      "Epoch 50/200\n",
      "Learning rate :  8.312457381923118e-06\n",
      "Average loss :  5.148482196126736e-10\n",
      "\n",
      "\n",
      "Stage  479\n",
      "Epoch 100/200\n",
      "Learning rate :  8.312457381923118e-06\n",
      "Average loss :  5.733075125746723e-10\n",
      "\n",
      "\n",
      "Stage  479\n",
      "Epoch 150/200\n",
      "Learning rate :  8.312457381923118e-06\n",
      "Average loss :  4.5600012654745115e-10\n",
      "\n",
      "\n",
      "Stage  479\n",
      "Epoch 200/200\n",
      "Learning rate :  8.312457381923118e-06\n",
      "Average loss :  5.08686481826004e-10\n",
      "expression length:\t 5\n",
      "Result stage 481: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999827]*t)\n",
      "\n",
      "\n",
      "Stage  480\n",
      "Epoch 50/200\n",
      "Learning rate :  8.22974704902003e-06\n",
      "Average loss :  6.896305748682607e-10\n",
      "\n",
      "\n",
      "Stage  480\n",
      "Epoch 100/200\n",
      "Learning rate :  8.22974704902003e-06\n",
      "Average loss :  4.924836094488683e-10\n",
      "\n",
      "\n",
      "Stage  480\n",
      "Epoch 150/200\n",
      "Learning rate :  8.22974704902003e-06\n",
      "Average loss :  5.011083215045176e-10\n",
      "\n",
      "\n",
      "Stage  480\n",
      "Epoch 200/200\n",
      "Learning rate :  8.22974704902003e-06\n",
      "Average loss :  4.944815668039837e-10\n",
      "expression length:\t 5\n",
      "Result stage 482: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999669]*t)\n",
      "\n",
      "\n",
      "Stage  481\n",
      "Epoch 50/200\n",
      "Learning rate :  8.147859697679981e-06\n",
      "Average loss :  3.9832082077140285e-10\n",
      "\n",
      "\n",
      "Stage  481\n",
      "Epoch 100/200\n",
      "Learning rate :  8.147859697679981e-06\n",
      "Average loss :  4.488186489126633e-10\n",
      "\n",
      "\n",
      "Stage  481\n",
      "Epoch 150/200\n",
      "Learning rate :  8.147859697679981e-06\n",
      "Average loss :  8.083864688757103e-10\n",
      "\n",
      "\n",
      "Stage  481\n",
      "Epoch 200/200\n",
      "Learning rate :  8.147859697679981e-06\n",
      "Average loss :  7.458623163536515e-10\n",
      "expression length:\t 5\n",
      "Result stage 483: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999692]*t)\n",
      "\n",
      "\n",
      "Stage  482\n",
      "Epoch 50/200\n",
      "Learning rate :  8.066787139099615e-06\n",
      "Average loss :  4.587258906063596e-10\n",
      "\n",
      "\n",
      "Stage  482\n",
      "Epoch 100/200\n",
      "Learning rate :  8.066787139099615e-06\n",
      "Average loss :  4.78084738464446e-10\n",
      "\n",
      "\n",
      "Stage  482\n",
      "Epoch 150/200\n",
      "Learning rate :  8.066787139099615e-06\n",
      "Average loss :  6.301524857477148e-10\n",
      "\n",
      "\n",
      "Stage  482\n",
      "Epoch 200/200\n",
      "Learning rate :  8.066787139099615e-06\n",
      "Average loss :  3.930288317022246e-10\n",
      "expression length:\t 5\n",
      "Result stage 484: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999714]*t)\n",
      "\n",
      "\n",
      "Stage  483\n",
      "Epoch 50/200\n",
      "Learning rate :  7.986521265955502e-06\n",
      "Average loss :  4.359939076437058e-10\n",
      "\n",
      "\n",
      "Stage  483\n",
      "Epoch 100/200\n",
      "Learning rate :  7.986521265955502e-06\n",
      "Average loss :  4.579869816723203e-10\n",
      "\n",
      "\n",
      "Stage  483\n",
      "Epoch 150/200\n",
      "Learning rate :  7.986521265955502e-06\n",
      "Average loss :  6.452842704618433e-10\n",
      "\n",
      "\n",
      "Stage  483\n",
      "Epoch 200/200\n",
      "Learning rate :  7.986521265955502e-06\n",
      "Average loss :  4.844895040712061e-10\n",
      "expression length:\t 5\n",
      "Result stage 485: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999707]*t)\n",
      "\n",
      "\n",
      "Stage  484\n",
      "Epoch 50/200\n",
      "Learning rate :  7.907054051593441e-06\n",
      "Average loss :  3.281912241970275e-10\n",
      "\n",
      "\n",
      "Stage  484\n",
      "Epoch 100/200\n",
      "Learning rate :  7.907054051593441e-06\n",
      "Average loss :  6.443872657690974e-10\n",
      "\n",
      "\n",
      "Stage  484\n",
      "Epoch 150/200\n",
      "Learning rate :  7.907054051593441e-06\n",
      "Average loss :  3.838425688407199e-10\n",
      "\n",
      "\n",
      "Stage  484\n",
      "Epoch 200/200\n",
      "Learning rate :  7.907054051593441e-06\n",
      "Average loss :  7.0892552939128e-10\n",
      "expression length:\t 5\n",
      "Result stage 486: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999707]*t)\n",
      "\n",
      "\n",
      "Stage  485\n",
      "Epoch 50/200\n",
      "Learning rate :  7.828377549225767e-06\n",
      "Average loss :  5.331974306521658e-10\n",
      "\n",
      "\n",
      "Stage  485\n",
      "Epoch 100/200\n",
      "Learning rate :  7.828377549225767e-06\n",
      "Average loss :  1.0505327718846047e-09\n",
      "\n",
      "\n",
      "Stage  485\n",
      "Epoch 150/200\n",
      "Learning rate :  7.828377549225767e-06\n",
      "Average loss :  3.9811851038074053e-10\n",
      "\n",
      "\n",
      "Stage  485\n",
      "Epoch 200/200\n",
      "Learning rate :  7.828377549225767e-06\n",
      "Average loss :  8.222670322410863e-10\n",
      "expression length:\t 5\n",
      "Result stage 487: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999608]*t)\n",
      "\n",
      "\n",
      "Stage  486\n",
      "Epoch 50/200\n",
      "Learning rate :  7.750483891136692e-06\n",
      "Average loss :  5.424480864490988e-10\n",
      "\n",
      "\n",
      "Stage  486\n",
      "Epoch 100/200\n",
      "Learning rate :  7.750483891136692e-06\n",
      "Average loss :  6.983864597742695e-10\n",
      "\n",
      "\n",
      "Stage  486\n",
      "Epoch 150/200\n",
      "Learning rate :  7.750483891136692e-06\n",
      "Average loss :  3.3013003442050604e-10\n",
      "\n",
      "\n",
      "Stage  486\n",
      "Epoch 200/200\n",
      "Learning rate :  7.750483891136692e-06\n",
      "Average loss :  4.486425952965334e-10\n",
      "expression length:\t 5\n",
      "Result stage 488: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399987]*t)\n",
      "\n",
      "\n",
      "Stage  487\n",
      "Epoch 50/200\n",
      "Learning rate :  7.67336528789549e-06\n",
      "Average loss :  4.2503514596781145e-10\n",
      "\n",
      "\n",
      "Stage  487\n",
      "Epoch 100/200\n",
      "Learning rate :  7.67336528789549e-06\n",
      "Average loss :  6.420934894890706e-10\n",
      "\n",
      "\n",
      "Stage  487\n",
      "Epoch 150/200\n",
      "Learning rate :  7.67336528789549e-06\n",
      "Average loss :  4.5705766948955784e-10\n",
      "\n",
      "\n",
      "Stage  487\n",
      "Epoch 200/200\n",
      "Learning rate :  7.67336528789549e-06\n",
      "Average loss :  4.2733303007302936e-10\n",
      "expression length:\t 5\n",
      "Result stage 489: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999836]*t)\n",
      "\n",
      "\n",
      "Stage  488\n",
      "Epoch 50/200\n",
      "Learning rate :  7.597014027577567e-06\n",
      "Average loss :  4.405414089081461e-10\n",
      "\n",
      "\n",
      "Stage  488\n",
      "Epoch 100/200\n",
      "Learning rate :  7.597014027577567e-06\n",
      "Average loss :  1.075668665251328e-09\n",
      "\n",
      "\n",
      "Stage  488\n",
      "Epoch 150/200\n",
      "Learning rate :  7.597014027577567e-06\n",
      "Average loss :  5.089265675550791e-10\n",
      "\n",
      "\n",
      "Stage  488\n",
      "Epoch 200/200\n",
      "Learning rate :  7.597014027577567e-06\n",
      "Average loss :  3.555296335111535e-10\n",
      "expression length:\t 5\n",
      "Result stage 490: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.1399969]*t)\n",
      "\n",
      "\n",
      "Stage  489\n",
      "Epoch 50/200\n",
      "Learning rate :  7.52142247499327e-06\n",
      "Average loss :  4.238640549658612e-10\n",
      "\n",
      "\n",
      "Stage  489\n",
      "Epoch 100/200\n",
      "Learning rate :  7.52142247499327e-06\n",
      "Average loss :  4.107553186472046e-10\n",
      "\n",
      "\n",
      "Stage  489\n",
      "Epoch 150/200\n",
      "Learning rate :  7.52142247499327e-06\n",
      "Average loss :  4.1403636075187933e-10\n",
      "\n",
      "\n",
      "Stage  489\n",
      "Epoch 200/200\n",
      "Learning rate :  7.52142247499327e-06\n",
      "Average loss :  4.129961650445324e-10\n",
      "expression length:\t 5\n",
      "Result stage 491: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999772]*t)\n",
      "\n",
      "\n",
      "Stage  490\n",
      "Epoch 50/200\n",
      "Learning rate :  7.446583070924338e-06\n",
      "Average loss :  6.507833716362654e-10\n",
      "\n",
      "\n",
      "Stage  490\n",
      "Epoch 100/200\n",
      "Learning rate :  7.446583070924338e-06\n",
      "Average loss :  4.20866619332827e-10\n",
      "\n",
      "\n",
      "Stage  490\n",
      "Epoch 150/200\n",
      "Learning rate :  7.446583070924338e-06\n",
      "Average loss :  4.989296198409932e-10\n",
      "\n",
      "\n",
      "Stage  490\n",
      "Epoch 200/200\n",
      "Learning rate :  7.446583070924338e-06\n",
      "Average loss :  3.887798416535304e-10\n",
      "expression length:\t 5\n",
      "Result stage 492: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999678]*t)\n",
      "\n",
      "\n",
      "Stage  491\n",
      "Epoch 50/200\n",
      "Learning rate :  7.372488331368012e-06\n",
      "Average loss :  4.0003472756566794e-10\n",
      "\n",
      "\n",
      "Stage  491\n",
      "Epoch 100/200\n",
      "Learning rate :  7.372488331368012e-06\n",
      "Average loss :  4.896651417674036e-10\n",
      "\n",
      "\n",
      "Stage  491\n",
      "Epoch 150/200\n",
      "Learning rate :  7.372488331368012e-06\n",
      "Average loss :  7.61183227560025e-10\n",
      "\n",
      "\n",
      "Stage  491\n",
      "Epoch 200/200\n",
      "Learning rate :  7.372488331368012e-06\n",
      "Average loss :  5.569971706087529e-10\n",
      "expression length:\t 5\n",
      "Result stage 493: -1.739*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999599]*t)\n",
      "\n",
      "\n",
      "Stage  492\n",
      "Epoch 50/200\n",
      "Learning rate :  7.299130846788583e-06\n",
      "Average loss :  4.0368922094025095e-10\n",
      "\n",
      "\n",
      "Stage  492\n",
      "Epoch 100/200\n",
      "Learning rate :  7.299130846788583e-06\n",
      "Average loss :  3.5562239264486095e-10\n",
      "\n",
      "\n",
      "Stage  492\n",
      "Epoch 150/200\n",
      "Learning rate :  7.299130846788583e-06\n",
      "Average loss :  4.457275937230776e-10\n",
      "\n",
      "\n",
      "Stage  492\n",
      "Epoch 200/200\n",
      "Learning rate :  7.299130846788583e-06\n",
      "Average loss :  3.879947196860911e-10\n",
      "expression length:\t 5\n",
      "Result stage 494: -1.739*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999803]*t)\n",
      "\n",
      "\n",
      "Stage  493\n",
      "Epoch 50/200\n",
      "Learning rate :  7.226503281376463e-06\n",
      "Average loss :  3.535996773162964e-10\n",
      "\n",
      "\n",
      "Stage  493\n",
      "Epoch 100/200\n",
      "Learning rate :  7.226503281376463e-06\n",
      "Average loss :  1.5150229681903937e-10\n",
      "\n",
      "\n",
      "Stage  493\n",
      "Epoch 150/200\n",
      "Learning rate :  7.226503281376463e-06\n",
      "Average loss :  3.6538935765939584e-10\n",
      "\n",
      "\n",
      "Stage  493\n",
      "Epoch 200/200\n",
      "Learning rate :  7.226503281376463e-06\n",
      "Average loss :  3.883771915180745e-10\n",
      "expression length:\t 5\n",
      "Result stage 495: -1.739*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999851]*t)\n",
      "\n",
      "\n",
      "Stage  494\n",
      "Epoch 50/200\n",
      "Learning rate :  7.154598372314579e-06\n",
      "Average loss :  4.5699641293417415e-10\n",
      "\n",
      "\n",
      "Stage  494\n",
      "Epoch 100/200\n",
      "Learning rate :  7.154598372314579e-06\n",
      "Average loss :  6.827157728039879e-10\n",
      "\n",
      "\n",
      "Stage  494\n",
      "Epoch 150/200\n",
      "Learning rate :  7.154598372314579e-06\n",
      "Average loss :  7.486259390176997e-10\n",
      "\n",
      "\n",
      "Stage  494\n",
      "Epoch 200/200\n",
      "Learning rate :  7.154598372314579e-06\n",
      "Average loss :  3.350002775182048e-10\n",
      "expression length:\t 5\n",
      "Result stage 496: -1.739*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.421*x0_t*cos(x0) + \n",
      "exp([0.13999678]*t)\n",
      "\n",
      "\n",
      "Stage  495\n",
      "Epoch 50/200\n",
      "Learning rate :  7.083408929052118e-06\n",
      "Average loss :  3.6442970863248547e-10\n",
      "\n",
      "\n",
      "Stage  495\n",
      "Epoch 100/200\n",
      "Learning rate :  7.083408929052118e-06\n",
      "Average loss :  2.611790783646484e-10\n",
      "\n",
      "\n",
      "Stage  495\n",
      "Epoch 150/200\n",
      "Learning rate :  7.083408929052118e-06\n",
      "Average loss :  3.649822388762658e-10\n",
      "\n",
      "\n",
      "Stage  495\n",
      "Epoch 200/200\n",
      "Learning rate :  7.083408929052118e-06\n",
      "Average loss :  4.3711098629550804e-10\n",
      "expression length:\t 5\n",
      "Result stage 497: -1.739*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999756]*t)\n",
      "\n",
      "\n",
      "Stage  496\n",
      "Epoch 50/200\n",
      "Learning rate :  7.012927832585425e-06\n",
      "Average loss :  3.836776452104118e-10\n",
      "\n",
      "\n",
      "Stage  496\n",
      "Epoch 100/200\n",
      "Learning rate :  7.012927832585425e-06\n",
      "Average loss :  5.391038726543229e-10\n",
      "\n",
      "\n",
      "Stage  496\n",
      "Epoch 150/200\n",
      "Learning rate :  7.012927832585425e-06\n",
      "Average loss :  3.328316511286289e-10\n",
      "\n",
      "\n",
      "Stage  496\n",
      "Epoch 200/200\n",
      "Learning rate :  7.012927832585425e-06\n",
      "Average loss :  5.002039893398091e-10\n",
      "expression length:\t 5\n",
      "Result stage 498: -1.739*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.1399976]*t)\n",
      "\n",
      "\n",
      "Stage  497\n",
      "Epoch 50/200\n",
      "Learning rate :  6.943148034746115e-06\n",
      "Average loss :  3.5412259236089483e-10\n",
      "\n",
      "\n",
      "Stage  497\n",
      "Epoch 100/200\n",
      "Learning rate :  6.943148034746115e-06\n",
      "Average loss :  3.382348845448746e-10\n",
      "\n",
      "\n",
      "Stage  497\n",
      "Epoch 150/200\n",
      "Learning rate :  6.943148034746115e-06\n",
      "Average loss :  3.295378692147466e-10\n",
      "\n",
      "\n",
      "Stage  497\n",
      "Epoch 200/200\n",
      "Learning rate :  6.943148034746115e-06\n",
      "Average loss :  7.268238233493207e-10\n",
      "expression length:\t 5\n",
      "Result stage 499: -1.739*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999717]*t)\n",
      "\n",
      "\n",
      "Stage  498\n",
      "Epoch 50/200\n",
      "Learning rate :  6.874062557496248e-06\n",
      "Average loss :  3.9437189625068925e-10\n",
      "\n",
      "\n",
      "Stage  498\n",
      "Epoch 100/200\n",
      "Learning rate :  6.874062557496248e-06\n",
      "Average loss :  3.194579878407211e-10\n",
      "\n",
      "\n",
      "Stage  498\n",
      "Epoch 150/200\n",
      "Learning rate :  6.874062557496248e-06\n",
      "Average loss :  3.3283534262018577e-10\n",
      "\n",
      "\n",
      "Stage  498\n",
      "Epoch 200/200\n",
      "Learning rate :  6.874062557496248e-06\n",
      "Average loss :  9.140441736832372e-10\n",
      "expression length:\t 5\n",
      "Result stage 500: -1.739*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999839]*t)\n",
      "\n",
      "\n",
      "Stage  499\n",
      "Epoch 50/200\n",
      "Learning rate :  6.805664492230543e-06\n",
      "Average loss :  3.242317803131556e-10\n",
      "\n",
      "\n",
      "Stage  499\n",
      "Epoch 100/200\n",
      "Learning rate :  6.805664492230543e-06\n",
      "Average loss :  5.976351635794686e-10\n",
      "\n",
      "\n",
      "Stage  499\n",
      "Epoch 150/200\n",
      "Learning rate :  6.805664492230543e-06\n",
      "Average loss :  3.1016830770447257e-10\n",
      "\n",
      "\n",
      "Stage  499\n",
      "Epoch 200/200\n",
      "Learning rate :  6.805664492230543e-06\n",
      "Average loss :  3.071096987827815e-10\n",
      "expression length:\t 5\n",
      "Result stage 501: -1.739*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999681]*t)\n",
      "\n",
      "\n",
      "Stage  500\n",
      "Epoch 50/200\n",
      "Learning rate :  6.7379469990854676e-06\n",
      "Average loss :  3.640731327525515e-10\n",
      "\n",
      "\n",
      "Stage  500\n",
      "Epoch 100/200\n",
      "Learning rate :  6.7379469990854676e-06\n",
      "Average loss :  3.2683539208377965e-10\n",
      "\n",
      "\n",
      "Stage  500\n",
      "Epoch 150/200\n",
      "Learning rate :  6.7379469990854676e-06\n",
      "Average loss :  6.332310786838491e-10\n",
      "\n",
      "\n",
      "Stage  500\n",
      "Epoch 200/200\n",
      "Learning rate :  6.7379469990854676e-06\n",
      "Average loss :  3.4436226092893207e-10\n",
      "expression length:\t 5\n",
      "Result stage 502: -1.739*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999738]*t)\n",
      "\n",
      "\n",
      "Stage  501\n",
      "Epoch 50/200\n",
      "Learning rate :  6.670903306255274e-06\n",
      "Average loss :  2.9898070130762733e-10\n",
      "\n",
      "\n",
      "Stage  501\n",
      "Epoch 100/200\n",
      "Learning rate :  6.670903306255274e-06\n",
      "Average loss :  2.9205982077229464e-10\n",
      "\n",
      "\n",
      "Stage  501\n",
      "Epoch 150/200\n",
      "Learning rate :  6.670903306255274e-06\n",
      "Average loss :  2.953317035370162e-10\n",
      "\n",
      "\n",
      "Stage  501\n",
      "Epoch 200/200\n",
      "Learning rate :  6.670903306255274e-06\n",
      "Average loss :  2.945337862492181e-10\n",
      "expression length:\t 5\n",
      "Result stage 503: -1.739*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.1399968]*t)\n",
      "\n",
      "\n",
      "Stage  502\n",
      "Epoch 50/200\n",
      "Learning rate :  6.604526709314805e-06\n",
      "Average loss :  3.761293221327122e-10\n",
      "\n",
      "\n",
      "Stage  502\n",
      "Epoch 100/200\n",
      "Learning rate :  6.604526709314805e-06\n",
      "Average loss :  4.223073002407318e-10\n",
      "\n",
      "\n",
      "Stage  502\n",
      "Epoch 150/200\n",
      "Learning rate :  6.604526709314805e-06\n",
      "Average loss :  3.1462987770680684e-10\n",
      "\n",
      "\n",
      "Stage  502\n",
      "Epoch 200/200\n",
      "Learning rate :  6.604526709314805e-06\n",
      "Average loss :  5.835106287044312e-10\n",
      "expression length:\t 5\n",
      "Result stage 504: -1.739*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999704]*t)\n",
      "\n",
      "\n",
      "Stage  503\n",
      "Epoch 50/200\n",
      "Learning rate :  6.538810570549064e-06\n",
      "Average loss :  3.3823796541376794e-10\n",
      "\n",
      "\n",
      "Stage  503\n",
      "Epoch 100/200\n",
      "Learning rate :  6.538810570549064e-06\n",
      "Average loss :  3.4143374239015145e-10\n",
      "\n",
      "\n",
      "Stage  503\n",
      "Epoch 150/200\n",
      "Learning rate :  6.538810570549064e-06\n",
      "Average loss :  3.3227465223717445e-10\n",
      "\n",
      "\n",
      "Stage  503\n",
      "Epoch 200/200\n",
      "Learning rate :  6.538810570549064e-06\n",
      "Average loss :  5.814402848081102e-10\n",
      "expression length:\t 5\n",
      "Result stage 505: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999687]*t)\n",
      "\n",
      "\n",
      "Stage  504\n",
      "Epoch 50/200\n",
      "Learning rate :  6.4737483182894054e-06\n",
      "Average loss :  2.916301367061891e-10\n",
      "\n",
      "\n",
      "Stage  504\n",
      "Epoch 100/200\n",
      "Learning rate :  6.4737483182894054e-06\n",
      "Average loss :  2.2497310958602412e-10\n",
      "\n",
      "\n",
      "Stage  504\n",
      "Epoch 150/200\n",
      "Learning rate :  6.4737483182894054e-06\n",
      "Average loss :  3.6271169401302927e-10\n",
      "\n",
      "\n",
      "Stage  504\n",
      "Epoch 200/200\n",
      "Learning rate :  6.4737483182894054e-06\n",
      "Average loss :  2.7332325291951065e-10\n",
      "expression length:\t 5\n",
      "Result stage 506: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999714]*t)\n",
      "\n",
      "\n",
      "Stage  505\n",
      "Epoch 50/200\n",
      "Learning rate :  6.4093334462563835e-06\n",
      "Average loss :  4.080083493285258e-10\n",
      "\n",
      "\n",
      "Stage  505\n",
      "Epoch 100/200\n",
      "Learning rate :  6.4093334462563835e-06\n",
      "Average loss :  2.0756513174902125e-10\n",
      "\n",
      "\n",
      "Stage  505\n",
      "Epoch 150/200\n",
      "Learning rate :  6.4093334462563835e-06\n",
      "Average loss :  3.233697476456854e-10\n",
      "\n",
      "\n",
      "Stage  505\n",
      "Epoch 200/200\n",
      "Learning rate :  6.4093334462563835e-06\n",
      "Average loss :  3.687496419324532e-10\n",
      "expression length:\t 5\n",
      "Result stage 507: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999687]*t)\n",
      "\n",
      "\n",
      "Stage  506\n",
      "Epoch 50/200\n",
      "Learning rate :  6.34555951290911e-06\n",
      "Average loss :  4.110156381909036e-10\n",
      "\n",
      "\n",
      "Stage  506\n",
      "Epoch 100/200\n",
      "Learning rate :  6.34555951290911e-06\n",
      "Average loss :  5.154463522671904e-10\n",
      "\n",
      "\n",
      "Stage  506\n",
      "Epoch 150/200\n",
      "Learning rate :  6.34555951290911e-06\n",
      "Average loss :  3.385922375809258e-10\n",
      "\n",
      "\n",
      "Stage  506\n",
      "Epoch 200/200\n",
      "Learning rate :  6.34555951290911e-06\n",
      "Average loss :  2.6282534482113817e-10\n",
      "expression length:\t 5\n",
      "Result stage 508: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999686]*t)\n",
      "\n",
      "\n",
      "Stage  507\n",
      "Epoch 50/200\n",
      "Learning rate :  6.282420140801118e-06\n",
      "Average loss :  6.988978284994118e-10\n",
      "\n",
      "\n",
      "Stage  507\n",
      "Epoch 100/200\n",
      "Learning rate :  6.282420140801118e-06\n",
      "Average loss :  2.6032070943315944e-10\n",
      "\n",
      "\n",
      "Stage  507\n",
      "Epoch 150/200\n",
      "Learning rate :  6.282420140801118e-06\n",
      "Average loss :  5.581946571631136e-10\n",
      "\n",
      "\n",
      "Stage  507\n",
      "Epoch 200/200\n",
      "Learning rate :  6.282420140801118e-06\n",
      "Average loss :  2.5867374908727925e-10\n",
      "expression length:\t 5\n",
      "Result stage 509: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.139997]*t)\n",
      "\n",
      "\n",
      "Stage  508\n",
      "Epoch 50/200\n",
      "Learning rate :  6.219909015942573e-06\n",
      "Average loss :  6.754420356358537e-10\n",
      "\n",
      "\n",
      "Stage  508\n",
      "Epoch 100/200\n",
      "Learning rate :  6.219909015942573e-06\n",
      "Average loss :  4.3376216507517995e-10\n",
      "\n",
      "\n",
      "Stage  508\n",
      "Epoch 150/200\n",
      "Learning rate :  6.219909015942573e-06\n",
      "Average loss :  3.9772357629530575e-10\n",
      "\n",
      "\n",
      "Stage  508\n",
      "Epoch 200/200\n",
      "Learning rate :  6.219909015942573e-06\n",
      "Average loss :  5.808380998395535e-10\n",
      "expression length:\t 5\n",
      "Result stage 510: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999723]*t)\n",
      "\n",
      "\n",
      "Stage  509\n",
      "Epoch 50/200\n",
      "Learning rate :  6.1580198871688975e-06\n",
      "Average loss :  7.420595804497054e-10\n",
      "\n",
      "\n",
      "Stage  509\n",
      "Epoch 100/200\n",
      "Learning rate :  6.1580198871688975e-06\n",
      "Average loss :  5.835513738894349e-10\n",
      "\n",
      "\n",
      "Stage  509\n",
      "Epoch 150/200\n",
      "Learning rate :  6.1580198871688975e-06\n",
      "Average loss :  2.4626015115991606e-10\n",
      "\n",
      "\n",
      "Stage  509\n",
      "Epoch 200/200\n",
      "Learning rate :  6.1580198871688975e-06\n",
      "Average loss :  2.7590593698612054e-10\n",
      "expression length:\t 5\n",
      "Result stage 511: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999814]*t)\n",
      "\n",
      "\n",
      "Stage  510\n",
      "Epoch 50/200\n",
      "Learning rate :  6.096746565515633e-06\n",
      "Average loss :  2.4880789095682587e-10\n",
      "\n",
      "\n",
      "Stage  510\n",
      "Epoch 100/200\n",
      "Learning rate :  6.096746565515633e-06\n",
      "Average loss :  5.587465490286547e-10\n",
      "\n",
      "\n",
      "Stage  510\n",
      "Epoch 150/200\n",
      "Learning rate :  6.096746565515633e-06\n",
      "Average loss :  3.0145314022789194e-10\n",
      "\n",
      "\n",
      "Stage  510\n",
      "Epoch 200/200\n",
      "Learning rate :  6.096746565515633e-06\n",
      "Average loss :  3.608090493045779e-10\n",
      "expression length:\t 5\n",
      "Result stage 512: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999687]*t)\n",
      "\n",
      "\n",
      "Stage  511\n",
      "Epoch 50/200\n",
      "Learning rate :  6.036082923599565e-06\n",
      "Average loss :  4.5460743502978573e-10\n",
      "\n",
      "\n",
      "Stage  511\n",
      "Epoch 100/200\n",
      "Learning rate :  6.036082923599565e-06\n",
      "Average loss :  3.9835085230421896e-10\n",
      "\n",
      "\n",
      "Stage  511\n",
      "Epoch 150/200\n",
      "Learning rate :  6.036082923599565e-06\n",
      "Average loss :  2.548699862270354e-10\n",
      "\n",
      "\n",
      "Stage  511\n",
      "Epoch 200/200\n",
      "Learning rate :  6.036082923599565e-06\n",
      "Average loss :  3.1553737400713544e-10\n",
      "expression length:\t 5\n",
      "Result stage 513: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999715]*t)\n",
      "\n",
      "\n",
      "Stage  512\n",
      "Epoch 50/200\n",
      "Learning rate :  5.9760228950059426e-06\n",
      "Average loss :  1.3380171970389654e-10\n",
      "\n",
      "\n",
      "Stage  512\n",
      "Epoch 100/200\n",
      "Learning rate :  5.9760228950059426e-06\n",
      "Average loss :  2.5457883023882744e-10\n",
      "\n",
      "\n",
      "Stage  512\n",
      "Epoch 150/200\n",
      "Learning rate :  5.9760228950059426e-06\n",
      "Average loss :  2.653488262449599e-10\n",
      "\n",
      "\n",
      "Stage  512\n",
      "Epoch 200/200\n",
      "Learning rate :  5.9760228950059426e-06\n",
      "Average loss :  4.2953496315334405e-10\n",
      "expression length:\t 5\n",
      "Result stage 514: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399975]*t)\n",
      "\n",
      "\n",
      "Stage  513\n",
      "Epoch 50/200\n",
      "Learning rate :  5.916560473681858e-06\n",
      "Average loss :  2.575603064158827e-10\n",
      "\n",
      "\n",
      "Stage  513\n",
      "Epoch 100/200\n",
      "Learning rate :  5.916560473681858e-06\n",
      "Average loss :  3.069088594376268e-10\n",
      "\n",
      "\n",
      "Stage  513\n",
      "Epoch 150/200\n",
      "Learning rate :  5.916560473681858e-06\n",
      "Average loss :  2.369995311113371e-10\n",
      "\n",
      "\n",
      "Stage  513\n",
      "Epoch 200/200\n",
      "Learning rate :  5.916560473681858e-06\n",
      "Average loss :  5.17171194758248e-10\n",
      "expression length:\t 5\n",
      "Result stage 515: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999751]*t)\n",
      "\n",
      "\n",
      "Stage  514\n",
      "Epoch 50/200\n",
      "Learning rate :  5.8576897133356225e-06\n",
      "Average loss :  2.3245164126883822e-10\n",
      "\n",
      "\n",
      "Stage  514\n",
      "Epoch 100/200\n",
      "Learning rate :  5.8576897133356225e-06\n",
      "Average loss :  2.1812630868200955e-10\n",
      "\n",
      "\n",
      "Stage  514\n",
      "Epoch 150/200\n",
      "Learning rate :  5.8576897133356225e-06\n",
      "Average loss :  5.572534100828364e-10\n",
      "\n",
      "\n",
      "Stage  514\n",
      "Epoch 200/200\n",
      "Learning rate :  5.8576897133356225e-06\n",
      "Average loss :  2.288520345450351e-10\n",
      "expression length:\t 5\n",
      "Result stage 516: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999766]*t)\n",
      "\n",
      "\n",
      "Stage  515\n",
      "Epoch 50/200\n",
      "Learning rate :  5.799404726842142e-06\n",
      "Average loss :  3.256205582946592e-10\n",
      "\n",
      "\n",
      "Stage  515\n",
      "Epoch 100/200\n",
      "Learning rate :  5.799404726842142e-06\n",
      "Average loss :  2.1800430904939105e-10\n",
      "\n",
      "\n",
      "Stage  515\n",
      "Epoch 150/200\n",
      "Learning rate :  5.799404726842142e-06\n",
      "Average loss :  2.4718765923026353e-10\n",
      "\n",
      "\n",
      "Stage  515\n",
      "Epoch 200/200\n",
      "Learning rate :  5.799404726842142e-06\n",
      "Average loss :  2.9440544446757144e-10\n",
      "expression length:\t 5\n",
      "Result stage 517: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999802]*t)\n",
      "\n",
      "\n",
      "Stage  516\n",
      "Epoch 50/200\n",
      "Learning rate :  5.7416996856542025e-06\n",
      "Average loss :  2.378493235699608e-10\n",
      "\n",
      "\n",
      "Stage  516\n",
      "Epoch 100/200\n",
      "Learning rate :  5.7416996856542025e-06\n",
      "Average loss :  2.718109626265175e-10\n",
      "\n",
      "\n",
      "Stage  516\n",
      "Epoch 150/200\n",
      "Learning rate :  5.7416996856542025e-06\n",
      "Average loss :  3.464401265862449e-10\n",
      "\n",
      "\n",
      "Stage  516\n",
      "Epoch 200/200\n",
      "Learning rate :  5.7416996856542025e-06\n",
      "Average loss :  2.3872684384862453e-10\n",
      "expression length:\t 5\n",
      "Result stage 518: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999765]*t)\n",
      "\n",
      "\n",
      "Stage  517\n",
      "Epoch 50/200\n",
      "Learning rate :  5.684568819219595e-06\n",
      "Average loss :  2.428748313576534e-10\n",
      "\n",
      "\n",
      "Stage  517\n",
      "Epoch 100/200\n",
      "Learning rate :  5.684568819219595e-06\n",
      "Average loss :  2.3317470176920096e-10\n",
      "\n",
      "\n",
      "Stage  517\n",
      "Epoch 150/200\n",
      "Learning rate :  5.684568819219595e-06\n",
      "Average loss :  4.342518844513421e-10\n",
      "\n",
      "\n",
      "Stage  517\n",
      "Epoch 200/200\n",
      "Learning rate :  5.684568819219595e-06\n",
      "Average loss :  2.178504043826024e-10\n",
      "expression length:\t 5\n",
      "Result stage 519: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999753]*t)\n",
      "\n",
      "\n",
      "Stage  518\n",
      "Epoch 50/200\n",
      "Learning rate :  5.628006414404065e-06\n",
      "Average loss :  3.0481386859015913e-10\n",
      "\n",
      "\n",
      "Stage  518\n",
      "Epoch 100/200\n",
      "Learning rate :  5.628006414404065e-06\n",
      "Average loss :  1.833039692256122e-10\n",
      "\n",
      "\n",
      "Stage  518\n",
      "Epoch 150/200\n",
      "Learning rate :  5.628006414404065e-06\n",
      "Average loss :  2.3890783795721404e-10\n",
      "\n",
      "\n",
      "Stage  518\n",
      "Epoch 200/200\n",
      "Learning rate :  5.628006414404065e-06\n",
      "Average loss :  2.290507367108674e-10\n",
      "expression length:\t 5\n",
      "Result stage 520: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999858]*t)\n",
      "\n",
      "\n",
      "Stage  519\n",
      "Epoch 50/200\n",
      "Learning rate :  5.572006814919993e-06\n",
      "Average loss :  4.732932379347687e-10\n",
      "\n",
      "\n",
      "Stage  519\n",
      "Epoch 100/200\n",
      "Learning rate :  5.572006814919993e-06\n",
      "Average loss :  2.3573376584096195e-10\n",
      "\n",
      "\n",
      "Stage  519\n",
      "Epoch 150/200\n",
      "Learning rate :  5.572006814919993e-06\n",
      "Average loss :  2.1565441099546945e-10\n",
      "\n",
      "\n",
      "Stage  519\n",
      "Epoch 200/200\n",
      "Learning rate :  5.572006814919993e-06\n",
      "Average loss :  3.2031563512724404e-10\n",
      "expression length:\t 5\n",
      "Result stage 521: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999705]*t)\n",
      "\n",
      "\n",
      "Stage  520\n",
      "Epoch 50/200\n",
      "Learning rate :  5.516564420760772e-06\n",
      "Average loss :  2.993875147794256e-10\n",
      "\n",
      "\n",
      "Stage  520\n",
      "Epoch 100/200\n",
      "Learning rate :  5.516564420760772e-06\n",
      "Average loss :  2.3216130407011093e-10\n",
      "\n",
      "\n",
      "Stage  520\n",
      "Epoch 150/200\n",
      "Learning rate :  5.516564420760772e-06\n",
      "Average loss :  1.1808877486974012e-10\n",
      "\n",
      "\n",
      "Stage  520\n",
      "Epoch 200/200\n",
      "Learning rate :  5.516564420760772e-06\n",
      "Average loss :  2.6688767862381724e-10\n",
      "expression length:\t 5\n",
      "Result stage 522: -1.739*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999735]*t)\n",
      "\n",
      "\n",
      "Stage  521\n",
      "Epoch 50/200\n",
      "Learning rate :  5.461673687640779e-06\n",
      "Average loss :  3.619675947863499e-10\n",
      "\n",
      "\n",
      "Stage  521\n",
      "Epoch 100/200\n",
      "Learning rate :  5.461673687640779e-06\n",
      "Average loss :  2.283655903267956e-10\n",
      "\n",
      "\n",
      "Stage  521\n",
      "Epoch 150/200\n",
      "Learning rate :  5.461673687640779e-06\n",
      "Average loss :  1.9063205181080178e-10\n",
      "\n",
      "\n",
      "Stage  521\n",
      "Epoch 200/200\n",
      "Learning rate :  5.461673687640779e-06\n",
      "Average loss :  1.970117124994175e-10\n",
      "expression length:\t 5\n",
      "Result stage 523: -1.739*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999741]*t)\n",
      "\n",
      "\n",
      "Stage  522\n",
      "Epoch 50/200\n",
      "Learning rate :  5.40732912644096e-06\n",
      "Average loss :  2.4517257668499326e-10\n",
      "\n",
      "\n",
      "Stage  522\n",
      "Epoch 100/200\n",
      "Learning rate :  5.40732912644096e-06\n",
      "Average loss :  2.8982324873361165e-10\n",
      "\n",
      "\n",
      "Stage  522\n",
      "Epoch 150/200\n",
      "Learning rate :  5.40732912644096e-06\n",
      "Average loss :  1.9461565692324712e-10\n",
      "\n",
      "\n",
      "Stage  522\n",
      "Epoch 200/200\n",
      "Learning rate :  5.40732912644096e-06\n",
      "Average loss :  2.6384128215539704e-10\n",
      "expression length:\t 5\n",
      "Result stage 524: -1.739*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999817]*t)\n",
      "\n",
      "\n",
      "Stage  523\n",
      "Epoch 50/200\n",
      "Learning rate :  5.353525302659903e-06\n",
      "Average loss :  2.4913268670267996e-10\n",
      "\n",
      "\n",
      "Stage  523\n",
      "Epoch 100/200\n",
      "Learning rate :  5.353525302659903e-06\n",
      "Average loss :  1.8675995472339224e-10\n",
      "\n",
      "\n",
      "Stage  523\n",
      "Epoch 150/200\n",
      "Learning rate :  5.353525302659903e-06\n",
      "Average loss :  2.0019576274510342e-10\n",
      "\n",
      "\n",
      "Stage  523\n",
      "Epoch 200/200\n",
      "Learning rate :  5.353525302659903e-06\n",
      "Average loss :  2.097406970325011e-10\n",
      "expression length:\t 5\n",
      "Result stage 525: -1.739*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999864]*t)\n",
      "\n",
      "\n",
      "Stage  524\n",
      "Epoch 50/200\n",
      "Learning rate :  5.300256835870402e-06\n",
      "Average loss :  2.2103584240706908e-10\n",
      "\n",
      "\n",
      "Stage  524\n",
      "Epoch 100/200\n",
      "Learning rate :  5.300256835870402e-06\n",
      "Average loss :  4.303090106461127e-10\n",
      "\n",
      "\n",
      "Stage  524\n",
      "Epoch 150/200\n",
      "Learning rate :  5.300256835870402e-06\n",
      "Average loss :  2.56759613570523e-10\n",
      "\n",
      "\n",
      "Stage  524\n",
      "Epoch 200/200\n",
      "Learning rate :  5.300256835870402e-06\n",
      "Average loss :  2.2243214214956453e-10\n",
      "expression length:\t 5\n",
      "Result stage 526: -1.739*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999791]*t)\n",
      "\n",
      "\n",
      "Stage  525\n",
      "Epoch 50/200\n",
      "Learning rate :  5.247518399181385e-06\n",
      "Average loss :  5.593713270357625e-10\n",
      "\n",
      "\n",
      "Stage  525\n",
      "Epoch 100/200\n",
      "Learning rate :  5.247518399181385e-06\n",
      "Average loss :  1.6115794809756778e-10\n",
      "\n",
      "\n",
      "Stage  525\n",
      "Epoch 150/200\n",
      "Learning rate :  5.247518399181385e-06\n",
      "Average loss :  1.9075482859953752e-10\n",
      "\n",
      "\n",
      "Stage  525\n",
      "Epoch 200/200\n",
      "Learning rate :  5.247518399181385e-06\n",
      "Average loss :  2.0389037680423883e-10\n",
      "expression length:\t 5\n",
      "Result stage 527: -1.739*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.139999]*t)\n",
      "\n",
      "\n",
      "Stage  526\n",
      "Epoch 50/200\n",
      "Learning rate :  5.195304718705232e-06\n",
      "Average loss :  1.9239138060456185e-10\n",
      "\n",
      "\n",
      "Stage  526\n",
      "Epoch 100/200\n",
      "Learning rate :  5.195304718705232e-06\n",
      "Average loss :  3.05203307071622e-10\n",
      "\n",
      "\n",
      "Stage  526\n",
      "Epoch 150/200\n",
      "Learning rate :  5.195304718705232e-06\n",
      "Average loss :  2.509791263705097e-10\n",
      "\n",
      "\n",
      "Stage  526\n",
      "Epoch 200/200\n",
      "Learning rate :  5.195304718705232e-06\n",
      "Average loss :  1.744888677990275e-10\n",
      "expression length:\t 5\n",
      "Result stage 528: -1.739*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.1399976]*t)\n",
      "\n",
      "\n",
      "Stage  527\n",
      "Epoch 50/200\n",
      "Learning rate :  5.143610573030379e-06\n",
      "Average loss :  2.0164656056032015e-10\n",
      "\n",
      "\n",
      "Stage  527\n",
      "Epoch 100/200\n",
      "Learning rate :  5.143610573030379e-06\n",
      "Average loss :  2.679554911289017e-10\n",
      "\n",
      "\n",
      "Stage  527\n",
      "Epoch 150/200\n",
      "Learning rate :  5.143610573030379e-06\n",
      "Average loss :  2.8943644703183224e-10\n",
      "\n",
      "\n",
      "Stage  527\n",
      "Epoch 200/200\n",
      "Learning rate :  5.143610573030379e-06\n",
      "Average loss :  4.350113880224882e-10\n",
      "expression length:\t 5\n",
      "Result stage 529: -1.739*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999842]*t)\n",
      "\n",
      "\n",
      "Stage  528\n",
      "Epoch 50/200\n",
      "Learning rate :  5.092430792699191e-06\n",
      "Average loss :  1.740026039920295e-10\n",
      "\n",
      "\n",
      "Stage  528\n",
      "Epoch 100/200\n",
      "Learning rate :  5.092430792699191e-06\n",
      "Average loss :  3.3767166840448226e-10\n",
      "\n",
      "\n",
      "Stage  528\n",
      "Epoch 150/200\n",
      "Learning rate :  5.092430792699191e-06\n",
      "Average loss :  1.742766209122948e-10\n",
      "\n",
      "\n",
      "Stage  528\n",
      "Epoch 200/200\n",
      "Learning rate :  5.092430792699191e-06\n",
      "Average loss :  4.433301226125508e-10\n",
      "expression length:\t 5\n",
      "Result stage 530: -1.738*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999827]*t)\n",
      "\n",
      "\n",
      "Stage  529\n",
      "Epoch 50/200\n",
      "Learning rate :  5.041760259690979e-06\n",
      "Average loss :  1.8234150300777685e-10\n",
      "\n",
      "\n",
      "Stage  529\n",
      "Epoch 100/200\n",
      "Learning rate :  5.041760259690979e-06\n",
      "Average loss :  7.876900520731311e-11\n",
      "\n",
      "\n",
      "Stage  529\n",
      "Epoch 150/200\n",
      "Learning rate :  5.041760259690979e-06\n",
      "Average loss :  1.7505140392781726e-10\n",
      "\n",
      "\n",
      "Stage  529\n",
      "Epoch 200/200\n",
      "Learning rate :  5.041760259690979e-06\n",
      "Average loss :  1.626884738037404e-10\n",
      "expression length:\t 5\n",
      "Result stage 531: -1.739*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999788]*t)\n",
      "\n",
      "\n",
      "Stage  530\n",
      "Epoch 50/200\n",
      "Learning rate :  4.991593906910217e-06\n",
      "Average loss :  2.761426365349706e-10\n",
      "\n",
      "\n",
      "Stage  530\n",
      "Epoch 100/200\n",
      "Learning rate :  4.991593906910217e-06\n",
      "Average loss :  2.9365393450220267e-10\n",
      "\n",
      "\n",
      "Stage  530\n",
      "Epoch 150/200\n",
      "Learning rate :  4.991593906910217e-06\n",
      "Average loss :  1.9673421225441245e-10\n",
      "\n",
      "\n",
      "Stage  530\n",
      "Epoch 200/200\n",
      "Learning rate :  4.991593906910217e-06\n",
      "Average loss :  1.7958708131704526e-10\n",
      "expression length:\t 5\n",
      "Result stage 532: -1.738*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999802]*t)\n",
      "\n",
      "\n",
      "Stage  531\n",
      "Epoch 50/200\n",
      "Learning rate :  4.941926717679818e-06\n",
      "Average loss :  1.9062949829784515e-10\n",
      "\n",
      "\n",
      "Stage  531\n",
      "Epoch 100/200\n",
      "Learning rate :  4.941926717679818e-06\n",
      "Average loss :  1.6081531939438065e-10\n",
      "\n",
      "\n",
      "Stage  531\n",
      "Epoch 150/200\n",
      "Learning rate :  4.941926717679818e-06\n",
      "Average loss :  1.6002793534752868e-10\n",
      "\n",
      "\n",
      "Stage  531\n",
      "Epoch 200/200\n",
      "Learning rate :  4.941926717679818e-06\n",
      "Average loss :  2.170523344391384e-10\n",
      "expression length:\t 5\n",
      "Result stage 533: -1.738*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.1399975]*t)\n",
      "\n",
      "\n",
      "Stage  532\n",
      "Epoch 50/200\n",
      "Learning rate :  4.892753725239476e-06\n",
      "Average loss :  2.6336893776957027e-10\n",
      "\n",
      "\n",
      "Stage  532\n",
      "Epoch 100/200\n",
      "Learning rate :  4.892753725239476e-06\n",
      "Average loss :  1.7088115644714463e-10\n",
      "\n",
      "\n",
      "Stage  532\n",
      "Epoch 150/200\n",
      "Learning rate :  4.892753725239476e-06\n",
      "Average loss :  1.7147579189913387e-10\n",
      "\n",
      "\n",
      "Stage  532\n",
      "Epoch 200/200\n",
      "Learning rate :  4.892753725239476e-06\n",
      "Average loss :  1.6167275851408647e-10\n",
      "expression length:\t 5\n",
      "Result stage 534: -1.738*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999787]*t)\n",
      "\n",
      "\n",
      "Stage  533\n",
      "Epoch 50/200\n",
      "Learning rate :  4.8440700122489675e-06\n",
      "Average loss :  1.726291193326901e-10\n",
      "\n",
      "\n",
      "Stage  533\n",
      "Epoch 100/200\n",
      "Learning rate :  4.8440700122489675e-06\n",
      "Average loss :  1.5663804975307727e-10\n",
      "\n",
      "\n",
      "Stage  533\n",
      "Epoch 150/200\n",
      "Learning rate :  4.8440700122489675e-06\n",
      "Average loss :  2.1246328307800155e-10\n",
      "\n",
      "\n",
      "Stage  533\n",
      "Epoch 200/200\n",
      "Learning rate :  4.8440700122489675e-06\n",
      "Average loss :  6.230208710045204e-11\n",
      "expression length:\t 5\n",
      "Result stage 535: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999973]*t)\n",
      "\n",
      "\n",
      "Stage  534\n",
      "Epoch 50/200\n",
      "Learning rate :  4.795870710296422e-06\n",
      "Average loss :  1.8361914766451548e-10\n",
      "\n",
      "\n",
      "Stage  534\n",
      "Epoch 100/200\n",
      "Learning rate :  4.795870710296422e-06\n",
      "Average loss :  1.6445082795524257e-10\n",
      "\n",
      "\n",
      "Stage  534\n",
      "Epoch 150/200\n",
      "Learning rate :  4.795870710296422e-06\n",
      "Average loss :  1.7189914769399905e-10\n",
      "\n",
      "\n",
      "Stage  534\n",
      "Epoch 200/200\n",
      "Learning rate :  4.795870710296422e-06\n",
      "Average loss :  1.4894104005680475e-10\n",
      "expression length:\t 5\n",
      "Result stage 536: -1.738*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999777]*t)\n",
      "\n",
      "\n",
      "Stage  535\n",
      "Epoch 50/200\n",
      "Learning rate :  4.748150999411474e-06\n",
      "Average loss :  1.7892305692601695e-10\n",
      "\n",
      "\n",
      "Stage  535\n",
      "Epoch 100/200\n",
      "Learning rate :  4.748150999411474e-06\n",
      "Average loss :  2.562797474237044e-10\n",
      "\n",
      "\n",
      "Stage  535\n",
      "Epoch 150/200\n",
      "Learning rate :  4.748150999411474e-06\n",
      "Average loss :  2.3226662260178443e-10\n",
      "\n",
      "\n",
      "Stage  535\n",
      "Epoch 200/200\n",
      "Learning rate :  4.748150999411474e-06\n",
      "Average loss :  1.5034785916245852e-10\n",
      "expression length:\t 5\n",
      "Result stage 537: -1.738*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999775]*t)\n",
      "\n",
      "\n",
      "Stage  536\n",
      "Epoch 50/200\n",
      "Learning rate :  4.700906107583276e-06\n",
      "Average loss :  1.3049356040184534e-10\n",
      "\n",
      "\n",
      "Stage  536\n",
      "Epoch 100/200\n",
      "Learning rate :  4.700906107583276e-06\n",
      "Average loss :  1.7151211006982692e-10\n",
      "\n",
      "\n",
      "Stage  536\n",
      "Epoch 150/200\n",
      "Learning rate :  4.700906107583276e-06\n",
      "Average loss :  1.5401287190019985e-10\n",
      "\n",
      "\n",
      "Stage  536\n",
      "Epoch 200/200\n",
      "Learning rate :  4.700906107583276e-06\n",
      "Average loss :  2.7319499440459083e-10\n",
      "expression length:\t 5\n",
      "Result stage 538: -1.738*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999757]*t)\n",
      "\n",
      "\n",
      "Stage  537\n",
      "Epoch 50/200\n",
      "Learning rate :  4.654131310283272e-06\n",
      "Average loss :  2.6587737567140834e-10\n",
      "\n",
      "\n",
      "Stage  537\n",
      "Epoch 100/200\n",
      "Learning rate :  4.654131310283272e-06\n",
      "Average loss :  2.256546616230537e-10\n",
      "\n",
      "\n",
      "Stage  537\n",
      "Epoch 150/200\n",
      "Learning rate :  4.654131310283272e-06\n",
      "Average loss :  2.9258886979910415e-10\n",
      "\n",
      "\n",
      "Stage  537\n",
      "Epoch 200/200\n",
      "Learning rate :  4.654131310283272e-06\n",
      "Average loss :  1.8372924015519487e-10\n",
      "expression length:\t 5\n",
      "Result stage 539: -1.738*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999799]*t)\n",
      "\n",
      "\n",
      "Stage  538\n",
      "Epoch 50/200\n",
      "Learning rate :  4.607821929992752e-06\n",
      "Average loss :  1.7649397221486396e-10\n",
      "\n",
      "\n",
      "Stage  538\n",
      "Epoch 100/200\n",
      "Learning rate :  4.607821929992752e-06\n",
      "Average loss :  3.4497310563708083e-10\n",
      "\n",
      "\n",
      "Stage  538\n",
      "Epoch 150/200\n",
      "Learning rate :  4.607821929992752e-06\n",
      "Average loss :  2.725848713414081e-10\n",
      "\n",
      "\n",
      "Stage  538\n",
      "Epoch 200/200\n",
      "Learning rate :  4.607821929992752e-06\n",
      "Average loss :  1.539222221902392e-10\n",
      "expression length:\t 5\n",
      "Result stage 540: -1.738*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999903]*t)\n",
      "\n",
      "\n",
      "Stage  539\n",
      "Epoch 50/200\n",
      "Learning rate :  4.561973335735097e-06\n",
      "Average loss :  2.8560348530604074e-10\n",
      "\n",
      "\n",
      "Stage  539\n",
      "Epoch 100/200\n",
      "Learning rate :  4.561973335735097e-06\n",
      "Average loss :  1.3823631128673242e-10\n",
      "\n",
      "\n",
      "Stage  539\n",
      "Epoch 150/200\n",
      "Learning rate :  4.561973335735097e-06\n",
      "Average loss :  2.1893785395743492e-10\n",
      "\n",
      "\n",
      "Stage  539\n",
      "Epoch 200/200\n",
      "Learning rate :  4.561973335735097e-06\n",
      "Average loss :  1.906650948235722e-10\n",
      "expression length:\t 5\n",
      "Result stage 541: -1.738*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.1399985]*t)\n",
      "\n",
      "\n",
      "Stage  540\n",
      "Epoch 50/200\n",
      "Learning rate :  4.516580942612666e-06\n",
      "Average loss :  1.505048308203527e-10\n",
      "\n",
      "\n",
      "Stage  540\n",
      "Epoch 100/200\n",
      "Learning rate :  4.516580942612666e-06\n",
      "Average loss :  1.6575001093865893e-10\n",
      "\n",
      "\n",
      "Stage  540\n",
      "Epoch 150/200\n",
      "Learning rate :  4.516580942612666e-06\n",
      "Average loss :  1.3469383941533408e-10\n",
      "\n",
      "\n",
      "Stage  540\n",
      "Epoch 200/200\n",
      "Learning rate :  4.516580942612666e-06\n",
      "Average loss :  1.9526466554786737e-10\n",
      "expression length:\t 5\n",
      "Result stage 542: -1.738*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.1399977]*t)\n",
      "\n",
      "\n",
      "Stage  541\n",
      "Epoch 50/200\n",
      "Learning rate :  4.471640211348332e-06\n",
      "Average loss :  2.980935775998006e-10\n",
      "\n",
      "\n",
      "Stage  541\n",
      "Epoch 100/200\n",
      "Learning rate :  4.471640211348332e-06\n",
      "Average loss :  1.3628922990172043e-10\n",
      "\n",
      "\n",
      "Stage  541\n",
      "Epoch 150/200\n",
      "Learning rate :  4.471640211348332e-06\n",
      "Average loss :  1.4625248234700905e-10\n",
      "\n",
      "\n",
      "Stage  541\n",
      "Epoch 200/200\n",
      "Learning rate :  4.471640211348332e-06\n",
      "Average loss :  1.5105158790440498e-10\n",
      "expression length:\t 5\n",
      "Result stage 543: -1.738*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999835]*t)\n",
      "\n",
      "\n",
      "Stage  542\n",
      "Epoch 50/200\n",
      "Learning rate :  4.427146647831512e-06\n",
      "Average loss :  1.2923731529390636e-10\n",
      "\n",
      "\n",
      "Stage  542\n",
      "Epoch 100/200\n",
      "Learning rate :  4.427146647831512e-06\n",
      "Average loss :  2.4104854223772065e-10\n",
      "\n",
      "\n",
      "Stage  542\n",
      "Epoch 150/200\n",
      "Learning rate :  4.427146647831512e-06\n",
      "Average loss :  1.4616924337573778e-10\n",
      "\n",
      "\n",
      "Stage  542\n",
      "Epoch 200/200\n",
      "Learning rate :  4.427146647831512e-06\n",
      "Average loss :  1.7696605292272238e-10\n",
      "expression length:\t 5\n",
      "Result stage 544: -1.738*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999854]*t)\n",
      "\n",
      "\n",
      "Stage  543\n",
      "Epoch 50/200\n",
      "Learning rate :  4.383095802668776e-06\n",
      "Average loss :  1.2397755044801784e-10\n",
      "\n",
      "\n",
      "Stage  543\n",
      "Epoch 100/200\n",
      "Learning rate :  4.383095802668776e-06\n",
      "Average loss :  3.7240796557647116e-10\n",
      "\n",
      "\n",
      "Stage  543\n",
      "Epoch 150/200\n",
      "Learning rate :  4.383095802668776e-06\n",
      "Average loss :  2.782754304764268e-10\n",
      "\n",
      "\n",
      "Stage  543\n",
      "Epoch 200/200\n",
      "Learning rate :  4.383095802668776e-06\n",
      "Average loss :  1.3662468378861092e-10\n",
      "expression length:\t 5\n",
      "Result stage 545: -1.738*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999932]*t)\n",
      "\n",
      "\n",
      "Stage  544\n",
      "Epoch 50/200\n",
      "Learning rate :  4.339483270738895e-06\n",
      "Average loss :  1.2707958296775956e-10\n",
      "\n",
      "\n",
      "Stage  544\n",
      "Epoch 100/200\n",
      "Learning rate :  4.339483270738895e-06\n",
      "Average loss :  1.6259305013477388e-10\n",
      "\n",
      "\n",
      "Stage  544\n",
      "Epoch 150/200\n",
      "Learning rate :  4.339483270738895e-06\n",
      "Average loss :  2.600573090205671e-10\n",
      "\n",
      "\n",
      "Stage  544\n",
      "Epoch 200/200\n",
      "Learning rate :  4.339483270738895e-06\n",
      "Average loss :  1.4718272434155466e-10\n",
      "expression length:\t 5\n",
      "Result stage 546: -1.738*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999845]*t)\n",
      "\n",
      "\n",
      "Stage  545\n",
      "Epoch 50/200\n",
      "Learning rate :  4.29630469075234e-06\n",
      "Average loss :  1.228998569580142e-10\n",
      "\n",
      "\n",
      "Stage  545\n",
      "Epoch 100/200\n",
      "Learning rate :  4.29630469075234e-06\n",
      "Average loss :  2.583600555716714e-10\n",
      "\n",
      "\n",
      "Stage  545\n",
      "Epoch 150/200\n",
      "Learning rate :  4.29630469075234e-06\n",
      "Average loss :  1.2283295214299272e-10\n",
      "\n",
      "\n",
      "Stage  545\n",
      "Epoch 200/200\n",
      "Learning rate :  4.29630469075234e-06\n",
      "Average loss :  2.6539806463610205e-10\n",
      "expression length:\t 5\n",
      "Result stage 547: -1.738*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999757]*t)\n",
      "\n",
      "\n",
      "Stage  546\n",
      "Epoch 50/200\n",
      "Learning rate :  4.253555744815126e-06\n",
      "Average loss :  1.167218127706704e-10\n",
      "\n",
      "\n",
      "Stage  546\n",
      "Epoch 100/200\n",
      "Learning rate :  4.253555744815126e-06\n",
      "Average loss :  2.690975775543336e-10\n",
      "\n",
      "\n",
      "Stage  546\n",
      "Epoch 150/200\n",
      "Learning rate :  4.253555744815126e-06\n",
      "Average loss :  1.237158847589015e-10\n",
      "\n",
      "\n",
      "Stage  546\n",
      "Epoch 200/200\n",
      "Learning rate :  4.253555744815126e-06\n",
      "Average loss :  1.36409203377319e-10\n",
      "expression length:\t 5\n",
      "Result stage 548: -1.738*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999873]*t)\n",
      "\n",
      "\n",
      "Stage  547\n",
      "Epoch 50/200\n",
      "Learning rate :  4.211232157997035e-06\n",
      "Average loss :  1.2899646628650174e-10\n",
      "\n",
      "\n",
      "Stage  547\n",
      "Epoch 100/200\n",
      "Learning rate :  4.211232157997035e-06\n",
      "Average loss :  1.2082539135871428e-10\n",
      "\n",
      "\n",
      "Stage  547\n",
      "Epoch 150/200\n",
      "Learning rate :  4.211232157997035e-06\n",
      "Average loss :  1.3195580739200352e-10\n",
      "\n",
      "\n",
      "Stage  547\n",
      "Epoch 200/200\n",
      "Learning rate :  4.211232157997035e-06\n",
      "Average loss :  1.3087290973157195e-10\n",
      "expression length:\t 5\n",
      "Result stage 549: -1.738*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.824*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999845]*t)\n",
      "\n",
      "\n",
      "Stage  548\n",
      "Epoch 50/200\n",
      "Learning rate :  4.169329697904112e-06\n",
      "Average loss :  1.820633088733814e-10\n",
      "\n",
      "\n",
      "Stage  548\n",
      "Epoch 100/200\n",
      "Learning rate :  4.169329697904112e-06\n",
      "Average loss :  9.64306134942916e-11\n",
      "\n",
      "\n",
      "Stage  548\n",
      "Epoch 150/200\n",
      "Learning rate :  4.169329697904112e-06\n",
      "Average loss :  1.1568147134655149e-10\n",
      "\n",
      "\n",
      "Stage  548\n",
      "Epoch 200/200\n",
      "Learning rate :  4.169329697904112e-06\n",
      "Average loss :  2.1027264651696242e-10\n",
      "expression length:\t 5\n",
      "Result stage 550: -1.738*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.824*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999818]*t)\n",
      "\n",
      "\n",
      "Stage  549\n",
      "Epoch 50/200\n",
      "Learning rate :  4.127844174255436e-06\n",
      "Average loss :  2.1151921880679936e-10\n",
      "\n",
      "\n",
      "Stage  549\n",
      "Epoch 100/200\n",
      "Learning rate :  4.127844174255436e-06\n",
      "Average loss :  2.131765597379598e-10\n",
      "\n",
      "\n",
      "Stage  549\n",
      "Epoch 150/200\n",
      "Learning rate :  4.127844174255436e-06\n",
      "Average loss :  1.8869326934289887e-10\n",
      "\n",
      "\n",
      "Stage  549\n",
      "Epoch 200/200\n",
      "Learning rate :  4.127844174255436e-06\n",
      "Average loss :  1.3117174013643762e-10\n",
      "expression length:\t 5\n",
      "Result stage 551: -1.738*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.824*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.1399984]*t)\n",
      "\n",
      "\n",
      "Stage  550\n",
      "Epoch 50/200\n",
      "Learning rate :  4.086771438464067e-06\n",
      "Average loss :  1.214478934086216e-10\n",
      "\n",
      "\n",
      "Stage  550\n",
      "Epoch 100/200\n",
      "Learning rate :  4.086771438464067e-06\n",
      "Average loss :  2.778804686354164e-10\n",
      "\n",
      "\n",
      "Stage  550\n",
      "Epoch 150/200\n",
      "Learning rate :  4.086771438464067e-06\n",
      "Average loss :  2.7105506728020146e-10\n",
      "\n",
      "\n",
      "Stage  550\n",
      "Epoch 200/200\n",
      "Learning rate :  4.086771438464067e-06\n",
      "Average loss :  1.0879269013441828e-10\n",
      "expression length:\t 5\n",
      "Result stage 552: -1.739*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.823*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999818]*t)\n",
      "\n",
      "\n",
      "Stage  551\n",
      "Epoch 50/200\n",
      "Learning rate :  4.046107383222199e-06\n",
      "Average loss :  1.1831866042477657e-10\n",
      "\n",
      "\n",
      "Stage  551\n",
      "Epoch 100/200\n",
      "Learning rate :  4.046107383222199e-06\n",
      "Average loss :  1.0943136674601561e-10\n",
      "\n",
      "\n",
      "Stage  551\n",
      "Epoch 150/200\n",
      "Learning rate :  4.046107383222199e-06\n",
      "Average loss :  1.0646789699864101e-10\n",
      "\n",
      "\n",
      "Stage  551\n",
      "Epoch 200/200\n",
      "Learning rate :  4.046107383222199e-06\n",
      "Average loss :  1.1230300717146591e-10\n",
      "expression length:\t 5\n",
      "Result stage 553: -1.739*sin(x0) + 25.075*cos(x0) + 1.42*x0_t**2 + 19.823*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999805]*t)\n",
      "\n",
      "\n",
      "Stage  552\n",
      "Epoch 50/200\n",
      "Learning rate :  4.005847942090417e-06\n",
      "Average loss :  1.4160687900055535e-10\n",
      "\n",
      "\n",
      "Stage  552\n",
      "Epoch 100/200\n",
      "Learning rate :  4.005847942090417e-06\n",
      "Average loss :  1.26743268658025e-10\n",
      "\n",
      "\n",
      "Stage  552\n",
      "Epoch 150/200\n",
      "Learning rate :  4.005847942090417e-06\n",
      "Average loss :  1.5797774199910464e-10\n",
      "\n",
      "\n",
      "Stage  552\n",
      "Epoch 200/200\n",
      "Learning rate :  4.005847942090417e-06\n",
      "Average loss :  1.1144773992555201e-10\n",
      "expression length:\t 5\n",
      "Result stage 554: -1.739*sin(x0) + 25.075*cos(x0) + 1.419*x0_t**2 + 19.823*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999827]*t)\n",
      "\n",
      "\n",
      "Stage  553\n",
      "Epoch 50/200\n",
      "Learning rate :  3.965989089091065e-06\n",
      "Average loss :  1.8995842399061047e-10\n",
      "\n",
      "\n",
      "Stage  553\n",
      "Epoch 100/200\n",
      "Learning rate :  3.965989089091065e-06\n",
      "Average loss :  1.0431847746739109e-10\n",
      "\n",
      "\n",
      "Stage  553\n",
      "Epoch 150/200\n",
      "Learning rate :  3.965989089091065e-06\n",
      "Average loss :  1.0698148616983261e-10\n",
      "\n",
      "\n",
      "Stage  553\n",
      "Epoch 200/200\n",
      "Learning rate :  3.965989089091065e-06\n",
      "Average loss :  2.2027457635687142e-10\n",
      "expression length:\t 5\n",
      "Result stage 555: -1.739*sin(x0) + 25.075*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999778]*t)\n",
      "\n",
      "\n",
      "Stage  554\n",
      "Epoch 50/200\n",
      "Learning rate :  3.9265268383056245e-06\n",
      "Average loss :  2.5643187573365367e-10\n",
      "\n",
      "\n",
      "Stage  554\n",
      "Epoch 100/200\n",
      "Learning rate :  3.9265268383056245e-06\n",
      "Average loss :  1.0912207942803676e-10\n",
      "\n",
      "\n",
      "Stage  554\n",
      "Epoch 150/200\n",
      "Learning rate :  3.9265268383056245e-06\n",
      "Average loss :  1.2221296197267861e-10\n",
      "\n",
      "\n",
      "Stage  554\n",
      "Epoch 200/200\n",
      "Learning rate :  3.9265268383056245e-06\n",
      "Average loss :  1.134610669306646e-10\n",
      "expression length:\t 5\n",
      "Result stage 556: -1.739*sin(x0) + 25.075*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.139999]*t)\n",
      "\n",
      "\n",
      "Stage  555\n",
      "Epoch 50/200\n",
      "Learning rate :  3.88745724347613e-06\n",
      "Average loss :  9.922201255063712e-11\n",
      "\n",
      "\n",
      "Stage  555\n",
      "Epoch 100/200\n",
      "Learning rate :  3.88745724347613e-06\n",
      "Average loss :  2.924527287007095e-10\n",
      "\n",
      "\n",
      "Stage  555\n",
      "Epoch 150/200\n",
      "Learning rate :  3.88745724347613e-06\n",
      "Average loss :  2.0037300985098483e-10\n",
      "\n",
      "\n",
      "Stage  555\n",
      "Epoch 200/200\n",
      "Learning rate :  3.88745724347613e-06\n",
      "Average loss :  1.2993929543458904e-10\n",
      "expression length:\t 5\n",
      "Result stage 557: -1.739*sin(x0) + 25.075*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999823]*t)\n",
      "\n",
      "\n",
      "Stage  556\n",
      "Epoch 50/200\n",
      "Learning rate :  3.84877639761054e-06\n",
      "Average loss :  1.7817733399816404e-10\n",
      "\n",
      "\n",
      "Stage  556\n",
      "Epoch 100/200\n",
      "Learning rate :  3.84877639761054e-06\n",
      "Average loss :  9.884009583016606e-11\n",
      "\n",
      "\n",
      "Stage  556\n",
      "Epoch 150/200\n",
      "Learning rate :  3.84877639761054e-06\n",
      "Average loss :  9.473291595618605e-11\n",
      "\n",
      "\n",
      "Stage  556\n",
      "Epoch 200/200\n",
      "Learning rate :  3.84877639761054e-06\n",
      "Average loss :  2.476706062459755e-10\n",
      "expression length:\t 5\n",
      "Result stage 558: -1.739*sin(x0) + 25.074*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999869]*t)\n",
      "\n",
      "\n",
      "Stage  557\n",
      "Epoch 50/200\n",
      "Learning rate :  3.810480432592037e-06\n",
      "Average loss :  1.0957876273032241e-10\n",
      "\n",
      "\n",
      "Stage  557\n",
      "Epoch 100/200\n",
      "Learning rate :  3.810480432592037e-06\n",
      "Average loss :  1.1591275161926262e-10\n",
      "\n",
      "\n",
      "Stage  557\n",
      "Epoch 150/200\n",
      "Learning rate :  3.810480432592037e-06\n",
      "Average loss :  9.537296646877635e-11\n",
      "\n",
      "\n",
      "Stage  557\n",
      "Epoch 200/200\n",
      "Learning rate :  3.810480432592037e-06\n",
      "Average loss :  1.1189529164346013e-10\n",
      "expression length:\t 5\n",
      "Result stage 559: -1.739*sin(x0) + 25.074*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999937]*t)\n",
      "\n",
      "\n",
      "Stage  558\n",
      "Epoch 50/200\n",
      "Learning rate :  3.7725655187922055e-06\n",
      "Average loss :  1.0247878934332988e-10\n",
      "\n",
      "\n",
      "Stage  558\n",
      "Epoch 100/200\n",
      "Learning rate :  3.7725655187922055e-06\n",
      "Average loss :  9.297256020612821e-11\n",
      "\n",
      "\n",
      "Stage  558\n",
      "Epoch 150/200\n",
      "Learning rate :  3.7725655187922055e-06\n",
      "Average loss :  1.6229055599392694e-10\n",
      "\n",
      "\n",
      "Stage  558\n",
      "Epoch 200/200\n",
      "Learning rate :  3.7725655187922055e-06\n",
      "Average loss :  1.0579283282741159e-10\n",
      "expression length:\t 5\n",
      "Result stage 560: -1.739*sin(x0) + 25.074*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999906]*t)\n",
      "\n",
      "\n",
      "Stage  559\n",
      "Epoch 50/200\n",
      "Learning rate :  3.7350278646880674e-06\n",
      "Average loss :  1.0636330705082742e-10\n",
      "\n",
      "\n",
      "Stage  559\n",
      "Epoch 100/200\n",
      "Learning rate :  3.7350278646880674e-06\n",
      "Average loss :  1.1692297130494467e-10\n",
      "\n",
      "\n",
      "Stage  559\n",
      "Epoch 150/200\n",
      "Learning rate :  3.7350278646880674e-06\n",
      "Average loss :  1.1679471279002485e-10\n",
      "\n",
      "\n",
      "Stage  559\n",
      "Epoch 200/200\n",
      "Learning rate :  3.7350278646880674e-06\n",
      "Average loss :  9.201795575508598e-11\n",
      "expression length:\t 5\n",
      "Result stage 561: -1.739*sin(x0) + 25.074*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999835]*t)\n",
      "\n",
      "\n",
      "Stage  560\n",
      "Epoch 50/200\n",
      "Learning rate :  3.697863716482929e-06\n",
      "Average loss :  1.8305297555532007e-10\n",
      "\n",
      "\n",
      "Stage  560\n",
      "Epoch 100/200\n",
      "Learning rate :  3.697863716482929e-06\n",
      "Average loss :  9.424602070984278e-11\n",
      "\n",
      "\n",
      "Stage  560\n",
      "Epoch 150/200\n",
      "Learning rate :  3.697863716482929e-06\n",
      "Average loss :  9.651165283619534e-11\n",
      "\n",
      "\n",
      "Stage  560\n",
      "Epoch 200/200\n",
      "Learning rate :  3.697863716482929e-06\n",
      "Average loss :  1.2213059730203923e-10\n",
      "expression length:\t 5\n",
      "Result stage 562: -1.739*sin(x0) + 25.074*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999827]*t)\n",
      "\n",
      "\n",
      "Stage  561\n",
      "Epoch 50/200\n",
      "Learning rate :  3.661069357731005e-06\n",
      "Average loss :  1.8038057159053267e-10\n",
      "\n",
      "\n",
      "Stage  561\n",
      "Epoch 100/200\n",
      "Learning rate :  3.661069357731005e-06\n",
      "Average loss :  9.039034104540988e-11\n",
      "\n",
      "\n",
      "Stage  561\n",
      "Epoch 150/200\n",
      "Learning rate :  3.661069357731005e-06\n",
      "Average loss :  1.0590393839660095e-10\n",
      "\n",
      "\n",
      "Stage  561\n",
      "Epoch 200/200\n",
      "Learning rate :  3.661069357731005e-06\n",
      "Average loss :  9.641844961327806e-11\n",
      "expression length:\t 5\n",
      "Result stage 563: -1.739*sin(x0) + 25.074*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999921]*t)\n",
      "\n",
      "\n",
      "Stage  562\n",
      "Epoch 50/200\n",
      "Learning rate :  3.6246411089657557e-06\n",
      "Average loss :  1.4146059323927318e-10\n",
      "\n",
      "\n",
      "Stage  562\n",
      "Epoch 100/200\n",
      "Learning rate :  3.6246411089657557e-06\n",
      "Average loss :  9.59926721444404e-11\n",
      "\n",
      "\n",
      "Stage  562\n",
      "Epoch 150/200\n",
      "Learning rate :  3.6246411089657557e-06\n",
      "Average loss :  1.7599666168877093e-10\n",
      "\n",
      "\n",
      "Stage  562\n",
      "Epoch 200/200\n",
      "Learning rate :  3.6246411089657557e-06\n",
      "Average loss :  9.105660669916915e-11\n",
      "expression length:\t 5\n",
      "Result stage 564: -1.739*sin(x0) + 25.074*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999866]*t)\n",
      "\n",
      "\n",
      "Stage  563\n",
      "Epoch 50/200\n",
      "Learning rate :  3.5885753273319478e-06\n",
      "Average loss :  2.021760259207639e-10\n",
      "\n",
      "\n",
      "Stage  563\n",
      "Epoch 100/200\n",
      "Learning rate :  3.5885753273319478e-06\n",
      "Average loss :  2.3582666375254746e-10\n",
      "\n",
      "\n",
      "Stage  563\n",
      "Epoch 150/200\n",
      "Learning rate :  3.5885753273319478e-06\n",
      "Average loss :  1.0253985854857817e-10\n",
      "\n",
      "\n",
      "Stage  563\n",
      "Epoch 200/200\n",
      "Learning rate :  3.5885753273319478e-06\n",
      "Average loss :  1.4800265180081595e-10\n",
      "expression length:\t 5\n",
      "Result stage 565: -1.739*sin(x0) + 25.074*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999864]*t)\n",
      "\n",
      "\n",
      "Stage  564\n",
      "Epoch 50/200\n",
      "Learning rate :  3.552868406221362e-06\n",
      "Average loss :  2.1857050891416208e-10\n",
      "\n",
      "\n",
      "Stage  564\n",
      "Epoch 100/200\n",
      "Learning rate :  3.552868406221362e-06\n",
      "Average loss :  8.297924153355396e-11\n",
      "\n",
      "\n",
      "Stage  564\n",
      "Epoch 150/200\n",
      "Learning rate :  3.552868406221362e-06\n",
      "Average loss :  9.297296266197463e-11\n",
      "\n",
      "\n",
      "Stage  564\n",
      "Epoch 200/200\n",
      "Learning rate :  3.552868406221362e-06\n",
      "Average loss :  9.262522693287423e-11\n",
      "expression length:\t 5\n",
      "Result stage 566: -1.739*sin(x0) + 25.074*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999951]*t)\n",
      "\n",
      "\n",
      "Stage  565\n",
      "Epoch 50/200\n",
      "Learning rate :  3.5175167749121286e-06\n",
      "Average loss :  9.356101310364906e-11\n",
      "\n",
      "\n",
      "Stage  565\n",
      "Epoch 100/200\n",
      "Learning rate :  3.5175167749121286e-06\n",
      "Average loss :  9.012107032857486e-11\n",
      "\n",
      "\n",
      "Stage  565\n",
      "Epoch 150/200\n",
      "Learning rate :  3.5175167749121286e-06\n",
      "Average loss :  1.8129571455194338e-10\n",
      "\n",
      "\n",
      "Stage  565\n",
      "Epoch 200/200\n",
      "Learning rate :  3.5175167749121286e-06\n",
      "Average loss :  8.195823880674524e-11\n",
      "expression length:\t 5\n",
      "Result stage 567: -1.739*sin(x0) + 25.074*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999847]*t)\n",
      "\n",
      "\n",
      "Stage  566\n",
      "Epoch 50/200\n",
      "Learning rate :  3.482516898211663e-06\n",
      "Average loss :  9.48363679253994e-11\n",
      "\n",
      "\n",
      "Stage  566\n",
      "Epoch 100/200\n",
      "Learning rate :  3.482516898211663e-06\n",
      "Average loss :  1.5250814500156196e-10\n",
      "\n",
      "\n",
      "Stage  566\n",
      "Epoch 150/200\n",
      "Learning rate :  3.482516898211663e-06\n",
      "Average loss :  8.120764477537179e-11\n",
      "\n",
      "\n",
      "Stage  566\n",
      "Epoch 200/200\n",
      "Learning rate :  3.482516898211663e-06\n",
      "Average loss :  8.523617922584492e-11\n",
      "expression length:\t 5\n",
      "Result stage 568: -1.739*sin(x0) + 25.074*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999857]*t)\n",
      "\n",
      "\n",
      "Stage  567\n",
      "Epoch 50/200\n",
      "Learning rate :  3.4478652761031266e-06\n",
      "Average loss :  1.5022595667435468e-10\n",
      "\n",
      "\n",
      "Stage  567\n",
      "Epoch 100/200\n",
      "Learning rate :  3.4478652761031266e-06\n",
      "Average loss :  8.386693423068081e-11\n",
      "\n",
      "\n",
      "Stage  567\n",
      "Epoch 150/200\n",
      "Learning rate :  3.4478652761031266e-06\n",
      "Average loss :  8.017558145168024e-11\n",
      "\n",
      "\n",
      "Stage  567\n",
      "Epoch 200/200\n",
      "Learning rate :  3.4478652761031266e-06\n",
      "Average loss :  9.062400829762396e-11\n",
      "expression length:\t 5\n",
      "Result stage 569: -1.739*sin(x0) + 25.075*cos(x0) + 1.419*x0_t**2 + 19.822*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999882]*t)\n",
      "\n",
      "\n",
      "Stage  568\n",
      "Epoch 50/200\n",
      "Learning rate :  3.4135584433954305e-06\n",
      "Average loss :  1.6136937619481984e-10\n",
      "\n",
      "\n",
      "Stage  568\n",
      "Epoch 100/200\n",
      "Learning rate :  3.4135584433954305e-06\n",
      "Average loss :  1.0261535371425268e-10\n",
      "\n",
      "\n",
      "Stage  568\n",
      "Epoch 150/200\n",
      "Learning rate :  3.4135584433954305e-06\n",
      "Average loss :  8.145725760577704e-11\n",
      "\n",
      "\n",
      "Stage  568\n",
      "Epoch 200/200\n",
      "Learning rate :  3.4135584433954305e-06\n",
      "Average loss :  7.980917315908442e-11\n",
      "expression length:\t 5\n",
      "Result stage 570: -1.739*sin(x0) + 25.075*cos(x0) + 1.419*x0_t**2 + 19.823*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999839]*t)\n",
      "\n",
      "\n",
      "Stage  569\n",
      "Epoch 50/200\n",
      "Learning rate :  3.3795929693767124e-06\n",
      "Average loss :  8.630289538569258e-11\n",
      "\n",
      "\n",
      "Stage  569\n",
      "Epoch 100/200\n",
      "Learning rate :  3.3795929693767124e-06\n",
      "Average loss :  8.50908718486032e-11\n",
      "\n",
      "\n",
      "Stage  569\n",
      "Epoch 150/200\n",
      "Learning rate :  3.3795929693767124e-06\n",
      "Average loss :  8.500938147859571e-11\n",
      "\n",
      "\n",
      "Stage  569\n",
      "Epoch 200/200\n",
      "Learning rate :  3.3795929693767124e-06\n",
      "Average loss :  1.5262842378849228e-10\n",
      "expression length:\t 5\n",
      "Result stage 571: -1.739*sin(x0) + 25.075*cos(x0) + 1.419*x0_t**2 + 19.823*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999838]*t)\n",
      "\n",
      "\n",
      "Stage  570\n",
      "Epoch 50/200\n",
      "Learning rate :  3.345965457471272e-06\n",
      "Average loss :  8.351371677539632e-11\n",
      "\n",
      "\n",
      "Stage  570\n",
      "Epoch 100/200\n",
      "Learning rate :  3.345965457471272e-06\n",
      "Average loss :  1.8144108437923023e-10\n",
      "\n",
      "\n",
      "Stage  570\n",
      "Epoch 150/200\n",
      "Learning rate :  3.345965457471272e-06\n",
      "Average loss :  7.701319443276233e-11\n",
      "\n",
      "\n",
      "Stage  570\n",
      "Epoch 200/200\n",
      "Learning rate :  3.345965457471272e-06\n",
      "Average loss :  1.4222698019317193e-10\n",
      "expression length:\t 5\n",
      "Result stage 572: -1.739*sin(x0) + 25.075*cos(x0) + 1.419*x0_t**2 + 19.823*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999836]*t)\n",
      "\n",
      "\n",
      "Stage  571\n",
      "Epoch 50/200\n",
      "Learning rate :  3.3126725448998925e-06\n",
      "Average loss :  7.859787820585495e-11\n",
      "\n",
      "\n",
      "Stage  571\n",
      "Epoch 100/200\n",
      "Learning rate :  3.3126725448998925e-06\n",
      "Average loss :  8.646158095038103e-11\n",
      "\n",
      "\n",
      "Stage  571\n",
      "Epoch 150/200\n",
      "Learning rate :  3.3126725448998925e-06\n",
      "Average loss :  7.362067899752134e-11\n",
      "\n",
      "\n",
      "Stage  571\n",
      "Epoch 200/200\n",
      "Learning rate :  3.3126725448998925e-06\n",
      "Average loss :  1.5839810019180334e-10\n",
      "expression length:\t 5\n",
      "Result stage 573: -1.739*sin(x0) + 25.075*cos(x0) + 1.419*x0_t**2 + 19.823*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999864]*t)\n",
      "\n",
      "\n",
      "Stage  572\n",
      "Epoch 50/200\n",
      "Learning rate :  3.279710902343573e-06\n",
      "Average loss :  1.586393932884178e-10\n",
      "\n",
      "\n",
      "Stage  572\n",
      "Epoch 100/200\n",
      "Learning rate :  3.279710902343573e-06\n",
      "Average loss :  1.4609317922076315e-10\n",
      "\n",
      "\n",
      "Stage  572\n",
      "Epoch 150/200\n",
      "Learning rate :  3.279710902343573e-06\n",
      "Average loss :  7.028529841468512e-11\n",
      "\n",
      "\n",
      "Stage  572\n",
      "Epoch 200/200\n",
      "Learning rate :  3.279710902343573e-06\n",
      "Average loss :  8.127233608323792e-11\n",
      "expression length:\t 5\n",
      "Result stage 574: -1.739*sin(x0) + 25.075*cos(x0) + 1.419*x0_t**2 + 19.823*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999887]*t)\n",
      "\n",
      "\n",
      "Stage  573\n",
      "Epoch 50/200\n",
      "Learning rate :  3.2470772336105864e-06\n",
      "Average loss :  9.962123487250452e-11\n",
      "\n",
      "\n",
      "Stage  573\n",
      "Epoch 100/200\n",
      "Learning rate :  3.2470772336105864e-06\n",
      "Average loss :  6.416982223367285e-11\n",
      "\n",
      "\n",
      "Stage  573\n",
      "Epoch 150/200\n",
      "Learning rate :  3.2470772336105864e-06\n",
      "Average loss :  9.477679752123436e-11\n",
      "\n",
      "\n",
      "Stage  573\n",
      "Epoch 200/200\n",
      "Learning rate :  3.2470772336105864e-06\n",
      "Average loss :  9.171852166645067e-11\n",
      "expression length:\t 5\n",
      "Result stage 575: -1.739*sin(x0) + 25.075*cos(x0) + 1.42*x0_t**2 + 19.823*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999839]*t)\n",
      "\n",
      "\n",
      "Stage  574\n",
      "Epoch 50/200\n",
      "Learning rate :  3.2147682753068702e-06\n",
      "Average loss :  7.820183389739555e-11\n",
      "\n",
      "\n",
      "Stage  574\n",
      "Epoch 100/200\n",
      "Learning rate :  3.2147682753068702e-06\n",
      "Average loss :  7.455779049703182e-11\n",
      "\n",
      "\n",
      "Stage  574\n",
      "Epoch 150/200\n",
      "Learning rate :  3.2147682753068702e-06\n",
      "Average loss :  7.099355131545693e-11\n",
      "\n",
      "\n",
      "Stage  574\n",
      "Epoch 200/200\n",
      "Learning rate :  3.2147682753068702e-06\n",
      "Average loss :  1.3212862748357423e-10\n",
      "expression length:\t 5\n",
      "Result stage 576: -1.739*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.823*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999854]*t)\n",
      "\n",
      "\n",
      "Stage  575\n",
      "Epoch 50/200\n",
      "Learning rate :  3.182780796509667e-06\n",
      "Average loss :  1.3888189209776414e-10\n",
      "\n",
      "\n",
      "Stage  575\n",
      "Epoch 100/200\n",
      "Learning rate :  3.182780796509667e-06\n",
      "Average loss :  1.5252657470377073e-10\n",
      "\n",
      "\n",
      "Stage  575\n",
      "Epoch 150/200\n",
      "Learning rate :  3.182780796509667e-06\n",
      "Average loss :  7.139106666942396e-11\n",
      "\n",
      "\n",
      "Stage  575\n",
      "Epoch 200/200\n",
      "Learning rate :  3.182780796509667e-06\n",
      "Average loss :  7.291337672521436e-11\n",
      "expression length:\t 5\n",
      "Result stage 577: -1.739*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.824*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999921]*t)\n",
      "\n",
      "\n",
      "Stage  576\n",
      "Epoch 50/200\n",
      "Learning rate :  3.1511115984444413e-06\n",
      "Average loss :  7.146704061877784e-11\n",
      "\n",
      "\n",
      "Stage  576\n",
      "Epoch 100/200\n",
      "Learning rate :  3.1511115984444413e-06\n",
      "Average loss :  6.793746815114687e-11\n",
      "\n",
      "\n",
      "Stage  576\n",
      "Epoch 150/200\n",
      "Learning rate :  3.1511115984444413e-06\n",
      "Average loss :  7.244783939430732e-11\n",
      "\n",
      "\n",
      "Stage  576\n",
      "Epoch 200/200\n",
      "Learning rate :  3.1511115984444413e-06\n",
      "Average loss :  1.2701120710723046e-10\n",
      "expression length:\t 5\n",
      "Result stage 578: -1.739*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.824*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999847]*t)\n",
      "\n",
      "\n",
      "Stage  577\n",
      "Epoch 50/200\n",
      "Learning rate :  3.1197575141649923e-06\n",
      "Average loss :  1.2736885157682565e-10\n",
      "\n",
      "\n",
      "Stage  577\n",
      "Epoch 100/200\n",
      "Learning rate :  3.1197575141649923e-06\n",
      "Average loss :  1.3677431409675478e-10\n",
      "\n",
      "\n",
      "Stage  577\n",
      "Epoch 150/200\n",
      "Learning rate :  3.1197575141649923e-06\n",
      "Average loss :  6.804164870422014e-11\n",
      "\n",
      "\n",
      "Stage  577\n",
      "Epoch 200/200\n",
      "Learning rate :  3.1197575141649923e-06\n",
      "Average loss :  1.8179147076580193e-10\n",
      "expression length:\t 5\n",
      "Result stage 579: -1.739*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.824*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999927]*t)\n",
      "\n",
      "\n",
      "Stage  578\n",
      "Epoch 50/200\n",
      "Learning rate :  3.0887154082367687e-06\n",
      "Average loss :  1.1901570007299966e-10\n",
      "\n",
      "\n",
      "Stage  578\n",
      "Epoch 100/200\n",
      "Learning rate :  3.0887154082367687e-06\n",
      "Average loss :  6.996075246901157e-11\n",
      "\n",
      "\n",
      "Stage  578\n",
      "Epoch 150/200\n",
      "Learning rate :  3.0887154082367687e-06\n",
      "Average loss :  2.7837145782916295e-11\n",
      "\n",
      "\n",
      "Stage  578\n",
      "Epoch 200/200\n",
      "Learning rate :  3.0887154082367687e-06\n",
      "Average loss :  6.69962835209148e-11\n",
      "expression length:\t 5\n",
      "Result stage 580: -1.739*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.824*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999869]*t)\n",
      "\n",
      "\n",
      "Stage  579\n",
      "Epoch 50/200\n",
      "Learning rate :  3.057982176423307e-06\n",
      "Average loss :  6.915394645812256e-11\n",
      "\n",
      "\n",
      "Stage  579\n",
      "Epoch 100/200\n",
      "Learning rate :  3.057982176423307e-06\n",
      "Average loss :  6.174205591236159e-11\n",
      "\n",
      "\n",
      "Stage  579\n",
      "Epoch 150/200\n",
      "Learning rate :  3.057982176423307e-06\n",
      "Average loss :  6.085391218713099e-11\n",
      "\n",
      "\n",
      "Stage  579\n",
      "Epoch 200/200\n",
      "Learning rate :  3.057982176423307e-06\n",
      "Average loss :  5.183867571312284e-11\n",
      "expression length:\t 5\n",
      "Result stage 581: -1.739*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.824*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999908]*t)\n",
      "\n",
      "\n",
      "Stage  580\n",
      "Epoch 50/200\n",
      "Learning rate :  3.0275547453758155e-06\n",
      "Average loss :  6.741695396383918e-11\n",
      "\n",
      "\n",
      "Stage  580\n",
      "Epoch 100/200\n",
      "Learning rate :  3.0275547453758155e-06\n",
      "Average loss :  1.178386693778677e-10\n",
      "\n",
      "\n",
      "Stage  580\n",
      "Epoch 150/200\n",
      "Learning rate :  3.0275547453758155e-06\n",
      "Average loss :  6.806587932173258e-11\n",
      "\n",
      "\n",
      "Stage  580\n",
      "Epoch 200/200\n",
      "Learning rate :  3.0275547453758155e-06\n",
      "Average loss :  6.920723022441067e-11\n",
      "expression length:\t 5\n",
      "Result stage 582: -1.739*sin(x0) + 25.076*cos(x0) + 1.42*x0_t**2 + 19.824*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999902]*t)\n",
      "\n",
      "\n",
      "Stage  581\n",
      "Epoch 50/200\n",
      "Learning rate :  2.9974300723258287e-06\n",
      "Average loss :  6.377440936455869e-11\n",
      "\n",
      "\n",
      "Stage  581\n",
      "Epoch 100/200\n",
      "Learning rate :  2.9974300723258287e-06\n",
      "Average loss :  1.0609364081703987e-10\n",
      "\n",
      "\n",
      "Stage  581\n",
      "Epoch 150/200\n",
      "Learning rate :  2.9974300723258287e-06\n",
      "Average loss :  6.297634635998861e-11\n",
      "\n",
      "\n",
      "Stage  581\n",
      "Epoch 200/200\n",
      "Learning rate :  2.9974300723258287e-06\n",
      "Average loss :  6.33112728909424e-11\n",
      "expression length:\t 5\n",
      "Result stage 583: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.824*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999926]*t)\n",
      "\n",
      "\n",
      "Stage  582\n",
      "Epoch 50/200\n",
      "Learning rate :  2.9676051447809443e-06\n",
      "Average loss :  5.76659900386467e-11\n",
      "\n",
      "\n",
      "Stage  582\n",
      "Epoch 100/200\n",
      "Learning rate :  2.9676051447809443e-06\n",
      "Average loss :  1.6111734169044212e-10\n",
      "\n",
      "\n",
      "Stage  582\n",
      "Epoch 150/200\n",
      "Learning rate :  2.9676051447809443e-06\n",
      "Average loss :  1.51115203683716e-10\n",
      "\n",
      "\n",
      "Stage  582\n",
      "Epoch 200/200\n",
      "Learning rate :  2.9676051447809443e-06\n",
      "Average loss :  1.1460039861521665e-10\n",
      "expression length:\t 5\n",
      "Result stage 584: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999851]*t)\n",
      "\n",
      "\n",
      "Stage  583\n",
      "Epoch 50/200\n",
      "Learning rate :  2.9380769802235504e-06\n",
      "Average loss :  9.591633737260352e-11\n",
      "\n",
      "\n",
      "Stage  583\n",
      "Epoch 100/200\n",
      "Learning rate :  2.9380769802235504e-06\n",
      "Average loss :  6.216788195345657e-11\n",
      "\n",
      "\n",
      "Stage  583\n",
      "Epoch 150/200\n",
      "Learning rate :  2.9380769802235504e-06\n",
      "Average loss :  1.0954840506949282e-10\n",
      "\n",
      "\n",
      "Stage  583\n",
      "Epoch 200/200\n",
      "Learning rate :  2.9380769802235504e-06\n",
      "Average loss :  6.464934837469016e-11\n",
      "expression length:\t 5\n",
      "Result stage 585: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999882]*t)\n",
      "\n",
      "\n",
      "Stage  584\n",
      "Epoch 50/200\n",
      "Learning rate :  2.908842625812584e-06\n",
      "Average loss :  5.961597188131051e-11\n",
      "\n",
      "\n",
      "Stage  584\n",
      "Epoch 100/200\n",
      "Learning rate :  2.908842625812584e-06\n",
      "Average loss :  6.701832144795361e-11\n",
      "\n",
      "\n",
      "Stage  584\n",
      "Epoch 150/200\n",
      "Learning rate :  2.908842625812584e-06\n",
      "Average loss :  1.2121319226121585e-10\n",
      "\n",
      "\n",
      "Stage  584\n",
      "Epoch 200/200\n",
      "Learning rate :  2.908842625812584e-06\n",
      "Average loss :  5.6315403729190194e-11\n",
      "expression length:\t 5\n",
      "Result stage 586: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999864]*t)\n",
      "\n",
      "\n",
      "Stage  585\n",
      "Epoch 50/200\n",
      "Learning rate :  2.8798991580882404e-06\n",
      "Average loss :  5.268706304573101e-11\n",
      "\n",
      "\n",
      "Stage  585\n",
      "Epoch 100/200\n",
      "Learning rate :  2.8798991580882404e-06\n",
      "Average loss :  7.100021959249858e-11\n",
      "\n",
      "\n",
      "Stage  585\n",
      "Epoch 150/200\n",
      "Learning rate :  2.8798991580882404e-06\n",
      "Average loss :  6.191053919524236e-11\n",
      "\n",
      "\n",
      "Stage  585\n",
      "Epoch 200/200\n",
      "Learning rate :  2.8798991580882404e-06\n",
      "Average loss :  9.927701022371949e-11\n",
      "expression length:\t 5\n",
      "Result stage 587: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999863]*t)\n",
      "\n",
      "\n",
      "Stage  586\n",
      "Epoch 50/200\n",
      "Learning rate :  2.8512436826796323e-06\n",
      "Average loss :  6.035517918778766e-11\n",
      "\n",
      "\n",
      "Stage  586\n",
      "Epoch 100/200\n",
      "Learning rate :  2.8512436826796323e-06\n",
      "Average loss :  6.372991023795294e-11\n",
      "\n",
      "\n",
      "Stage  586\n",
      "Epoch 150/200\n",
      "Learning rate :  2.8512436826796323e-06\n",
      "Average loss :  6.233225741114623e-11\n",
      "\n",
      "\n",
      "Stage  586\n",
      "Epoch 200/200\n",
      "Learning rate :  2.8512436826796323e-06\n",
      "Average loss :  5.452895773805366e-11\n",
      "expression length:\t 5\n",
      "Result stage 588: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999882]*t)\n",
      "\n",
      "\n",
      "Stage  587\n",
      "Epoch 50/200\n",
      "Learning rate :  2.8228733340153365e-06\n",
      "Average loss :  9.822182650554012e-11\n",
      "\n",
      "\n",
      "Stage  587\n",
      "Epoch 100/200\n",
      "Learning rate :  2.8228733340153365e-06\n",
      "Average loss :  1.4737186471158736e-10\n",
      "\n",
      "\n",
      "Stage  587\n",
      "Epoch 150/200\n",
      "Learning rate :  2.8228733340153365e-06\n",
      "Average loss :  5.997419921799363e-11\n",
      "\n",
      "\n",
      "Stage  587\n",
      "Epoch 200/200\n",
      "Learning rate :  2.8228733340153365e-06\n",
      "Average loss :  6.161874482879526e-11\n",
      "expression length:\t 5\n",
      "Result stage 589: -1.739*sin(x0) + 25.077*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.139999]*t)\n",
      "\n",
      "\n",
      "Stage  588\n",
      "Epoch 50/200\n",
      "Learning rate :  2.7947852750368438e-06\n",
      "Average loss :  5.763931693048008e-11\n",
      "\n",
      "\n",
      "Stage  588\n",
      "Epoch 100/200\n",
      "Learning rate :  2.7947852750368438e-06\n",
      "Average loss :  1.0453973797730498e-10\n",
      "\n",
      "\n",
      "Stage  588\n",
      "Epoch 150/200\n",
      "Learning rate :  2.7947852750368438e-06\n",
      "Average loss :  7.194186218972831e-11\n",
      "\n",
      "\n",
      "Stage  588\n",
      "Epoch 200/200\n",
      "Learning rate :  2.7947852750368438e-06\n",
      "Average loss :  1.0533540706347821e-10\n",
      "expression length:\t 5\n",
      "Result stage 590: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.825*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.1399987]*t)\n",
      "\n",
      "\n",
      "Stage  589\n",
      "Epoch 50/200\n",
      "Learning rate :  2.766976696914851e-06\n",
      "Average loss :  9.284480823046337e-11\n",
      "\n",
      "\n",
      "Stage  589\n",
      "Epoch 100/200\n",
      "Learning rate :  2.766976696914851e-06\n",
      "Average loss :  7.011321384586822e-11\n",
      "\n",
      "\n",
      "Stage  589\n",
      "Epoch 150/200\n",
      "Learning rate :  2.766976696914851e-06\n",
      "Average loss :  5.3154494694673815e-11\n",
      "\n",
      "\n",
      "Stage  589\n",
      "Epoch 200/200\n",
      "Learning rate :  2.766976696914851e-06\n",
      "Average loss :  6.155414372654988e-11\n",
      "expression length:\t 5\n",
      "Result stage 591: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999885]*t)\n",
      "\n",
      "\n",
      "Stage  590\n",
      "Epoch 50/200\n",
      "Learning rate :  2.7394448187683683e-06\n",
      "Average loss :  9.28974328018306e-11\n",
      "\n",
      "\n",
      "Stage  590\n",
      "Epoch 100/200\n",
      "Learning rate :  2.7394448187683683e-06\n",
      "Average loss :  5.3424098478416226e-11\n",
      "\n",
      "\n",
      "Stage  590\n",
      "Epoch 150/200\n",
      "Learning rate :  2.7394448187683683e-06\n",
      "Average loss :  5.198566924158321e-11\n",
      "\n",
      "\n",
      "Stage  590\n",
      "Epoch 200/200\n",
      "Learning rate :  2.7394448187683683e-06\n",
      "Average loss :  7.238486893212936e-11\n",
      "expression length:\t 5\n",
      "Result stage 592: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.1399991]*t)\n",
      "\n",
      "\n",
      "Stage  591\n",
      "Epoch 50/200\n",
      "Learning rate :  2.7121868873866435e-06\n",
      "Average loss :  5.4908418090082733e-11\n",
      "\n",
      "\n",
      "Stage  591\n",
      "Epoch 100/200\n",
      "Learning rate :  2.7121868873866435e-06\n",
      "Average loss :  1.4454275276687412e-10\n",
      "\n",
      "\n",
      "Stage  591\n",
      "Epoch 150/200\n",
      "Learning rate :  2.7121868873866435e-06\n",
      "Average loss :  4.4552812827891586e-11\n",
      "\n",
      "\n",
      "Stage  591\n",
      "Epoch 200/200\n",
      "Learning rate :  2.7121868873866435e-06\n",
      "Average loss :  5.6774192985775684e-11\n",
      "expression length:\t 5\n",
      "Result stage 593: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999903]*t)\n",
      "\n",
      "\n",
      "Stage  592\n",
      "Epoch 50/200\n",
      "Learning rate :  2.6852001769538204e-06\n",
      "Average loss :  5.339274161686447e-11\n",
      "\n",
      "\n",
      "Stage  592\n",
      "Epoch 100/200\n",
      "Learning rate :  2.6852001769538204e-06\n",
      "Average loss :  1.0937144245826147e-10\n",
      "\n",
      "\n",
      "Stage  592\n",
      "Epoch 150/200\n",
      "Learning rate :  2.6852001769538204e-06\n",
      "Average loss :  4.831073388555929e-11\n",
      "\n",
      "\n",
      "Stage  592\n",
      "Epoch 200/200\n",
      "Learning rate :  2.6852001769538204e-06\n",
      "Average loss :  5.355323129396794e-11\n",
      "expression length:\t 5\n",
      "Result stage 594: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999961]*t)\n",
      "\n",
      "\n",
      "Stage  593\n",
      "Epoch 50/200\n",
      "Learning rate :  2.658481988776367e-06\n",
      "Average loss :  1.274744199086797e-10\n",
      "\n",
      "\n",
      "Stage  593\n",
      "Epoch 100/200\n",
      "Learning rate :  2.658481988776367e-06\n",
      "Average loss :  4.059865985062139e-11\n",
      "\n",
      "\n",
      "Stage  593\n",
      "Epoch 150/200\n",
      "Learning rate :  2.658481988776367e-06\n",
      "Average loss :  4.538129941278335e-11\n",
      "\n",
      "\n",
      "Stage  593\n",
      "Epoch 200/200\n",
      "Learning rate :  2.658481988776367e-06\n",
      "Average loss :  5.471689767944099e-11\n",
      "expression length:\t 5\n",
      "Result stage 595: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999902]*t)\n",
      "\n",
      "\n",
      "Stage  594\n",
      "Epoch 50/200\n",
      "Learning rate :  2.6320296510131985e-06\n",
      "Average loss :  5.1594246236463803e-11\n",
      "\n",
      "\n",
      "Stage  594\n",
      "Epoch 100/200\n",
      "Learning rate :  2.6320296510131985e-06\n",
      "Average loss :  1.0246063025798335e-10\n",
      "\n",
      "\n",
      "Stage  594\n",
      "Epoch 150/200\n",
      "Learning rate :  2.6320296510131985e-06\n",
      "Average loss :  1.3338019577702198e-10\n",
      "\n",
      "\n",
      "Stage  594\n",
      "Epoch 200/200\n",
      "Learning rate :  2.6320296510131985e-06\n",
      "Average loss :  6.009194530864903e-11\n",
      "expression length:\t 5\n",
      "Result stage 596: -1.739*sin(x0) + 25.078*cos(x0) + 1.42*x0_t**2 + 19.826*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999873]*t)\n",
      "\n",
      "\n",
      "Stage  595\n",
      "Epoch 50/200\n",
      "Learning rate :  2.6058405184084985e-06\n",
      "Average loss :  6.275883285278283e-11\n",
      "\n",
      "\n",
      "Stage  595\n",
      "Epoch 100/200\n",
      "Learning rate :  2.6058405184084985e-06\n",
      "Average loss :  4.602753941873594e-11\n",
      "\n",
      "\n",
      "Stage  595\n",
      "Epoch 150/200\n",
      "Learning rate :  2.6058405184084985e-06\n",
      "Average loss :  5.047779208511294e-11\n",
      "\n",
      "\n",
      "Stage  595\n",
      "Epoch 200/200\n",
      "Learning rate :  2.6058405184084985e-06\n",
      "Average loss :  8.656556721442499e-11\n",
      "expression length:\t 5\n",
      "Result stage 597: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999875]*t)\n",
      "\n",
      "\n",
      "Stage  596\n",
      "Epoch 50/200\n",
      "Learning rate :  2.57991197202718e-06\n",
      "Average loss :  5.546919520926785e-11\n",
      "\n",
      "\n",
      "Stage  596\n",
      "Epoch 100/200\n",
      "Learning rate :  2.57991197202718e-06\n",
      "Average loss :  5.000066333193942e-11\n",
      "\n",
      "\n",
      "Stage  596\n",
      "Epoch 150/200\n",
      "Learning rate :  2.57991197202718e-06\n",
      "Average loss :  1.3036124957288564e-10\n",
      "\n",
      "\n",
      "Stage  596\n",
      "Epoch 200/200\n",
      "Learning rate :  2.57991197202718e-06\n",
      "Average loss :  4.187772698061032e-11\n",
      "expression length:\t 5\n",
      "Result stage 598: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999912]*t)\n",
      "\n",
      "\n",
      "Stage  597\n",
      "Epoch 50/200\n",
      "Learning rate :  2.5542414189929985e-06\n",
      "Average loss :  6.155969484167301e-11\n",
      "\n",
      "\n",
      "Stage  597\n",
      "Epoch 100/200\n",
      "Learning rate :  2.5542414189929985e-06\n",
      "Average loss :  2.373949474498982e-11\n",
      "\n",
      "\n",
      "Stage  597\n",
      "Epoch 150/200\n",
      "Learning rate :  2.5542414189929985e-06\n",
      "Average loss :  4.6264769792969673e-11\n",
      "\n",
      "\n",
      "Stage  597\n",
      "Epoch 200/200\n",
      "Learning rate :  2.5542414189929985e-06\n",
      "Average loss :  4.9391532530584925e-11\n",
      "expression length:\t 5\n",
      "Result stage 599: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999937]*t)\n",
      "\n",
      "\n",
      "Stage  598\n",
      "Epoch 50/200\n",
      "Learning rate :  2.5288262922292557e-06\n",
      "Average loss :  1.2815702665758266e-10\n",
      "\n",
      "\n",
      "Stage  598\n",
      "Epoch 100/200\n",
      "Learning rate :  2.5288262922292557e-06\n",
      "Average loss :  4.358148911198789e-11\n",
      "\n",
      "\n",
      "Stage  598\n",
      "Epoch 150/200\n",
      "Learning rate :  2.5288262922292557e-06\n",
      "Average loss :  4.9923079559199834e-11\n",
      "\n",
      "\n",
      "Stage  598\n",
      "Epoch 200/200\n",
      "Learning rate :  2.5288262922292557e-06\n",
      "Average loss :  5.926952678647623e-11\n",
      "expression length:\t 5\n",
      "Result stage 600: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399988]*t)\n",
      "\n",
      "\n",
      "Stage  599\n",
      "Epoch 50/200\n",
      "Learning rate :  2.5036640502021e-06\n",
      "Average loss :  5.433546321209626e-11\n",
      "\n",
      "\n",
      "Stage  599\n",
      "Epoch 100/200\n",
      "Learning rate :  2.5036640502021e-06\n",
      "Average loss :  1.1199368515901753e-10\n",
      "\n",
      "\n",
      "Stage  599\n",
      "Epoch 150/200\n",
      "Learning rate :  2.5036640502021e-06\n",
      "Average loss :  8.622189073825837e-11\n",
      "\n",
      "\n",
      "Stage  599\n",
      "Epoch 200/200\n",
      "Learning rate :  2.5036640502021e-06\n",
      "Average loss :  9.926260507997497e-11\n",
      "expression length:\t 5\n",
      "Result stage 601: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999899]*t)\n",
      "\n",
      "\n",
      "Stage  600\n",
      "Epoch 50/200\n",
      "Learning rate :  2.4787521766663587e-06\n",
      "Average loss :  4.8162512172877925e-11\n",
      "\n",
      "\n",
      "Stage  600\n",
      "Epoch 100/200\n",
      "Learning rate :  2.4787521766663587e-06\n",
      "Average loss :  3.8814944314236044e-11\n",
      "\n",
      "\n",
      "Stage  600\n",
      "Epoch 150/200\n",
      "Learning rate :  2.4787521766663587e-06\n",
      "Average loss :  4.391809485526643e-11\n",
      "\n",
      "\n",
      "Stage  600\n",
      "Epoch 200/200\n",
      "Learning rate :  2.4787521766663587e-06\n",
      "Average loss :  5.281850651295272e-11\n",
      "expression length:\t 5\n",
      "Result stage 602: -1.739*sin(x0) + 25.079*cos(x0) + 1.42*x0_t**2 + 19.827*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999908]*t)\n",
      "\n",
      "\n",
      "Stage  601\n",
      "Epoch 50/200\n",
      "Learning rate :  2.454088180413917e-06\n",
      "Average loss :  4.95622466678558e-11\n",
      "\n",
      "\n",
      "Stage  601\n",
      "Epoch 100/200\n",
      "Learning rate :  2.454088180413917e-06\n",
      "Average loss :  4.360606667419553e-11\n",
      "\n",
      "\n",
      "Stage  601\n",
      "Epoch 150/200\n",
      "Learning rate :  2.454088180413917e-06\n",
      "Average loss :  4.240183898440719e-11\n",
      "\n",
      "\n",
      "Stage  601\n",
      "Epoch 200/200\n",
      "Learning rate :  2.454088180413917e-06\n",
      "Average loss :  4.0026315595298456e-11\n",
      "expression length:\t 5\n",
      "Result stage 603: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999891]*t)\n",
      "\n",
      "\n",
      "Stage  602\n",
      "Epoch 50/200\n",
      "Learning rate :  2.4296695950245954e-06\n",
      "Average loss :  3.916482416155276e-11\n",
      "\n",
      "\n",
      "Stage  602\n",
      "Epoch 100/200\n",
      "Learning rate :  2.4296695950245954e-06\n",
      "Average loss :  4.0991540023460615e-11\n",
      "\n",
      "\n",
      "Stage  602\n",
      "Epoch 150/200\n",
      "Learning rate :  2.4296695950245954e-06\n",
      "Average loss :  1.1972126068293676e-10\n",
      "\n",
      "\n",
      "Stage  602\n",
      "Epoch 200/200\n",
      "Learning rate :  2.4296695950245954e-06\n",
      "Average loss :  8.188936334585506e-11\n",
      "expression length:\t 5\n",
      "Result stage 604: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999884]*t)\n",
      "\n",
      "\n",
      "Stage  603\n",
      "Epoch 50/200\n",
      "Learning rate :  2.4054939786195094e-06\n",
      "Average loss :  2.1802228425404913e-11\n",
      "\n",
      "\n",
      "Stage  603\n",
      "Epoch 100/200\n",
      "Learning rate :  2.4054939786195094e-06\n",
      "Average loss :  4.910899117915868e-11\n",
      "\n",
      "\n",
      "Stage  603\n",
      "Epoch 150/200\n",
      "Learning rate :  2.4054939786195094e-06\n",
      "Average loss :  8.081339764043349e-11\n",
      "\n",
      "\n",
      "Stage  603\n",
      "Epoch 200/200\n",
      "Learning rate :  2.4054939786195094e-06\n",
      "Average loss :  8.706634024857607e-11\n",
      "expression length:\t 5\n",
      "Result stage 605: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999903]*t)\n",
      "\n",
      "\n",
      "Stage  604\n",
      "Epoch 50/200\n",
      "Learning rate :  2.381558913616871e-06\n",
      "Average loss :  3.46629600023185e-11\n",
      "\n",
      "\n",
      "Stage  604\n",
      "Epoch 100/200\n",
      "Learning rate :  2.381558913616871e-06\n",
      "Average loss :  3.750676158542632e-11\n",
      "\n",
      "\n",
      "Stage  604\n",
      "Epoch 150/200\n",
      "Learning rate :  2.381558913616871e-06\n",
      "Average loss :  7.354526709857367e-11\n",
      "\n",
      "\n",
      "Stage  604\n",
      "Epoch 200/200\n",
      "Learning rate :  2.381558913616871e-06\n",
      "Average loss :  4.174595044648122e-11\n",
      "expression length:\t 5\n",
      "Result stage 606: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999902]*t)\n",
      "\n",
      "\n",
      "Stage  605\n",
      "Epoch 50/200\n",
      "Learning rate :  2.357862006490233e-06\n",
      "Average loss :  4.055245722556222e-11\n",
      "\n",
      "\n",
      "Stage  605\n",
      "Epoch 100/200\n",
      "Learning rate :  2.357862006490233e-06\n",
      "Average loss :  5.688664816982936e-11\n",
      "\n",
      "\n",
      "Stage  605\n",
      "Epoch 150/200\n",
      "Learning rate :  2.357862006490233e-06\n",
      "Average loss :  7.868419110712566e-11\n",
      "\n",
      "\n",
      "Stage  605\n",
      "Epoch 200/200\n",
      "Learning rate :  2.357862006490233e-06\n",
      "Average loss :  3.173742865736351e-11\n",
      "expression length:\t 5\n",
      "Result stage 607: -1.739*sin(x0) + 25.08*cos(x0) + 1.42*x0_t**2 + 19.828*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999937]*t)\n",
      "\n",
      "\n",
      "Stage  606\n",
      "Epoch 50/200\n",
      "Learning rate :  2.334400887529133e-06\n",
      "Average loss :  3.415359314806743e-11\n",
      "\n",
      "\n",
      "Stage  606\n",
      "Epoch 100/200\n",
      "Learning rate :  2.334400887529133e-06\n",
      "Average loss :  4.2438337566341744e-11\n",
      "\n",
      "\n",
      "Stage  606\n",
      "Epoch 150/200\n",
      "Learning rate :  2.334400887529133e-06\n",
      "Average loss :  3.87759754860717e-11\n",
      "\n",
      "\n",
      "Stage  606\n",
      "Epoch 200/200\n",
      "Learning rate :  2.334400887529133e-06\n",
      "Average loss :  6.847442751700683e-11\n",
      "expression length:\t 5\n",
      "Result stage 608: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999891]*t)\n",
      "\n",
      "\n",
      "Stage  607\n",
      "Epoch 50/200\n",
      "Learning rate :  2.311173210602129e-06\n",
      "Average loss :  5.3305554414961875e-11\n",
      "\n",
      "\n",
      "Stage  607\n",
      "Epoch 100/200\n",
      "Learning rate :  2.311173210602129e-06\n",
      "Average loss :  4.625894112209039e-11\n",
      "\n",
      "\n",
      "Stage  607\n",
      "Epoch 150/200\n",
      "Learning rate :  2.311173210602129e-06\n",
      "Average loss :  6.051835421683194e-11\n",
      "\n",
      "\n",
      "Stage  607\n",
      "Epoch 200/200\n",
      "Learning rate :  2.311173210602129e-06\n",
      "Average loss :  4.476060147529104e-11\n",
      "expression length:\t 5\n",
      "Result stage 609: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999896]*t)\n",
      "\n",
      "\n",
      "Stage  608\n",
      "Epoch 50/200\n",
      "Learning rate :  2.2881766529221694e-06\n",
      "Average loss :  4.106931461578256e-11\n",
      "\n",
      "\n",
      "Stage  608\n",
      "Epoch 100/200\n",
      "Learning rate :  2.2881766529221694e-06\n",
      "Average loss :  2.6524001744965275e-11\n",
      "\n",
      "\n",
      "Stage  608\n",
      "Epoch 150/200\n",
      "Learning rate :  2.2881766529221694e-06\n",
      "Average loss :  6.245912814728527e-11\n",
      "\n",
      "\n",
      "Stage  608\n",
      "Epoch 200/200\n",
      "Learning rate :  2.2881766529221694e-06\n",
      "Average loss :  2.832763364157831e-11\n",
      "expression length:\t 5\n",
      "Result stage 610: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999937]*t)\n",
      "\n",
      "\n",
      "Stage  609\n",
      "Epoch 50/200\n",
      "Learning rate :  2.265408914814322e-06\n",
      "Average loss :  4.510660595036242e-11\n",
      "\n",
      "\n",
      "Stage  609\n",
      "Epoch 100/200\n",
      "Learning rate :  2.265408914814322e-06\n",
      "Average loss :  2.8635805532362113e-11\n",
      "\n",
      "\n",
      "Stage  609\n",
      "Epoch 150/200\n",
      "Learning rate :  2.265408914814322e-06\n",
      "Average loss :  3.367219697514301e-11\n",
      "\n",
      "\n",
      "Stage  609\n",
      "Epoch 200/200\n",
      "Learning rate :  2.265408914814322e-06\n",
      "Average loss :  3.364197115329759e-11\n",
      "expression length:\t 5\n",
      "Result stage 611: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999896]*t)\n",
      "\n",
      "\n",
      "Stage  610\n",
      "Epoch 50/200\n",
      "Learning rate :  2.2428677194858014e-06\n",
      "Average loss :  5.843558276152905e-11\n",
      "\n",
      "\n",
      "Stage  610\n",
      "Epoch 100/200\n",
      "Learning rate :  2.2428677194858014e-06\n",
      "Average loss :  9.235440884269863e-11\n",
      "\n",
      "\n",
      "Stage  610\n",
      "Epoch 150/200\n",
      "Learning rate :  2.2428677194858014e-06\n",
      "Average loss :  8.91497223265425e-11\n",
      "\n",
      "\n",
      "Stage  610\n",
      "Epoch 200/200\n",
      "Learning rate :  2.2428677194858014e-06\n",
      "Average loss :  4.023785124540602e-11\n",
      "expression length:\t 5\n",
      "Result stage 612: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999926]*t)\n",
      "\n",
      "\n",
      "Stage  611\n",
      "Epoch 50/200\n",
      "Learning rate :  2.220550812798294e-06\n",
      "Average loss :  3.954303898212608e-11\n",
      "\n",
      "\n",
      "Stage  611\n",
      "Epoch 100/200\n",
      "Learning rate :  2.220550812798294e-06\n",
      "Average loss :  3.954303898212608e-11\n",
      "\n",
      "\n",
      "Stage  611\n",
      "Epoch 150/200\n",
      "Learning rate :  2.220550812798294e-06\n",
      "Average loss :  3.954303898212608e-11\n",
      "\n",
      "\n",
      "Stage  611\n",
      "Epoch 200/200\n",
      "Learning rate :  2.220550812798294e-06\n",
      "Average loss :  3.954303898212608e-11\n",
      "expression length:\t 5\n",
      "Result stage 613: -1.739*sin(x0) + 25.081*cos(x0) + 1.42*x0_t**2 + 19.829*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999926]*t)\n",
      "\n",
      "\n",
      "Stage  612\n",
      "Epoch 50/200\n",
      "Learning rate :  2.1984559630425315e-06\n",
      "Average loss :  4.688546773046198e-11\n",
      "\n",
      "\n",
      "Stage  612\n",
      "Epoch 100/200\n",
      "Learning rate :  2.1984559630425315e-06\n",
      "Average loss :  8.682075891552898e-11\n",
      "\n",
      "\n",
      "Stage  612\n",
      "Epoch 150/200\n",
      "Learning rate :  2.1984559630425315e-06\n",
      "Average loss :  4.7692017002276543e-11\n",
      "\n",
      "\n",
      "Stage  612\n",
      "Epoch 200/200\n",
      "Learning rate :  2.1984559630425315e-06\n",
      "Average loss :  1.7078239863965727e-11\n",
      "expression length:\t 5\n",
      "Result stage 614: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999915]*t)\n",
      "\n",
      "\n",
      "Stage  613\n",
      "Epoch 50/200\n",
      "Learning rate :  2.1765809607151254e-06\n",
      "Average loss :  2.5827305571990422e-11\n",
      "\n",
      "\n",
      "Stage  613\n",
      "Epoch 100/200\n",
      "Learning rate :  2.1765809607151254e-06\n",
      "Average loss :  6.811307767806696e-11\n",
      "\n",
      "\n",
      "Stage  613\n",
      "Epoch 150/200\n",
      "Learning rate :  2.1765809607151254e-06\n",
      "Average loss :  3.0842040726897224e-11\n",
      "\n",
      "\n",
      "Stage  613\n",
      "Epoch 200/200\n",
      "Learning rate :  2.1765809607151254e-06\n",
      "Average loss :  1.3993410596935263e-11\n",
      "expression length:\t 5\n",
      "Result stage 615: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1400002]*t)\n",
      "\n",
      "\n",
      "Stage  614\n",
      "Epoch 50/200\n",
      "Learning rate :  2.1549236182976133e-06\n",
      "Average loss :  3.33368020688507e-11\n",
      "\n",
      "\n",
      "Stage  614\n",
      "Epoch 100/200\n",
      "Learning rate :  2.1549236182976133e-06\n",
      "Average loss :  6.763128945763697e-11\n",
      "\n",
      "\n",
      "Stage  614\n",
      "Epoch 150/200\n",
      "Learning rate :  2.1549236182976133e-06\n",
      "Average loss :  3.581421617604441e-11\n",
      "\n",
      "\n",
      "Stage  614\n",
      "Epoch 200/200\n",
      "Learning rate :  2.1549236182976133e-06\n",
      "Average loss :  3.427135658595759e-11\n",
      "expression length:\t 5\n",
      "Result stage 616: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999937]*t)\n",
      "\n",
      "\n",
      "Stage  615\n",
      "Epoch 50/200\n",
      "Learning rate :  2.133481770037708e-06\n",
      "Average loss :  4.091226663005543e-11\n",
      "\n",
      "\n",
      "Stage  615\n",
      "Epoch 100/200\n",
      "Learning rate :  2.133481770037708e-06\n",
      "Average loss :  3.1301006925277264e-11\n",
      "\n",
      "\n",
      "Stage  615\n",
      "Epoch 150/200\n",
      "Learning rate :  2.133481770037708e-06\n",
      "Average loss :  2.9858133326898795e-11\n",
      "\n",
      "\n",
      "Stage  615\n",
      "Epoch 200/200\n",
      "Learning rate :  2.133481770037708e-06\n",
      "Average loss :  2.8732575346746003e-11\n",
      "expression length:\t 5\n",
      "Result stage 617: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999909]*t)\n",
      "\n",
      "\n",
      "Stage  616\n",
      "Epoch 50/200\n",
      "Learning rate :  2.112253271732714e-06\n",
      "Average loss :  3.256172415033731e-11\n",
      "\n",
      "\n",
      "Stage  616\n",
      "Epoch 100/200\n",
      "Learning rate :  2.112253271732714e-06\n",
      "Average loss :  1.8087694536594867e-11\n",
      "\n",
      "\n",
      "Stage  616\n",
      "Epoch 150/200\n",
      "Learning rate :  2.112253271732714e-06\n",
      "Average loss :  6.161464394249805e-11\n",
      "\n",
      "\n",
      "Stage  616\n",
      "Epoch 200/200\n",
      "Learning rate :  2.112253271732714e-06\n",
      "Average loss :  7.33764229932099e-11\n",
      "expression length:\t 5\n",
      "Result stage 618: -1.739*sin(x0) + 25.082*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999847]*t)\n",
      "\n",
      "\n",
      "Stage  617\n",
      "Epoch 50/200\n",
      "Learning rate :  2.0912360005151105e-06\n",
      "Average loss :  3.5500418577028015e-11\n",
      "\n",
      "\n",
      "Stage  617\n",
      "Epoch 100/200\n",
      "Learning rate :  2.0912360005151105e-06\n",
      "Average loss :  2.674883058106925e-11\n",
      "\n",
      "\n",
      "Stage  617\n",
      "Epoch 150/200\n",
      "Learning rate :  2.0912360005151105e-06\n",
      "Average loss :  2.9245904309416204e-11\n",
      "\n",
      "\n",
      "Stage  617\n",
      "Epoch 200/200\n",
      "Learning rate :  2.0912360005151105e-06\n",
      "Average loss :  3.065668205404215e-11\n",
      "expression length:\t 5\n",
      "Result stage 619: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.83*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.1399992]*t)\n",
      "\n",
      "\n",
      "Stage  618\n",
      "Epoch 50/200\n",
      "Learning rate :  2.0704278546402605e-06\n",
      "Average loss :  3.52570923844997e-11\n",
      "\n",
      "\n",
      "Stage  618\n",
      "Epoch 100/200\n",
      "Learning rate :  2.0704278546402605e-06\n",
      "Average loss :  2.9943821727718145e-11\n",
      "\n",
      "\n",
      "Stage  618\n",
      "Epoch 150/200\n",
      "Learning rate :  2.0704278546402605e-06\n",
      "Average loss :  3.900460163186459e-11\n",
      "\n",
      "\n",
      "Stage  618\n",
      "Epoch 200/200\n",
      "Learning rate :  2.0704278546402605e-06\n",
      "Average loss :  3.723931579768802e-11\n",
      "expression length:\t 5\n",
      "Result stage 620: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999934]*t)\n",
      "\n",
      "\n",
      "Stage  619\n",
      "Epoch 50/200\n",
      "Learning rate :  2.049826753276235e-06\n",
      "Average loss :  5.364046359868091e-11\n",
      "\n",
      "\n",
      "Stage  619\n",
      "Epoch 100/200\n",
      "Learning rate :  2.049826753276235e-06\n",
      "Average loss :  3.4982475249911715e-11\n",
      "\n",
      "\n",
      "Stage  619\n",
      "Epoch 150/200\n",
      "Learning rate :  2.049826753276235e-06\n",
      "Average loss :  3.0982445775595835e-11\n",
      "\n",
      "\n",
      "Stage  619\n",
      "Epoch 200/200\n",
      "Learning rate :  2.049826753276235e-06\n",
      "Average loss :  7.942027591134604e-11\n",
      "expression length:\t 5\n",
      "Result stage 621: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999952]*t)\n",
      "\n",
      "\n",
      "Stage  620\n",
      "Epoch 50/200\n",
      "Learning rate :  2.029430636295734e-06\n",
      "Average loss :  2.8645820090988927e-11\n",
      "\n",
      "\n",
      "Stage  620\n",
      "Epoch 100/200\n",
      "Learning rate :  2.029430636295734e-06\n",
      "Average loss :  3.7129323920970236e-11\n",
      "\n",
      "\n",
      "Stage  620\n",
      "Epoch 150/200\n",
      "Learning rate :  2.029430636295734e-06\n",
      "Average loss :  6.806544217141663e-11\n",
      "\n",
      "\n",
      "Stage  620\n",
      "Epoch 200/200\n",
      "Learning rate :  2.029430636295734e-06\n",
      "Average loss :  3.12432649196559e-11\n",
      "expression length:\t 5\n",
      "Result stage 622: -1.739*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999967]*t)\n",
      "\n",
      "\n",
      "Stage  621\n",
      "Epoch 50/200\n",
      "Learning rate :  2.0092374640700603e-06\n",
      "Average loss :  2.965830012136017e-11\n",
      "\n",
      "\n",
      "Stage  621\n",
      "Epoch 100/200\n",
      "Learning rate :  2.0092374640700603e-06\n",
      "Average loss :  3.8588146566986836e-11\n",
      "\n",
      "\n",
      "Stage  621\n",
      "Epoch 150/200\n",
      "Learning rate :  2.0092374640700603e-06\n",
      "Average loss :  3.649925847670765e-11\n",
      "\n",
      "\n",
      "Stage  621\n",
      "Epoch 200/200\n",
      "Learning rate :  2.0092374640700603e-06\n",
      "Average loss :  7.138269142448195e-11\n",
      "expression length:\t 5\n",
      "Result stage 623: -1.738*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.1399994]*t)\n",
      "\n",
      "\n",
      "Stage  622\n",
      "Epoch 50/200\n",
      "Learning rate :  1.9892452172651636e-06\n",
      "Average loss :  5.906145017497977e-11\n",
      "\n",
      "\n",
      "Stage  622\n",
      "Epoch 100/200\n",
      "Learning rate :  1.9892452172651636e-06\n",
      "Average loss :  3.8413518893554155e-11\n",
      "\n",
      "\n",
      "Stage  622\n",
      "Epoch 150/200\n",
      "Learning rate :  1.9892452172651636e-06\n",
      "Average loss :  2.8687323350151672e-11\n",
      "\n",
      "\n",
      "Stage  622\n",
      "Epoch 200/200\n",
      "Learning rate :  1.9892452172651636e-06\n",
      "Average loss :  2.8623140316264006e-11\n",
      "expression length:\t 5\n",
      "Result stage 624: -1.738*sin(x0) + 25.083*cos(x0) + 1.42*x0_t**2 + 19.831*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999924]*t)\n",
      "\n",
      "\n",
      "Stage  623\n",
      "Epoch 50/200\n",
      "Learning rate :  1.9694518966397012e-06\n",
      "Average loss :  7.307442151383015e-11\n",
      "\n",
      "\n",
      "Stage  623\n",
      "Epoch 100/200\n",
      "Learning rate :  1.9694518966397012e-06\n",
      "Average loss :  2.7139753985827575e-11\n",
      "\n",
      "\n",
      "Stage  623\n",
      "Epoch 150/200\n",
      "Learning rate :  1.9694518966397012e-06\n",
      "Average loss :  3.6403491332492877e-11\n",
      "\n",
      "\n",
      "Stage  623\n",
      "Epoch 200/200\n",
      "Learning rate :  1.9694518966397012e-06\n",
      "Average loss :  2.597950847504915e-11\n",
      "expression length:\t 5\n",
      "Result stage 625: -1.738*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999921]*t)\n",
      "\n",
      "\n",
      "Stage  624\n",
      "Epoch 50/200\n",
      "Learning rate :  1.9498555228451207e-06\n",
      "Average loss :  2.4284534452800877e-11\n",
      "\n",
      "\n",
      "Stage  624\n",
      "Epoch 100/200\n",
      "Learning rate :  1.9498555228451207e-06\n",
      "Average loss :  2.8159332504662515e-11\n",
      "\n",
      "\n",
      "Stage  624\n",
      "Epoch 150/200\n",
      "Learning rate :  1.9498555228451207e-06\n",
      "Average loss :  2.587544761789573e-11\n",
      "\n",
      "\n",
      "Stage  624\n",
      "Epoch 200/200\n",
      "Learning rate :  1.9498555228451207e-06\n",
      "Average loss :  2.838783895453556e-11\n",
      "expression length:\t 5\n",
      "Result stage 626: -1.738*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999934]*t)\n",
      "\n",
      "\n",
      "Stage  625\n",
      "Epoch 50/200\n",
      "Learning rate :  1.930454136227709e-06\n",
      "Average loss :  6.525689710823457e-11\n",
      "\n",
      "\n",
      "Stage  625\n",
      "Epoch 100/200\n",
      "Learning rate :  1.930454136227709e-06\n",
      "Average loss :  5.418012566371644e-11\n",
      "\n",
      "\n",
      "Stage  625\n",
      "Epoch 150/200\n",
      "Learning rate :  1.930454136227709e-06\n",
      "Average loss :  2.6538490155436634e-11\n",
      "\n",
      "\n",
      "Stage  625\n",
      "Epoch 200/200\n",
      "Learning rate :  1.930454136227709e-06\n",
      "Average loss :  2.7510318675871837e-11\n",
      "expression length:\t 5\n",
      "Result stage 627: -1.738*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999954]*t)\n",
      "\n",
      "\n",
      "Stage  626\n",
      "Epoch 50/200\n",
      "Learning rate :  1.9112457966326376e-06\n",
      "Average loss :  3.2484390177778266e-11\n",
      "\n",
      "\n",
      "Stage  626\n",
      "Epoch 100/200\n",
      "Learning rate :  1.9112457966326376e-06\n",
      "Average loss :  3.4669649096041866e-11\n",
      "\n",
      "\n",
      "Stage  626\n",
      "Epoch 150/200\n",
      "Learning rate :  1.9112457966326376e-06\n",
      "Average loss :  4.312706095022101e-11\n",
      "\n",
      "\n",
      "Stage  626\n",
      "Epoch 200/200\n",
      "Learning rate :  1.9112457966326376e-06\n",
      "Average loss :  5.58003053485745e-11\n",
      "expression length:\t 5\n",
      "Result stage 628: -1.738*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999921]*t)\n",
      "\n",
      "\n",
      "Stage  627\n",
      "Epoch 50/200\n",
      "Learning rate :  1.892228583209938e-06\n",
      "Average loss :  4.1862267124992414e-11\n",
      "\n",
      "\n",
      "Stage  627\n",
      "Epoch 100/200\n",
      "Learning rate :  1.892228583209938e-06\n",
      "Average loss :  2.9735738177327775e-11\n",
      "\n",
      "\n",
      "Stage  627\n",
      "Epoch 150/200\n",
      "Learning rate :  1.892228583209938e-06\n",
      "Average loss :  2.5569248107704112e-11\n",
      "\n",
      "\n",
      "Stage  627\n",
      "Epoch 200/200\n",
      "Learning rate :  1.892228583209938e-06\n",
      "Average loss :  3.002820908593051e-11\n",
      "expression length:\t 5\n",
      "Result stage 629: -1.738*sin(x0) + 25.084*cos(x0) + 1.42*x0_t**2 + 19.832*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999936]*t)\n",
      "\n",
      "\n",
      "Stage  628\n",
      "Epoch 50/200\n",
      "Learning rate :  1.8734005942224234e-06\n",
      "Average loss :  2.9477132540423057e-11\n",
      "\n",
      "\n",
      "Stage  628\n",
      "Epoch 100/200\n",
      "Learning rate :  1.8734005942224234e-06\n",
      "Average loss :  3.790478000920139e-11\n",
      "\n",
      "\n",
      "Stage  628\n",
      "Epoch 150/200\n",
      "Learning rate :  1.8734005942224234e-06\n",
      "Average loss :  2.557279735193596e-11\n",
      "\n",
      "\n",
      "Stage  628\n",
      "Epoch 200/200\n",
      "Learning rate :  1.8734005942224234e-06\n",
      "Average loss :  2.897911771659878e-11\n",
      "expression length:\t 5\n",
      "Result stage 630: -1.738*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999917]*t)\n",
      "\n",
      "\n",
      "Stage  629\n",
      "Epoch 50/200\n",
      "Learning rate :  1.8547599468555033e-06\n",
      "Average loss :  3.018789038189418e-11\n",
      "\n",
      "\n",
      "Stage  629\n",
      "Epoch 100/200\n",
      "Learning rate :  1.8547599468555033e-06\n",
      "Average loss :  2.956986391855487e-11\n",
      "\n",
      "\n",
      "Stage  629\n",
      "Epoch 150/200\n",
      "Learning rate :  1.8547599468555033e-06\n",
      "Average loss :  3.00370631145519e-11\n",
      "\n",
      "\n",
      "Stage  629\n",
      "Epoch 200/200\n",
      "Learning rate :  1.8547599468555033e-06\n",
      "Average loss :  6.07623049098116e-11\n",
      "expression length:\t 5\n",
      "Result stage 631: -1.738*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.1399996]*t)\n",
      "\n",
      "\n",
      "Stage  630\n",
      "Epoch 50/200\n",
      "Learning rate :  1.836304777028907e-06\n",
      "Average loss :  5.262833571717529e-11\n",
      "\n",
      "\n",
      "Stage  630\n",
      "Epoch 100/200\n",
      "Learning rate :  1.836304777028907e-06\n",
      "Average loss :  2.772206075807304e-11\n",
      "\n",
      "\n",
      "Stage  630\n",
      "Epoch 150/200\n",
      "Learning rate :  1.836304777028907e-06\n",
      "Average loss :  4.918923254826346e-11\n",
      "\n",
      "\n",
      "Stage  630\n",
      "Epoch 200/200\n",
      "Learning rate :  1.836304777028907e-06\n",
      "Average loss :  3.960083302945172e-11\n",
      "expression length:\t 5\n",
      "Result stage 632: -1.738*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.139999]*t)\n",
      "\n",
      "\n",
      "Stage  631\n",
      "Epoch 50/200\n",
      "Learning rate :  1.8180332392102712e-06\n",
      "Average loss :  2.1183554910209068e-11\n",
      "\n",
      "\n",
      "Stage  631\n",
      "Epoch 100/200\n",
      "Learning rate :  1.8180332392102712e-06\n",
      "Average loss :  2.4389627470422504e-11\n",
      "\n",
      "\n",
      "Stage  631\n",
      "Epoch 150/200\n",
      "Learning rate :  1.8180332392102712e-06\n",
      "Average loss :  2.8391755960144316e-11\n",
      "\n",
      "\n",
      "Stage  631\n",
      "Epoch 200/200\n",
      "Learning rate :  1.8180332392102712e-06\n",
      "Average loss :  2.7387248718868662e-11\n",
      "expression length:\t 5\n",
      "Result stage 633: -1.738*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999937]*t)\n",
      "\n",
      "\n",
      "Stage  632\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7999435062305911e-06\n",
      "Average loss :  2.3874825727521198e-11\n",
      "\n",
      "\n",
      "Stage  632\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7999435062305911e-06\n",
      "Average loss :  2.373145777112562e-11\n",
      "\n",
      "\n",
      "Stage  632\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7999435062305911e-06\n",
      "Average loss :  2.281635817780181e-11\n",
      "\n",
      "\n",
      "Stage  632\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7999435062305911e-06\n",
      "Average loss :  2.0627220417845926e-11\n",
      "expression length:\t 5\n",
      "Result stage 634: -1.738*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999927]*t)\n",
      "\n",
      "\n",
      "Stage  633\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7820337691014917e-06\n",
      "Average loss :  2.9391634959186064e-11\n",
      "\n",
      "\n",
      "Stage  633\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7820337691014917e-06\n",
      "Average loss :  2.877822112556938e-11\n",
      "\n",
      "\n",
      "Stage  633\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7820337691014917e-06\n",
      "Average loss :  2.1013382006662695e-11\n",
      "\n",
      "\n",
      "Stage  633\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7820337691014917e-06\n",
      "Average loss :  2.327939403745649e-11\n",
      "expression length:\t 5\n",
      "Result stage 635: -1.738*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999972]*t)\n",
      "\n",
      "\n",
      "Stage  634\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7643022368343356e-06\n",
      "Average loss :  3.413995822154625e-11\n",
      "\n",
      "\n",
      "Stage  634\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7643022368343356e-06\n",
      "Average loss :  2.7197199353734547e-11\n",
      "\n",
      "\n",
      "Stage  634\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7643022368343356e-06\n",
      "Average loss :  2.390129934248808e-11\n",
      "\n",
      "\n",
      "Stage  634\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7643022368343356e-06\n",
      "Average loss :  2.503140750231836e-11\n",
      "expression length:\t 5\n",
      "Result stage 636: -1.738*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.1399993]*t)\n",
      "\n",
      "\n",
      "Stage  635\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7467471362611183e-06\n",
      "Average loss :  3.2317419573768547e-11\n",
      "\n",
      "\n",
      "Stage  635\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7467471362611183e-06\n",
      "Average loss :  2.5960447333495118e-11\n",
      "\n",
      "\n",
      "Stage  635\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7467471362611183e-06\n",
      "Average loss :  2.2027119711554022e-11\n",
      "\n",
      "\n",
      "Stage  635\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7467471362611183e-06\n",
      "Average loss :  1.9552890556662206e-11\n",
      "expression length:\t 5\n",
      "Result stage 637: -1.738*sin(x0) + 25.085*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.1399993]*t)\n",
      "\n",
      "\n",
      "Stage  636\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7293667118571558e-06\n",
      "Average loss :  2.4250880817366927e-11\n",
      "\n",
      "\n",
      "Stage  636\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7293667118571558e-06\n",
      "Average loss :  2.667928898636429e-11\n",
      "\n",
      "\n",
      "Stage  636\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7293667118571558e-06\n",
      "Average loss :  2.2721081960330736e-11\n",
      "\n",
      "\n",
      "Stage  636\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7293667118571558e-06\n",
      "Average loss :  6.921371028395518e-12\n",
      "expression length:\t 5\n",
      "Result stage 638: -1.738*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.833*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999972]*t)\n",
      "\n",
      "\n",
      "Stage  637\n",
      "Epoch 50/200\n",
      "Learning rate :  1.712159225565523e-06\n",
      "Average loss :  1.938046771676749e-11\n",
      "\n",
      "\n",
      "Stage  637\n",
      "Epoch 100/200\n",
      "Learning rate :  1.712159225565523e-06\n",
      "Average loss :  2.465076059943172e-11\n",
      "\n",
      "\n",
      "Stage  637\n",
      "Epoch 150/200\n",
      "Learning rate :  1.712159225565523e-06\n",
      "Average loss :  1.9249827426515154e-11\n",
      "\n",
      "\n",
      "Stage  637\n",
      "Epoch 200/200\n",
      "Learning rate :  1.712159225565523e-06\n",
      "Average loss :  2.276135703527249e-11\n",
      "expression length:\t 5\n",
      "Result stage 639: -1.738*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999933]*t)\n",
      "\n",
      "\n",
      "Stage  638\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6951229566232506e-06\n",
      "Average loss :  2.7361212254217726e-11\n",
      "\n",
      "\n",
      "Stage  638\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6951229566232506e-06\n",
      "Average loss :  3.95822333243423e-11\n",
      "\n",
      "\n",
      "Stage  638\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6951229566232506e-06\n",
      "Average loss :  2.610163300775792e-11\n",
      "\n",
      "\n",
      "Stage  638\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6951229566232506e-06\n",
      "Average loss :  1.7502591390106126e-11\n",
      "expression length:\t 5\n",
      "Result stage 640: -1.738*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999933]*t)\n",
      "\n",
      "\n",
      "Stage  639\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6782562013892463e-06\n",
      "Average loss :  3.86854957790117e-11\n",
      "\n",
      "\n",
      "Stage  639\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6782562013892463e-06\n",
      "Average loss :  1.9000594500551138e-11\n",
      "\n",
      "\n",
      "Stage  639\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6782562013892463e-06\n",
      "Average loss :  2.666500874271005e-11\n",
      "\n",
      "\n",
      "Stage  639\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6782562013892463e-06\n",
      "Average loss :  2.189312273137567e-11\n",
      "expression length:\t 5\n",
      "Result stage 641: -1.738*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999929]*t)\n",
      "\n",
      "\n",
      "Stage  640\n",
      "Epoch 50/200\n",
      "Learning rate :  1.661557273173934e-06\n",
      "Average loss :  3.1568334751819194e-11\n",
      "\n",
      "\n",
      "Stage  640\n",
      "Epoch 100/200\n",
      "Learning rate :  1.661557273173934e-06\n",
      "Average loss :  2.1459433188764088e-11\n",
      "\n",
      "\n",
      "Stage  640\n",
      "Epoch 150/200\n",
      "Learning rate :  1.661557273173934e-06\n",
      "Average loss :  1.9502972153917497e-11\n",
      "\n",
      "\n",
      "Stage  640\n",
      "Epoch 200/200\n",
      "Learning rate :  1.661557273173934e-06\n",
      "Average loss :  1.9108813489876475e-11\n",
      "expression length:\t 5\n",
      "Result stage 642: -1.738*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999923]*t)\n",
      "\n",
      "\n",
      "Stage  641\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6450245020705746e-06\n",
      "Average loss :  2.090127723675117e-11\n",
      "\n",
      "\n",
      "Stage  641\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6450245020705746e-06\n",
      "Average loss :  5.4618646411208616e-11\n",
      "\n",
      "\n",
      "Stage  641\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6450245020705746e-06\n",
      "Average loss :  2.8530967519091455e-11\n",
      "\n",
      "\n",
      "Stage  641\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6450245020705746e-06\n",
      "Average loss :  2.4051526395507672e-11\n",
      "expression length:\t 5\n",
      "Result stage 643: -1.738*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999915]*t)\n",
      "\n",
      "\n",
      "Stage  642\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6286562347882806e-06\n",
      "Average loss :  3.104295986933181e-11\n",
      "\n",
      "\n",
      "Stage  642\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6286562347882806e-06\n",
      "Average loss :  2.3757187189721307e-11\n",
      "\n",
      "\n",
      "Stage  642\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6286562347882806e-06\n",
      "Average loss :  1.9016148031236746e-11\n",
      "\n",
      "\n",
      "Stage  642\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6286562347882806e-06\n",
      "Average loss :  2.0011818591125774e-11\n",
      "expression length:\t 5\n",
      "Result stage 644: -1.738*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999963]*t)\n",
      "\n",
      "\n",
      "Stage  643\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6124508344866837e-06\n",
      "Average loss :  2.371527973998866e-11\n",
      "\n",
      "\n",
      "Stage  643\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6124508344866837e-06\n",
      "Average loss :  2.9870425577449566e-11\n",
      "\n",
      "\n",
      "Stage  643\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6124508344866837e-06\n",
      "Average loss :  4.900554614883923e-11\n",
      "\n",
      "\n",
      "Stage  643\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6124508344866837e-06\n",
      "Average loss :  3.44936267049345e-11\n",
      "expression length:\t 5\n",
      "Result stage 645: -1.738*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999918]*t)\n",
      "\n",
      "\n",
      "Stage  644\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5964066806122474e-06\n",
      "Average loss :  4.948310164398784e-11\n",
      "\n",
      "\n",
      "Stage  644\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5964066806122474e-06\n",
      "Average loss :  1.9206518320213917e-11\n",
      "\n",
      "\n",
      "Stage  644\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5964066806122474e-06\n",
      "Average loss :  2.2644478306355076e-11\n",
      "\n",
      "\n",
      "Stage  644\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5964066806122474e-06\n",
      "Average loss :  2.1519848403261932e-11\n",
      "expression length:\t 5\n",
      "Result stage 646: -1.738*sin(x0) + 25.086*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999937]*t)\n",
      "\n",
      "\n",
      "Stage  645\n",
      "Epoch 50/200\n",
      "Learning rate :  1.580522168736217e-06\n",
      "Average loss :  2.1466313102069812e-11\n",
      "\n",
      "\n",
      "Stage  645\n",
      "Epoch 100/200\n",
      "Learning rate :  1.580522168736217e-06\n",
      "Average loss :  1.788020079218633e-11\n",
      "\n",
      "\n",
      "Stage  645\n",
      "Epoch 150/200\n",
      "Learning rate :  1.580522168736217e-06\n",
      "Average loss :  1.8770181589577994e-11\n",
      "\n",
      "\n",
      "Stage  645\n",
      "Epoch 200/200\n",
      "Learning rate :  1.580522168736217e-06\n",
      "Average loss :  1.8293476108932616e-11\n",
      "expression length:\t 5\n",
      "Result stage 647: -1.738*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999927]*t)\n",
      "\n",
      "\n",
      "Stage  646\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5647957103941665e-06\n",
      "Average loss :  1.894342321895337e-11\n",
      "\n",
      "\n",
      "Stage  646\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5647957103941665e-06\n",
      "Average loss :  1.9075688945102698e-11\n",
      "\n",
      "\n",
      "Stage  646\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5647957103941665e-06\n",
      "Average loss :  1.8110195634801762e-11\n",
      "\n",
      "\n",
      "Stage  646\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5647957103941665e-06\n",
      "Average loss :  1.6336538025130132e-11\n",
      "expression length:\t 5\n",
      "Result stage 648: -1.738*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.834*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.1399992]*t)\n",
      "\n",
      "\n",
      "Stage  647\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5492257329271562e-06\n",
      "Average loss :  1.678722612308281e-11\n",
      "\n",
      "\n",
      "Stage  647\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5492257329271562e-06\n",
      "Average loss :  1.8821534608637336e-11\n",
      "\n",
      "\n",
      "Stage  647\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5492257329271562e-06\n",
      "Average loss :  2.4340045604032134e-11\n",
      "\n",
      "\n",
      "Stage  647\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5492257329271562e-06\n",
      "Average loss :  2.006458887926499e-11\n",
      "expression length:\t 5\n",
      "Result stage 649: -1.738*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999952]*t)\n",
      "\n",
      "\n",
      "Stage  648\n",
      "Epoch 50/200\n",
      "Learning rate :  1.533810679324463e-06\n",
      "Average loss :  2.8208475486013462e-11\n",
      "\n",
      "\n",
      "Stage  648\n",
      "Epoch 100/200\n",
      "Learning rate :  1.533810679324463e-06\n",
      "Average loss :  1.7780905220421417e-11\n",
      "\n",
      "\n",
      "Stage  648\n",
      "Epoch 150/200\n",
      "Learning rate :  1.533810679324463e-06\n",
      "Average loss :  2.1247961723425135e-11\n",
      "\n",
      "\n",
      "Stage  648\n",
      "Epoch 200/200\n",
      "Learning rate :  1.533810679324463e-06\n",
      "Average loss :  2.17246897554757e-11\n",
      "expression length:\t 5\n",
      "Result stage 650: -1.738*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999951]*t)\n",
      "\n",
      "\n",
      "Stage  649\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5185490080678836e-06\n",
      "Average loss :  3.2612555017630385e-11\n",
      "\n",
      "\n",
      "Stage  649\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5185490080678836e-06\n",
      "Average loss :  3.805776180310083e-11\n",
      "\n",
      "\n",
      "Stage  649\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5185490080678836e-06\n",
      "Average loss :  3.517447791367978e-11\n",
      "\n",
      "\n",
      "Stage  649\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5185490080678836e-06\n",
      "Average loss :  1.9450894020445197e-11\n",
      "expression length:\t 5\n",
      "Result stage 651: -1.738*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.1399993]*t)\n",
      "\n",
      "\n",
      "Stage  650\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5034391929775723e-06\n",
      "Average loss :  2.2096349056033304e-11\n",
      "\n",
      "\n",
      "Stage  650\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5034391929775723e-06\n",
      "Average loss :  2.5711851051046786e-11\n",
      "\n",
      "\n",
      "Stage  650\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5034391929775723e-06\n",
      "Average loss :  3.635768075493928e-11\n",
      "\n",
      "\n",
      "Stage  650\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5034391929775723e-06\n",
      "Average loss :  1.6614412970406e-11\n",
      "expression length:\t 5\n",
      "Result stage 652: -1.738*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.1399997]*t)\n",
      "\n",
      "\n",
      "Stage  651\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4884797230594294e-06\n",
      "Average loss :  1.6699731875124968e-11\n",
      "\n",
      "\n",
      "Stage  651\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4884797230594294e-06\n",
      "Average loss :  3.392039774063882e-11\n",
      "\n",
      "\n",
      "Stage  651\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4884797230594294e-06\n",
      "Average loss :  1.5969201655474663e-11\n",
      "\n",
      "\n",
      "Stage  651\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4884797230594294e-06\n",
      "Average loss :  1.7885075365153824e-11\n",
      "expression length:\t 5\n",
      "Result stage 653: -1.738*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999951]*t)\n",
      "\n",
      "\n",
      "Stage  652\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4736691023539949e-06\n",
      "Average loss :  1.5633765115818932e-11\n",
      "\n",
      "\n",
      "Stage  652\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4736691023539949e-06\n",
      "Average loss :  1.5071362560736823e-11\n",
      "\n",
      "\n",
      "Stage  652\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4736691023539949e-06\n",
      "Average loss :  1.5071362560736823e-11\n",
      "\n",
      "\n",
      "Stage  652\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4736691023539949e-06\n",
      "Average loss :  1.5071362560736823e-11\n",
      "expression length:\t 5\n",
      "Result stage 654: -1.738*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.417*x0_t*cos(x0) + \n",
      "exp([0.13999927]*t)\n",
      "\n",
      "\n",
      "Stage  653\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4590058497868585e-06\n",
      "Average loss :  3.565010786577005e-11\n",
      "\n",
      "\n",
      "Stage  653\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4590058497868585e-06\n",
      "Average loss :  1.634004390127508e-11\n",
      "\n",
      "\n",
      "Stage  653\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4590058497868585e-06\n",
      "Average loss :  1.565883533949375e-11\n",
      "\n",
      "\n",
      "Stage  653\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4590058497868585e-06\n",
      "Average loss :  1.5872133468652905e-11\n",
      "expression length:\t 5\n",
      "Result stage 655: -1.738*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999967]*t)\n",
      "\n",
      "\n",
      "Stage  654\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4444884990205433e-06\n",
      "Average loss :  1.0344052003841142e-11\n",
      "\n",
      "\n",
      "Stage  654\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4444884990205433e-06\n",
      "Average loss :  1.732288618105926e-11\n",
      "\n",
      "\n",
      "Stage  654\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4444884990205433e-06\n",
      "Average loss :  1.5035707054411596e-11\n",
      "\n",
      "\n",
      "Stage  654\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4444884990205433e-06\n",
      "Average loss :  2.7060459775740675e-11\n",
      "expression length:\t 5\n",
      "Result stage 656: -1.738*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999934]*t)\n",
      "\n",
      "\n",
      "Stage  655\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4301155983078744e-06\n",
      "Average loss :  1.3190224086578883e-11\n",
      "\n",
      "\n",
      "Stage  655\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4301155983078744e-06\n",
      "Average loss :  1.8643656063410674e-11\n",
      "\n",
      "\n",
      "Stage  655\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4301155983078744e-06\n",
      "Average loss :  1.6590097351443234e-11\n",
      "\n",
      "\n",
      "Stage  655\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4301155983078744e-06\n",
      "Average loss :  1.566451829360105e-11\n",
      "expression length:\t 5\n",
      "Result stage 657: -1.738*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999964]*t)\n",
      "\n",
      "\n",
      "Stage  656\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4158857103468023e-06\n",
      "Average loss :  1.5479983614397064e-11\n",
      "\n",
      "\n",
      "Stage  656\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4158857103468023e-06\n",
      "Average loss :  1.4537742537568121e-11\n",
      "\n",
      "\n",
      "Stage  656\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4158857103468023e-06\n",
      "Average loss :  3.041651999713402e-11\n",
      "\n",
      "\n",
      "Stage  656\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4158857103468023e-06\n",
      "Average loss :  3.389365177408621e-11\n",
      "expression length:\t 5\n",
      "Result stage 658: -1.738*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999948]*t)\n",
      "\n",
      "\n",
      "Stage  657\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4017974121366745e-06\n",
      "Average loss :  1.599080069747405e-11\n",
      "\n",
      "\n",
      "Stage  657\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4017974121366745e-06\n",
      "Average loss :  2.0101028480601357e-11\n",
      "\n",
      "\n",
      "Stage  657\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4017974121366745e-06\n",
      "Average loss :  2.9967937853481175e-11\n",
      "\n",
      "\n",
      "Stage  657\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4017974121366745e-06\n",
      "Average loss :  1.4793645475297268e-11\n",
      "expression length:\t 5\n",
      "Result stage 659: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999982]*t)\n",
      "\n",
      "\n",
      "Stage  658\n",
      "Epoch 50/200\n",
      "Learning rate :  1.387849294835929e-06\n",
      "Average loss :  3.8313852090965383e-11\n",
      "\n",
      "\n",
      "Stage  658\n",
      "Epoch 100/200\n",
      "Learning rate :  1.387849294835929e-06\n",
      "Average loss :  2.7587652648430883e-11\n",
      "\n",
      "\n",
      "Stage  658\n",
      "Epoch 150/200\n",
      "Learning rate :  1.387849294835929e-06\n",
      "Average loss :  1.6918881226568594e-11\n",
      "\n",
      "\n",
      "Stage  658\n",
      "Epoch 200/200\n",
      "Learning rate :  1.387849294835929e-06\n",
      "Average loss :  1.5368199768328594e-11\n",
      "expression length:\t 5\n",
      "Result stage 660: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999969]*t)\n",
      "\n",
      "\n",
      "Stage  659\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3740399636212118e-06\n",
      "Average loss :  1.297675248507213e-11\n",
      "\n",
      "\n",
      "Stage  659\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3740399636212118e-06\n",
      "Average loss :  2.4450051358537728e-11\n",
      "\n",
      "\n",
      "Stage  659\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3740399636212118e-06\n",
      "Average loss :  2.2695356011182e-11\n",
      "\n",
      "\n",
      "Stage  659\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3740399636212118e-06\n",
      "Average loss :  2.5041538287418064e-11\n",
      "expression length:\t 5\n",
      "Result stage 661: -1.739*sin(x0) + 25.087*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999929]*t)\n",
      "\n",
      "\n",
      "Stage  660\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3603680375478928e-06\n",
      "Average loss :  1.3240002844083776e-11\n",
      "\n",
      "\n",
      "Stage  660\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3603680375478928e-06\n",
      "Average loss :  1.4245353160968754e-11\n",
      "\n",
      "\n",
      "Stage  660\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3603680375478928e-06\n",
      "Average loss :  1.4388814792432036e-11\n",
      "\n",
      "\n",
      "Stage  660\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3603680375478928e-06\n",
      "Average loss :  1.4309615992136315e-11\n",
      "expression length:\t 5\n",
      "Result stage 662: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999926]*t)\n",
      "\n",
      "\n",
      "Stage  661\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3468321494119735e-06\n",
      "Average loss :  1.3698224846092621e-11\n",
      "\n",
      "\n",
      "Stage  661\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3468321494119735e-06\n",
      "Average loss :  2.361722102606212e-11\n",
      "\n",
      "\n",
      "Stage  661\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3468321494119735e-06\n",
      "Average loss :  1.3414766693309321e-11\n",
      "\n",
      "\n",
      "Stage  661\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3468321494119735e-06\n",
      "Average loss :  2.7074885736166898e-11\n",
      "expression length:\t 5\n",
      "Result stage 663: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.13999912]*t)\n",
      "\n",
      "\n",
      "Stage  662\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3334309456133594e-06\n",
      "Average loss :  3.0074300688687217e-11\n",
      "\n",
      "\n",
      "Stage  662\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3334309456133594e-06\n",
      "Average loss :  1.3080063941683928e-11\n",
      "\n",
      "\n",
      "Stage  662\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3334309456133594e-06\n",
      "Average loss :  2.226162656993047e-11\n",
      "\n",
      "\n",
      "Stage  662\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3334309456133594e-06\n",
      "Average loss :  1.3085617658892268e-11\n",
      "expression length:\t 5\n",
      "Result stage 664: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.418*x0_t*cos(x0) + \n",
      "exp([0.1399993]*t)\n",
      "\n",
      "\n",
      "Stage  663\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3201630860205027e-06\n",
      "Average loss :  1.475473042356068e-11\n",
      "\n",
      "\n",
      "Stage  663\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3201630860205027e-06\n",
      "Average loss :  1.5883240903069584e-11\n",
      "\n",
      "\n",
      "Stage  663\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3201630860205027e-06\n",
      "Average loss :  1.3394880690742461e-11\n",
      "\n",
      "\n",
      "Stage  663\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3201630860205027e-06\n",
      "Average loss :  2.0502075731565483e-11\n",
      "expression length:\t 5\n",
      "Result stage 665: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999929]*t)\n",
      "\n",
      "\n",
      "Stage  664\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3070272438363864e-06\n",
      "Average loss :  1.3615057865845603e-11\n",
      "\n",
      "\n",
      "Stage  664\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3070272438363864e-06\n",
      "Average loss :  2.0715503964985338e-11\n",
      "\n",
      "\n",
      "Stage  664\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3070272438363864e-06\n",
      "Average loss :  5.381674272886272e-12\n",
      "\n",
      "\n",
      "Stage  664\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3070272438363864e-06\n",
      "Average loss :  1.3027190437497893e-11\n",
      "expression length:\t 5\n",
      "Result stage 666: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999973]*t)\n",
      "\n",
      "\n",
      "Stage  665\n",
      "Epoch 50/200\n",
      "Learning rate :  1.294022105465848e-06\n",
      "Average loss :  1.3806078676126265e-11\n",
      "\n",
      "\n",
      "Stage  665\n",
      "Epoch 100/200\n",
      "Learning rate :  1.294022105465848e-06\n",
      "Average loss :  2.570470919449619e-11\n",
      "\n",
      "\n",
      "Stage  665\n",
      "Epoch 150/200\n",
      "Learning rate :  1.294022105465848e-06\n",
      "Average loss :  1.1907400412902724e-11\n",
      "\n",
      "\n",
      "Stage  665\n",
      "Epoch 200/200\n",
      "Learning rate :  1.294022105465848e-06\n",
      "Average loss :  1.4693850303171274e-11\n",
      "expression length:\t 5\n",
      "Result stage 667: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999952]*t)\n",
      "\n",
      "\n",
      "Stage  666\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2811463703842114e-06\n",
      "Average loss :  1.2275731646471666e-11\n",
      "\n",
      "\n",
      "Stage  666\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2811463703842114e-06\n",
      "Average loss :  1.4934336753369415e-11\n",
      "\n",
      "\n",
      "Stage  666\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2811463703842114e-06\n",
      "Average loss :  1.239242042316846e-11\n",
      "\n",
      "\n",
      "Stage  666\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2811463703842114e-06\n",
      "Average loss :  1.1537320578069998e-11\n",
      "expression length:\t 5\n",
      "Result stage 668: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999976]*t)\n",
      "\n",
      "\n",
      "Stage  667\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2683987510072388e-06\n",
      "Average loss :  2.797906697993291e-11\n",
      "\n",
      "\n",
      "Stage  667\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2683987510072388e-06\n",
      "Average loss :  1.5583081700021317e-11\n",
      "\n",
      "\n",
      "Stage  667\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2683987510072388e-06\n",
      "Average loss :  2.3881546046267133e-11\n",
      "\n",
      "\n",
      "Stage  667\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2683987510072388e-06\n",
      "Average loss :  1.160465733923699e-11\n",
      "expression length:\t 5\n",
      "Result stage 669: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999934]*t)\n",
      "\n",
      "\n",
      "Stage  668\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2557779725623694e-06\n",
      "Average loss :  1.2587222063265013e-11\n",
      "\n",
      "\n",
      "Stage  668\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2557779725623694e-06\n",
      "Average loss :  2.031169850369441e-11\n",
      "\n",
      "\n",
      "Stage  668\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2557779725623694e-06\n",
      "Average loss :  2.356563381933352e-11\n",
      "\n",
      "\n",
      "Stage  668\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2557779725623694e-06\n",
      "Average loss :  1.5130979802435718e-11\n",
      "expression length:\t 5\n",
      "Result stage 670: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999957]*t)\n",
      "\n",
      "\n",
      "Stage  669\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2432827729612405e-06\n",
      "Average loss :  1.6048029224946525e-11\n",
      "\n",
      "\n",
      "Stage  669\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2432827729612405e-06\n",
      "Average loss :  1.2318772737995864e-11\n",
      "\n",
      "\n",
      "Stage  669\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2432827729612405e-06\n",
      "Average loss :  1.0517055976100309e-11\n",
      "\n",
      "\n",
      "Stage  669\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2432827729612405e-06\n",
      "Average loss :  6.690690102645336e-12\n",
      "expression length:\t 5\n",
      "Result stage 671: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999978]*t)\n",
      "\n",
      "\n",
      "Stage  670\n",
      "Epoch 50/200\n",
      "Learning rate :  1.230911902673481e-06\n",
      "Average loss :  7.53605684800096e-12\n",
      "\n",
      "\n",
      "Stage  670\n",
      "Epoch 100/200\n",
      "Learning rate :  1.230911902673481e-06\n",
      "Average loss :  1.2311401030584701e-11\n",
      "\n",
      "\n",
      "Stage  670\n",
      "Epoch 150/200\n",
      "Learning rate :  1.230911902673481e-06\n",
      "Average loss :  1.2311401030584701e-11\n",
      "\n",
      "\n",
      "Stage  670\n",
      "Epoch 200/200\n",
      "Learning rate :  1.230911902673481e-06\n",
      "Average loss :  1.2311401030584701e-11\n",
      "expression length:\t 5\n",
      "Result stage 672: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999979]*t)\n",
      "\n",
      "\n",
      "Stage  671\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2186641246017523e-06\n",
      "Average loss :  3.295149569870759e-11\n",
      "\n",
      "\n",
      "Stage  671\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2186641246017523e-06\n",
      "Average loss :  1.2676277562351235e-11\n",
      "\n",
      "\n",
      "Stage  671\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2186641246017523e-06\n",
      "Average loss :  1.3777843449469529e-11\n",
      "\n",
      "\n",
      "Stage  671\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2186641246017523e-06\n",
      "Average loss :  1.2411587382854528e-11\n",
      "expression length:\t 5\n",
      "Result stage 673: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999966]*t)\n",
      "\n",
      "\n",
      "Stage  672\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2065382139580405e-06\n",
      "Average loss :  1.1597976919131003e-11\n",
      "\n",
      "\n",
      "Stage  672\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2065382139580405e-06\n",
      "Average loss :  1.2285434822234542e-11\n",
      "\n",
      "\n",
      "Stage  672\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2065382139580405e-06\n",
      "Average loss :  1.1856077751504213e-11\n",
      "\n",
      "\n",
      "Stage  672\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2065382139580405e-06\n",
      "Average loss :  1.670433583123021e-11\n",
      "expression length:\t 5\n",
      "Result stage 674: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999936]*t)\n",
      "\n",
      "\n",
      "Stage  673\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1945329581411753e-06\n",
      "Average loss :  9.569400827302843e-12\n",
      "\n",
      "\n",
      "Stage  673\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1945329581411753e-06\n",
      "Average loss :  1.5430884001133016e-11\n",
      "\n",
      "\n",
      "Stage  673\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1945329581411753e-06\n",
      "Average loss :  1.6015928167023574e-11\n",
      "\n",
      "\n",
      "Stage  673\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1945329581411753e-06\n",
      "Average loss :  1.400573493987034e-11\n",
      "expression length:\t 5\n",
      "Result stage 675: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999954]*t)\n",
      "\n",
      "\n",
      "Stage  674\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1826471566155728e-06\n",
      "Average loss :  9.635220572790093e-12\n",
      "\n",
      "\n",
      "Stage  674\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1826471566155728e-06\n",
      "Average loss :  1.2443288587016266e-11\n",
      "\n",
      "\n",
      "Stage  674\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1826471566155728e-06\n",
      "Average loss :  2.0638393771754693e-11\n",
      "\n",
      "\n",
      "Stage  674\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1826471566155728e-06\n",
      "Average loss :  9.874747720906019e-12\n",
      "expression length:\t 5\n",
      "Result stage 676: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999963]*t)\n",
      "\n",
      "\n",
      "Stage  675\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1708796207911744e-06\n",
      "Average loss :  1.0103095443581012e-11\n",
      "\n",
      "\n",
      "Stage  675\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1708796207911744e-06\n",
      "Average loss :  1.1430299415304823e-11\n",
      "\n",
      "\n",
      "Stage  675\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1708796207911744e-06\n",
      "Average loss :  1.0284597826148989e-11\n",
      "\n",
      "\n",
      "Stage  675\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1708796207911744e-06\n",
      "Average loss :  1.3583678452888659e-11\n",
      "expression length:\t 5\n",
      "Result stage 677: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999952]*t)\n",
      "\n",
      "\n",
      "Stage  676\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1592291739045915e-06\n",
      "Average loss :  9.256014357750253e-12\n",
      "\n",
      "\n",
      "Stage  676\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1592291739045915e-06\n",
      "Average loss :  9.541913266464253e-12\n",
      "\n",
      "\n",
      "Stage  676\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1592291739045915e-06\n",
      "Average loss :  9.000278820836538e-12\n",
      "\n",
      "\n",
      "Stage  676\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1592291739045915e-06\n",
      "Average loss :  9.639893917834375e-12\n",
      "expression length:\t 5\n",
      "Result stage 678: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999952]*t)\n",
      "\n",
      "\n",
      "Stage  677\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1476946509014253e-06\n",
      "Average loss :  1.624120456178435e-11\n",
      "\n",
      "\n",
      "Stage  677\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1476946509014253e-06\n",
      "Average loss :  1.6289990190099246e-11\n",
      "\n",
      "\n",
      "Stage  677\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1476946509014253e-06\n",
      "Average loss :  7.221363264309222e-12\n",
      "\n",
      "\n",
      "Stage  677\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1476946509014253e-06\n",
      "Average loss :  1.1308331875070632e-11\n",
      "expression length:\t 5\n",
      "Result stage 679: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.1399998]*t)\n",
      "\n",
      "\n",
      "Stage  678\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1362748983197658e-06\n",
      "Average loss :  1.4923827798551947e-11\n",
      "\n",
      "\n",
      "Stage  678\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1362748983197658e-06\n",
      "Average loss :  1.4209309943946646e-11\n",
      "\n",
      "\n",
      "Stage  678\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1362748983197658e-06\n",
      "Average loss :  9.359659748631177e-12\n",
      "\n",
      "\n",
      "Stage  678\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1362748983197658e-06\n",
      "Average loss :  1.075045781562256e-11\n",
      "expression length:\t 5\n",
      "Result stage 680: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999957]*t)\n",
      "\n",
      "\n",
      "Stage  679\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1249687741748374e-06\n",
      "Average loss :  9.927337597803731e-12\n",
      "\n",
      "\n",
      "Stage  679\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1249687741748374e-06\n",
      "Average loss :  1.9536714260248722e-11\n",
      "\n",
      "\n",
      "Stage  679\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1249687741748374e-06\n",
      "Average loss :  1.0365934673128852e-11\n",
      "\n",
      "\n",
      "Stage  679\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1249687741748374e-06\n",
      "Average loss :  1.709653772719033e-11\n",
      "expression length:\t 5\n",
      "Result stage 681: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.835*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.1399994]*t)\n",
      "\n",
      "\n",
      "Stage  680\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1137751478448033e-06\n",
      "Average loss :  1.0217817911217786e-11\n",
      "\n",
      "\n",
      "Stage  680\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1137751478448033e-06\n",
      "Average loss :  1.0367355411655677e-11\n",
      "\n",
      "\n",
      "Stage  680\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1137751478448033e-06\n",
      "Average loss :  1.136771492910027e-11\n",
      "\n",
      "\n",
      "Stage  680\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1137751478448033e-06\n",
      "Average loss :  5.7331027945861646e-12\n",
      "expression length:\t 5\n",
      "Result stage 682: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999961]*t)\n",
      "\n",
      "\n",
      "Stage  681\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1026928999577018e-06\n",
      "Average loss :  8.428897337042773e-12\n",
      "\n",
      "\n",
      "Stage  681\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1026928999577018e-06\n",
      "Average loss :  9.866407170433522e-12\n",
      "\n",
      "\n",
      "Stage  681\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1026928999577018e-06\n",
      "Average loss :  1.5671578618148274e-11\n",
      "\n",
      "\n",
      "Stage  681\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1026928999577018e-06\n",
      "Average loss :  8.925253765224017e-12\n",
      "expression length:\t 5\n",
      "Result stage 683: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999982]*t)\n",
      "\n",
      "\n",
      "Stage  682\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0917209222795109e-06\n",
      "Average loss :  9.640690155909848e-12\n",
      "\n",
      "\n",
      "Stage  682\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0917209222795109e-06\n",
      "Average loss :  9.292492990364831e-12\n",
      "\n",
      "\n",
      "Stage  682\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0917209222795109e-06\n",
      "Average loss :  8.52328450873241e-12\n",
      "\n",
      "\n",
      "Stage  682\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0917209222795109e-06\n",
      "Average loss :  1.6647848030681978e-11\n",
      "expression length:\t 5\n",
      "Result stage 684: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999946]*t)\n",
      "\n",
      "\n",
      "Stage  683\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0808581176033184e-06\n",
      "Average loss :  1.0680185034972478e-11\n",
      "\n",
      "\n",
      "Stage  683\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0808581176033184e-06\n",
      "Average loss :  1.002951541262398e-11\n",
      "\n",
      "\n",
      "Stage  683\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0808581176033184e-06\n",
      "Average loss :  8.837146292517417e-12\n",
      "\n",
      "\n",
      "Stage  683\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0808581176033184e-06\n",
      "Average loss :  8.837146292517417e-12\n",
      "expression length:\t 5\n",
      "Result stage 685: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999943]*t)\n",
      "\n",
      "\n",
      "Stage  684\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0701033996396044e-06\n",
      "Average loss :  8.25745288118851e-12\n",
      "\n",
      "\n",
      "Stage  684\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0701033996396044e-06\n",
      "Average loss :  8.25745288118851e-12\n",
      "\n",
      "\n",
      "Stage  684\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0701033996396044e-06\n",
      "Average loss :  8.25745288118851e-12\n",
      "\n",
      "\n",
      "Stage  684\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0701033996396044e-06\n",
      "Average loss :  8.25745288118851e-12\n",
      "expression length:\t 5\n",
      "Result stage 686: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999952]*t)\n",
      "\n",
      "\n",
      "Stage  685\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0594556929076091e-06\n",
      "Average loss :  8.562919470711527e-12\n",
      "\n",
      "\n",
      "Stage  685\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0594556929076091e-06\n",
      "Average loss :  8.697160179538255e-12\n",
      "\n",
      "\n",
      "Stage  685\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0594556929076091e-06\n",
      "Average loss :  1.6146270084838044e-11\n",
      "\n",
      "\n",
      "Stage  685\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0594556929076091e-06\n",
      "Average loss :  1.1050126959288864e-11\n",
      "expression length:\t 5\n",
      "Result stage 687: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.1399995]*t)\n",
      "\n",
      "\n",
      "Stage  686\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0489139326277882e-06\n",
      "Average loss :  8.967613977783895e-12\n",
      "\n",
      "\n",
      "Stage  686\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0489139326277882e-06\n",
      "Average loss :  1.0243379061636304e-11\n",
      "\n",
      "\n",
      "Stage  686\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0489139326277882e-06\n",
      "Average loss :  1.1428857860096286e-11\n",
      "\n",
      "\n",
      "Stage  686\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0489139326277882e-06\n",
      "Average loss :  9.128758512999546e-12\n",
      "expression length:\t 5\n",
      "Result stage 688: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  687\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0384770646153283e-06\n",
      "Average loss :  8.696997115531513e-12\n",
      "\n",
      "\n",
      "Stage  687\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0384770646153283e-06\n",
      "Average loss :  1.8687959166263646e-11\n",
      "\n",
      "\n",
      "Stage  687\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0384770646153283e-06\n",
      "Average loss :  7.814952678042442e-12\n",
      "\n",
      "\n",
      "Stage  687\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0384770646153283e-06\n",
      "Average loss :  1.7838088645083516e-11\n",
      "expression length:\t 5\n",
      "Result stage 689: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999973]*t)\n",
      "\n",
      "\n",
      "Stage  688\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0281440451747297e-06\n",
      "Average loss :  2.0526127672559902e-11\n",
      "\n",
      "\n",
      "Stage  688\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0281440451747297e-06\n",
      "Average loss :  7.664285005259952e-12\n",
      "\n",
      "\n",
      "Stage  688\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0281440451747297e-06\n",
      "Average loss :  9.272114326330794e-12\n",
      "\n",
      "\n",
      "Stage  688\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0281440451747297e-06\n",
      "Average loss :  1.2659422121696906e-11\n",
      "expression length:\t 5\n",
      "Result stage 690: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999954]*t)\n",
      "\n",
      "\n",
      "Stage  689\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0179138409954376e-06\n",
      "Average loss :  8.388205061105047e-12\n",
      "\n",
      "\n",
      "Stage  689\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0179138409954376e-06\n",
      "Average loss :  1.1288579446211422e-11\n",
      "\n",
      "\n",
      "Stage  689\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0179138409954376e-06\n",
      "Average loss :  7.772439809816678e-12\n",
      "\n",
      "\n",
      "Stage  689\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0179138409954376e-06\n",
      "Average loss :  1.120962697664929e-11\n",
      "expression length:\t 5\n",
      "Result stage 691: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999958]*t)\n",
      "\n",
      "\n",
      "Stage  690\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0077854290485105e-06\n",
      "Average loss :  9.256172217586567e-12\n",
      "\n",
      "\n",
      "Stage  690\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0077854290485105e-06\n",
      "Average loss :  8.388185111785074e-12\n",
      "\n",
      "\n",
      "Stage  690\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0077854290485105e-06\n",
      "Average loss :  1.0838352784703353e-11\n",
      "\n",
      "\n",
      "Stage  690\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0077854290485105e-06\n",
      "Average loss :  1.4593172156796008e-11\n",
      "expression length:\t 5\n",
      "Result stage 692: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999951]*t)\n",
      "\n",
      "\n",
      "Stage  691\n",
      "Epoch 50/200\n",
      "Learning rate :  9.97757796484312e-07\n",
      "Average loss :  9.53581744816967e-12\n",
      "\n",
      "\n",
      "Stage  691\n",
      "Epoch 100/200\n",
      "Learning rate :  9.97757796484312e-07\n",
      "Average loss :  1.1969395960487184e-11\n",
      "\n",
      "\n",
      "Stage  691\n",
      "Epoch 150/200\n",
      "Learning rate :  9.97757796484312e-07\n",
      "Average loss :  7.701204257637428e-12\n",
      "\n",
      "\n",
      "Stage  691\n",
      "Epoch 200/200\n",
      "Learning rate :  9.97757796484312e-07\n",
      "Average loss :  1.4081257861120466e-11\n",
      "expression length:\t 5\n",
      "Result stage 693: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999945]*t)\n",
      "\n",
      "\n",
      "Stage  692\n",
      "Epoch 50/200\n",
      "Learning rate :  9.878299405312295e-07\n",
      "Average loss :  8.195568355906513e-12\n",
      "\n",
      "\n",
      "Stage  692\n",
      "Epoch 100/200\n",
      "Learning rate :  9.878299405312295e-07\n",
      "Average loss :  1.835293375607172e-11\n",
      "\n",
      "\n",
      "Stage  692\n",
      "Epoch 150/200\n",
      "Learning rate :  9.878299405312295e-07\n",
      "Average loss :  1.9122684338790386e-11\n",
      "\n",
      "\n",
      "Stage  692\n",
      "Epoch 200/200\n",
      "Learning rate :  9.878299405312295e-07\n",
      "Average loss :  8.403363074838133e-12\n",
      "expression length:\t 5\n",
      "Result stage 694: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999943]*t)\n",
      "\n",
      "\n",
      "Stage  693\n",
      "Epoch 50/200\n",
      "Learning rate :  9.780008683953945e-07\n",
      "Average loss :  1.0489974340555097e-11\n",
      "\n",
      "\n",
      "Stage  693\n",
      "Epoch 100/200\n",
      "Learning rate :  9.780008683953945e-07\n",
      "Average loss :  6.524423362685994e-12\n",
      "\n",
      "\n",
      "Stage  693\n",
      "Epoch 150/200\n",
      "Learning rate :  9.780008683953945e-07\n",
      "Average loss :  1.0052640143920488e-11\n",
      "\n",
      "\n",
      "Stage  693\n",
      "Epoch 200/200\n",
      "Learning rate :  9.780008683953945e-07\n",
      "Average loss :  6.200171452641623e-12\n",
      "expression length:\t 5\n",
      "Result stage 695: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999957]*t)\n",
      "\n",
      "\n",
      "Stage  694\n",
      "Epoch 50/200\n",
      "Learning rate :  9.682695971614018e-07\n",
      "Average loss :  8.122504405183584e-12\n",
      "\n",
      "\n",
      "Stage  694\n",
      "Epoch 100/200\n",
      "Learning rate :  9.682695971614018e-07\n",
      "Average loss :  1.0816346082687112e-11\n",
      "\n",
      "\n",
      "Stage  694\n",
      "Epoch 150/200\n",
      "Learning rate :  9.682695971614018e-07\n",
      "Average loss :  6.34551959588503e-12\n",
      "\n",
      "\n",
      "Stage  694\n",
      "Epoch 200/200\n",
      "Learning rate :  9.682695971614018e-07\n",
      "Average loss :  1.4061758701888749e-11\n",
      "expression length:\t 5\n",
      "Result stage 696: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.1399995]*t)\n",
      "\n",
      "\n",
      "Stage  695\n",
      "Epoch 50/200\n",
      "Learning rate :  9.586351536940198e-07\n",
      "Average loss :  1.471381176620934e-11\n",
      "\n",
      "\n",
      "Stage  695\n",
      "Epoch 100/200\n",
      "Learning rate :  9.586351536940198e-07\n",
      "Average loss :  8.254596658985314e-12\n",
      "\n",
      "\n",
      "Stage  695\n",
      "Epoch 150/200\n",
      "Learning rate :  9.586351536940198e-07\n",
      "Average loss :  8.254596658985314e-12\n",
      "\n",
      "\n",
      "Stage  695\n",
      "Epoch 200/200\n",
      "Learning rate :  9.586351536940198e-07\n",
      "Average loss :  8.254596658985314e-12\n",
      "expression length:\t 5\n",
      "Result stage 697: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999982]*t)\n",
      "\n",
      "\n",
      "Stage  696\n",
      "Epoch 50/200\n",
      "Learning rate :  9.490965745408728e-07\n",
      "Average loss :  9.048636839814606e-12\n",
      "\n",
      "\n",
      "Stage  696\n",
      "Epoch 100/200\n",
      "Learning rate :  9.490965745408728e-07\n",
      "Average loss :  8.746577247198406e-12\n",
      "\n",
      "\n",
      "Stage  696\n",
      "Epoch 150/200\n",
      "Learning rate :  9.490965745408728e-07\n",
      "Average loss :  9.468865795614345e-12\n",
      "\n",
      "\n",
      "Stage  696\n",
      "Epoch 200/200\n",
      "Learning rate :  9.490965745408728e-07\n",
      "Average loss :  7.178070204200138e-12\n",
      "expression length:\t 5\n",
      "Result stage 698: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999954]*t)\n",
      "\n",
      "\n",
      "Stage  697\n",
      "Epoch 50/200\n",
      "Learning rate :  9.396529058360962e-07\n",
      "Average loss :  8.434893408737487e-12\n",
      "\n",
      "\n",
      "Stage  697\n",
      "Epoch 100/200\n",
      "Learning rate :  9.396529058360962e-07\n",
      "Average loss :  7.92761255946628e-12\n",
      "\n",
      "\n",
      "Stage  697\n",
      "Epoch 150/200\n",
      "Learning rate :  9.396529058360962e-07\n",
      "Average loss :  6.871966537480567e-12\n",
      "\n",
      "\n",
      "Stage  697\n",
      "Epoch 200/200\n",
      "Learning rate :  9.396529058360962e-07\n",
      "Average loss :  1.3363157802537273e-11\n",
      "expression length:\t 5\n",
      "Result stage 699: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999957]*t)\n",
      "\n",
      "\n",
      "Stage  698\n",
      "Epoch 50/200\n",
      "Learning rate :  9.30303203204949e-07\n",
      "Average loss :  6.363964043243353e-12\n",
      "\n",
      "\n",
      "Stage  698\n",
      "Epoch 100/200\n",
      "Learning rate :  9.30303203204949e-07\n",
      "Average loss :  7.492316662915943e-12\n",
      "\n",
      "\n",
      "Stage  698\n",
      "Epoch 150/200\n",
      "Learning rate :  9.30303203204949e-07\n",
      "Average loss :  1.595616000438227e-11\n",
      "\n",
      "\n",
      "Stage  698\n",
      "Epoch 200/200\n",
      "Learning rate :  9.30303203204949e-07\n",
      "Average loss :  6.587144024683411e-12\n",
      "expression length:\t 5\n",
      "Result stage 700: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999982]*t)\n",
      "\n",
      "\n",
      "Stage  699\n",
      "Epoch 50/200\n",
      "Learning rate :  9.210465316693784e-07\n",
      "Average loss :  4.614787718626445e-12\n",
      "\n",
      "\n",
      "Stage  699\n",
      "Epoch 100/200\n",
      "Learning rate :  9.210465316693784e-07\n",
      "Average loss :  6.2711788886837816e-12\n",
      "\n",
      "\n",
      "Stage  699\n",
      "Epoch 150/200\n",
      "Learning rate :  9.210465316693784e-07\n",
      "Average loss :  8.073593876778418e-12\n",
      "\n",
      "\n",
      "Stage  699\n",
      "Epoch 200/200\n",
      "Learning rate :  9.210465316693784e-07\n",
      "Average loss :  1.853058505252303e-11\n",
      "expression length:\t 5\n",
      "Result stage 701: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  700\n",
      "Epoch 50/200\n",
      "Learning rate :  9.118819655545163e-07\n",
      "Average loss :  1.139448691650502e-11\n",
      "\n",
      "\n",
      "Stage  700\n",
      "Epoch 100/200\n",
      "Learning rate :  9.118819655545163e-07\n",
      "Average loss :  1.0441494890933711e-11\n",
      "\n",
      "\n",
      "Stage  700\n",
      "Epoch 150/200\n",
      "Learning rate :  9.118819655545163e-07\n",
      "Average loss :  6.364651861101578e-12\n",
      "\n",
      "\n",
      "Stage  700\n",
      "Epoch 200/200\n",
      "Learning rate :  9.118819655545163e-07\n",
      "Average loss :  6.918478810680195e-12\n",
      "expression length:\t 5\n",
      "Result stage 702: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999958]*t)\n",
      "\n",
      "\n",
      "Stage  701\n",
      "Epoch 50/200\n",
      "Learning rate :  9.028085883961136e-07\n",
      "Average loss :  7.1006664090211835e-12\n",
      "\n",
      "\n",
      "Stage  701\n",
      "Epoch 100/200\n",
      "Learning rate :  9.028085883961136e-07\n",
      "Average loss :  5.821395449023825e-12\n",
      "\n",
      "\n",
      "Stage  701\n",
      "Epoch 150/200\n",
      "Learning rate :  9.028085883961136e-07\n",
      "Average loss :  9.527740575665522e-12\n",
      "\n",
      "\n",
      "Stage  701\n",
      "Epoch 200/200\n",
      "Learning rate :  9.028085883961136e-07\n",
      "Average loss :  7.371896496022323e-12\n",
      "expression length:\t 5\n",
      "Result stage 703: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999966]*t)\n",
      "\n",
      "\n",
      "Stage  702\n",
      "Epoch 50/200\n",
      "Learning rate :  8.938254928488927e-07\n",
      "Average loss :  1.0237544319224856e-11\n",
      "\n",
      "\n",
      "Stage  702\n",
      "Epoch 100/200\n",
      "Learning rate :  8.938254928488927e-07\n",
      "Average loss :  7.2386675646629595e-12\n",
      "\n",
      "\n",
      "Stage  702\n",
      "Epoch 150/200\n",
      "Learning rate :  8.938254928488927e-07\n",
      "Average loss :  7.2386675646629595e-12\n",
      "\n",
      "\n",
      "Stage  702\n",
      "Epoch 200/200\n",
      "Learning rate :  8.938254928488927e-07\n",
      "Average loss :  7.2386675646629595e-12\n",
      "expression length:\t 5\n",
      "Result stage 704: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.1399995]*t)\n",
      "\n",
      "\n",
      "Stage  703\n",
      "Epoch 50/200\n",
      "Learning rate :  8.849317805958146e-07\n",
      "Average loss :  8.731080095025767e-12\n",
      "\n",
      "\n",
      "Stage  703\n",
      "Epoch 100/200\n",
      "Learning rate :  8.849317805958146e-07\n",
      "Average loss :  8.942919321741627e-12\n",
      "\n",
      "\n",
      "Stage  703\n",
      "Epoch 150/200\n",
      "Learning rate :  8.849317805958146e-07\n",
      "Average loss :  8.98527693221629e-12\n",
      "\n",
      "\n",
      "Stage  703\n",
      "Epoch 200/200\n",
      "Learning rate :  8.849317805958146e-07\n",
      "Average loss :  6.597348101849976e-12\n",
      "expression length:\t 5\n",
      "Result stage 705: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999975]*t)\n",
      "\n",
      "\n",
      "Stage  704\n",
      "Epoch 50/200\n",
      "Learning rate :  8.761265622582417e-07\n",
      "Average loss :  7.453486612629678e-12\n",
      "\n",
      "\n",
      "Stage  704\n",
      "Epoch 100/200\n",
      "Learning rate :  8.761265622582417e-07\n",
      "Average loss :  1.0081484258517293e-11\n",
      "\n",
      "\n",
      "Stage  704\n",
      "Epoch 150/200\n",
      "Learning rate :  8.761265622582417e-07\n",
      "Average loss :  6.206775978595536e-12\n",
      "\n",
      "\n",
      "Stage  704\n",
      "Epoch 200/200\n",
      "Learning rate :  8.761265622582417e-07\n",
      "Average loss :  7.146564590110316e-12\n",
      "expression length:\t 5\n",
      "Result stage 706: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999946]*t)\n",
      "\n",
      "\n",
      "Stage  705\n",
      "Epoch 50/200\n",
      "Learning rate :  8.674089573070026e-07\n",
      "Average loss :  6.469127750846626e-12\n",
      "\n",
      "\n",
      "Stage  705\n",
      "Epoch 100/200\n",
      "Learning rate :  8.674089573070026e-07\n",
      "Average loss :  6.70067864042001e-12\n",
      "\n",
      "\n",
      "Stage  705\n",
      "Epoch 150/200\n",
      "Learning rate :  8.674089573070026e-07\n",
      "Average loss :  5.67070435747441e-12\n",
      "\n",
      "\n",
      "Stage  705\n",
      "Epoch 200/200\n",
      "Learning rate :  8.674089573070026e-07\n",
      "Average loss :  4.805158874965354e-12\n",
      "expression length:\t 5\n",
      "Result stage 707: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999979]*t)\n",
      "\n",
      "\n",
      "Stage  706\n",
      "Epoch 50/200\n",
      "Learning rate :  8.587780939743365e-07\n",
      "Average loss :  6.7869698576472626e-12\n",
      "\n",
      "\n",
      "Stage  706\n",
      "Epoch 100/200\n",
      "Learning rate :  8.587780939743365e-07\n",
      "Average loss :  6.897565851815557e-12\n",
      "\n",
      "\n",
      "Stage  706\n",
      "Epoch 150/200\n",
      "Learning rate :  8.587780939743365e-07\n",
      "Average loss :  9.865394091923552e-12\n",
      "\n",
      "\n",
      "Stage  706\n",
      "Epoch 200/200\n",
      "Learning rate :  8.587780939743365e-07\n",
      "Average loss :  6.8488361683327614e-12\n",
      "expression length:\t 5\n",
      "Result stage 708: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.42*x0_t*cos(x0) + \n",
      "exp([0.13999975]*t)\n",
      "\n",
      "\n",
      "Stage  707\n",
      "Epoch 50/200\n",
      "Learning rate :  8.502331091667194e-07\n",
      "Average loss :  5.638370412924809e-12\n",
      "\n",
      "\n",
      "Stage  707\n",
      "Epoch 100/200\n",
      "Learning rate :  8.502331091667194e-07\n",
      "Average loss :  6.317900629743134e-12\n",
      "\n",
      "\n",
      "Stage  707\n",
      "Epoch 150/200\n",
      "Learning rate :  8.502331091667194e-07\n",
      "Average loss :  7.42735213610235e-12\n",
      "\n",
      "\n",
      "Stage  707\n",
      "Epoch 200/200\n",
      "Learning rate :  8.502331091667194e-07\n",
      "Average loss :  4.838302935378236e-12\n",
      "expression length:\t 5\n",
      "Result stage 709: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999975]*t)\n",
      "\n",
      "\n",
      "Stage  708\n",
      "Epoch 50/200\n",
      "Learning rate :  8.41773148378549e-07\n",
      "Average loss :  5.673033223740909e-12\n",
      "\n",
      "\n",
      "Stage  708\n",
      "Epoch 100/200\n",
      "Learning rate :  8.41773148378549e-07\n",
      "Average loss :  8.44606849736973e-12\n",
      "\n",
      "\n",
      "Stage  708\n",
      "Epoch 150/200\n",
      "Learning rate :  8.41773148378549e-07\n",
      "Average loss :  8.768610837428525e-12\n",
      "\n",
      "\n",
      "Stage  708\n",
      "Epoch 200/200\n",
      "Learning rate :  8.41773148378549e-07\n",
      "Average loss :  4.525812016820119e-12\n",
      "expression length:\t 5\n",
      "Result stage 710: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999972]*t)\n",
      "\n",
      "\n",
      "Stage  709\n",
      "Epoch 50/200\n",
      "Learning rate :  8.333973656066965e-07\n",
      "Average loss :  4.121243710880629e-12\n",
      "\n",
      "\n",
      "Stage  709\n",
      "Epoch 100/200\n",
      "Learning rate :  8.333973656066965e-07\n",
      "Average loss :  4.121243710880629e-12\n",
      "\n",
      "\n",
      "Stage  709\n",
      "Epoch 150/200\n",
      "Learning rate :  8.333973656066965e-07\n",
      "Average loss :  4.121243710880629e-12\n",
      "\n",
      "\n",
      "Stage  709\n",
      "Epoch 200/200\n",
      "Learning rate :  8.333973656066965e-07\n",
      "Average loss :  4.121243710880629e-12\n",
      "expression length:\t 5\n",
      "Result stage 711: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999972]*t)\n",
      "\n",
      "\n",
      "Stage  710\n",
      "Epoch 50/200\n",
      "Learning rate :  8.251049232659039e-07\n",
      "Average loss :  6.321656739749493e-12\n",
      "\n",
      "\n",
      "Stage  710\n",
      "Epoch 100/200\n",
      "Learning rate :  8.251049232659039e-07\n",
      "Average loss :  8.133071473237496e-12\n",
      "\n",
      "\n",
      "Stage  710\n",
      "Epoch 150/200\n",
      "Learning rate :  8.251049232659039e-07\n",
      "Average loss :  6.687438363489617e-12\n",
      "\n",
      "\n",
      "Stage  710\n",
      "Epoch 200/200\n",
      "Learning rate :  8.251049232659039e-07\n",
      "Average loss :  7.265795604061154e-12\n",
      "expression length:\t 5\n",
      "Result stage 712: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999957]*t)\n",
      "\n",
      "\n",
      "Stage  711\n",
      "Epoch 50/200\n",
      "Learning rate :  8.168949921050283e-07\n",
      "Average loss :  1.1472971010728639e-11\n",
      "\n",
      "\n",
      "Stage  711\n",
      "Epoch 100/200\n",
      "Learning rate :  8.168949921050283e-07\n",
      "Average loss :  5.917532089338984e-12\n",
      "\n",
      "\n",
      "Stage  711\n",
      "Epoch 150/200\n",
      "Learning rate :  8.168949921050283e-07\n",
      "Average loss :  7.57634233128357e-12\n",
      "\n",
      "\n",
      "Stage  711\n",
      "Epoch 200/200\n",
      "Learning rate :  8.168949921050283e-07\n",
      "Average loss :  4.287267589553334e-12\n",
      "expression length:\t 5\n",
      "Result stage 713: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999969]*t)\n",
      "\n",
      "\n",
      "Stage  712\n",
      "Epoch 50/200\n",
      "Learning rate :  8.087667511241115e-07\n",
      "Average loss :  1.2889229614176934e-11\n",
      "\n",
      "\n",
      "Stage  712\n",
      "Epoch 100/200\n",
      "Learning rate :  8.087667511241115e-07\n",
      "Average loss :  5.948559787111174e-12\n",
      "\n",
      "\n",
      "Stage  712\n",
      "Epoch 150/200\n",
      "Learning rate :  8.087667511241115e-07\n",
      "Average loss :  1.0810611086875532e-11\n",
      "\n",
      "\n",
      "Stage  712\n",
      "Epoch 200/200\n",
      "Learning rate :  8.087667511241115e-07\n",
      "Average loss :  6.1053631768281935e-12\n",
      "expression length:\t 5\n",
      "Result stage 714: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999979]*t)\n",
      "\n",
      "\n",
      "Stage  713\n",
      "Epoch 50/200\n",
      "Learning rate :  8.007193874922814e-07\n",
      "Average loss :  6.88957918493216e-12\n",
      "\n",
      "\n",
      "Stage  713\n",
      "Epoch 100/200\n",
      "Learning rate :  8.007193874922814e-07\n",
      "Average loss :  5.244869209081182e-12\n",
      "\n",
      "\n",
      "Stage  713\n",
      "Epoch 150/200\n",
      "Learning rate :  8.007193874922814e-07\n",
      "Average loss :  6.727167867898176e-12\n",
      "\n",
      "\n",
      "Stage  713\n",
      "Epoch 200/200\n",
      "Learning rate :  8.007193874922814e-07\n",
      "Average loss :  3.775593986760084e-12\n",
      "expression length:\t 5\n",
      "Result stage 715: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399998]*t)\n",
      "\n",
      "\n",
      "Stage  714\n",
      "Epoch 50/200\n",
      "Learning rate :  7.927520964664684e-07\n",
      "Average loss :  6.451700285126094e-12\n",
      "\n",
      "\n",
      "Stage  714\n",
      "Epoch 100/200\n",
      "Learning rate :  7.927520964664684e-07\n",
      "Average loss :  3.740373896027327e-12\n",
      "\n",
      "\n",
      "Stage  714\n",
      "Epoch 150/200\n",
      "Learning rate :  7.927520964664684e-07\n",
      "Average loss :  3.740373896027327e-12\n",
      "\n",
      "\n",
      "Stage  714\n",
      "Epoch 200/200\n",
      "Learning rate :  7.927520964664684e-07\n",
      "Average loss :  3.740373896027327e-12\n",
      "expression length:\t 5\n",
      "Result stage 716: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  715\n",
      "Epoch 50/200\n",
      "Learning rate :  7.848640813109316e-07\n",
      "Average loss :  6.121465313813079e-12\n",
      "\n",
      "\n",
      "Stage  715\n",
      "Epoch 100/200\n",
      "Learning rate :  7.848640813109316e-07\n",
      "Average loss :  7.270430785188964e-12\n",
      "\n",
      "\n",
      "Stage  715\n",
      "Epoch 150/200\n",
      "Learning rate :  7.848640813109316e-07\n",
      "Average loss :  5.040661464617013e-12\n",
      "\n",
      "\n",
      "Stage  715\n",
      "Epoch 200/200\n",
      "Learning rate :  7.848640813109316e-07\n",
      "Average loss :  6.121465313813079e-12\n",
      "expression length:\t 5\n",
      "Result stage 717: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999979]*t)\n",
      "\n",
      "\n",
      "Stage  716\n",
      "Epoch 50/200\n",
      "Learning rate :  7.770545532175816e-07\n",
      "Average loss :  1.1499134977555059e-11\n",
      "\n",
      "\n",
      "Stage  716\n",
      "Epoch 100/200\n",
      "Learning rate :  7.770545532175816e-07\n",
      "Average loss :  9.80648288267938e-12\n",
      "\n",
      "\n",
      "Stage  716\n",
      "Epoch 150/200\n",
      "Learning rate :  7.770545532175816e-07\n",
      "Average loss :  3.619889544365096e-12\n",
      "\n",
      "\n",
      "Stage  716\n",
      "Epoch 200/200\n",
      "Learning rate :  7.770545532175816e-07\n",
      "Average loss :  5.804619371968522e-12\n",
      "expression length:\t 5\n",
      "Result stage 718: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999957]*t)\n",
      "\n",
      "\n",
      "Stage  717\n",
      "Epoch 50/200\n",
      "Learning rate :  7.693227312271008e-07\n",
      "Average loss :  7.110505326896055e-12\n",
      "\n",
      "\n",
      "Stage  717\n",
      "Epoch 100/200\n",
      "Learning rate :  7.693227312271008e-07\n",
      "Average loss :  7.030074005570652e-12\n",
      "\n",
      "\n",
      "Stage  717\n",
      "Epoch 150/200\n",
      "Learning rate :  7.693227312271008e-07\n",
      "Average loss :  7.030074005570652e-12\n",
      "\n",
      "\n",
      "Stage  717\n",
      "Epoch 200/200\n",
      "Learning rate :  7.693227312271008e-07\n",
      "Average loss :  7.030074005570652e-12\n",
      "expression length:\t 5\n",
      "Result stage 719: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999967]*t)\n",
      "\n",
      "\n",
      "Stage  718\n",
      "Epoch 50/200\n",
      "Learning rate :  7.616678421508473e-07\n",
      "Average loss :  4.450262207356115e-12\n",
      "\n",
      "\n",
      "Stage  718\n",
      "Epoch 100/200\n",
      "Learning rate :  7.616678421508473e-07\n",
      "Average loss :  5.67209256993606e-12\n",
      "\n",
      "\n",
      "Stage  718\n",
      "Epoch 150/200\n",
      "Learning rate :  7.616678421508473e-07\n",
      "Average loss :  5.5816445215794985e-12\n",
      "\n",
      "\n",
      "Stage  718\n",
      "Epoch 200/200\n",
      "Learning rate :  7.616678421508473e-07\n",
      "Average loss :  4.903578411374898e-12\n",
      "expression length:\t 5\n",
      "Result stage 720: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999978]*t)\n",
      "\n",
      "\n",
      "Stage  719\n",
      "Epoch 50/200\n",
      "Learning rate :  7.540891204935333e-07\n",
      "Average loss :  5.2210627314586144e-12\n",
      "\n",
      "\n",
      "Stage  719\n",
      "Epoch 100/200\n",
      "Learning rate :  7.540891204935333e-07\n",
      "Average loss :  5.2210627314586144e-12\n",
      "\n",
      "\n",
      "Stage  719\n",
      "Epoch 150/200\n",
      "Learning rate :  7.540891204935333e-07\n",
      "Average loss :  5.2210627314586144e-12\n",
      "\n",
      "\n",
      "Stage  719\n",
      "Epoch 200/200\n",
      "Learning rate :  7.540891204935333e-07\n",
      "Average loss :  5.2210627314586144e-12\n",
      "expression length:\t 5\n",
      "Result stage 721: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999955]*t)\n",
      "\n",
      "\n",
      "Stage  720\n",
      "Epoch 50/200\n",
      "Learning rate :  7.465858083766792e-07\n",
      "Average loss :  6.34633881904656e-12\n",
      "\n",
      "\n",
      "Stage  720\n",
      "Epoch 100/200\n",
      "Learning rate :  7.465858083766792e-07\n",
      "Average loss :  9.77370875204775e-12\n",
      "\n",
      "\n",
      "Stage  720\n",
      "Epoch 150/200\n",
      "Learning rate :  7.465858083766792e-07\n",
      "Average loss :  1.0204526459944852e-11\n",
      "\n",
      "\n",
      "Stage  720\n",
      "Epoch 200/200\n",
      "Learning rate :  7.465858083766792e-07\n",
      "Average loss :  3.125912723112023e-12\n",
      "expression length:\t 5\n",
      "Result stage 722: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000013]*t)\n",
      "\n",
      "\n",
      "Stage  721\n",
      "Epoch 50/200\n",
      "Learning rate :  7.391571554628196e-07\n",
      "Average loss :  6.492186562651048e-12\n",
      "\n",
      "\n",
      "Stage  721\n",
      "Epoch 100/200\n",
      "Learning rate :  7.391571554628196e-07\n",
      "Average loss :  6.217873872033097e-12\n",
      "\n",
      "\n",
      "Stage  721\n",
      "Epoch 150/200\n",
      "Learning rate :  7.391571554628196e-07\n",
      "Average loss :  4.171483471149262e-12\n",
      "\n",
      "\n",
      "Stage  721\n",
      "Epoch 200/200\n",
      "Learning rate :  7.391571554628196e-07\n",
      "Average loss :  6.104811101081964e-12\n",
      "expression length:\t 5\n",
      "Result stage 723: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999967]*t)\n",
      "\n",
      "\n",
      "Stage  722\n",
      "Epoch 50/200\n",
      "Learning rate :  7.318024188804728e-07\n",
      "Average loss :  5.3900946206386635e-12\n",
      "\n",
      "\n",
      "Stage  722\n",
      "Epoch 100/200\n",
      "Learning rate :  7.318024188804728e-07\n",
      "Average loss :  5.3900946206386635e-12\n",
      "\n",
      "\n",
      "Stage  722\n",
      "Epoch 150/200\n",
      "Learning rate :  7.318024188804728e-07\n",
      "Average loss :  5.3900946206386635e-12\n",
      "\n",
      "\n",
      "Stage  722\n",
      "Epoch 200/200\n",
      "Learning rate :  7.318024188804728e-07\n",
      "Average loss :  5.3900946206386635e-12\n",
      "expression length:\t 5\n",
      "Result stage 724: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399998]*t)\n",
      "\n",
      "\n",
      "Stage  723\n",
      "Epoch 50/200\n",
      "Learning rate :  7.245208631498506e-07\n",
      "Average loss :  5.910138697884371e-12\n",
      "\n",
      "\n",
      "Stage  723\n",
      "Epoch 100/200\n",
      "Learning rate :  7.245208631498506e-07\n",
      "Average loss :  6.672191878859257e-12\n",
      "\n",
      "\n",
      "Stage  723\n",
      "Epoch 150/200\n",
      "Learning rate :  7.245208631498506e-07\n",
      "Average loss :  5.910138697884371e-12\n",
      "\n",
      "\n",
      "Stage  723\n",
      "Epoch 200/200\n",
      "Learning rate :  7.245208631498506e-07\n",
      "Average loss :  6.672191878859257e-12\n",
      "expression length:\t 5\n",
      "Result stage 725: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999957]*t)\n",
      "\n",
      "\n",
      "Stage  724\n",
      "Epoch 50/200\n",
      "Learning rate :  7.173117601093135e-07\n",
      "Average loss :  1.151924042264163e-11\n",
      "\n",
      "\n",
      "Stage  724\n",
      "Epoch 100/200\n",
      "Learning rate :  7.173117601093135e-07\n",
      "Average loss :  4.674244498403812e-12\n",
      "\n",
      "\n",
      "Stage  724\n",
      "Epoch 150/200\n",
      "Learning rate :  7.173117601093135e-07\n",
      "Average loss :  4.067554019299147e-12\n",
      "\n",
      "\n",
      "Stage  724\n",
      "Epoch 200/200\n",
      "Learning rate :  7.173117601093135e-07\n",
      "Average loss :  8.116820583714546e-12\n",
      "expression length:\t 5\n",
      "Result stage 726: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999963]*t)\n",
      "\n",
      "\n",
      "Stage  725\n",
      "Epoch 50/200\n",
      "Learning rate :  7.10174388842549e-07\n",
      "Average loss :  5.241415374640512e-12\n",
      "\n",
      "\n",
      "Stage  725\n",
      "Epoch 100/200\n",
      "Learning rate :  7.10174388842549e-07\n",
      "Average loss :  4.5617372726458605e-12\n",
      "\n",
      "\n",
      "Stage  725\n",
      "Epoch 150/200\n",
      "Learning rate :  7.10174388842549e-07\n",
      "Average loss :  1.1024221466260364e-11\n",
      "\n",
      "\n",
      "Stage  725\n",
      "Epoch 200/200\n",
      "Learning rate :  7.10174388842549e-07\n",
      "Average loss :  4.043813461168666e-12\n",
      "expression length:\t 5\n",
      "Result stage 727: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999972]*t)\n",
      "\n",
      "\n",
      "Stage  726\n",
      "Epoch 50/200\n",
      "Learning rate :  7.031080356064829e-07\n",
      "Average loss :  5.4068494473313855e-12\n",
      "\n",
      "\n",
      "Stage  726\n",
      "Epoch 100/200\n",
      "Learning rate :  7.031080356064829e-07\n",
      "Average loss :  4.740089831062333e-12\n",
      "\n",
      "\n",
      "Stage  726\n",
      "Epoch 150/200\n",
      "Learning rate :  7.031080356064829e-07\n",
      "Average loss :  4.59406731406764e-12\n",
      "\n",
      "\n",
      "Stage  726\n",
      "Epoch 200/200\n",
      "Learning rate :  7.031080356064829e-07\n",
      "Average loss :  1.132193644393098e-11\n",
      "expression length:\t 5\n",
      "Result stage 728: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  727\n",
      "Epoch 50/200\n",
      "Learning rate :  6.961119937599021e-07\n",
      "Average loss :  5.449816379426986e-12\n",
      "\n",
      "\n",
      "Stage  727\n",
      "Epoch 100/200\n",
      "Learning rate :  6.961119937599021e-07\n",
      "Average loss :  5.676841809132416e-12\n",
      "\n",
      "\n",
      "Stage  727\n",
      "Epoch 150/200\n",
      "Learning rate :  6.961119937599021e-07\n",
      "Average loss :  5.94354686994647e-12\n",
      "\n",
      "\n",
      "Stage  727\n",
      "Epoch 200/200\n",
      "Learning rate :  6.961119937599021e-07\n",
      "Average loss :  5.94354686994647e-12\n",
      "expression length:\t 5\n",
      "Result stage 729: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999975]*t)\n",
      "\n",
      "\n",
      "Stage  728\n",
      "Epoch 50/200\n",
      "Learning rate :  6.891855636927932e-07\n",
      "Average loss :  1.077395291038119e-11\n",
      "\n",
      "\n",
      "Stage  728\n",
      "Epoch 100/200\n",
      "Learning rate :  6.891855636927932e-07\n",
      "Average loss :  4.585502550585874e-12\n",
      "\n",
      "\n",
      "Stage  728\n",
      "Epoch 150/200\n",
      "Learning rate :  6.891855636927932e-07\n",
      "Average loss :  4.675516918073441e-12\n",
      "\n",
      "\n",
      "Stage  728\n",
      "Epoch 200/200\n",
      "Learning rate :  6.891855636927932e-07\n",
      "Average loss :  5.084497059493209e-12\n",
      "expression length:\t 5\n",
      "Result stage 730: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999982]*t)\n",
      "\n",
      "\n",
      "Stage  729\n",
      "Epoch 50/200\n",
      "Learning rate :  6.823280527563766e-07\n",
      "Average loss :  5.620712662662841e-12\n",
      "\n",
      "\n",
      "Stage  729\n",
      "Epoch 100/200\n",
      "Learning rate :  6.823280527563766e-07\n",
      "Average loss :  5.524621992519796e-12\n",
      "\n",
      "\n",
      "Stage  729\n",
      "Epoch 150/200\n",
      "Learning rate :  6.823280527563766e-07\n",
      "Average loss :  6.378880496732409e-12\n",
      "\n",
      "\n",
      "Stage  729\n",
      "Epoch 200/200\n",
      "Learning rate :  6.823280527563766e-07\n",
      "Average loss :  5.620712662662841e-12\n",
      "expression length:\t 5\n",
      "Result stage 731: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999967]*t)\n",
      "\n",
      "\n",
      "Stage  730\n",
      "Epoch 50/200\n",
      "Learning rate :  6.755387751938444e-07\n",
      "Average loss :  5.585729795365424e-12\n",
      "\n",
      "\n",
      "Stage  730\n",
      "Epoch 100/200\n",
      "Learning rate :  6.755387751938444e-07\n",
      "Average loss :  5.585729795365424e-12\n",
      "\n",
      "\n",
      "Stage  730\n",
      "Epoch 150/200\n",
      "Learning rate :  6.755387751938444e-07\n",
      "Average loss :  5.585729795365424e-12\n",
      "\n",
      "\n",
      "Stage  730\n",
      "Epoch 200/200\n",
      "Learning rate :  6.755387751938444e-07\n",
      "Average loss :  5.585729795365424e-12\n",
      "expression length:\t 5\n",
      "Result stage 732: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999976]*t)\n",
      "\n",
      "\n",
      "Stage  731\n",
      "Epoch 50/200\n",
      "Learning rate :  6.688170520717818e-07\n",
      "Average loss :  5.816751594278635e-12\n",
      "\n",
      "\n",
      "Stage  731\n",
      "Epoch 100/200\n",
      "Learning rate :  6.688170520717818e-07\n",
      "Average loss :  4.570207493698186e-12\n",
      "\n",
      "\n",
      "Stage  731\n",
      "Epoch 150/200\n",
      "Learning rate :  6.688170520717818e-07\n",
      "Average loss :  4.570207493698186e-12\n",
      "\n",
      "\n",
      "Stage  731\n",
      "Epoch 200/200\n",
      "Learning rate :  6.688170520717818e-07\n",
      "Average loss :  4.570207493698186e-12\n",
      "expression length:\t 5\n",
      "Result stage 733: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  732\n",
      "Epoch 50/200\n",
      "Learning rate :  6.621622112122764e-07\n",
      "Average loss :  5.267257550262139e-12\n",
      "\n",
      "\n",
      "Stage  732\n",
      "Epoch 100/200\n",
      "Learning rate :  6.621622112122764e-07\n",
      "Average loss :  5.267257550262139e-12\n",
      "\n",
      "\n",
      "Stage  732\n",
      "Epoch 150/200\n",
      "Learning rate :  6.621622112122764e-07\n",
      "Average loss :  5.267257550262139e-12\n",
      "\n",
      "\n",
      "Stage  732\n",
      "Epoch 200/200\n",
      "Learning rate :  6.621622112122764e-07\n",
      "Average loss :  5.267257550262139e-12\n",
      "expression length:\t 5\n",
      "Result stage 734: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999979]*t)\n",
      "\n",
      "\n",
      "Stage  733\n",
      "Epoch 50/200\n",
      "Learning rate :  6.555735871256958e-07\n",
      "Average loss :  3.1765061501293212e-12\n",
      "\n",
      "\n",
      "Stage  733\n",
      "Epoch 100/200\n",
      "Learning rate :  6.555735871256958e-07\n",
      "Average loss :  4.133813517187557e-12\n",
      "\n",
      "\n",
      "Stage  733\n",
      "Epoch 150/200\n",
      "Learning rate :  6.555735871256958e-07\n",
      "Average loss :  4.7208278952659555e-12\n",
      "\n",
      "\n",
      "Stage  733\n",
      "Epoch 200/200\n",
      "Learning rate :  6.555735871256958e-07\n",
      "Average loss :  4.000136593490522e-12\n",
      "expression length:\t 5\n",
      "Result stage 735: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  734\n",
      "Epoch 50/200\n",
      "Learning rate :  6.490505209441411e-07\n",
      "Average loss :  3.082195739953497e-12\n",
      "\n",
      "\n",
      "Stage  734\n",
      "Epoch 100/200\n",
      "Learning rate :  6.490505209441411e-07\n",
      "Average loss :  4.225182270028993e-12\n",
      "\n",
      "\n",
      "Stage  734\n",
      "Epoch 150/200\n",
      "Learning rate :  6.490505209441411e-07\n",
      "Average loss :  4.225182270028993e-12\n",
      "\n",
      "\n",
      "Stage  734\n",
      "Epoch 200/200\n",
      "Learning rate :  6.490505209441411e-07\n",
      "Average loss :  4.225182270028993e-12\n",
      "expression length:\t 5\n",
      "Result stage 736: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999979]*t)\n",
      "\n",
      "\n",
      "Stage  735\n",
      "Epoch 50/200\n",
      "Learning rate :  6.425923603555573e-07\n",
      "Average loss :  4.641515470582558e-12\n",
      "\n",
      "\n",
      "Stage  735\n",
      "Epoch 100/200\n",
      "Learning rate :  6.425923603555573e-07\n",
      "Average loss :  4.447997525858227e-12\n",
      "\n",
      "\n",
      "Stage  735\n",
      "Epoch 150/200\n",
      "Learning rate :  6.425923603555573e-07\n",
      "Average loss :  4.641515470582558e-12\n",
      "\n",
      "\n",
      "Stage  735\n",
      "Epoch 200/200\n",
      "Learning rate :  6.425923603555573e-07\n",
      "Average loss :  4.447997525858227e-12\n",
      "expression length:\t 5\n",
      "Result stage 737: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999966]*t)\n",
      "\n",
      "\n",
      "Stage  736\n",
      "Epoch 50/200\n",
      "Learning rate :  6.361984595385052e-07\n",
      "Average loss :  7.97936283020162e-12\n",
      "\n",
      "\n",
      "Stage  736\n",
      "Epoch 100/200\n",
      "Learning rate :  6.361984595385052e-07\n",
      "Average loss :  3.970336212577585e-12\n",
      "\n",
      "\n",
      "Stage  736\n",
      "Epoch 150/200\n",
      "Learning rate :  6.361984595385052e-07\n",
      "Average loss :  4.878368108779396e-12\n",
      "\n",
      "\n",
      "Stage  736\n",
      "Epoch 200/200\n",
      "Learning rate :  6.361984595385052e-07\n",
      "Average loss :  8.153588047787874e-12\n",
      "expression length:\t 5\n",
      "Result stage 738: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399998]*t)\n",
      "\n",
      "\n",
      "Stage  737\n",
      "Epoch 50/200\n",
      "Learning rate :  6.29868179097574e-07\n",
      "Average loss :  5.375828688453099e-12\n",
      "\n",
      "\n",
      "Stage  737\n",
      "Epoch 100/200\n",
      "Learning rate :  6.29868179097574e-07\n",
      "Average loss :  4.911881665292661e-12\n",
      "\n",
      "\n",
      "Stage  737\n",
      "Epoch 150/200\n",
      "Learning rate :  6.29868179097574e-07\n",
      "Average loss :  4.911881665292661e-12\n",
      "\n",
      "\n",
      "Stage  737\n",
      "Epoch 200/200\n",
      "Learning rate :  6.29868179097574e-07\n",
      "Average loss :  4.911881665292661e-12\n",
      "expression length:\t 5\n",
      "Result stage 739: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999975]*t)\n",
      "\n",
      "\n",
      "Stage  738\n",
      "Epoch 50/200\n",
      "Learning rate :  6.236008859994444e-07\n",
      "Average loss :  4.071768529984032e-12\n",
      "\n",
      "\n",
      "Stage  738\n",
      "Epoch 100/200\n",
      "Learning rate :  6.236008859994444e-07\n",
      "Average loss :  4.071768529984032e-12\n",
      "\n",
      "\n",
      "Stage  738\n",
      "Epoch 150/200\n",
      "Learning rate :  6.236008859994444e-07\n",
      "Average loss :  4.071768529984032e-12\n",
      "\n",
      "\n",
      "Stage  738\n",
      "Epoch 200/200\n",
      "Learning rate :  6.236008859994444e-07\n",
      "Average loss :  4.071768529984032e-12\n",
      "expression length:\t 5\n",
      "Result stage 740: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999973]*t)\n",
      "\n",
      "\n",
      "Stage  739\n",
      "Epoch 50/200\n",
      "Learning rate :  6.173959535095834e-07\n",
      "Average loss :  4.1167767979299885e-12\n",
      "\n",
      "\n",
      "Stage  739\n",
      "Epoch 100/200\n",
      "Learning rate :  6.173959535095834e-07\n",
      "Average loss :  4.1167767979299885e-12\n",
      "\n",
      "\n",
      "Stage  739\n",
      "Epoch 150/200\n",
      "Learning rate :  6.173959535095834e-07\n",
      "Average loss :  4.1167767979299885e-12\n",
      "\n",
      "\n",
      "Stage  739\n",
      "Epoch 200/200\n",
      "Learning rate :  6.173959535095834e-07\n",
      "Average loss :  4.1167767979299885e-12\n",
      "expression length:\t 5\n",
      "Result stage 741: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999973]*t)\n",
      "\n",
      "\n",
      "Stage  740\n",
      "Epoch 50/200\n",
      "Learning rate :  6.112527611295724e-07\n",
      "Average loss :  4.1167767979299885e-12\n",
      "\n",
      "\n",
      "Stage  740\n",
      "Epoch 100/200\n",
      "Learning rate :  6.112527611295724e-07\n",
      "Average loss :  4.1167767979299885e-12\n",
      "\n",
      "\n",
      "Stage  740\n",
      "Epoch 150/200\n",
      "Learning rate :  6.112527611295724e-07\n",
      "Average loss :  4.1167767979299885e-12\n",
      "\n",
      "\n",
      "Stage  740\n",
      "Epoch 200/200\n",
      "Learning rate :  6.112527611295724e-07\n",
      "Average loss :  4.1167767979299885e-12\n",
      "expression length:\t 5\n",
      "Result stage 742: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999973]*t)\n",
      "\n",
      "\n",
      "Stage  741\n",
      "Epoch 50/200\n",
      "Learning rate :  6.051706945350532e-07\n",
      "Average loss :  4.048647268134475e-12\n",
      "\n",
      "\n",
      "Stage  741\n",
      "Epoch 100/200\n",
      "Learning rate :  6.051706945350532e-07\n",
      "Average loss :  4.048647268134475e-12\n",
      "\n",
      "\n",
      "Stage  741\n",
      "Epoch 150/200\n",
      "Learning rate :  6.051706945350532e-07\n",
      "Average loss :  4.048647268134475e-12\n",
      "\n",
      "\n",
      "Stage  741\n",
      "Epoch 200/200\n",
      "Learning rate :  6.051706945350532e-07\n",
      "Average loss :  4.048647268134475e-12\n",
      "expression length:\t 5\n",
      "Result stage 743: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999973]*t)\n",
      "\n",
      "\n",
      "Stage  742\n",
      "Epoch 50/200\n",
      "Learning rate :  5.991491455142981e-07\n",
      "Average loss :  4.028723101651144e-12\n",
      "\n",
      "\n",
      "Stage  742\n",
      "Epoch 100/200\n",
      "Learning rate :  5.991491455142981e-07\n",
      "Average loss :  4.028723101651144e-12\n",
      "\n",
      "\n",
      "Stage  742\n",
      "Epoch 150/200\n",
      "Learning rate :  5.991491455142981e-07\n",
      "Average loss :  4.028723101651144e-12\n",
      "\n",
      "\n",
      "Stage  742\n",
      "Epoch 200/200\n",
      "Learning rate :  5.991491455142981e-07\n",
      "Average loss :  4.028723101651144e-12\n",
      "expression length:\t 5\n",
      "Result stage 744: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999973]*t)\n",
      "\n",
      "\n",
      "Stage  743\n",
      "Epoch 50/200\n",
      "Learning rate :  5.93187511907387e-07\n",
      "Average loss :  3.669192120275833e-12\n",
      "\n",
      "\n",
      "Stage  743\n",
      "Epoch 100/200\n",
      "Learning rate :  5.93187511907387e-07\n",
      "Average loss :  3.669192120275833e-12\n",
      "\n",
      "\n",
      "Stage  743\n",
      "Epoch 150/200\n",
      "Learning rate :  5.93187511907387e-07\n",
      "Average loss :  3.669192120275833e-12\n",
      "\n",
      "\n",
      "Stage  743\n",
      "Epoch 200/200\n",
      "Learning rate :  5.93187511907387e-07\n",
      "Average loss :  3.669192120275833e-12\n",
      "expression length:\t 5\n",
      "Result stage 745: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999978]*t)\n",
      "\n",
      "\n",
      "Stage  744\n",
      "Epoch 50/200\n",
      "Learning rate :  5.872851975459907e-07\n",
      "Average loss :  3.828463587818298e-12\n",
      "\n",
      "\n",
      "Stage  744\n",
      "Epoch 100/200\n",
      "Learning rate :  5.872851975459907e-07\n",
      "Average loss :  3.828463587818298e-12\n",
      "\n",
      "\n",
      "Stage  744\n",
      "Epoch 150/200\n",
      "Learning rate :  5.872851975459907e-07\n",
      "Average loss :  3.828463587818298e-12\n",
      "\n",
      "\n",
      "Stage  744\n",
      "Epoch 200/200\n",
      "Learning rate :  5.872851975459907e-07\n",
      "Average loss :  3.828463587818298e-12\n",
      "expression length:\t 5\n",
      "Result stage 746: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999978]*t)\n",
      "\n",
      "\n",
      "Stage  745\n",
      "Epoch 50/200\n",
      "Learning rate :  5.814416121937556e-07\n",
      "Average loss :  3.743738392208984e-12\n",
      "\n",
      "\n",
      "Stage  745\n",
      "Epoch 100/200\n",
      "Learning rate :  5.814416121937556e-07\n",
      "Average loss :  3.743738392208984e-12\n",
      "\n",
      "\n",
      "Stage  745\n",
      "Epoch 150/200\n",
      "Learning rate :  5.814416121937556e-07\n",
      "Average loss :  3.743738392208984e-12\n",
      "\n",
      "\n",
      "Stage  745\n",
      "Epoch 200/200\n",
      "Learning rate :  5.814416121937556e-07\n",
      "Average loss :  3.743738392208984e-12\n",
      "expression length:\t 5\n",
      "Result stage 747: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999978]*t)\n",
      "\n",
      "\n",
      "Stage  746\n",
      "Epoch 50/200\n",
      "Learning rate :  5.756561714872761e-07\n",
      "Average loss :  2.7597943461771246e-12\n",
      "\n",
      "\n",
      "Stage  746\n",
      "Epoch 100/200\n",
      "Learning rate :  5.756561714872761e-07\n",
      "Average loss :  3.917709906486877e-12\n",
      "\n",
      "\n",
      "Stage  746\n",
      "Epoch 150/200\n",
      "Learning rate :  5.756561714872761e-07\n",
      "Average loss :  8.146070623604729e-12\n",
      "\n",
      "\n",
      "Stage  746\n",
      "Epoch 200/200\n",
      "Learning rate :  5.756561714872761e-07\n",
      "Average loss :  3.8220824075119175e-12\n",
      "expression length:\t 5\n",
      "Result stage 748: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999978]*t)\n",
      "\n",
      "\n",
      "Stage  747\n",
      "Epoch 50/200\n",
      "Learning rate :  5.699282968776604e-07\n",
      "Average loss :  3.79213587614613e-12\n",
      "\n",
      "\n",
      "Stage  747\n",
      "Epoch 100/200\n",
      "Learning rate :  5.699282968776604e-07\n",
      "Average loss :  3.79213587614613e-12\n",
      "\n",
      "\n",
      "Stage  747\n",
      "Epoch 150/200\n",
      "Learning rate :  5.699282968776604e-07\n",
      "Average loss :  3.79213587614613e-12\n",
      "\n",
      "\n",
      "Stage  747\n",
      "Epoch 200/200\n",
      "Learning rate :  5.699282968776604e-07\n",
      "Average loss :  3.79213587614613e-12\n",
      "expression length:\t 5\n",
      "Result stage 749: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999976]*t)\n",
      "\n",
      "\n",
      "Stage  748\n",
      "Epoch 50/200\n",
      "Learning rate :  5.642574155726738e-07\n",
      "Average loss :  3.876054859019984e-12\n",
      "\n",
      "\n",
      "Stage  748\n",
      "Epoch 100/200\n",
      "Learning rate :  5.642574155726738e-07\n",
      "Average loss :  3.876054859019984e-12\n",
      "\n",
      "\n",
      "Stage  748\n",
      "Epoch 150/200\n",
      "Learning rate :  5.642574155726738e-07\n",
      "Average loss :  3.876054859019984e-12\n",
      "\n",
      "\n",
      "Stage  748\n",
      "Epoch 200/200\n",
      "Learning rate :  5.642574155726738e-07\n",
      "Average loss :  3.876054859019984e-12\n",
      "expression length:\t 5\n",
      "Result stage 750: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999976]*t)\n",
      "\n",
      "\n",
      "Stage  749\n",
      "Epoch 50/200\n",
      "Learning rate :  5.586429604794611e-07\n",
      "Average loss :  3.825407005053627e-12\n",
      "\n",
      "\n",
      "Stage  749\n",
      "Epoch 100/200\n",
      "Learning rate :  5.586429604794611e-07\n",
      "Average loss :  3.825407005053627e-12\n",
      "\n",
      "\n",
      "Stage  749\n",
      "Epoch 150/200\n",
      "Learning rate :  5.586429604794611e-07\n",
      "Average loss :  3.825407005053627e-12\n",
      "\n",
      "\n",
      "Stage  749\n",
      "Epoch 200/200\n",
      "Learning rate :  5.586429604794611e-07\n",
      "Average loss :  3.825407005053627e-12\n",
      "expression length:\t 5\n",
      "Result stage 751: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999976]*t)\n",
      "\n",
      "\n",
      "Stage  750\n",
      "Epoch 50/200\n",
      "Learning rate :  5.530843701478336e-07\n",
      "Average loss :  7.42649431534348e-12\n",
      "\n",
      "\n",
      "Stage  750\n",
      "Epoch 100/200\n",
      "Learning rate :  5.530843701478336e-07\n",
      "Average loss :  2.25834173410433e-12\n",
      "\n",
      "\n",
      "Stage  750\n",
      "Epoch 150/200\n",
      "Learning rate :  5.530843701478336e-07\n",
      "Average loss :  2.4359000060092395e-12\n",
      "\n",
      "\n",
      "Stage  750\n",
      "Epoch 200/200\n",
      "Learning rate :  5.530843701478336e-07\n",
      "Average loss :  2.25834173410433e-12\n",
      "expression length:\t 5\n",
      "Result stage 752: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999976]*t)\n",
      "\n",
      "\n",
      "Stage  751\n",
      "Epoch 50/200\n",
      "Learning rate :  5.475810887141261e-07\n",
      "Average loss :  2.9035005736505193e-12\n",
      "\n",
      "\n",
      "Stage  751\n",
      "Epoch 100/200\n",
      "Learning rate :  5.475810887141261e-07\n",
      "Average loss :  3.931237713833413e-12\n",
      "\n",
      "\n",
      "Stage  751\n",
      "Epoch 150/200\n",
      "Learning rate :  5.475810887141261e-07\n",
      "Average loss :  3.725238867380298e-12\n",
      "\n",
      "\n",
      "Stage  751\n",
      "Epoch 200/200\n",
      "Learning rate :  5.475810887141261e-07\n",
      "Average loss :  2.9035005736505193e-12\n",
      "expression length:\t 5\n",
      "Result stage 753: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399998]*t)\n",
      "\n",
      "\n",
      "Stage  752\n",
      "Epoch 50/200\n",
      "Learning rate :  5.421325658456086e-07\n",
      "Average loss :  3.795280929808076e-12\n",
      "\n",
      "\n",
      "Stage  752\n",
      "Epoch 100/200\n",
      "Learning rate :  5.421325658456086e-07\n",
      "Average loss :  3.788821686945276e-12\n",
      "\n",
      "\n",
      "Stage  752\n",
      "Epoch 150/200\n",
      "Learning rate :  5.421325658456086e-07\n",
      "Average loss :  3.802829579013789e-12\n",
      "\n",
      "\n",
      "Stage  752\n",
      "Epoch 200/200\n",
      "Learning rate :  5.421325658456086e-07\n",
      "Average loss :  3.795280929808076e-12\n",
      "expression length:\t 5\n",
      "Result stage 754: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999975]*t)\n",
      "\n",
      "\n",
      "Stage  753\n",
      "Epoch 50/200\n",
      "Learning rate :  5.367382566854548e-07\n",
      "Average loss :  4.932465026696864e-12\n",
      "\n",
      "\n",
      "Stage  753\n",
      "Epoch 100/200\n",
      "Learning rate :  5.367382566854548e-07\n",
      "Average loss :  7.372819368911543e-12\n",
      "\n",
      "\n",
      "Stage  753\n",
      "Epoch 150/200\n",
      "Learning rate :  5.367382566854548e-07\n",
      "Average loss :  3.0003332717604136e-12\n",
      "\n",
      "\n",
      "Stage  753\n",
      "Epoch 200/200\n",
      "Learning rate :  5.367382566854548e-07\n",
      "Average loss :  3.1783371507582148e-12\n",
      "expression length:\t 5\n",
      "Result stage 755: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999975]*t)\n",
      "\n",
      "\n",
      "Stage  754\n",
      "Epoch 50/200\n",
      "Learning rate :  5.313976217982529e-07\n",
      "Average loss :  7.287248061926821e-12\n",
      "\n",
      "\n",
      "Stage  754\n",
      "Epoch 100/200\n",
      "Learning rate :  5.313976217982529e-07\n",
      "Average loss :  7.287248061926821e-12\n",
      "\n",
      "\n",
      "Stage  754\n",
      "Epoch 150/200\n",
      "Learning rate :  5.313976217982529e-07\n",
      "Average loss :  7.287248061926821e-12\n",
      "\n",
      "\n",
      "Stage  754\n",
      "Epoch 200/200\n",
      "Learning rate :  5.313976217982529e-07\n",
      "Average loss :  7.287248061926821e-12\n",
      "expression length:\t 5\n",
      "Result stage 756: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  755\n",
      "Epoch 50/200\n",
      "Learning rate :  5.261101271160638e-07\n",
      "Average loss :  2.997238091398402e-12\n",
      "\n",
      "\n",
      "Stage  755\n",
      "Epoch 100/200\n",
      "Learning rate :  5.261101271160638e-07\n",
      "Average loss :  3.4441217239278288e-12\n",
      "\n",
      "\n",
      "Stage  755\n",
      "Epoch 150/200\n",
      "Learning rate :  5.261101271160638e-07\n",
      "Average loss :  4.36619707402941e-12\n",
      "\n",
      "\n",
      "Stage  755\n",
      "Epoch 200/200\n",
      "Learning rate :  5.261101271160638e-07\n",
      "Average loss :  3.2343210141366763e-12\n",
      "expression length:\t 5\n",
      "Result stage 757: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  756\n",
      "Epoch 50/200\n",
      "Learning rate :  5.208752438850121e-07\n",
      "Average loss :  3.390354186630362e-12\n",
      "\n",
      "\n",
      "Stage  756\n",
      "Epoch 100/200\n",
      "Learning rate :  5.208752438850121e-07\n",
      "Average loss :  5.027047354777547e-12\n",
      "\n",
      "\n",
      "Stage  756\n",
      "Epoch 150/200\n",
      "Learning rate :  5.208752438850121e-07\n",
      "Average loss :  4.466330950914088e-12\n",
      "\n",
      "\n",
      "Stage  756\n",
      "Epoch 200/200\n",
      "Learning rate :  5.208752438850121e-07\n",
      "Average loss :  3.804550858382827e-12\n",
      "expression length:\t 5\n",
      "Result stage 758: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999979]*t)\n",
      "\n",
      "\n",
      "Stage  757\n",
      "Epoch 50/200\n",
      "Learning rate :  5.156924486124138e-07\n",
      "Average loss :  2.97871753304757e-12\n",
      "\n",
      "\n",
      "Stage  757\n",
      "Epoch 100/200\n",
      "Learning rate :  5.156924486124138e-07\n",
      "Average loss :  4.450461700555852e-12\n",
      "\n",
      "\n",
      "Stage  757\n",
      "Epoch 150/200\n",
      "Learning rate :  5.156924486124138e-07\n",
      "Average loss :  4.877259186797378e-12\n",
      "\n",
      "\n",
      "Stage  757\n",
      "Epoch 200/200\n",
      "Learning rate :  5.156924486124138e-07\n",
      "Average loss :  2.974043537481985e-12\n",
      "expression length:\t 5\n",
      "Result stage 759: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  758\n",
      "Epoch 50/200\n",
      "Learning rate :  5.105612230144218e-07\n",
      "Average loss :  2.9937979179051055e-12\n",
      "\n",
      "\n",
      "Stage  758\n",
      "Epoch 100/200\n",
      "Learning rate :  5.105612230144218e-07\n",
      "Average loss :  2.9937979179051055e-12\n",
      "\n",
      "\n",
      "Stage  758\n",
      "Epoch 150/200\n",
      "Learning rate :  5.105612230144218e-07\n",
      "Average loss :  2.9937979179051055e-12\n",
      "\n",
      "\n",
      "Stage  758\n",
      "Epoch 200/200\n",
      "Learning rate :  5.105612230144218e-07\n",
      "Average loss :  2.9937979179051055e-12\n",
      "expression length:\t 5\n",
      "Result stage 760: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  759\n",
      "Epoch 50/200\n",
      "Learning rate :  5.054810539642003e-07\n",
      "Average loss :  7.796682570393454e-12\n",
      "\n",
      "\n",
      "Stage  759\n",
      "Epoch 100/200\n",
      "Learning rate :  5.054810539642003e-07\n",
      "Average loss :  7.796682570393454e-12\n",
      "\n",
      "\n",
      "Stage  759\n",
      "Epoch 150/200\n",
      "Learning rate :  5.054810539642003e-07\n",
      "Average loss :  7.796682570393454e-12\n",
      "\n",
      "\n",
      "Stage  759\n",
      "Epoch 200/200\n",
      "Learning rate :  5.054810539642003e-07\n",
      "Average loss :  7.796682570393454e-12\n",
      "expression length:\t 5\n",
      "Result stage 761: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000002]*t)\n",
      "\n",
      "\n",
      "Stage  760\n",
      "Epoch 50/200\n",
      "Learning rate :  5.004514334406104e-07\n",
      "Average loss :  2.467922350854468e-12\n",
      "\n",
      "\n",
      "Stage  760\n",
      "Epoch 100/200\n",
      "Learning rate :  5.004514334406104e-07\n",
      "Average loss :  2.691072191474131e-12\n",
      "\n",
      "\n",
      "Stage  760\n",
      "Epoch 150/200\n",
      "Learning rate :  5.004514334406104e-07\n",
      "Average loss :  3.0645019941794027e-12\n",
      "\n",
      "\n",
      "Stage  760\n",
      "Epoch 200/200\n",
      "Learning rate :  5.004514334406104e-07\n",
      "Average loss :  7.785152730810374e-12\n",
      "expression length:\t 5\n",
      "Result stage 762: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000002]*t)\n",
      "\n",
      "\n",
      "Stage  761\n",
      "Epoch 50/200\n",
      "Learning rate :  4.954718584774093e-07\n",
      "Average loss :  2.9158977749715875e-12\n",
      "\n",
      "\n",
      "Stage  761\n",
      "Epoch 100/200\n",
      "Learning rate :  4.954718584774093e-07\n",
      "Average loss :  3.3844821476641807e-12\n",
      "\n",
      "\n",
      "Stage  761\n",
      "Epoch 150/200\n",
      "Learning rate :  4.954718584774093e-07\n",
      "Average loss :  4.1701811274996725e-12\n",
      "\n",
      "\n",
      "Stage  761\n",
      "Epoch 200/200\n",
      "Learning rate :  4.954718584774093e-07\n",
      "Average loss :  4.487445571382809e-12\n",
      "expression length:\t 5\n",
      "Result stage 763: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999978]*t)\n",
      "\n",
      "\n",
      "Stage  762\n",
      "Epoch 50/200\n",
      "Learning rate :  4.905418311129506e-07\n",
      "Average loss :  3.25113764035323e-12\n",
      "\n",
      "\n",
      "Stage  762\n",
      "Epoch 100/200\n",
      "Learning rate :  4.905418311129506e-07\n",
      "Average loss :  4.791180473195933e-12\n",
      "\n",
      "\n",
      "Stage  762\n",
      "Epoch 150/200\n",
      "Learning rate :  4.905418311129506e-07\n",
      "Average loss :  3.25113764035323e-12\n",
      "\n",
      "\n",
      "Stage  762\n",
      "Epoch 200/200\n",
      "Learning rate :  4.905418311129506e-07\n",
      "Average loss :  4.791180473195933e-12\n",
      "expression length:\t 5\n",
      "Result stage 764: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999973]*t)\n",
      "\n",
      "\n",
      "Stage  763\n",
      "Epoch 50/200\n",
      "Learning rate :  4.856608583403893e-07\n",
      "Average loss :  2.8684903844583554e-12\n",
      "\n",
      "\n",
      "Stage  763\n",
      "Epoch 100/200\n",
      "Learning rate :  4.856608583403893e-07\n",
      "Average loss :  3.929841695116121e-12\n",
      "\n",
      "\n",
      "Stage  763\n",
      "Epoch 150/200\n",
      "Learning rate :  4.856608583403893e-07\n",
      "Average loss :  2.8977391233059313e-12\n",
      "\n",
      "\n",
      "Stage  763\n",
      "Epoch 200/200\n",
      "Learning rate :  4.856608583403893e-07\n",
      "Average loss :  2.457192001953379e-12\n",
      "expression length:\t 5\n",
      "Result stage 765: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  764\n",
      "Epoch 50/200\n",
      "Learning rate :  4.808284520583803e-07\n",
      "Average loss :  3.704525835396266e-12\n",
      "\n",
      "\n",
      "Stage  764\n",
      "Epoch 100/200\n",
      "Learning rate :  4.808284520583803e-07\n",
      "Average loss :  3.704525835396266e-12\n",
      "\n",
      "\n",
      "Stage  764\n",
      "Epoch 150/200\n",
      "Learning rate :  4.808284520583803e-07\n",
      "Average loss :  3.704525835396266e-12\n",
      "\n",
      "\n",
      "Stage  764\n",
      "Epoch 200/200\n",
      "Learning rate :  4.808284520583803e-07\n",
      "Average loss :  3.704525835396266e-12\n",
      "expression length:\t 5\n",
      "Result stage 766: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  765\n",
      "Epoch 50/200\n",
      "Learning rate :  4.7604412902226936e-07\n",
      "Average loss :  3.650408534477956e-12\n",
      "\n",
      "\n",
      "Stage  765\n",
      "Epoch 100/200\n",
      "Learning rate :  4.7604412902226936e-07\n",
      "Average loss :  3.650408534477956e-12\n",
      "\n",
      "\n",
      "Stage  765\n",
      "Epoch 150/200\n",
      "Learning rate :  4.7604412902226936e-07\n",
      "Average loss :  3.650408534477956e-12\n",
      "\n",
      "\n",
      "Stage  765\n",
      "Epoch 200/200\n",
      "Learning rate :  4.7604412902226936e-07\n",
      "Average loss :  3.650408534477956e-12\n",
      "expression length:\t 5\n",
      "Result stage 767: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  766\n",
      "Epoch 50/200\n",
      "Learning rate :  4.7130741079576536e-07\n",
      "Average loss :  2.1325053268378413e-12\n",
      "\n",
      "\n",
      "Stage  766\n",
      "Epoch 100/200\n",
      "Learning rate :  4.7130741079576536e-07\n",
      "Average loss :  3.79876729031392e-12\n",
      "\n",
      "\n",
      "Stage  766\n",
      "Epoch 150/200\n",
      "Learning rate :  4.7130741079576536e-07\n",
      "Average loss :  2.1325053268378413e-12\n",
      "\n",
      "\n",
      "Stage  766\n",
      "Epoch 200/200\n",
      "Learning rate :  4.7130741079576536e-07\n",
      "Average loss :  3.79876729031392e-12\n",
      "expression length:\t 5\n",
      "Result stage 768: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999982]*t)\n",
      "\n",
      "\n",
      "Stage  767\n",
      "Epoch 50/200\n",
      "Learning rate :  4.666178237030984e-07\n",
      "Average loss :  2.8153594906765722e-12\n",
      "\n",
      "\n",
      "Stage  767\n",
      "Epoch 100/200\n",
      "Learning rate :  4.666178237030984e-07\n",
      "Average loss :  2.860087600781158e-12\n",
      "\n",
      "\n",
      "Stage  767\n",
      "Epoch 150/200\n",
      "Learning rate :  4.666178237030984e-07\n",
      "Average loss :  2.8153594906765722e-12\n",
      "\n",
      "\n",
      "Stage  767\n",
      "Epoch 200/200\n",
      "Learning rate :  4.666178237030984e-07\n",
      "Average loss :  2.860087600781158e-12\n",
      "expression length:\t 5\n",
      "Result stage 769: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999987]*t)\n",
      "\n",
      "\n",
      "Stage  768\n",
      "Epoch 50/200\n",
      "Learning rate :  4.619748987816513e-07\n",
      "Average loss :  2.834059809747602e-12\n",
      "\n",
      "\n",
      "Stage  768\n",
      "Epoch 100/200\n",
      "Learning rate :  4.619748987816513e-07\n",
      "Average loss :  2.834059809747602e-12\n",
      "\n",
      "\n",
      "Stage  768\n",
      "Epoch 150/200\n",
      "Learning rate :  4.619748987816513e-07\n",
      "Average loss :  2.834059809747602e-12\n",
      "\n",
      "\n",
      "Stage  768\n",
      "Epoch 200/200\n",
      "Learning rate :  4.619748987816513e-07\n",
      "Average loss :  2.834059809747602e-12\n",
      "expression length:\t 5\n",
      "Result stage 770: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  769\n",
      "Epoch 50/200\n",
      "Learning rate :  4.573781717350623e-07\n",
      "Average loss :  3.4007514686240636e-12\n",
      "\n",
      "\n",
      "Stage  769\n",
      "Epoch 100/200\n",
      "Learning rate :  4.573781717350623e-07\n",
      "Average loss :  2.3938468395046097e-12\n",
      "\n",
      "\n",
      "Stage  769\n",
      "Epoch 150/200\n",
      "Learning rate :  4.573781717350623e-07\n",
      "Average loss :  3.9089196289532335e-12\n",
      "\n",
      "\n",
      "Stage  769\n",
      "Epoch 200/200\n",
      "Learning rate :  4.573781717350623e-07\n",
      "Average loss :  2.155268801970478e-12\n",
      "expression length:\t 5\n",
      "Result stage 771: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  770\n",
      "Epoch 50/200\n",
      "Learning rate :  4.5282718288679697e-07\n",
      "Average loss :  4.098056963219854e-12\n",
      "\n",
      "\n",
      "Stage  770\n",
      "Epoch 100/200\n",
      "Learning rate :  4.5282718288679697e-07\n",
      "Average loss :  4.098056963219854e-12\n",
      "\n",
      "\n",
      "Stage  770\n",
      "Epoch 150/200\n",
      "Learning rate :  4.5282718288679697e-07\n",
      "Average loss :  4.098056963219854e-12\n",
      "\n",
      "\n",
      "Stage  770\n",
      "Epoch 200/200\n",
      "Learning rate :  4.5282718288679697e-07\n",
      "Average loss :  4.098056963219854e-12\n",
      "expression length:\t 5\n",
      "Result stage 772: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399998]*t)\n",
      "\n",
      "\n",
      "Stage  771\n",
      "Epoch 50/200\n",
      "Learning rate :  4.483214771341776e-07\n",
      "Average loss :  3.1512496605212714e-12\n",
      "\n",
      "\n",
      "Stage  771\n",
      "Epoch 100/200\n",
      "Learning rate :  4.483214771341776e-07\n",
      "Average loss :  3.2206943275520095e-12\n",
      "\n",
      "\n",
      "Stage  771\n",
      "Epoch 150/200\n",
      "Learning rate :  4.483214771341776e-07\n",
      "Average loss :  3.67875261503281e-12\n",
      "\n",
      "\n",
      "Stage  771\n",
      "Epoch 200/200\n",
      "Learning rate :  4.483214771341776e-07\n",
      "Average loss :  2.1371671793390945e-12\n",
      "expression length:\t 5\n",
      "Result stage 773: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999976]*t)\n",
      "\n",
      "\n",
      "Stage  772\n",
      "Epoch 50/200\n",
      "Learning rate :  4.4386060390287404e-07\n",
      "Average loss :  2.171613149720697e-12\n",
      "\n",
      "\n",
      "Stage  772\n",
      "Epoch 100/200\n",
      "Learning rate :  4.4386060390287404e-07\n",
      "Average loss :  3.3188785920901243e-12\n",
      "\n",
      "\n",
      "Stage  772\n",
      "Epoch 150/200\n",
      "Learning rate :  4.4386060390287404e-07\n",
      "Average loss :  3.377768117290847e-12\n",
      "\n",
      "\n",
      "Stage  772\n",
      "Epoch 200/200\n",
      "Learning rate :  4.4386060390287404e-07\n",
      "Average loss :  3.967552415079512e-12\n",
      "expression length:\t 5\n",
      "Result stage 774: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999978]*t)\n",
      "\n",
      "\n",
      "Stage  773\n",
      "Epoch 50/200\n",
      "Learning rate :  4.3944411710184547e-07\n",
      "Average loss :  4.189616101962779e-12\n",
      "\n",
      "\n",
      "Stage  773\n",
      "Epoch 100/200\n",
      "Learning rate :  4.3944411710184547e-07\n",
      "Average loss :  2.645956804353533e-12\n",
      "\n",
      "\n",
      "Stage  773\n",
      "Epoch 150/200\n",
      "Learning rate :  4.3944411710184547e-07\n",
      "Average loss :  3.0166513818180585e-12\n",
      "\n",
      "\n",
      "Stage  773\n",
      "Epoch 200/200\n",
      "Learning rate :  4.3944411710184547e-07\n",
      "Average loss :  3.230202130083404e-12\n",
      "expression length:\t 5\n",
      "Result stage 775: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999979]*t)\n",
      "\n",
      "\n",
      "Stage  774\n",
      "Epoch 50/200\n",
      "Learning rate :  4.350715750787321e-07\n",
      "Average loss :  3.2304920457443265e-12\n",
      "\n",
      "\n",
      "Stage  774\n",
      "Epoch 100/200\n",
      "Learning rate :  4.350715750787321e-07\n",
      "Average loss :  5.2266615514773296e-12\n",
      "\n",
      "\n",
      "Stage  774\n",
      "Epoch 150/200\n",
      "Learning rate :  4.350715750787321e-07\n",
      "Average loss :  3.833809138209521e-12\n",
      "\n",
      "\n",
      "Stage  774\n",
      "Epoch 200/200\n",
      "Learning rate :  4.350715750787321e-07\n",
      "Average loss :  3.2304920457443265e-12\n",
      "expression length:\t 5\n",
      "Result stage 776: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999978]*t)\n",
      "\n",
      "\n",
      "Stage  775\n",
      "Epoch 50/200\n",
      "Learning rate :  4.3074254057568754e-07\n",
      "Average loss :  4.0394224423701e-12\n",
      "\n",
      "\n",
      "Stage  775\n",
      "Epoch 100/200\n",
      "Learning rate :  4.3074254057568754e-07\n",
      "Average loss :  3.897294813259844e-12\n",
      "\n",
      "\n",
      "Stage  775\n",
      "Epoch 150/200\n",
      "Learning rate :  4.3074254057568754e-07\n",
      "Average loss :  4.0241009309494036e-12\n",
      "\n",
      "\n",
      "Stage  775\n",
      "Epoch 200/200\n",
      "Learning rate :  4.3074254057568754e-07\n",
      "Average loss :  3.2187293195345967e-12\n",
      "expression length:\t 5\n",
      "Result stage 777: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399998]*t)\n",
      "\n",
      "\n",
      "Stage  776\n",
      "Epoch 50/200\n",
      "Learning rate :  4.2645658068565385e-07\n",
      "Average loss :  3.04088525193702e-12\n",
      "\n",
      "\n",
      "Stage  776\n",
      "Epoch 100/200\n",
      "Learning rate :  4.2645658068565385e-07\n",
      "Average loss :  3.019290763586757e-12\n",
      "\n",
      "\n",
      "Stage  776\n",
      "Epoch 150/200\n",
      "Learning rate :  4.2645658068565385e-07\n",
      "Average loss :  2.571388414696063e-12\n",
      "\n",
      "\n",
      "Stage  776\n",
      "Epoch 200/200\n",
      "Learning rate :  4.2645658068565385e-07\n",
      "Average loss :  4.39866502596753e-12\n",
      "expression length:\t 5\n",
      "Result stage 778: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  777\n",
      "Epoch 50/200\n",
      "Learning rate :  4.2221326680906995e-07\n",
      "Average loss :  3.7592628662763694e-12\n",
      "\n",
      "\n",
      "Stage  777\n",
      "Epoch 100/200\n",
      "Learning rate :  4.2221326680906995e-07\n",
      "Average loss :  2.854631895449211e-12\n",
      "\n",
      "\n",
      "Stage  777\n",
      "Epoch 150/200\n",
      "Learning rate :  4.2221326680906995e-07\n",
      "Average loss :  2.8281916739092416e-12\n",
      "\n",
      "\n",
      "Stage  777\n",
      "Epoch 200/200\n",
      "Learning rate :  4.2221326680906995e-07\n",
      "Average loss :  2.3584749604677047e-12\n",
      "expression length:\t 5\n",
      "Result stage 779: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  778\n",
      "Epoch 50/200\n",
      "Learning rate :  4.1801217461101295e-07\n",
      "Average loss :  2.3405500627904363e-12\n",
      "\n",
      "\n",
      "Stage  778\n",
      "Epoch 100/200\n",
      "Learning rate :  4.1801217461101295e-07\n",
      "Average loss :  2.3405500627904363e-12\n",
      "\n",
      "\n",
      "Stage  778\n",
      "Epoch 150/200\n",
      "Learning rate :  4.1801217461101295e-07\n",
      "Average loss :  2.3405500627904363e-12\n",
      "\n",
      "\n",
      "Stage  778\n",
      "Epoch 200/200\n",
      "Learning rate :  4.1801217461101295e-07\n",
      "Average loss :  2.3405500627904363e-12\n",
      "expression length:\t 5\n",
      "Result stage 780: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  779\n",
      "Epoch 50/200\n",
      "Learning rate :  4.1385288397876165e-07\n",
      "Average loss :  3.0007428833411787e-12\n",
      "\n",
      "\n",
      "Stage  779\n",
      "Epoch 100/200\n",
      "Learning rate :  4.1385288397876165e-07\n",
      "Average loss :  2.6023939947439345e-12\n",
      "\n",
      "\n",
      "Stage  779\n",
      "Epoch 150/200\n",
      "Learning rate :  4.1385288397876165e-07\n",
      "Average loss :  2.3486230321667634e-12\n",
      "\n",
      "\n",
      "Stage  779\n",
      "Epoch 200/200\n",
      "Learning rate :  4.1385288397876165e-07\n",
      "Average loss :  2.186077490903826e-12\n",
      "expression length:\t 5\n",
      "Result stage 781: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  780\n",
      "Epoch 50/200\n",
      "Learning rate :  4.0973497897978684e-07\n",
      "Average loss :  2.4762498909008945e-12\n",
      "\n",
      "\n",
      "Stage  780\n",
      "Epoch 100/200\n",
      "Learning rate :  4.0973497897978684e-07\n",
      "Average loss :  2.4762498909008945e-12\n",
      "\n",
      "\n",
      "Stage  780\n",
      "Epoch 150/200\n",
      "Learning rate :  4.0973497897978684e-07\n",
      "Average loss :  2.4762498909008945e-12\n",
      "\n",
      "\n",
      "Stage  780\n",
      "Epoch 200/200\n",
      "Learning rate :  4.0973497897978684e-07\n",
      "Average loss :  2.4762498909008945e-12\n",
      "expression length:\t 5\n",
      "Result stage 782: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999973]*t)\n",
      "\n",
      "\n",
      "Stage  781\n",
      "Epoch 50/200\n",
      "Learning rate :  4.0565804782015654e-07\n",
      "Average loss :  2.2584915708445674e-12\n",
      "\n",
      "\n",
      "Stage  781\n",
      "Epoch 100/200\n",
      "Learning rate :  4.0565804782015654e-07\n",
      "Average loss :  3.0678777660636536e-12\n",
      "\n",
      "\n",
      "Stage  781\n",
      "Epoch 150/200\n",
      "Learning rate :  4.0565804782015654e-07\n",
      "Average loss :  2.415171578354358e-12\n",
      "\n",
      "\n",
      "Stage  781\n",
      "Epoch 200/200\n",
      "Learning rate :  4.0565804782015654e-07\n",
      "Average loss :  2.7080275955687627e-12\n",
      "expression length:\t 5\n",
      "Result stage 783: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999978]*t)\n",
      "\n",
      "\n",
      "Stage  782\n",
      "Epoch 50/200\n",
      "Learning rate :  4.016216828033581e-07\n",
      "Average loss :  3.0726126937913323e-12\n",
      "\n",
      "\n",
      "Stage  782\n",
      "Epoch 100/200\n",
      "Learning rate :  4.016216828033581e-07\n",
      "Average loss :  2.750045633923004e-12\n",
      "\n",
      "\n",
      "Stage  782\n",
      "Epoch 150/200\n",
      "Learning rate :  4.016216828033581e-07\n",
      "Average loss :  2.4602409953028426e-12\n",
      "\n",
      "\n",
      "Stage  782\n",
      "Epoch 200/200\n",
      "Learning rate :  4.016216828033581e-07\n",
      "Average loss :  2.9573164663648788e-12\n",
      "expression length:\t 5\n",
      "Result stage 784: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999982]*t)\n",
      "\n",
      "\n",
      "Stage  783\n",
      "Epoch 50/200\n",
      "Learning rate :  3.976254802895259e-07\n",
      "Average loss :  2.23357031654825e-12\n",
      "\n",
      "\n",
      "Stage  783\n",
      "Epoch 100/200\n",
      "Learning rate :  3.976254802895259e-07\n",
      "Average loss :  2.811569553562432e-12\n",
      "\n",
      "\n",
      "Stage  783\n",
      "Epoch 150/200\n",
      "Learning rate :  3.976254802895259e-07\n",
      "Average loss :  2.733467965865266e-12\n",
      "\n",
      "\n",
      "Stage  783\n",
      "Epoch 200/200\n",
      "Learning rate :  3.976254802895259e-07\n",
      "Average loss :  2.23357031654825e-12\n",
      "expression length:\t 5\n",
      "Result stage 785: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  784\n",
      "Epoch 50/200\n",
      "Learning rate :  3.936690406550783e-07\n",
      "Average loss :  2.2375278713182567e-12\n",
      "\n",
      "\n",
      "Stage  784\n",
      "Epoch 100/200\n",
      "Learning rate :  3.936690406550783e-07\n",
      "Average loss :  2.2375278713182567e-12\n",
      "\n",
      "\n",
      "Stage  784\n",
      "Epoch 150/200\n",
      "Learning rate :  3.936690406550783e-07\n",
      "Average loss :  2.2375278713182567e-12\n",
      "\n",
      "\n",
      "Stage  784\n",
      "Epoch 200/200\n",
      "Learning rate :  3.936690406550783e-07\n",
      "Average loss :  2.2375278713182567e-12\n",
      "expression length:\t 5\n",
      "Result stage 786: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  785\n",
      "Epoch 50/200\n",
      "Learning rate :  3.8975196825275447e-07\n",
      "Average loss :  2.3689229831230785e-12\n",
      "\n",
      "\n",
      "Stage  785\n",
      "Epoch 100/200\n",
      "Learning rate :  3.8975196825275447e-07\n",
      "Average loss :  2.3689229831230785e-12\n",
      "\n",
      "\n",
      "Stage  785\n",
      "Epoch 150/200\n",
      "Learning rate :  3.8975196825275447e-07\n",
      "Average loss :  2.3689229831230785e-12\n",
      "\n",
      "\n",
      "Stage  785\n",
      "Epoch 200/200\n",
      "Learning rate :  3.8975196825275447e-07\n",
      "Average loss :  2.3689229831230785e-12\n",
      "expression length:\t 5\n",
      "Result stage 787: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  786\n",
      "Epoch 50/200\n",
      "Learning rate :  3.8587387137205066e-07\n",
      "Average loss :  2.3176387024814726e-12\n",
      "\n",
      "\n",
      "Stage  786\n",
      "Epoch 100/200\n",
      "Learning rate :  3.8587387137205066e-07\n",
      "Average loss :  2.3176387024814726e-12\n",
      "\n",
      "\n",
      "Stage  786\n",
      "Epoch 150/200\n",
      "Learning rate :  3.8587387137205066e-07\n",
      "Average loss :  2.3176387024814726e-12\n",
      "\n",
      "\n",
      "Stage  786\n",
      "Epoch 200/200\n",
      "Learning rate :  3.8587387137205066e-07\n",
      "Average loss :  2.3176387024814726e-12\n",
      "expression length:\t 5\n",
      "Result stage 788: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999979]*t)\n",
      "\n",
      "\n",
      "Stage  787\n",
      "Epoch 50/200\n",
      "Learning rate :  3.820343622000467e-07\n",
      "Average loss :  2.349314753152809e-12\n",
      "\n",
      "\n",
      "Stage  787\n",
      "Epoch 100/200\n",
      "Learning rate :  3.820343622000467e-07\n",
      "Average loss :  2.640323940386602e-12\n",
      "\n",
      "\n",
      "Stage  787\n",
      "Epoch 150/200\n",
      "Learning rate :  3.820343622000467e-07\n",
      "Average loss :  2.606578364608425e-12\n",
      "\n",
      "\n",
      "Stage  787\n",
      "Epoch 200/200\n",
      "Learning rate :  3.820343622000467e-07\n",
      "Average loss :  2.237923605111214e-12\n",
      "expression length:\t 5\n",
      "Result stage 789: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999987]*t)\n",
      "\n",
      "\n",
      "Stage  788\n",
      "Epoch 50/200\n",
      "Learning rate :  3.7823305678262577e-07\n",
      "Average loss :  2.2009035219316964e-12\n",
      "\n",
      "\n",
      "Stage  788\n",
      "Epoch 100/200\n",
      "Learning rate :  3.7823305678262577e-07\n",
      "Average loss :  2.6914633716179637e-12\n",
      "\n",
      "\n",
      "Stage  788\n",
      "Epoch 150/200\n",
      "Learning rate :  3.7823305678262577e-07\n",
      "Average loss :  2.6463963399142587e-12\n",
      "\n",
      "\n",
      "Stage  788\n",
      "Epoch 200/200\n",
      "Learning rate :  3.7823305678262577e-07\n",
      "Average loss :  2.3811662277356538e-12\n",
      "expression length:\t 5\n",
      "Result stage 790: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999982]*t)\n",
      "\n",
      "\n",
      "Stage  789\n",
      "Epoch 50/200\n",
      "Learning rate :  3.74469574986078e-07\n",
      "Average loss :  2.7846050118518484e-12\n",
      "\n",
      "\n",
      "Stage  789\n",
      "Epoch 100/200\n",
      "Learning rate :  3.74469574986078e-07\n",
      "Average loss :  2.44353387350571e-12\n",
      "\n",
      "\n",
      "Stage  789\n",
      "Epoch 150/200\n",
      "Learning rate :  3.74469574986078e-07\n",
      "Average loss :  2.6572056187335047e-12\n",
      "\n",
      "\n",
      "Stage  789\n",
      "Epoch 200/200\n",
      "Learning rate :  3.74469574986078e-07\n",
      "Average loss :  2.514632599370792e-12\n",
      "expression length:\t 5\n",
      "Result stage 791: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  790\n",
      "Epoch 50/200\n",
      "Learning rate :  3.7074354045908823e-07\n",
      "Average loss :  1.7312924097817595e-12\n",
      "\n",
      "\n",
      "Stage  790\n",
      "Epoch 100/200\n",
      "Learning rate :  3.7074354045908823e-07\n",
      "Average loss :  2.207767172204833e-12\n",
      "\n",
      "\n",
      "Stage  790\n",
      "Epoch 150/200\n",
      "Learning rate :  3.7074354045908823e-07\n",
      "Average loss :  1.7312924097817595e-12\n",
      "\n",
      "\n",
      "Stage  790\n",
      "Epoch 200/200\n",
      "Learning rate :  3.7074354045908823e-07\n",
      "Average loss :  2.207767172204833e-12\n",
      "expression length:\t 5\n",
      "Result stage 792: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999996]*t)\n",
      "\n",
      "\n",
      "Stage  791\n",
      "Epoch 50/200\n",
      "Learning rate :  3.670545805950984e-07\n",
      "Average loss :  2.095382027611503e-12\n",
      "\n",
      "\n",
      "Stage  791\n",
      "Epoch 100/200\n",
      "Learning rate :  3.670545805950984e-07\n",
      "Average loss :  2.095382027611503e-12\n",
      "\n",
      "\n",
      "Stage  791\n",
      "Epoch 150/200\n",
      "Learning rate :  3.670545805950984e-07\n",
      "Average loss :  2.095382027611503e-12\n",
      "\n",
      "\n",
      "Stage  791\n",
      "Epoch 200/200\n",
      "Learning rate :  3.670545805950984e-07\n",
      "Average loss :  2.095382027611503e-12\n",
      "expression length:\t 5\n",
      "Result stage 793: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  792\n",
      "Epoch 50/200\n",
      "Learning rate :  3.6340232649504783e-07\n",
      "Average loss :  2.408970809289479e-12\n",
      "\n",
      "\n",
      "Stage  792\n",
      "Epoch 100/200\n",
      "Learning rate :  3.6340232649504783e-07\n",
      "Average loss :  2.408970809289479e-12\n",
      "\n",
      "\n",
      "Stage  792\n",
      "Epoch 150/200\n",
      "Learning rate :  3.6340232649504783e-07\n",
      "Average loss :  2.408970809289479e-12\n",
      "\n",
      "\n",
      "Stage  792\n",
      "Epoch 200/200\n",
      "Learning rate :  3.6340232649504783e-07\n",
      "Average loss :  2.408970809289479e-12\n",
      "expression length:\t 5\n",
      "Result stage 794: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  793\n",
      "Epoch 50/200\n",
      "Learning rate :  3.5978641293048277e-07\n",
      "Average loss :  2.3741165283697185e-12\n",
      "\n",
      "\n",
      "Stage  793\n",
      "Epoch 100/200\n",
      "Learning rate :  3.5978641293048277e-07\n",
      "Average loss :  2.3624156016838205e-12\n",
      "\n",
      "\n",
      "Stage  793\n",
      "Epoch 150/200\n",
      "Learning rate :  3.5978641293048277e-07\n",
      "Average loss :  2.3741165283697185e-12\n",
      "\n",
      "\n",
      "Stage  793\n",
      "Epoch 200/200\n",
      "Learning rate :  3.5978641293048277e-07\n",
      "Average loss :  2.3624156016838205e-12\n",
      "expression length:\t 5\n",
      "Result stage 795: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  794\n",
      "Epoch 50/200\n",
      "Learning rate :  3.5620647830703406e-07\n",
      "Average loss :  2.0992957806137413e-12\n",
      "\n",
      "\n",
      "Stage  794\n",
      "Epoch 100/200\n",
      "Learning rate :  3.5620647830703406e-07\n",
      "Average loss :  2.0992957806137413e-12\n",
      "\n",
      "\n",
      "Stage  794\n",
      "Epoch 150/200\n",
      "Learning rate :  3.5620647830703406e-07\n",
      "Average loss :  2.0992957806137413e-12\n",
      "\n",
      "\n",
      "Stage  794\n",
      "Epoch 200/200\n",
      "Learning rate :  3.5620647830703406e-07\n",
      "Average loss :  2.0992957806137413e-12\n",
      "expression length:\t 5\n",
      "Result stage 796: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999987]*t)\n",
      "\n",
      "\n",
      "Stage  795\n",
      "Epoch 50/200\n",
      "Learning rate :  3.5266216462825577e-07\n",
      "Average loss :  2.294353942944305e-12\n",
      "\n",
      "\n",
      "Stage  795\n",
      "Epoch 100/200\n",
      "Learning rate :  3.5266216462825577e-07\n",
      "Average loss :  2.5307421089304505e-12\n",
      "\n",
      "\n",
      "Stage  795\n",
      "Epoch 150/200\n",
      "Learning rate :  3.5266216462825577e-07\n",
      "Average loss :  2.538400479396019e-12\n",
      "\n",
      "\n",
      "Stage  795\n",
      "Epoch 200/200\n",
      "Learning rate :  3.5266216462825577e-07\n",
      "Average loss :  2.6003927743739608e-12\n",
      "expression length:\t 5\n",
      "Result stage 797: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  796\n",
      "Epoch 50/200\n",
      "Learning rate :  3.4915311745982645e-07\n",
      "Average loss :  2.3575562075467404e-12\n",
      "\n",
      "\n",
      "Stage  796\n",
      "Epoch 100/200\n",
      "Learning rate :  3.4915311745982645e-07\n",
      "Average loss :  1.9227620797618306e-12\n",
      "\n",
      "\n",
      "Stage  796\n",
      "Epoch 150/200\n",
      "Learning rate :  3.4915311745982645e-07\n",
      "Average loss :  2.4906405063362946e-12\n",
      "\n",
      "\n",
      "Stage  796\n",
      "Epoch 200/200\n",
      "Learning rate :  3.4915311745982645e-07\n",
      "Average loss :  1.509488064058151e-12\n",
      "expression length:\t 5\n",
      "Result stage 798: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  797\n",
      "Epoch 50/200\n",
      "Learning rate :  3.4567898589410493e-07\n",
      "Average loss :  1.9723962046969135e-12\n",
      "\n",
      "\n",
      "Stage  797\n",
      "Epoch 100/200\n",
      "Learning rate :  3.4567898589410493e-07\n",
      "Average loss :  1.9723962046969135e-12\n",
      "\n",
      "\n",
      "Stage  797\n",
      "Epoch 150/200\n",
      "Learning rate :  3.4567898589410493e-07\n",
      "Average loss :  1.9723962046969135e-12\n",
      "\n",
      "\n",
      "Stage  797\n",
      "Epoch 200/200\n",
      "Learning rate :  3.4567898589410493e-07\n",
      "Average loss :  1.9723962046969135e-12\n",
      "expression length:\t 5\n",
      "Result stage 799: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  798\n",
      "Epoch 50/200\n",
      "Learning rate :  3.422394225150394e-07\n",
      "Average loss :  2.0249119221660283e-12\n",
      "\n",
      "\n",
      "Stage  798\n",
      "Epoch 100/200\n",
      "Learning rate :  3.422394225150394e-07\n",
      "Average loss :  2.0249119221660283e-12\n",
      "\n",
      "\n",
      "Stage  798\n",
      "Epoch 150/200\n",
      "Learning rate :  3.422394225150394e-07\n",
      "Average loss :  2.0249119221660283e-12\n",
      "\n",
      "\n",
      "Stage  798\n",
      "Epoch 200/200\n",
      "Learning rate :  3.422394225150394e-07\n",
      "Average loss :  2.0249119221660283e-12\n",
      "expression length:\t 5\n",
      "Result stage 800: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  799\n",
      "Epoch 50/200\n",
      "Learning rate :  3.388340833634261e-07\n",
      "Average loss :  1.933884259328056e-12\n",
      "\n",
      "\n",
      "Stage  799\n",
      "Epoch 100/200\n",
      "Learning rate :  3.388340833634261e-07\n",
      "Average loss :  1.933884259328056e-12\n",
      "\n",
      "\n",
      "Stage  799\n",
      "Epoch 150/200\n",
      "Learning rate :  3.388340833634261e-07\n",
      "Average loss :  1.933884259328056e-12\n",
      "\n",
      "\n",
      "Stage  799\n",
      "Epoch 200/200\n",
      "Learning rate :  3.388340833634261e-07\n",
      "Average loss :  1.933884259328056e-12\n",
      "expression length:\t 5\n",
      "Result stage 801: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  800\n",
      "Epoch 50/200\n",
      "Learning rate :  3.3546262790251187e-07\n",
      "Average loss :  2.0329950830427768e-12\n",
      "\n",
      "\n",
      "Stage  800\n",
      "Epoch 100/200\n",
      "Learning rate :  3.3546262790251187e-07\n",
      "Average loss :  1.9293104440432085e-12\n",
      "\n",
      "\n",
      "Stage  800\n",
      "Epoch 150/200\n",
      "Learning rate :  3.3546262790251187e-07\n",
      "Average loss :  2.057540769706545e-12\n",
      "\n",
      "\n",
      "Stage  800\n",
      "Epoch 200/200\n",
      "Learning rate :  3.3546262790251187e-07\n",
      "Average loss :  2.4211199451534826e-12\n",
      "expression length:\t 5\n",
      "Result stage 802: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  801\n",
      "Epoch 50/200\n",
      "Learning rate :  3.3212471898394095e-07\n",
      "Average loss :  2.1070940131595606e-12\n",
      "\n",
      "\n",
      "Stage  801\n",
      "Epoch 100/200\n",
      "Learning rate :  3.3212471898394095e-07\n",
      "Average loss :  2.4957755046656205e-12\n",
      "\n",
      "\n",
      "Stage  801\n",
      "Epoch 150/200\n",
      "Learning rate :  3.3212471898394095e-07\n",
      "Average loss :  1.9828073644784228e-12\n",
      "\n",
      "\n",
      "Stage  801\n",
      "Epoch 200/200\n",
      "Learning rate :  3.3212471898394095e-07\n",
      "Average loss :  1.965578090915021e-12\n",
      "expression length:\t 5\n",
      "Result stage 803: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  802\n",
      "Epoch 50/200\n",
      "Learning rate :  3.2882002281403993e-07\n",
      "Average loss :  2.2104059034522283e-12\n",
      "\n",
      "\n",
      "Stage  802\n",
      "Epoch 100/200\n",
      "Learning rate :  3.2882002281403993e-07\n",
      "Average loss :  2.2104059034522283e-12\n",
      "\n",
      "\n",
      "Stage  802\n",
      "Epoch 150/200\n",
      "Learning rate :  3.2882002281403993e-07\n",
      "Average loss :  2.2104059034522283e-12\n",
      "\n",
      "\n",
      "Stage  802\n",
      "Epoch 200/200\n",
      "Learning rate :  3.2882002281403993e-07\n",
      "Average loss :  2.2104059034522283e-12\n",
      "expression length:\t 5\n",
      "Result stage 804: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  803\n",
      "Epoch 50/200\n",
      "Learning rate :  3.2554820892043795e-07\n",
      "Average loss :  1.8313193843322306e-12\n",
      "\n",
      "\n",
      "Stage  803\n",
      "Epoch 100/200\n",
      "Learning rate :  3.2554820892043795e-07\n",
      "Average loss :  1.8313193843322306e-12\n",
      "\n",
      "\n",
      "Stage  803\n",
      "Epoch 150/200\n",
      "Learning rate :  3.2554820892043795e-07\n",
      "Average loss :  1.8313193843322306e-12\n",
      "\n",
      "\n",
      "Stage  803\n",
      "Epoch 200/200\n",
      "Learning rate :  3.2554820892043795e-07\n",
      "Average loss :  1.8313193843322306e-12\n",
      "expression length:\t 5\n",
      "Result stage 805: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  804\n",
      "Epoch 50/200\n",
      "Learning rate :  3.2230895011901854e-07\n",
      "Average loss :  1.478107133218165e-12\n",
      "\n",
      "\n",
      "Stage  804\n",
      "Epoch 100/200\n",
      "Learning rate :  3.2230895011901854e-07\n",
      "Average loss :  2.0598982589103976e-12\n",
      "\n",
      "\n",
      "Stage  804\n",
      "Epoch 150/200\n",
      "Learning rate :  3.2230895011901854e-07\n",
      "Average loss :  2.8693061381729335e-12\n",
      "\n",
      "\n",
      "Stage  804\n",
      "Epoch 200/200\n",
      "Learning rate :  3.2230895011901854e-07\n",
      "Average loss :  2.758582641829155e-12\n",
      "expression length:\t 5\n",
      "Result stage 806: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  805\n",
      "Epoch 50/200\n",
      "Learning rate :  3.1910192248120326e-07\n",
      "Average loss :  1.733668222002327e-12\n",
      "\n",
      "\n",
      "Stage  805\n",
      "Epoch 100/200\n",
      "Learning rate :  3.1910192248120326e-07\n",
      "Average loss :  2.706576499381108e-12\n",
      "\n",
      "\n",
      "Stage  805\n",
      "Epoch 150/200\n",
      "Learning rate :  3.1910192248120326e-07\n",
      "Average loss :  2.758582641829155e-12\n",
      "\n",
      "\n",
      "Stage  805\n",
      "Epoch 200/200\n",
      "Learning rate :  3.1910192248120326e-07\n",
      "Average loss :  1.733668222002327e-12\n",
      "expression length:\t 5\n",
      "Result stage 807: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999997]*t)\n",
      "\n",
      "\n",
      "Stage  806\n",
      "Epoch 50/200\n",
      "Learning rate :  3.1592680530155527e-07\n",
      "Average loss :  1.926643306698894e-12\n",
      "\n",
      "\n",
      "Stage  806\n",
      "Epoch 100/200\n",
      "Learning rate :  3.1592680530155527e-07\n",
      "Average loss :  1.926643306698894e-12\n",
      "\n",
      "\n",
      "Stage  806\n",
      "Epoch 150/200\n",
      "Learning rate :  3.1592680530155527e-07\n",
      "Average loss :  1.926643306698894e-12\n",
      "\n",
      "\n",
      "Stage  806\n",
      "Epoch 200/200\n",
      "Learning rate :  3.1592680530155527e-07\n",
      "Average loss :  1.926643306698894e-12\n",
      "expression length:\t 5\n",
      "Result stage 808: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  807\n",
      "Epoch 50/200\n",
      "Learning rate :  3.1278328106571066e-07\n",
      "Average loss :  2.574768089708135e-12\n",
      "\n",
      "\n",
      "Stage  807\n",
      "Epoch 100/200\n",
      "Learning rate :  3.1278328106571066e-07\n",
      "Average loss :  1.95818383209867e-12\n",
      "\n",
      "\n",
      "Stage  807\n",
      "Epoch 150/200\n",
      "Learning rate :  3.1278328106571066e-07\n",
      "Average loss :  2.6631995220238736e-12\n",
      "\n",
      "\n",
      "Stage  807\n",
      "Epoch 200/200\n",
      "Learning rate :  3.1278328106571066e-07\n",
      "Average loss :  1.7742315863017444e-12\n",
      "expression length:\t 5\n",
      "Result stage 809: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999987]*t)\n",
      "\n",
      "\n",
      "Stage  808\n",
      "Epoch 50/200\n",
      "Learning rate :  3.096710354186262e-07\n",
      "Average loss :  2.5093878797816105e-12\n",
      "\n",
      "\n",
      "Stage  808\n",
      "Epoch 100/200\n",
      "Learning rate :  3.096710354186262e-07\n",
      "Average loss :  2.5093878797816105e-12\n",
      "\n",
      "\n",
      "Stage  808\n",
      "Epoch 150/200\n",
      "Learning rate :  3.096710354186262e-07\n",
      "Average loss :  2.5093878797816105e-12\n",
      "\n",
      "\n",
      "Stage  808\n",
      "Epoch 200/200\n",
      "Learning rate :  3.096710354186262e-07\n",
      "Average loss :  2.5093878797816105e-12\n",
      "expression length:\t 5\n",
      "Result stage 810: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  809\n",
      "Epoch 50/200\n",
      "Learning rate :  3.065897571331437e-07\n",
      "Average loss :  2.0346075085136972e-12\n",
      "\n",
      "\n",
      "Stage  809\n",
      "Epoch 100/200\n",
      "Learning rate :  3.065897571331437e-07\n",
      "Average loss :  1.8152188736506036e-12\n",
      "\n",
      "\n",
      "Stage  809\n",
      "Epoch 150/200\n",
      "Learning rate :  3.065897571331437e-07\n",
      "Average loss :  1.9175694018769285e-12\n",
      "\n",
      "\n",
      "Stage  809\n",
      "Epoch 200/200\n",
      "Learning rate :  3.065897571331437e-07\n",
      "Average loss :  2.0346075085136972e-12\n",
      "expression length:\t 5\n",
      "Result stage 811: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  810\n",
      "Epoch 50/200\n",
      "Learning rate :  3.035391380788668e-07\n",
      "Average loss :  1.915796948165349e-12\n",
      "\n",
      "\n",
      "Stage  810\n",
      "Epoch 100/200\n",
      "Learning rate :  3.035391380788668e-07\n",
      "Average loss :  1.7723769500654907e-12\n",
      "\n",
      "\n",
      "Stage  810\n",
      "Epoch 150/200\n",
      "Learning rate :  3.035391380788668e-07\n",
      "Average loss :  2.353398075374824e-12\n",
      "\n",
      "\n",
      "Stage  810\n",
      "Epoch 200/200\n",
      "Learning rate :  3.035391380788668e-07\n",
      "Average loss :  1.865186390753726e-12\n",
      "expression length:\t 5\n",
      "Result stage 812: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999987]*t)\n",
      "\n",
      "\n",
      "Stage  811\n",
      "Epoch 50/200\n",
      "Learning rate :  3.005188731913479e-07\n",
      "Average loss :  1.7210144984472486e-12\n",
      "\n",
      "\n",
      "Stage  811\n",
      "Epoch 100/200\n",
      "Learning rate :  3.005188731913479e-07\n",
      "Average loss :  1.9501308120423166e-12\n",
      "\n",
      "\n",
      "Stage  811\n",
      "Epoch 150/200\n",
      "Learning rate :  3.005188731913479e-07\n",
      "Average loss :  1.8719862899391204e-12\n",
      "\n",
      "\n",
      "Stage  811\n",
      "Epoch 200/200\n",
      "Learning rate :  3.005188731913479e-07\n",
      "Average loss :  1.973378275024751e-12\n",
      "expression length:\t 5\n",
      "Result stage 813: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  812\n",
      "Epoch 50/200\n",
      "Learning rate :  2.975286604415808e-07\n",
      "Average loss :  1.920592591214687e-12\n",
      "\n",
      "\n",
      "Stage  812\n",
      "Epoch 100/200\n",
      "Learning rate :  2.975286604415808e-07\n",
      "Average loss :  1.686641711712289e-12\n",
      "\n",
      "\n",
      "Stage  812\n",
      "Epoch 150/200\n",
      "Learning rate :  2.975286604415808e-07\n",
      "Average loss :  1.991243324742098e-12\n",
      "\n",
      "\n",
      "Stage  812\n",
      "Epoch 200/200\n",
      "Learning rate :  2.975286604415808e-07\n",
      "Average loss :  1.952132249252725e-12\n",
      "expression length:\t 5\n",
      "Result stage 814: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  813\n",
      "Epoch 50/200\n",
      "Learning rate :  2.945682008057998e-07\n",
      "Average loss :  2.989726088226119e-12\n",
      "\n",
      "\n",
      "Stage  813\n",
      "Epoch 100/200\n",
      "Learning rate :  2.945682008057998e-07\n",
      "Average loss :  1.6138888185926459e-12\n",
      "\n",
      "\n",
      "Stage  813\n",
      "Epoch 150/200\n",
      "Learning rate :  2.945682008057998e-07\n",
      "Average loss :  1.7076237342553147e-12\n",
      "\n",
      "\n",
      "Stage  813\n",
      "Epoch 200/200\n",
      "Learning rate :  2.945682008057998e-07\n",
      "Average loss :  1.991243324742098e-12\n",
      "expression length:\t 5\n",
      "Result stage 815: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  814\n",
      "Epoch 50/200\n",
      "Learning rate :  2.916371982355737e-07\n",
      "Average loss :  1.99284859447868e-12\n",
      "\n",
      "\n",
      "Stage  814\n",
      "Epoch 100/200\n",
      "Learning rate :  2.916371982355737e-07\n",
      "Average loss :  1.7680140121031918e-12\n",
      "\n",
      "\n",
      "Stage  814\n",
      "Epoch 150/200\n",
      "Learning rate :  2.916371982355737e-07\n",
      "Average loss :  1.887945745918107e-12\n",
      "\n",
      "\n",
      "Stage  814\n",
      "Epoch 200/200\n",
      "Learning rate :  2.916371982355737e-07\n",
      "Average loss :  1.783284566021781e-12\n",
      "expression length:\t 5\n",
      "Result stage 816: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  815\n",
      "Epoch 50/200\n",
      "Learning rate :  2.88735359628203e-07\n",
      "Average loss :  1.971561585864534e-12\n",
      "\n",
      "\n",
      "Stage  815\n",
      "Epoch 100/200\n",
      "Learning rate :  2.88735359628203e-07\n",
      "Average loss :  1.8486930736250073e-12\n",
      "\n",
      "\n",
      "Stage  815\n",
      "Epoch 150/200\n",
      "Learning rate :  2.88735359628203e-07\n",
      "Average loss :  1.7329609969252147e-12\n",
      "\n",
      "\n",
      "Stage  815\n",
      "Epoch 200/200\n",
      "Learning rate :  2.88735359628203e-07\n",
      "Average loss :  1.910957937029112e-12\n",
      "expression length:\t 5\n",
      "Result stage 817: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999982]*t)\n",
      "\n",
      "\n",
      "Stage  816\n",
      "Epoch 50/200\n",
      "Learning rate :  2.858623947974087e-07\n",
      "Average loss :  2.1803119205909827e-12\n",
      "\n",
      "\n",
      "Stage  816\n",
      "Epoch 100/200\n",
      "Learning rate :  2.858623947974087e-07\n",
      "Average loss :  2.569826729886815e-12\n",
      "\n",
      "\n",
      "Stage  816\n",
      "Epoch 150/200\n",
      "Learning rate :  2.858623947974087e-07\n",
      "Average loss :  1.6492024759728885e-12\n",
      "\n",
      "\n",
      "Stage  816\n",
      "Epoch 200/200\n",
      "Learning rate :  2.858623947974087e-07\n",
      "Average loss :  2.0377514779734707e-12\n",
      "expression length:\t 5\n",
      "Result stage 818: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  817\n",
      "Epoch 50/200\n",
      "Learning rate :  2.8301801644431357e-07\n",
      "Average loss :  2.0825680589753315e-12\n",
      "\n",
      "\n",
      "Stage  817\n",
      "Epoch 100/200\n",
      "Learning rate :  2.8301801644431357e-07\n",
      "Average loss :  1.6568605211778054e-12\n",
      "\n",
      "\n",
      "Stage  817\n",
      "Epoch 150/200\n",
      "Learning rate :  2.8301801644431357e-07\n",
      "Average loss :  1.8998951717419388e-12\n",
      "\n",
      "\n",
      "Stage  817\n",
      "Epoch 200/200\n",
      "Learning rate :  2.8301801644431357e-07\n",
      "Average loss :  2.0825680589753315e-12\n",
      "expression length:\t 5\n",
      "Result stage 819: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  818\n",
      "Epoch 50/200\n",
      "Learning rate :  2.8020194012871203e-07\n",
      "Average loss :  1.835404224437287e-12\n",
      "\n",
      "\n",
      "Stage  818\n",
      "Epoch 100/200\n",
      "Learning rate :  2.8020194012871203e-07\n",
      "Average loss :  1.6556574904472154e-12\n",
      "\n",
      "\n",
      "Stage  818\n",
      "Epoch 150/200\n",
      "Learning rate :  2.8020194012871203e-07\n",
      "Average loss :  1.4226924759802584e-12\n",
      "\n",
      "\n",
      "Stage  818\n",
      "Epoch 200/200\n",
      "Learning rate :  2.8020194012871203e-07\n",
      "Average loss :  1.636335815111134e-12\n",
      "expression length:\t 5\n",
      "Result stage 820: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999987]*t)\n",
      "\n",
      "\n",
      "Stage  819\n",
      "Epoch 50/200\n",
      "Learning rate :  2.774138842406257e-07\n",
      "Average loss :  1.9082261812353174e-12\n",
      "\n",
      "\n",
      "Stage  819\n",
      "Epoch 100/200\n",
      "Learning rate :  2.774138842406257e-07\n",
      "Average loss :  1.9082261812353174e-12\n",
      "\n",
      "\n",
      "Stage  819\n",
      "Epoch 150/200\n",
      "Learning rate :  2.774138842406257e-07\n",
      "Average loss :  1.9082261812353174e-12\n",
      "\n",
      "\n",
      "Stage  819\n",
      "Epoch 200/200\n",
      "Learning rate :  2.774138842406257e-07\n",
      "Average loss :  1.9082261812353174e-12\n",
      "expression length:\t 5\n",
      "Result stage 821: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  820\n",
      "Epoch 50/200\n",
      "Learning rate :  2.7465356997214254e-07\n",
      "Average loss :  1.6478388749005535e-12\n",
      "\n",
      "\n",
      "Stage  820\n",
      "Epoch 100/200\n",
      "Learning rate :  2.7465356997214254e-07\n",
      "Average loss :  1.846349245368528e-12\n",
      "\n",
      "\n",
      "Stage  820\n",
      "Epoch 150/200\n",
      "Learning rate :  2.7465356997214254e-07\n",
      "Average loss :  2.057966427479463e-12\n",
      "\n",
      "\n",
      "Stage  820\n",
      "Epoch 200/200\n",
      "Learning rate :  2.7465356997214254e-07\n",
      "Average loss :  1.6478388749005535e-12\n",
      "expression length:\t 5\n",
      "Result stage 822: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  821\n",
      "Epoch 50/200\n",
      "Learning rate :  2.7192072128953474e-07\n",
      "Average loss :  2.0387175021091553e-12\n",
      "\n",
      "\n",
      "Stage  821\n",
      "Epoch 100/200\n",
      "Learning rate :  2.7192072128953474e-07\n",
      "Average loss :  1.906865507508848e-12\n",
      "\n",
      "\n",
      "Stage  821\n",
      "Epoch 150/200\n",
      "Learning rate :  2.7192072128953474e-07\n",
      "Average loss :  1.740505851423324e-12\n",
      "\n",
      "\n",
      "Stage  821\n",
      "Epoch 200/200\n",
      "Learning rate :  2.7192072128953474e-07\n",
      "Average loss :  1.7619256748035994e-12\n",
      "expression length:\t 5\n",
      "Result stage 823: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  822\n",
      "Epoch 50/200\n",
      "Learning rate :  2.6921506490565786e-07\n",
      "Average loss :  1.821307644631065e-12\n",
      "\n",
      "\n",
      "Stage  822\n",
      "Epoch 100/200\n",
      "Learning rate :  2.6921506490565786e-07\n",
      "Average loss :  1.821307644631065e-12\n",
      "\n",
      "\n",
      "Stage  822\n",
      "Epoch 150/200\n",
      "Learning rate :  2.6921506490565786e-07\n",
      "Average loss :  1.821307644631065e-12\n",
      "\n",
      "\n",
      "Stage  822\n",
      "Epoch 200/200\n",
      "Learning rate :  2.6921506490565786e-07\n",
      "Average loss :  1.821307644631065e-12\n",
      "expression length:\t 5\n",
      "Result stage 824: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  823\n",
      "Epoch 50/200\n",
      "Learning rate :  2.665363302526181e-07\n",
      "Average loss :  2.0005780886067637e-12\n",
      "\n",
      "\n",
      "Stage  823\n",
      "Epoch 100/200\n",
      "Learning rate :  2.665363302526181e-07\n",
      "Average loss :  2.0005780886067637e-12\n",
      "\n",
      "\n",
      "Stage  823\n",
      "Epoch 150/200\n",
      "Learning rate :  2.665363302526181e-07\n",
      "Average loss :  2.0005780886067637e-12\n",
      "\n",
      "\n",
      "Stage  823\n",
      "Epoch 200/200\n",
      "Learning rate :  2.665363302526181e-07\n",
      "Average loss :  2.0005780886067637e-12\n",
      "expression length:\t 5\n",
      "Result stage 825: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  824\n",
      "Epoch 50/200\n",
      "Learning rate :  2.6388424945471795e-07\n",
      "Average loss :  1.9198707294082462e-12\n",
      "\n",
      "\n",
      "Stage  824\n",
      "Epoch 100/200\n",
      "Learning rate :  2.6388424945471795e-07\n",
      "Average loss :  1.933280141877547e-12\n",
      "\n",
      "\n",
      "Stage  824\n",
      "Epoch 150/200\n",
      "Learning rate :  2.6388424945471795e-07\n",
      "Average loss :  1.8807514139823622e-12\n",
      "\n",
      "\n",
      "Stage  824\n",
      "Epoch 200/200\n",
      "Learning rate :  2.6388424945471795e-07\n",
      "Average loss :  1.9198707294082462e-12\n",
      "expression length:\t 5\n",
      "Result stage 826: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  825\n",
      "Epoch 50/200\n",
      "Learning rate :  2.6125855730166756e-07\n",
      "Average loss :  1.8842232461790953e-12\n",
      "\n",
      "\n",
      "Stage  825\n",
      "Epoch 100/200\n",
      "Learning rate :  2.6125855730166756e-07\n",
      "Average loss :  1.420762921373886e-12\n",
      "\n",
      "\n",
      "Stage  825\n",
      "Epoch 150/200\n",
      "Learning rate :  2.6125855730166756e-07\n",
      "Average loss :  1.8842232461790953e-12\n",
      "\n",
      "\n",
      "Stage  825\n",
      "Epoch 200/200\n",
      "Learning rate :  2.6125855730166756e-07\n",
      "Average loss :  1.420762921373886e-12\n",
      "expression length:\t 5\n",
      "Result stage 827: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  826\n",
      "Epoch 50/200\n",
      "Learning rate :  2.586589912220635e-07\n",
      "Average loss :  2.178718143397429e-12\n",
      "\n",
      "\n",
      "Stage  826\n",
      "Epoch 100/200\n",
      "Learning rate :  2.586589912220635e-07\n",
      "Average loss :  2.178718143397429e-12\n",
      "\n",
      "\n",
      "Stage  826\n",
      "Epoch 150/200\n",
      "Learning rate :  2.586589912220635e-07\n",
      "Average loss :  2.178718143397429e-12\n",
      "\n",
      "\n",
      "Stage  826\n",
      "Epoch 200/200\n",
      "Learning rate :  2.586589912220635e-07\n",
      "Average loss :  2.178718143397429e-12\n",
      "expression length:\t 5\n",
      "Result stage 828: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399998]*t)\n",
      "\n",
      "\n",
      "Stage  827\n",
      "Epoch 50/200\n",
      "Learning rate :  2.5608529125713155e-07\n",
      "Average loss :  1.8962971384123284e-12\n",
      "\n",
      "\n",
      "Stage  827\n",
      "Epoch 100/200\n",
      "Learning rate :  2.5608529125713155e-07\n",
      "Average loss :  1.6185386364497845e-12\n",
      "\n",
      "\n",
      "Stage  827\n",
      "Epoch 150/200\n",
      "Learning rate :  2.5608529125713155e-07\n",
      "Average loss :  1.6221224667309353e-12\n",
      "\n",
      "\n",
      "Stage  827\n",
      "Epoch 200/200\n",
      "Learning rate :  2.5608529125713155e-07\n",
      "Average loss :  1.8957637109434655e-12\n",
      "expression length:\t 5\n",
      "Result stage 829: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  828\n",
      "Epoch 50/200\n",
      "Learning rate :  2.535372000347304e-07\n",
      "Average loss :  2.2289199565900253e-12\n",
      "\n",
      "\n",
      "Stage  828\n",
      "Epoch 100/200\n",
      "Learning rate :  2.535372000347304e-07\n",
      "Average loss :  1.7934267352442967e-12\n",
      "\n",
      "\n",
      "Stage  828\n",
      "Epoch 150/200\n",
      "Learning rate :  2.535372000347304e-07\n",
      "Average loss :  2.2289199565900253e-12\n",
      "\n",
      "\n",
      "Stage  828\n",
      "Epoch 200/200\n",
      "Learning rate :  2.535372000347304e-07\n",
      "Average loss :  1.7934267352442967e-12\n",
      "expression length:\t 5\n",
      "Result stage 830: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  829\n",
      "Epoch 50/200\n",
      "Learning rate :  2.5101446274361404e-07\n",
      "Average loss :  1.4953616686921856e-12\n",
      "\n",
      "\n",
      "Stage  829\n",
      "Epoch 100/200\n",
      "Learning rate :  2.5101446274361404e-07\n",
      "Average loss :  1.8461705688505026e-12\n",
      "\n",
      "\n",
      "Stage  829\n",
      "Epoch 150/200\n",
      "Learning rate :  2.5101446274361404e-07\n",
      "Average loss :  1.8902503260559422e-12\n",
      "\n",
      "\n",
      "Stage  829\n",
      "Epoch 200/200\n",
      "Learning rate :  2.5101446274361404e-07\n",
      "Average loss :  1.6175444230576153e-12\n",
      "expression length:\t 5\n",
      "Result stage 831: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999982]*t)\n",
      "\n",
      "\n",
      "Stage  830\n",
      "Epoch 50/200\n",
      "Learning rate :  2.4851682710795184e-07\n",
      "Average loss :  1.6175444230576153e-12\n",
      "\n",
      "\n",
      "Stage  830\n",
      "Epoch 100/200\n",
      "Learning rate :  2.4851682710795184e-07\n",
      "Average loss :  1.6175444230576153e-12\n",
      "\n",
      "\n",
      "Stage  830\n",
      "Epoch 150/200\n",
      "Learning rate :  2.4851682710795184e-07\n",
      "Average loss :  1.6175444230576153e-12\n",
      "\n",
      "\n",
      "Stage  830\n",
      "Epoch 200/200\n",
      "Learning rate :  2.4851682710795184e-07\n",
      "Average loss :  1.6175444230576153e-12\n",
      "expression length:\t 5\n",
      "Result stage 832: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999982]*t)\n",
      "\n",
      "\n",
      "Stage  831\n",
      "Epoch 50/200\n",
      "Learning rate :  2.4604404336209854e-07\n",
      "Average loss :  1.8848048122244165e-12\n",
      "\n",
      "\n",
      "Stage  831\n",
      "Epoch 100/200\n",
      "Learning rate :  2.4604404336209854e-07\n",
      "Average loss :  1.8513279017445816e-12\n",
      "\n",
      "\n",
      "Stage  831\n",
      "Epoch 150/200\n",
      "Learning rate :  2.4604404336209854e-07\n",
      "Average loss :  1.786698284982069e-12\n",
      "\n",
      "\n",
      "Stage  831\n",
      "Epoch 200/200\n",
      "Learning rate :  2.4604404336209854e-07\n",
      "Average loss :  2.239457751185281e-12\n",
      "expression length:\t 5\n",
      "Result stage 833: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  832\n",
      "Epoch 50/200\n",
      "Learning rate :  2.435958642256188e-07\n",
      "Average loss :  1.5996267895349026e-12\n",
      "\n",
      "\n",
      "Stage  832\n",
      "Epoch 100/200\n",
      "Learning rate :  2.435958642256188e-07\n",
      "Average loss :  1.7823595247282165e-12\n",
      "\n",
      "\n",
      "Stage  832\n",
      "Epoch 150/200\n",
      "Learning rate :  2.435958642256188e-07\n",
      "Average loss :  1.5996267895349026e-12\n",
      "\n",
      "\n",
      "Stage  832\n",
      "Epoch 200/200\n",
      "Learning rate :  2.435958642256188e-07\n",
      "Average loss :  1.7823595247282165e-12\n",
      "expression length:\t 5\n",
      "Result stage 834: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  833\n",
      "Epoch 50/200\n",
      "Learning rate :  2.4117204487855886e-07\n",
      "Average loss :  2.1331829531956448e-12\n",
      "\n",
      "\n",
      "Stage  833\n",
      "Epoch 100/200\n",
      "Learning rate :  2.4117204487855886e-07\n",
      "Average loss :  2.1331829531956448e-12\n",
      "\n",
      "\n",
      "Stage  833\n",
      "Epoch 150/200\n",
      "Learning rate :  2.4117204487855886e-07\n",
      "Average loss :  2.1331829531956448e-12\n",
      "\n",
      "\n",
      "Stage  833\n",
      "Epoch 200/200\n",
      "Learning rate :  2.4117204487855886e-07\n",
      "Average loss :  2.1331829531956448e-12\n",
      "expression length:\t 5\n",
      "Result stage 835: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  834\n",
      "Epoch 50/200\n",
      "Learning rate :  2.3877234293696417e-07\n",
      "Average loss :  1.6322237615315482e-12\n",
      "\n",
      "\n",
      "Stage  834\n",
      "Epoch 100/200\n",
      "Learning rate :  2.3877234293696417e-07\n",
      "Average loss :  1.6554179901873134e-12\n",
      "\n",
      "\n",
      "Stage  834\n",
      "Epoch 150/200\n",
      "Learning rate :  2.3877234293696417e-07\n",
      "Average loss :  1.5062187608272382e-12\n",
      "\n",
      "\n",
      "Stage  834\n",
      "Epoch 200/200\n",
      "Learning rate :  2.3877234293696417e-07\n",
      "Average loss :  1.6322237615315482e-12\n",
      "expression length:\t 5\n",
      "Result stage 836: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  835\n",
      "Epoch 50/200\n",
      "Learning rate :  2.3639651842864073e-07\n",
      "Average loss :  1.64594206319979e-12\n",
      "\n",
      "\n",
      "Stage  835\n",
      "Epoch 100/200\n",
      "Learning rate :  2.3639651842864073e-07\n",
      "Average loss :  1.64594206319979e-12\n",
      "\n",
      "\n",
      "Stage  835\n",
      "Epoch 150/200\n",
      "Learning rate :  2.3639651842864073e-07\n",
      "Average loss :  1.64594206319979e-12\n",
      "\n",
      "\n",
      "Stage  835\n",
      "Epoch 200/200\n",
      "Learning rate :  2.3639651842864073e-07\n",
      "Average loss :  1.64594206319979e-12\n",
      "expression length:\t 5\n",
      "Result stage 837: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  836\n",
      "Epoch 50/200\n",
      "Learning rate :  2.3404433376915795e-07\n",
      "Average loss :  1.64594206319979e-12\n",
      "\n",
      "\n",
      "Stage  836\n",
      "Epoch 100/200\n",
      "Learning rate :  2.3404433376915795e-07\n",
      "Average loss :  1.64594206319979e-12\n",
      "\n",
      "\n",
      "Stage  836\n",
      "Epoch 150/200\n",
      "Learning rate :  2.3404433376915795e-07\n",
      "Average loss :  1.64594206319979e-12\n",
      "\n",
      "\n",
      "Stage  836\n",
      "Epoch 200/200\n",
      "Learning rate :  2.3404433376915795e-07\n",
      "Average loss :  1.64594206319979e-12\n",
      "expression length:\t 5\n",
      "Result stage 838: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  837\n",
      "Epoch 50/200\n",
      "Learning rate :  2.3171555373808927e-07\n",
      "Average loss :  1.8401059755784877e-12\n",
      "\n",
      "\n",
      "Stage  837\n",
      "Epoch 100/200\n",
      "Learning rate :  2.3171555373808927e-07\n",
      "Average loss :  1.8401059755784877e-12\n",
      "\n",
      "\n",
      "Stage  837\n",
      "Epoch 150/200\n",
      "Learning rate :  2.3171555373808927e-07\n",
      "Average loss :  1.8401059755784877e-12\n",
      "\n",
      "\n",
      "Stage  837\n",
      "Epoch 200/200\n",
      "Learning rate :  2.3171555373808927e-07\n",
      "Average loss :  1.8401059755784877e-12\n",
      "expression length:\t 5\n",
      "Result stage 839: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999987]*t)\n",
      "\n",
      "\n",
      "Stage  838\n",
      "Epoch 50/200\n",
      "Learning rate :  2.2940994545549173e-07\n",
      "Average loss :  2.1666492384941893e-12\n",
      "\n",
      "\n",
      "Stage  838\n",
      "Epoch 100/200\n",
      "Learning rate :  2.2940994545549173e-07\n",
      "Average loss :  2.1666492384941893e-12\n",
      "\n",
      "\n",
      "Stage  838\n",
      "Epoch 150/200\n",
      "Learning rate :  2.2940994545549173e-07\n",
      "Average loss :  2.1666492384941893e-12\n",
      "\n",
      "\n",
      "Stage  838\n",
      "Epoch 200/200\n",
      "Learning rate :  2.2940994545549173e-07\n",
      "Average loss :  2.1666492384941893e-12\n",
      "expression length:\t 5\n",
      "Result stage 840: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  839\n",
      "Epoch 50/200\n",
      "Learning rate :  2.2712727835861535e-07\n",
      "Average loss :  1.5902681732224422e-12\n",
      "\n",
      "\n",
      "Stage  839\n",
      "Epoch 100/200\n",
      "Learning rate :  2.2712727835861535e-07\n",
      "Average loss :  1.603569490735146e-12\n",
      "\n",
      "\n",
      "Stage  839\n",
      "Epoch 150/200\n",
      "Learning rate :  2.2712727835861535e-07\n",
      "Average loss :  1.747310304257843e-12\n",
      "\n",
      "\n",
      "Stage  839\n",
      "Epoch 200/200\n",
      "Learning rate :  2.2712727835861535e-07\n",
      "Average loss :  1.5902681732224422e-12\n",
      "expression length:\t 5\n",
      "Result stage 841: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  840\n",
      "Epoch 50/200\n",
      "Learning rate :  2.248673241788482e-07\n",
      "Average loss :  1.931503568197712e-12\n",
      "\n",
      "\n",
      "Stage  840\n",
      "Epoch 100/200\n",
      "Learning rate :  2.248673241788482e-07\n",
      "Average loss :  1.931503568197712e-12\n",
      "\n",
      "\n",
      "Stage  840\n",
      "Epoch 150/200\n",
      "Learning rate :  2.248673241788482e-07\n",
      "Average loss :  1.931503568197712e-12\n",
      "\n",
      "\n",
      "Stage  840\n",
      "Epoch 200/200\n",
      "Learning rate :  2.248673241788482e-07\n",
      "Average loss :  1.931503568197712e-12\n",
      "expression length:\t 5\n",
      "Result stage 842: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  841\n",
      "Epoch 50/200\n",
      "Learning rate :  2.2262985691888899e-07\n",
      "Average loss :  1.5085966330319334e-12\n",
      "\n",
      "\n",
      "Stage  841\n",
      "Epoch 100/200\n",
      "Learning rate :  2.2262985691888899e-07\n",
      "Average loss :  1.831376630206938e-12\n",
      "\n",
      "\n",
      "Stage  841\n",
      "Epoch 150/200\n",
      "Learning rate :  2.2262985691888899e-07\n",
      "Average loss :  1.293123052213685e-12\n",
      "\n",
      "\n",
      "Stage  841\n",
      "Epoch 200/200\n",
      "Learning rate :  2.2262985691888899e-07\n",
      "Average loss :  1.5085966330319334e-12\n",
      "expression length:\t 5\n",
      "Result stage 843: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999996]*t)\n",
      "\n",
      "\n",
      "Stage  842\n",
      "Epoch 50/200\n",
      "Learning rate :  2.2041465283014715e-07\n",
      "Average loss :  1.4961576899272244e-12\n",
      "\n",
      "\n",
      "Stage  842\n",
      "Epoch 100/200\n",
      "Learning rate :  2.2041465283014715e-07\n",
      "Average loss :  1.5399129454224392e-12\n",
      "\n",
      "\n",
      "Stage  842\n",
      "Epoch 150/200\n",
      "Learning rate :  2.2041465283014715e-07\n",
      "Average loss :  1.4961576899272244e-12\n",
      "\n",
      "\n",
      "Stage  842\n",
      "Epoch 200/200\n",
      "Learning rate :  2.2041465283014715e-07\n",
      "Average loss :  1.5399129454224392e-12\n",
      "expression length:\t 5\n",
      "Result stage 844: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  843\n",
      "Epoch 50/200\n",
      "Learning rate :  2.1822149039036782e-07\n",
      "Average loss :  1.4838491763438655e-12\n",
      "\n",
      "\n",
      "Stage  843\n",
      "Epoch 100/200\n",
      "Learning rate :  2.1822149039036782e-07\n",
      "Average loss :  1.5625891422801907e-12\n",
      "\n",
      "\n",
      "Stage  843\n",
      "Epoch 150/200\n",
      "Learning rate :  2.1822149039036782e-07\n",
      "Average loss :  1.4838491763438655e-12\n",
      "\n",
      "\n",
      "Stage  843\n",
      "Epoch 200/200\n",
      "Learning rate :  2.1822149039036782e-07\n",
      "Average loss :  1.5625891422801907e-12\n",
      "expression length:\t 5\n",
      "Result stage 845: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  844\n",
      "Epoch 50/200\n",
      "Learning rate :  2.160501502814794e-07\n",
      "Average loss :  1.853914808128132e-12\n",
      "\n",
      "\n",
      "Stage  844\n",
      "Epoch 100/200\n",
      "Learning rate :  2.160501502814794e-07\n",
      "Average loss :  1.853914808128132e-12\n",
      "\n",
      "\n",
      "Stage  844\n",
      "Epoch 150/200\n",
      "Learning rate :  2.160501502814794e-07\n",
      "Average loss :  1.853914808128132e-12\n",
      "\n",
      "\n",
      "Stage  844\n",
      "Epoch 200/200\n",
      "Learning rate :  2.160501502814794e-07\n",
      "Average loss :  1.853914808128132e-12\n",
      "expression length:\t 5\n",
      "Result stage 846: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000002]*t)\n",
      "\n",
      "\n",
      "Stage  845\n",
      "Epoch 50/200\n",
      "Learning rate :  2.1390041536766148e-07\n",
      "Average loss :  1.8543823161049078e-12\n",
      "\n",
      "\n",
      "Stage  845\n",
      "Epoch 100/200\n",
      "Learning rate :  2.1390041536766148e-07\n",
      "Average loss :  1.8596977256757352e-12\n",
      "\n",
      "\n",
      "Stage  845\n",
      "Epoch 150/200\n",
      "Learning rate :  2.1390041536766148e-07\n",
      "Average loss :  1.8543823161049078e-12\n",
      "\n",
      "\n",
      "Stage  845\n",
      "Epoch 200/200\n",
      "Learning rate :  2.1390041536766148e-07\n",
      "Average loss :  1.8596977256757352e-12\n",
      "expression length:\t 5\n",
      "Result stage 847: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000002]*t)\n",
      "\n",
      "\n",
      "Stage  846\n",
      "Epoch 50/200\n",
      "Learning rate :  2.1177207067363092e-07\n",
      "Average loss :  1.852184855141714e-12\n",
      "\n",
      "\n",
      "Stage  846\n",
      "Epoch 100/200\n",
      "Learning rate :  2.1177207067363092e-07\n",
      "Average loss :  1.852184855141714e-12\n",
      "\n",
      "\n",
      "Stage  846\n",
      "Epoch 150/200\n",
      "Learning rate :  2.1177207067363092e-07\n",
      "Average loss :  1.852184855141714e-12\n",
      "\n",
      "\n",
      "Stage  846\n",
      "Epoch 200/200\n",
      "Learning rate :  2.1177207067363092e-07\n",
      "Average loss :  1.852184855141714e-12\n",
      "expression length:\t 5\n",
      "Result stage 848: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000002]*t)\n",
      "\n",
      "\n",
      "Stage  847\n",
      "Epoch 50/200\n",
      "Learning rate :  2.096649033631454e-07\n",
      "Average loss :  1.8147360784231958e-12\n",
      "\n",
      "\n",
      "Stage  847\n",
      "Epoch 100/200\n",
      "Learning rate :  2.096649033631454e-07\n",
      "Average loss :  1.3627455284007106e-12\n",
      "\n",
      "\n",
      "Stage  847\n",
      "Epoch 150/200\n",
      "Learning rate :  2.096649033631454e-07\n",
      "Average loss :  1.5205225316686222e-12\n",
      "\n",
      "\n",
      "Stage  847\n",
      "Epoch 200/200\n",
      "Learning rate :  2.096649033631454e-07\n",
      "Average loss :  1.3054928232197893e-12\n",
      "expression length:\t 5\n",
      "Result stage 849: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  848\n",
      "Epoch 50/200\n",
      "Learning rate :  2.0757870271771753e-07\n",
      "Average loss :  1.5248578224755227e-12\n",
      "\n",
      "\n",
      "Stage  848\n",
      "Epoch 100/200\n",
      "Learning rate :  2.0757870271771753e-07\n",
      "Average loss :  1.7830555825229522e-12\n",
      "\n",
      "\n",
      "Stage  848\n",
      "Epoch 150/200\n",
      "Learning rate :  2.0757870271771753e-07\n",
      "Average loss :  1.7536531038073178e-12\n",
      "\n",
      "\n",
      "Stage  848\n",
      "Epoch 200/200\n",
      "Learning rate :  2.0757870271771753e-07\n",
      "Average loss :  1.4802296758112399e-12\n",
      "expression length:\t 5\n",
      "Result stage 850: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  849\n",
      "Epoch 50/200\n",
      "Learning rate :  2.0551326011554428e-07\n",
      "Average loss :  1.4732091414837445e-12\n",
      "\n",
      "\n",
      "Stage  849\n",
      "Epoch 100/200\n",
      "Learning rate :  2.0551326011554428e-07\n",
      "Average loss :  1.947070976671128e-12\n",
      "\n",
      "\n",
      "Stage  849\n",
      "Epoch 150/200\n",
      "Learning rate :  2.0551326011554428e-07\n",
      "Average loss :  1.334262886808213e-12\n",
      "\n",
      "\n",
      "Stage  849\n",
      "Epoch 200/200\n",
      "Learning rate :  2.0551326011554428e-07\n",
      "Average loss :  1.4732091414837445e-12\n",
      "expression length:\t 5\n",
      "Result stage 851: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999996]*t)\n",
      "\n",
      "\n",
      "Stage  850\n",
      "Epoch 50/200\n",
      "Learning rate :  2.0346836901064418e-07\n",
      "Average loss :  1.4741652993796595e-12\n",
      "\n",
      "\n",
      "Stage  850\n",
      "Epoch 100/200\n",
      "Learning rate :  2.0346836901064418e-07\n",
      "Average loss :  1.4741652993796595e-12\n",
      "\n",
      "\n",
      "Stage  850\n",
      "Epoch 150/200\n",
      "Learning rate :  2.0346836901064418e-07\n",
      "Average loss :  1.4741652993796595e-12\n",
      "\n",
      "\n",
      "Stage  850\n",
      "Epoch 200/200\n",
      "Learning rate :  2.0346836901064418e-07\n",
      "Average loss :  1.4741652993796595e-12\n",
      "expression length:\t 5\n",
      "Result stage 852: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999996]*t)\n",
      "\n",
      "\n",
      "Stage  851\n",
      "Epoch 50/200\n",
      "Learning rate :  2.014438249122027e-07\n",
      "Average loss :  1.6167411376680207e-12\n",
      "\n",
      "\n",
      "Stage  851\n",
      "Epoch 100/200\n",
      "Learning rate :  2.014438249122027e-07\n",
      "Average loss :  1.459781948098815e-12\n",
      "\n",
      "\n",
      "Stage  851\n",
      "Epoch 150/200\n",
      "Learning rate :  2.014438249122027e-07\n",
      "Average loss :  1.6167411376680207e-12\n",
      "\n",
      "\n",
      "Stage  851\n",
      "Epoch 200/200\n",
      "Learning rate :  2.014438249122027e-07\n",
      "Average loss :  1.459781948098815e-12\n",
      "expression length:\t 5\n",
      "Result stage 853: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999987]*t)\n",
      "\n",
      "\n",
      "Stage  852\n",
      "Epoch 50/200\n",
      "Learning rate :  1.994394253641228e-07\n",
      "Average loss :  1.635297149429893e-12\n",
      "\n",
      "\n",
      "Stage  852\n",
      "Epoch 100/200\n",
      "Learning rate :  1.994394253641228e-07\n",
      "Average loss :  1.305649273593279e-12\n",
      "\n",
      "\n",
      "Stage  852\n",
      "Epoch 150/200\n",
      "Learning rate :  1.994394253641228e-07\n",
      "Average loss :  1.635297149429893e-12\n",
      "\n",
      "\n",
      "Stage  852\n",
      "Epoch 200/200\n",
      "Learning rate :  1.994394253641228e-07\n",
      "Average loss :  1.305649273593279e-12\n",
      "expression length:\t 5\n",
      "Result stage 854: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  853\n",
      "Epoch 50/200\n",
      "Learning rate :  1.9745496992477944e-07\n",
      "Average loss :  1.5084563372708137e-12\n",
      "\n",
      "\n",
      "Stage  853\n",
      "Epoch 100/200\n",
      "Learning rate :  1.9745496992477944e-07\n",
      "Average loss :  1.5084563372708137e-12\n",
      "\n",
      "\n",
      "Stage  853\n",
      "Epoch 150/200\n",
      "Learning rate :  1.9745496992477944e-07\n",
      "Average loss :  1.5084563372708137e-12\n",
      "\n",
      "\n",
      "Stage  853\n",
      "Epoch 200/200\n",
      "Learning rate :  1.9745496992477944e-07\n",
      "Average loss :  1.5084563372708137e-12\n",
      "expression length:\t 5\n",
      "Result stage 855: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  854\n",
      "Epoch 50/200\n",
      "Learning rate :  1.954902601469746e-07\n",
      "Average loss :  1.3598469138925706e-12\n",
      "\n",
      "\n",
      "Stage  854\n",
      "Epoch 100/200\n",
      "Learning rate :  1.954902601469746e-07\n",
      "Average loss :  1.3598469138925706e-12\n",
      "\n",
      "\n",
      "Stage  854\n",
      "Epoch 150/200\n",
      "Learning rate :  1.954902601469746e-07\n",
      "Average loss :  1.3598469138925706e-12\n",
      "\n",
      "\n",
      "Stage  854\n",
      "Epoch 200/200\n",
      "Learning rate :  1.954902601469746e-07\n",
      "Average loss :  1.3598469138925706e-12\n",
      "expression length:\t 5\n",
      "Result stage 856: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999996]*t)\n",
      "\n",
      "\n",
      "Stage  855\n",
      "Epoch 50/200\n",
      "Learning rate :  1.9354509955809383e-07\n",
      "Average loss :  1.8966462515118687e-12\n",
      "\n",
      "\n",
      "Stage  855\n",
      "Epoch 100/200\n",
      "Learning rate :  1.9354509955809383e-07\n",
      "Average loss :  1.3707960547920672e-12\n",
      "\n",
      "\n",
      "Stage  855\n",
      "Epoch 150/200\n",
      "Learning rate :  1.9354509955809383e-07\n",
      "Average loss :  1.3614211754470196e-12\n",
      "\n",
      "\n",
      "Stage  855\n",
      "Epoch 200/200\n",
      "Learning rate :  1.9354509955809383e-07\n",
      "Average loss :  1.8966462515118687e-12\n",
      "expression length:\t 5\n",
      "Result stage 857: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999997]*t)\n",
      "\n",
      "\n",
      "Stage  856\n",
      "Epoch 50/200\n",
      "Learning rate :  1.9161929364045704e-07\n",
      "Average loss :  1.3614211754470196e-12\n",
      "\n",
      "\n",
      "Stage  856\n",
      "Epoch 100/200\n",
      "Learning rate :  1.9161929364045704e-07\n",
      "Average loss :  1.739404410436296e-12\n",
      "\n",
      "\n",
      "Stage  856\n",
      "Epoch 150/200\n",
      "Learning rate :  1.9161929364045704e-07\n",
      "Average loss :  1.6309129611050133e-12\n",
      "\n",
      "\n",
      "Stage  856\n",
      "Epoch 200/200\n",
      "Learning rate :  1.9161929364045704e-07\n",
      "Average loss :  1.487425850890678e-12\n",
      "expression length:\t 5\n",
      "Result stage 858: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  857\n",
      "Epoch 50/200\n",
      "Learning rate :  1.8971264981186755e-07\n",
      "Average loss :  1.5193576648545037e-12\n",
      "\n",
      "\n",
      "Stage  857\n",
      "Epoch 100/200\n",
      "Learning rate :  1.8971264981186755e-07\n",
      "Average loss :  1.5446901570348448e-12\n",
      "\n",
      "\n",
      "Stage  857\n",
      "Epoch 150/200\n",
      "Learning rate :  1.8971264981186755e-07\n",
      "Average loss :  1.4838425627106133e-12\n",
      "\n",
      "\n",
      "Stage  857\n",
      "Epoch 200/200\n",
      "Learning rate :  1.8971264981186755e-07\n",
      "Average loss :  1.5193576648545037e-12\n",
      "expression length:\t 5\n",
      "Result stage 859: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  858\n",
      "Epoch 50/200\n",
      "Learning rate :  1.8782497740635363e-07\n",
      "Average loss :  1.5399801659571333e-12\n",
      "\n",
      "\n",
      "Stage  858\n",
      "Epoch 100/200\n",
      "Learning rate :  1.8782497740635363e-07\n",
      "Average loss :  1.3009756032883457e-12\n",
      "\n",
      "\n",
      "Stage  858\n",
      "Epoch 150/200\n",
      "Learning rate :  1.8782497740635363e-07\n",
      "Average loss :  1.5399801659571333e-12\n",
      "\n",
      "\n",
      "Stage  858\n",
      "Epoch 200/200\n",
      "Learning rate :  1.8782497740635363e-07\n",
      "Average loss :  1.3009756032883457e-12\n",
      "expression length:\t 5\n",
      "Result stage 860: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  859\n",
      "Epoch 50/200\n",
      "Learning rate :  1.8595608765510169e-07\n",
      "Average loss :  1.4929960479720394e-12\n",
      "\n",
      "\n",
      "Stage  859\n",
      "Epoch 100/200\n",
      "Learning rate :  1.8595608765510169e-07\n",
      "Average loss :  1.6219751236556945e-12\n",
      "\n",
      "\n",
      "Stage  859\n",
      "Epoch 150/200\n",
      "Learning rate :  1.8595608765510169e-07\n",
      "Average loss :  1.4929960479720394e-12\n",
      "\n",
      "\n",
      "Stage  859\n",
      "Epoch 200/200\n",
      "Learning rate :  1.8595608765510169e-07\n",
      "Average loss :  1.6219751236556945e-12\n",
      "expression length:\t 5\n",
      "Result stage 861: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399998]*t)\n",
      "\n",
      "\n",
      "Stage  860\n",
      "Epoch 50/200\n",
      "Learning rate :  1.841057936675792e-07\n",
      "Average loss :  1.536577180598353e-12\n",
      "\n",
      "\n",
      "Stage  860\n",
      "Epoch 100/200\n",
      "Learning rate :  1.841057936675792e-07\n",
      "Average loss :  1.4452239318479831e-12\n",
      "\n",
      "\n",
      "Stage  860\n",
      "Epoch 150/200\n",
      "Learning rate :  1.841057936675792e-07\n",
      "Average loss :  1.536577180598353e-12\n",
      "\n",
      "\n",
      "Stage  860\n",
      "Epoch 200/200\n",
      "Learning rate :  1.841057936675792e-07\n",
      "Average loss :  1.4452239318479831e-12\n",
      "expression length:\t 5\n",
      "Result stage 862: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  861\n",
      "Epoch 50/200\n",
      "Learning rate :  1.8227391041284545e-07\n",
      "Average loss :  1.5502620888396823e-12\n",
      "\n",
      "\n",
      "Stage  861\n",
      "Epoch 100/200\n",
      "Learning rate :  1.8227391041284545e-07\n",
      "Average loss :  1.4423643486180526e-12\n",
      "\n",
      "\n",
      "Stage  861\n",
      "Epoch 150/200\n",
      "Learning rate :  1.8227391041284545e-07\n",
      "Average loss :  1.5952470464389301e-12\n",
      "\n",
      "\n",
      "Stage  861\n",
      "Epoch 200/200\n",
      "Learning rate :  1.8227391041284545e-07\n",
      "Average loss :  1.5502620888396823e-12\n",
      "expression length:\t 5\n",
      "Result stage 863: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  862\n",
      "Epoch 50/200\n",
      "Learning rate :  1.8046025470104813e-07\n",
      "Average loss :  1.4460431550095132e-12\n",
      "\n",
      "\n",
      "Stage  862\n",
      "Epoch 100/200\n",
      "Learning rate :  1.8046025470104813e-07\n",
      "Average loss :  1.4423643486180526e-12\n",
      "\n",
      "\n",
      "Stage  862\n",
      "Epoch 150/200\n",
      "Learning rate :  1.8046025470104813e-07\n",
      "Average loss :  1.5279353303421228e-12\n",
      "\n",
      "\n",
      "Stage  862\n",
      "Epoch 200/200\n",
      "Learning rate :  1.8046025470104813e-07\n",
      "Average loss :  1.462659203824157e-12\n",
      "expression length:\t 5\n",
      "Result stage 864: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999996]*t)\n",
      "\n",
      "\n",
      "Stage  863\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7866464516510525e-07\n",
      "Average loss :  1.2934274961837189e-12\n",
      "\n",
      "\n",
      "Stage  863\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7866464516510525e-07\n",
      "Average loss :  1.4725645832922019e-12\n",
      "\n",
      "\n",
      "Stage  863\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7866464516510525e-07\n",
      "Average loss :  1.391342336481971e-12\n",
      "\n",
      "\n",
      "Stage  863\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7866464516510525e-07\n",
      "Average loss :  1.2934274961837189e-12\n",
      "expression length:\t 5\n",
      "Result stage 865: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  864\n",
      "Epoch 50/200\n",
      "Learning rate :  1.768869022425666e-07\n",
      "Average loss :  1.3346941824324277e-12\n",
      "\n",
      "\n",
      "Stage  864\n",
      "Epoch 100/200\n",
      "Learning rate :  1.768869022425666e-07\n",
      "Average loss :  1.4354507166247643e-12\n",
      "\n",
      "\n",
      "Stage  864\n",
      "Epoch 150/200\n",
      "Learning rate :  1.768869022425666e-07\n",
      "Average loss :  1.3346941824324277e-12\n",
      "\n",
      "\n",
      "Stage  864\n",
      "Epoch 200/200\n",
      "Learning rate :  1.768869022425666e-07\n",
      "Average loss :  1.4354507166247643e-12\n",
      "expression length:\t 5\n",
      "Result stage 866: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  865\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7512684815765844e-07\n",
      "Average loss :  1.329444150252601e-12\n",
      "\n",
      "\n",
      "Stage  865\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7512684815765844e-07\n",
      "Average loss :  1.4330063828268957e-12\n",
      "\n",
      "\n",
      "Stage  865\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7512684815765844e-07\n",
      "Average loss :  1.4828405430628022e-12\n",
      "\n",
      "\n",
      "Stage  865\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7512684815765844e-07\n",
      "Average loss :  1.329444150252601e-12\n",
      "expression length:\t 5\n",
      "Result stage 867: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  866\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7338430690350557e-07\n",
      "Average loss :  1.4325014698751692e-12\n",
      "\n",
      "\n",
      "Stage  866\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7338430690350557e-07\n",
      "Average loss :  1.494799618285969e-12\n",
      "\n",
      "\n",
      "Stage  866\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7338430690350557e-07\n",
      "Average loss :  1.2678881382288676e-12\n",
      "\n",
      "\n",
      "Stage  866\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7338430690350557e-07\n",
      "Average loss :  1.4325014698751692e-12\n",
      "expression length:\t 5\n",
      "Result stage 868: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  867\n",
      "Epoch 50/200\n",
      "Learning rate :  1.7165910422453046e-07\n",
      "Average loss :  1.2722448962387833e-12\n",
      "\n",
      "\n",
      "Stage  867\n",
      "Epoch 100/200\n",
      "Learning rate :  1.7165910422453046e-07\n",
      "Average loss :  1.3993746482768299e-12\n",
      "\n",
      "\n",
      "Stage  867\n",
      "Epoch 150/200\n",
      "Learning rate :  1.7165910422453046e-07\n",
      "Average loss :  1.381029405417289e-12\n",
      "\n",
      "\n",
      "Stage  867\n",
      "Epoch 200/200\n",
      "Learning rate :  1.7165910422453046e-07\n",
      "Average loss :  1.2722448962387833e-12\n",
      "expression length:\t 5\n",
      "Result stage 869: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000008]*t)\n",
      "\n",
      "\n",
      "Stage  868\n",
      "Epoch 50/200\n",
      "Learning rate :  1.699510675990275e-07\n",
      "Average loss :  1.367761264491063e-12\n",
      "\n",
      "\n",
      "Stage  868\n",
      "Epoch 100/200\n",
      "Learning rate :  1.699510675990275e-07\n",
      "Average loss :  1.6033887542329928e-12\n",
      "\n",
      "\n",
      "Stage  868\n",
      "Epoch 150/200\n",
      "Learning rate :  1.699510675990275e-07\n",
      "Average loss :  1.298707886024375e-12\n",
      "\n",
      "\n",
      "Stage  868\n",
      "Epoch 200/200\n",
      "Learning rate :  1.699510675990275e-07\n",
      "Average loss :  1.367761264491063e-12\n",
      "expression length:\t 5\n",
      "Result stage 870: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999997]*t)\n",
      "\n",
      "\n",
      "Stage  869\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6826002622191084e-07\n",
      "Average loss :  1.3881668167389782e-12\n",
      "\n",
      "\n",
      "Stage  869\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6826002622191084e-07\n",
      "Average loss :  1.3881668167389782e-12\n",
      "\n",
      "\n",
      "Stage  869\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6826002622191084e-07\n",
      "Average loss :  1.3881668167389782e-12\n",
      "\n",
      "\n",
      "Stage  869\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6826002622191084e-07\n",
      "Average loss :  1.3881668167389782e-12\n",
      "expression length:\t 5\n",
      "Result stage 871: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999996]*t)\n",
      "\n",
      "\n",
      "Stage  870\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6658581098763325e-07\n",
      "Average loss :  1.4459549009526729e-12\n",
      "\n",
      "\n",
      "Stage  870\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6658581098763325e-07\n",
      "Average loss :  1.4440637271032064e-12\n",
      "\n",
      "\n",
      "Stage  870\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6658581098763325e-07\n",
      "Average loss :  1.481738993655557e-12\n",
      "\n",
      "\n",
      "Stage  870\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6658581098763325e-07\n",
      "Average loss :  1.3260649089213983e-12\n",
      "expression length:\t 5\n",
      "Result stage 872: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  871\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6492825447327667e-07\n",
      "Average loss :  1.3852389287721811e-12\n",
      "\n",
      "\n",
      "Stage  871\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6492825447327667e-07\n",
      "Average loss :  1.6755658275788288e-12\n",
      "\n",
      "\n",
      "Stage  871\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6492825447327667e-07\n",
      "Average loss :  1.6878980851897651e-12\n",
      "\n",
      "\n",
      "Stage  871\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6492825447327667e-07\n",
      "Average loss :  1.3052792353918097e-12\n",
      "expression length:\t 5\n",
      "Result stage 873: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  872\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6328719092180806e-07\n",
      "Average loss :  1.3259894484501933e-12\n",
      "\n",
      "\n",
      "Stage  872\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6328719092180806e-07\n",
      "Average loss :  1.3259894484501933e-12\n",
      "\n",
      "\n",
      "Stage  872\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6328719092180806e-07\n",
      "Average loss :  1.3259894484501933e-12\n",
      "\n",
      "\n",
      "Stage  872\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6328719092180806e-07\n",
      "Average loss :  1.3259894484501933e-12\n",
      "expression length:\t 5\n",
      "Result stage 874: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  873\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6166245622550478e-07\n",
      "Average loss :  1.6566778331117415e-12\n",
      "\n",
      "\n",
      "Stage  873\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6166245622550478e-07\n",
      "Average loss :  1.3814412938226162e-12\n",
      "\n",
      "\n",
      "Stage  873\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6166245622550478e-07\n",
      "Average loss :  1.3222768149509512e-12\n",
      "\n",
      "\n",
      "Stage  873\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6166245622550478e-07\n",
      "Average loss :  1.6566778331117415e-12\n",
      "expression length:\t 5\n",
      "Result stage 875: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  874\n",
      "Epoch 50/200\n",
      "Learning rate :  1.6005388790954318e-07\n",
      "Average loss :  1.5444753765844754e-12\n",
      "\n",
      "\n",
      "Stage  874\n",
      "Epoch 100/200\n",
      "Learning rate :  1.6005388790954318e-07\n",
      "Average loss :  1.5444753765844754e-12\n",
      "\n",
      "\n",
      "Stage  874\n",
      "Epoch 150/200\n",
      "Learning rate :  1.6005388790954318e-07\n",
      "Average loss :  1.5444753765844754e-12\n",
      "\n",
      "\n",
      "Stage  874\n",
      "Epoch 200/200\n",
      "Learning rate :  1.6005388790954318e-07\n",
      "Average loss :  1.5444753765844754e-12\n",
      "expression length:\t 5\n",
      "Result stage 876: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  875\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5846132511575125e-07\n",
      "Average loss :  1.6559945689026412e-12\n",
      "\n",
      "\n",
      "Stage  875\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5846132511575125e-07\n",
      "Average loss :  1.3582002276329996e-12\n",
      "\n",
      "\n",
      "Stage  875\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5846132511575125e-07\n",
      "Average loss :  1.6559945689026412e-12\n",
      "\n",
      "\n",
      "Stage  875\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5846132511575125e-07\n",
      "Average loss :  1.3582002276329996e-12\n",
      "expression length:\t 5\n",
      "Result stage 877: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000002]*t)\n",
      "\n",
      "\n",
      "Stage  876\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5688460858652243e-07\n",
      "Average loss :  1.4935841192303956e-12\n",
      "\n",
      "\n",
      "Stage  876\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5688460858652243e-07\n",
      "Average loss :  1.3870513895439252e-12\n",
      "\n",
      "\n",
      "Stage  876\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5688460858652243e-07\n",
      "Average loss :  1.5756381659473573e-12\n",
      "\n",
      "\n",
      "Stage  876\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5688460858652243e-07\n",
      "Average loss :  1.3488437797248842e-12\n",
      "expression length:\t 5\n",
      "Result stage 878: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  877\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5532358064888985e-07\n",
      "Average loss :  1.4717426496252406e-12\n",
      "\n",
      "\n",
      "Stage  877\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5532358064888985e-07\n",
      "Average loss :  1.4474501241687476e-12\n",
      "\n",
      "\n",
      "Stage  877\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5532358064888985e-07\n",
      "Average loss :  1.312023623425973e-12\n",
      "\n",
      "\n",
      "Stage  877\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5532358064888985e-07\n",
      "Average loss :  1.4717426496252406e-12\n",
      "expression length:\t 5\n",
      "Result stage 879: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  878\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5377808519875893e-07\n",
      "Average loss :  1.525562445467421e-12\n",
      "\n",
      "\n",
      "Stage  878\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5377808519875893e-07\n",
      "Average loss :  1.2647421087849664e-12\n",
      "\n",
      "\n",
      "Stage  878\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5377808519875893e-07\n",
      "Average loss :  1.3190760332973395e-12\n",
      "\n",
      "\n",
      "Stage  878\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5377808519875893e-07\n",
      "Average loss :  1.6567911322387663e-12\n",
      "expression length:\t 5\n",
      "Result stage 880: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  879\n",
      "Epoch 50/200\n",
      "Learning rate :  1.5224796768529644e-07\n",
      "Average loss :  1.425277322379681e-12\n",
      "\n",
      "\n",
      "Stage  879\n",
      "Epoch 100/200\n",
      "Learning rate :  1.5224796768529644e-07\n",
      "Average loss :  1.4168979574694096e-12\n",
      "\n",
      "\n",
      "Stage  879\n",
      "Epoch 150/200\n",
      "Learning rate :  1.5224796768529644e-07\n",
      "Average loss :  1.3199230120344851e-12\n",
      "\n",
      "\n",
      "Stage  879\n",
      "Epoch 200/200\n",
      "Learning rate :  1.5224796768529644e-07\n",
      "Average loss :  1.425277322379681e-12\n",
      "expression length:\t 5\n",
      "Result stage 881: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999987]*t)\n",
      "\n",
      "\n",
      "Stage  880\n",
      "Epoch 50/200\n",
      "Learning rate :  1.507330750954765e-07\n",
      "Average loss :  1.4168979574694096e-12\n",
      "\n",
      "\n",
      "Stage  880\n",
      "Epoch 100/200\n",
      "Learning rate :  1.507330750954765e-07\n",
      "Average loss :  1.3199230120344851e-12\n",
      "\n",
      "\n",
      "Stage  880\n",
      "Epoch 150/200\n",
      "Learning rate :  1.507330750954765e-07\n",
      "Average loss :  1.430094757892686e-12\n",
      "\n",
      "\n",
      "Stage  880\n",
      "Epoch 200/200\n",
      "Learning rate :  1.507330750954765e-07\n",
      "Average loss :  1.4168979574694096e-12\n",
      "expression length:\t 5\n",
      "Result stage 882: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  881\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4923325593877738e-07\n",
      "Average loss :  1.338651195101348e-12\n",
      "\n",
      "\n",
      "Stage  881\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4923325593877738e-07\n",
      "Average loss :  1.3655809339221947e-12\n",
      "\n",
      "\n",
      "Stage  881\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4923325593877738e-07\n",
      "Average loss :  1.4754114813567143e-12\n",
      "\n",
      "\n",
      "Stage  881\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4923325593877738e-07\n",
      "Average loss :  1.4130012264412795e-12\n",
      "expression length:\t 5\n",
      "Result stage 883: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999982]*t)\n",
      "\n",
      "\n",
      "Stage  882\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4774836023203365e-07\n",
      "Average loss :  1.479465096439203e-12\n",
      "\n",
      "\n",
      "Stage  882\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4774836023203365e-07\n",
      "Average loss :  1.5245091430568514e-12\n",
      "\n",
      "\n",
      "Stage  882\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4774836023203365e-07\n",
      "Average loss :  1.315574819221732e-12\n",
      "\n",
      "\n",
      "Stage  882\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4774836023203365e-07\n",
      "Average loss :  1.3050902589531455e-12\n",
      "expression length:\t 5\n",
      "Result stage 884: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  883\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4627823948443712e-07\n",
      "Average loss :  1.3229468518935472e-12\n",
      "\n",
      "\n",
      "Stage  883\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4627823948443712e-07\n",
      "Average loss :  1.3194264474394868e-12\n",
      "\n",
      "\n",
      "Stage  883\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4627823948443712e-07\n",
      "Average loss :  1.3229468518935472e-12\n",
      "\n",
      "\n",
      "Stage  883\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4627823948443712e-07\n",
      "Average loss :  1.3194264474394868e-12\n",
      "expression length:\t 5\n",
      "Result stage 885: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  884\n",
      "Epoch 50/200\n",
      "Learning rate :  1.44822746682688e-07\n",
      "Average loss :  1.399231642010279e-12\n",
      "\n",
      "\n",
      "Stage  884\n",
      "Epoch 100/200\n",
      "Learning rate :  1.44822746682688e-07\n",
      "Average loss :  1.399231642010279e-12\n",
      "\n",
      "\n",
      "Stage  884\n",
      "Epoch 150/200\n",
      "Learning rate :  1.44822746682688e-07\n",
      "Average loss :  1.399231642010279e-12\n",
      "\n",
      "\n",
      "Stage  884\n",
      "Epoch 200/200\n",
      "Learning rate :  1.44822746682688e-07\n",
      "Average loss :  1.399231642010279e-12\n",
      "expression length:\t 5\n",
      "Result stage 886: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  885\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4338173627629318e-07\n",
      "Average loss :  1.399231642010279e-12\n",
      "\n",
      "\n",
      "Stage  885\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4338173627629318e-07\n",
      "Average loss :  1.399231642010279e-12\n",
      "\n",
      "\n",
      "Stage  885\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4338173627629318e-07\n",
      "Average loss :  1.399231642010279e-12\n",
      "\n",
      "\n",
      "Stage  885\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4338173627629318e-07\n",
      "Average loss :  1.399231642010279e-12\n",
      "expression length:\t 5\n",
      "Result stage 887: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  886\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4195506416301114e-07\n",
      "Average loss :  1.297239551022178e-12\n",
      "\n",
      "\n",
      "Stage  886\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4195506416301114e-07\n",
      "Average loss :  1.297239551022178e-12\n",
      "\n",
      "\n",
      "Stage  886\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4195506416301114e-07\n",
      "Average loss :  1.297239551022178e-12\n",
      "\n",
      "\n",
      "Stage  886\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4195506416301114e-07\n",
      "Average loss :  1.297239551022178e-12\n",
      "expression length:\t 5\n",
      "Result stage 888: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999996]*t)\n",
      "\n",
      "\n",
      "Stage  887\n",
      "Epoch 50/200\n",
      "Learning rate :  1.4054258767444144e-07\n",
      "Average loss :  1.2843484956115425e-12\n",
      "\n",
      "\n",
      "Stage  887\n",
      "Epoch 100/200\n",
      "Learning rate :  1.4054258767444144e-07\n",
      "Average loss :  1.2843484956115425e-12\n",
      "\n",
      "\n",
      "Stage  887\n",
      "Epoch 150/200\n",
      "Learning rate :  1.4054258767444144e-07\n",
      "Average loss :  1.2843484956115425e-12\n",
      "\n",
      "\n",
      "Stage  887\n",
      "Epoch 200/200\n",
      "Learning rate :  1.4054258767444144e-07\n",
      "Average loss :  1.2843484956115425e-12\n",
      "expression length:\t 5\n",
      "Result stage 889: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  888\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3914416556175864e-07\n",
      "Average loss :  1.2836103707725144e-12\n",
      "\n",
      "\n",
      "Stage  888\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3914416556175864e-07\n",
      "Average loss :  1.2836103707725144e-12\n",
      "\n",
      "\n",
      "Stage  888\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3914416556175864e-07\n",
      "Average loss :  1.2836103707725144e-12\n",
      "\n",
      "\n",
      "Stage  888\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3914416556175864e-07\n",
      "Average loss :  1.2836103707725144e-12\n",
      "expression length:\t 5\n",
      "Result stage 890: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  889\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3775965798158591e-07\n",
      "Average loss :  1.2836103707725144e-12\n",
      "\n",
      "\n",
      "Stage  889\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3775965798158591e-07\n",
      "Average loss :  1.2836103707725144e-12\n",
      "\n",
      "\n",
      "Stage  889\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3775965798158591e-07\n",
      "Average loss :  1.2836103707725144e-12\n",
      "\n",
      "\n",
      "Stage  889\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3775965798158591e-07\n",
      "Average loss :  1.2836103707725144e-12\n",
      "expression length:\t 5\n",
      "Result stage 891: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  890\n",
      "Epoch 50/200\n",
      "Learning rate :  1.363889264820114e-07\n",
      "Average loss :  1.281009911861808e-12\n",
      "\n",
      "\n",
      "Stage  890\n",
      "Epoch 100/200\n",
      "Learning rate :  1.363889264820114e-07\n",
      "Average loss :  1.281009911861808e-12\n",
      "\n",
      "\n",
      "Stage  890\n",
      "Epoch 150/200\n",
      "Learning rate :  1.363889264820114e-07\n",
      "Average loss :  1.281009911861808e-12\n",
      "\n",
      "\n",
      "Stage  890\n",
      "Epoch 200/200\n",
      "Learning rate :  1.363889264820114e-07\n",
      "Average loss :  1.281009911861808e-12\n",
      "expression length:\t 5\n",
      "Result stage 892: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  891\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3503183398874293e-07\n",
      "Average loss :  1.2964691169584097e-12\n",
      "\n",
      "\n",
      "Stage  891\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3503183398874293e-07\n",
      "Average loss :  1.2964691169584097e-12\n",
      "\n",
      "\n",
      "Stage  891\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3503183398874293e-07\n",
      "Average loss :  1.2964691169584097e-12\n",
      "\n",
      "\n",
      "Stage  891\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3503183398874293e-07\n",
      "Average loss :  1.2964691169584097e-12\n",
      "expression length:\t 5\n",
      "Result stage 893: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  892\n",
      "Epoch 50/200\n",
      "Learning rate :  1.3368824479140023e-07\n",
      "Average loss :  1.2964691169584097e-12\n",
      "\n",
      "\n",
      "Stage  892\n",
      "Epoch 100/200\n",
      "Learning rate :  1.3368824479140023e-07\n",
      "Average loss :  1.2964691169584097e-12\n",
      "\n",
      "\n",
      "Stage  892\n",
      "Epoch 150/200\n",
      "Learning rate :  1.3368824479140023e-07\n",
      "Average loss :  1.2964691169584097e-12\n",
      "\n",
      "\n",
      "Stage  892\n",
      "Epoch 200/200\n",
      "Learning rate :  1.3368824479140023e-07\n",
      "Average loss :  1.2964691169584097e-12\n",
      "expression length:\t 5\n",
      "Result stage 894: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  893\n",
      "Epoch 50/200\n",
      "Learning rate :  1.323580245299439e-07\n",
      "Average loss :  1.2964691169584097e-12\n",
      "\n",
      "\n",
      "Stage  893\n",
      "Epoch 100/200\n",
      "Learning rate :  1.323580245299439e-07\n",
      "Average loss :  1.2964691169584097e-12\n",
      "\n",
      "\n",
      "Stage  893\n",
      "Epoch 150/200\n",
      "Learning rate :  1.323580245299439e-07\n",
      "Average loss :  1.2964691169584097e-12\n",
      "\n",
      "\n",
      "Stage  893\n",
      "Epoch 200/200\n",
      "Learning rate :  1.323580245299439e-07\n",
      "Average loss :  1.2964691169584097e-12\n",
      "expression length:\t 5\n",
      "Result stage 895: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  894\n",
      "Epoch 50/200\n",
      "Learning rate :  1.310410401812393e-07\n",
      "Average loss :  1.4108228474363216e-12\n",
      "\n",
      "\n",
      "Stage  894\n",
      "Epoch 100/200\n",
      "Learning rate :  1.310410401812393e-07\n",
      "Average loss :  1.4108228474363216e-12\n",
      "\n",
      "\n",
      "Stage  894\n",
      "Epoch 150/200\n",
      "Learning rate :  1.310410401812393e-07\n",
      "Average loss :  1.4108228474363216e-12\n",
      "\n",
      "\n",
      "Stage  894\n",
      "Epoch 200/200\n",
      "Learning rate :  1.310410401812393e-07\n",
      "Average loss :  1.4108228474363216e-12\n",
      "expression length:\t 5\n",
      "Result stage 896: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  895\n",
      "Epoch 50/200\n",
      "Learning rate :  1.297371600457538e-07\n",
      "Average loss :  1.2729382435280878e-12\n",
      "\n",
      "\n",
      "Stage  895\n",
      "Epoch 100/200\n",
      "Learning rate :  1.297371600457538e-07\n",
      "Average loss :  1.2729382435280878e-12\n",
      "\n",
      "\n",
      "Stage  895\n",
      "Epoch 150/200\n",
      "Learning rate :  1.297371600457538e-07\n",
      "Average loss :  1.2729382435280878e-12\n",
      "\n",
      "\n",
      "Stage  895\n",
      "Epoch 200/200\n",
      "Learning rate :  1.297371600457538e-07\n",
      "Average loss :  1.2729382435280878e-12\n",
      "expression length:\t 5\n",
      "Result stage 897: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  896\n",
      "Epoch 50/200\n",
      "Learning rate :  1.284462537343878e-07\n",
      "Average loss :  1.3261080601678632e-12\n",
      "\n",
      "\n",
      "Stage  896\n",
      "Epoch 100/200\n",
      "Learning rate :  1.284462537343878e-07\n",
      "Average loss :  1.3636406457143146e-12\n",
      "\n",
      "\n",
      "Stage  896\n",
      "Epoch 150/200\n",
      "Learning rate :  1.284462537343878e-07\n",
      "Average loss :  1.346802660714963e-12\n",
      "\n",
      "\n",
      "Stage  896\n",
      "Epoch 200/200\n",
      "Learning rate :  1.284462537343878e-07\n",
      "Average loss :  1.3261080601678632e-12\n",
      "expression length:\t 5\n",
      "Result stage 898: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  897\n",
      "Epoch 50/200\n",
      "Learning rate :  1.271681921554341e-07\n",
      "Average loss :  1.3629207354717843e-12\n",
      "\n",
      "\n",
      "Stage  897\n",
      "Epoch 100/200\n",
      "Learning rate :  1.271681921554341e-07\n",
      "Average loss :  1.3968912832007518e-12\n",
      "\n",
      "\n",
      "Stage  897\n",
      "Epoch 150/200\n",
      "Learning rate :  1.271681921554341e-07\n",
      "Average loss :  1.3200609225508253e-12\n",
      "\n",
      "\n",
      "Stage  897\n",
      "Epoch 200/200\n",
      "Learning rate :  1.271681921554341e-07\n",
      "Average loss :  1.3629207354717843e-12\n",
      "expression length:\t 5\n",
      "Result stage 899: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  898\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2590284750166983e-07\n",
      "Average loss :  1.4562872392362425e-12\n",
      "\n",
      "\n",
      "Stage  898\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2590284750166983e-07\n",
      "Average loss :  1.4817588345553134e-12\n",
      "\n",
      "\n",
      "Stage  898\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2590284750166983e-07\n",
      "Average loss :  1.4562872392362425e-12\n",
      "\n",
      "\n",
      "Stage  898\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2590284750166983e-07\n",
      "Average loss :  1.4817588345553134e-12\n",
      "expression length:\t 5\n",
      "Result stage 900: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  899\n",
      "Epoch 50/200\n",
      "Learning rate :  1.246500932375751e-07\n",
      "Average loss :  1.4796317383131141e-12\n",
      "\n",
      "\n",
      "Stage  899\n",
      "Epoch 100/200\n",
      "Learning rate :  1.246500932375751e-07\n",
      "Average loss :  1.4796317383131141e-12\n",
      "\n",
      "\n",
      "Stage  899\n",
      "Epoch 150/200\n",
      "Learning rate :  1.246500932375751e-07\n",
      "Average loss :  1.4796317383131141e-12\n",
      "\n",
      "\n",
      "Stage  899\n",
      "Epoch 200/200\n",
      "Learning rate :  1.246500932375751e-07\n",
      "Average loss :  1.4796317383131141e-12\n",
      "expression length:\t 5\n",
      "Result stage 901: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  900\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2340980408667958e-07\n",
      "Average loss :  1.2664207790086257e-12\n",
      "\n",
      "\n",
      "Stage  900\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2340980408667958e-07\n",
      "Average loss :  1.3226826318241125e-12\n",
      "\n",
      "\n",
      "Stage  900\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2340980408667958e-07\n",
      "Average loss :  1.3040655794799294e-12\n",
      "\n",
      "\n",
      "Stage  900\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2340980408667958e-07\n",
      "Average loss :  1.4796317383131141e-12\n",
      "expression length:\t 5\n",
      "Result stage 902: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999984]*t)\n",
      "\n",
      "\n",
      "Stage  901\n",
      "Epoch 50/200\n",
      "Learning rate :  1.221818560190345e-07\n",
      "Average loss :  1.5031812600208028e-12\n",
      "\n",
      "\n",
      "Stage  901\n",
      "Epoch 100/200\n",
      "Learning rate :  1.221818560190345e-07\n",
      "Average loss :  1.3147780390451724e-12\n",
      "\n",
      "\n",
      "Stage  901\n",
      "Epoch 150/200\n",
      "Learning rate :  1.221818560190345e-07\n",
      "Average loss :  1.5031812600208028e-12\n",
      "\n",
      "\n",
      "Stage  901\n",
      "Epoch 200/200\n",
      "Learning rate :  1.221818560190345e-07\n",
      "Average loss :  1.3147780390451724e-12\n",
      "expression length:\t 5\n",
      "Result stage 903: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  902\n",
      "Epoch 50/200\n",
      "Learning rate :  1.2096612623880993e-07\n",
      "Average loss :  1.5031812600208028e-12\n",
      "\n",
      "\n",
      "Stage  902\n",
      "Epoch 100/200\n",
      "Learning rate :  1.2096612623880993e-07\n",
      "Average loss :  1.3336996437796067e-12\n",
      "\n",
      "\n",
      "Stage  902\n",
      "Epoch 150/200\n",
      "Learning rate :  1.2096612623880993e-07\n",
      "Average loss :  1.5031812600208028e-12\n",
      "\n",
      "\n",
      "Stage  902\n",
      "Epoch 200/200\n",
      "Learning rate :  1.2096612623880993e-07\n",
      "Average loss :  1.3336996437796067e-12\n",
      "expression length:\t 5\n",
      "Result stage 904: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  903\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1976249317201468e-07\n",
      "Average loss :  1.5049164171776486e-12\n",
      "\n",
      "\n",
      "Stage  903\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1976249317201468e-07\n",
      "Average loss :  1.3567376389023167e-12\n",
      "\n",
      "\n",
      "Stage  903\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1976249317201468e-07\n",
      "Average loss :  1.5049164171776486e-12\n",
      "\n",
      "\n",
      "Stage  903\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1976249317201468e-07\n",
      "Average loss :  1.3567376389023167e-12\n",
      "expression length:\t 5\n",
      "Result stage 905: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  904\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1857083645433882e-07\n",
      "Average loss :  1.4608347084082984e-12\n",
      "\n",
      "\n",
      "Stage  904\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1857083645433882e-07\n",
      "Average loss :  1.3312598636308626e-12\n",
      "\n",
      "\n",
      "Stage  904\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1857083645433882e-07\n",
      "Average loss :  1.3791116686145966e-12\n",
      "\n",
      "\n",
      "Stage  904\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1857083645433882e-07\n",
      "Average loss :  1.4608347084082984e-12\n",
      "expression length:\t 5\n",
      "Result stage 906: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  905\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1739103691911797e-07\n",
      "Average loss :  1.2973422249679123e-12\n",
      "\n",
      "\n",
      "Stage  905\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1739103691911797e-07\n",
      "Average loss :  1.4149873764010557e-12\n",
      "\n",
      "\n",
      "Stage  905\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1739103691911797e-07\n",
      "Average loss :  1.2973422249679123e-12\n",
      "\n",
      "\n",
      "Stage  905\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1739103691911797e-07\n",
      "Average loss :  1.4149873764010557e-12\n",
      "expression length:\t 5\n",
      "Result stage 907: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  906\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1622297658541523e-07\n",
      "Average loss :  1.3300951052369614e-12\n",
      "\n",
      "\n",
      "Stage  906\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1622297658541523e-07\n",
      "Average loss :  1.3300951052369614e-12\n",
      "\n",
      "\n",
      "Stage  906\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1622297658541523e-07\n",
      "Average loss :  1.3300951052369614e-12\n",
      "\n",
      "\n",
      "Stage  906\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1622297658541523e-07\n",
      "Average loss :  1.3300951052369614e-12\n",
      "expression length:\t 5\n",
      "Result stage 908: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999997]*t)\n",
      "\n",
      "\n",
      "Stage  907\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1506653864622381e-07\n",
      "Average loss :  1.3773697894042813e-12\n",
      "\n",
      "\n",
      "Stage  907\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1506653864622381e-07\n",
      "Average loss :  1.2813919847073918e-12\n",
      "\n",
      "\n",
      "Stage  907\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1506653864622381e-07\n",
      "Average loss :  1.3064230686837819e-12\n",
      "\n",
      "\n",
      "Stage  907\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1506653864622381e-07\n",
      "Average loss :  1.4470576429823079e-12\n",
      "expression length:\t 5\n",
      "Result stage 909: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  908\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1392160745678614e-07\n",
      "Average loss :  1.3322069142285287e-12\n",
      "\n",
      "\n",
      "Stage  908\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1392160745678614e-07\n",
      "Average loss :  1.284369637553906e-12\n",
      "\n",
      "\n",
      "Stage  908\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1392160745678614e-07\n",
      "Average loss :  1.330852637294877e-12\n",
      "\n",
      "\n",
      "Stage  908\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1392160745678614e-07\n",
      "Average loss :  1.3322069142285287e-12\n",
      "expression length:\t 5\n",
      "Result stage 910: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999996]*t)\n",
      "\n",
      "\n",
      "Stage  909\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1278806852302912e-07\n",
      "Average loss :  1.3774340825931097e-12\n",
      "\n",
      "\n",
      "Stage  909\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1278806852302912e-07\n",
      "Average loss :  1.5015358748038388e-12\n",
      "\n",
      "\n",
      "Stage  909\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1278806852302912e-07\n",
      "Average loss :  1.3331932129448387e-12\n",
      "\n",
      "\n",
      "Stage  909\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1278806852302912e-07\n",
      "Average loss :  1.3774340825931097e-12\n",
      "expression length:\t 5\n",
      "Result stage 911: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  910\n",
      "Epoch 50/200\n",
      "Learning rate :  1.1166580849011478e-07\n",
      "Average loss :  1.330852637294877e-12\n",
      "\n",
      "\n",
      "Stage  910\n",
      "Epoch 100/200\n",
      "Learning rate :  1.1166580849011478e-07\n",
      "Average loss :  1.3305043915570747e-12\n",
      "\n",
      "\n",
      "Stage  910\n",
      "Epoch 150/200\n",
      "Learning rate :  1.1166580849011478e-07\n",
      "Average loss :  1.2979149005554191e-12\n",
      "\n",
      "\n",
      "Stage  910\n",
      "Epoch 200/200\n",
      "Learning rate :  1.1166580849011478e-07\n",
      "Average loss :  1.330852637294877e-12\n",
      "expression length:\t 5\n",
      "Result stage 912: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  911\n",
      "Epoch 50/200\n",
      "Learning rate :  1.105547151311046e-07\n",
      "Average loss :  1.3305043915570747e-12\n",
      "\n",
      "\n",
      "Stage  911\n",
      "Epoch 100/200\n",
      "Learning rate :  1.105547151311046e-07\n",
      "Average loss :  1.2979149005554191e-12\n",
      "\n",
      "\n",
      "Stage  911\n",
      "Epoch 150/200\n",
      "Learning rate :  1.105547151311046e-07\n",
      "Average loss :  1.330852637294877e-12\n",
      "\n",
      "\n",
      "Stage  911\n",
      "Epoch 200/200\n",
      "Learning rate :  1.105547151311046e-07\n",
      "Average loss :  1.3305043915570747e-12\n",
      "expression length:\t 5\n",
      "Result stage 913: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999996]*t)\n",
      "\n",
      "\n",
      "Stage  912\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0945467733573657e-07\n",
      "Average loss :  1.3891828225948144e-12\n",
      "\n",
      "\n",
      "Stage  912\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0945467733573657e-07\n",
      "Average loss :  1.3491375985136278e-12\n",
      "\n",
      "\n",
      "Stage  912\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0945467733573657e-07\n",
      "Average loss :  1.3093681954651215e-12\n",
      "\n",
      "\n",
      "Stage  912\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0945467733573657e-07\n",
      "Average loss :  1.3891828225948144e-12\n",
      "expression length:\t 5\n",
      "Result stage 914: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999987]*t)\n",
      "\n",
      "\n",
      "Stage  913\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0836558509931485e-07\n",
      "Average loss :  1.3432739079041744e-12\n",
      "\n",
      "\n",
      "Stage  913\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0836558509931485e-07\n",
      "Average loss :  1.3003182515111678e-12\n",
      "\n",
      "\n",
      "Stage  913\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0836558509931485e-07\n",
      "Average loss :  1.3925533903086373e-12\n",
      "\n",
      "\n",
      "Stage  913\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0836558509931485e-07\n",
      "Average loss :  1.3432739079041744e-12\n",
      "expression length:\t 5\n",
      "Result stage 915: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999997]*t)\n",
      "\n",
      "\n",
      "Stage  914\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0728732951170801e-07\n",
      "Average loss :  1.2813191263214008e-12\n",
      "\n",
      "\n",
      "Stage  914\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0728732951170801e-07\n",
      "Average loss :  1.2813191263214008e-12\n",
      "\n",
      "\n",
      "Stage  914\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0728732951170801e-07\n",
      "Average loss :  1.2813191263214008e-12\n",
      "\n",
      "\n",
      "Stage  914\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0728732951170801e-07\n",
      "Average loss :  1.2813191263214008e-12\n",
      "expression length:\t 5\n",
      "Result stage 916: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999997]*t)\n",
      "\n",
      "\n",
      "Stage  915\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0621980274645875e-07\n",
      "Average loss :  1.3258109887726022e-12\n",
      "\n",
      "\n",
      "Stage  915\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0621980274645875e-07\n",
      "Average loss :  1.3258109887726022e-12\n",
      "\n",
      "\n",
      "Stage  915\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0621980274645875e-07\n",
      "Average loss :  1.3258109887726022e-12\n",
      "\n",
      "\n",
      "Stage  915\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0621980274645875e-07\n",
      "Average loss :  1.3258109887726022e-12\n",
      "expression length:\t 5\n",
      "Result stage 917: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  916\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0516289805000094e-07\n",
      "Average loss :  1.327533027083161e-12\n",
      "\n",
      "\n",
      "Stage  916\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0516289805000094e-07\n",
      "Average loss :  1.2358095232908872e-12\n",
      "\n",
      "\n",
      "Stage  916\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0516289805000094e-07\n",
      "Average loss :  1.327533027083161e-12\n",
      "\n",
      "\n",
      "Stage  916\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0516289805000094e-07\n",
      "Average loss :  1.2358095232908872e-12\n",
      "expression length:\t 5\n",
      "Result stage 918: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  917\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0411650973098415e-07\n",
      "Average loss :  1.3416289563680794e-12\n",
      "\n",
      "\n",
      "Stage  917\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0411650973098415e-07\n",
      "Average loss :  1.297819273923806e-12\n",
      "\n",
      "\n",
      "Stage  917\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0411650973098415e-07\n",
      "Average loss :  1.3871814938046234e-12\n",
      "\n",
      "\n",
      "Stage  917\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0411650973098415e-07\n",
      "Average loss :  1.3416289563680794e-12\n",
      "expression length:\t 5\n",
      "Result stage 919: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  918\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0308053314970452e-07\n",
      "Average loss :  1.3727424145321132e-12\n",
      "\n",
      "\n",
      "Stage  918\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0308053314970452e-07\n",
      "Average loss :  1.272246956222911e-12\n",
      "\n",
      "\n",
      "Stage  918\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0308053314970452e-07\n",
      "Average loss :  1.2305989560701391e-12\n",
      "\n",
      "\n",
      "Stage  918\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0308053314970452e-07\n",
      "Average loss :  1.3727424145321132e-12\n",
      "expression length:\t 5\n",
      "Result stage 920: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  919\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0205486470764058e-07\n",
      "Average loss :  1.3211408963348381e-12\n",
      "\n",
      "\n",
      "Stage  919\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0205486470764058e-07\n",
      "Average loss :  1.3211408963348381e-12\n",
      "\n",
      "\n",
      "Stage  919\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0205486470764058e-07\n",
      "Average loss :  1.3211408963348381e-12\n",
      "\n",
      "\n",
      "Stage  919\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0205486470764058e-07\n",
      "Average loss :  1.3211408963348381e-12\n",
      "expression length:\t 5\n",
      "Result stage 921: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  920\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0103940183709325e-07\n",
      "Average loss :  1.3211408963348381e-12\n",
      "\n",
      "\n",
      "Stage  920\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0103940183709325e-07\n",
      "Average loss :  1.3211408963348381e-12\n",
      "\n",
      "\n",
      "Stage  920\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0103940183709325e-07\n",
      "Average loss :  1.3211408963348381e-12\n",
      "\n",
      "\n",
      "Stage  920\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0103940183709325e-07\n",
      "Average loss :  1.3211408963348381e-12\n",
      "expression length:\t 5\n",
      "Result stage 922: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  921\n",
      "Epoch 50/200\n",
      "Learning rate :  1.0003404299092957e-07\n",
      "Average loss :  1.3211408963348381e-12\n",
      "\n",
      "\n",
      "Stage  921\n",
      "Epoch 100/200\n",
      "Learning rate :  1.0003404299092957e-07\n",
      "Average loss :  1.3211408963348381e-12\n",
      "\n",
      "\n",
      "Stage  921\n",
      "Epoch 150/200\n",
      "Learning rate :  1.0003404299092957e-07\n",
      "Average loss :  1.3211408963348381e-12\n",
      "\n",
      "\n",
      "Stage  921\n",
      "Epoch 200/200\n",
      "Learning rate :  1.0003404299092957e-07\n",
      "Average loss :  1.3211408963348381e-12\n",
      "expression length:\t 5\n",
      "Result stage 923: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  922\n",
      "Epoch 50/200\n",
      "Learning rate :  9.903868763242698e-08\n",
      "Average loss :  1.3206019394348956e-12\n",
      "\n",
      "\n",
      "Stage  922\n",
      "Epoch 100/200\n",
      "Learning rate :  9.903868763242698e-08\n",
      "Average loss :  1.3206019394348956e-12\n",
      "\n",
      "\n",
      "Stage  922\n",
      "Epoch 150/200\n",
      "Learning rate :  9.903868763242698e-08\n",
      "Average loss :  1.3206019394348956e-12\n",
      "\n",
      "\n",
      "Stage  922\n",
      "Epoch 200/200\n",
      "Learning rate :  9.903868763242698e-08\n",
      "Average loss :  1.3206019394348956e-12\n",
      "expression length:\t 5\n",
      "Result stage 924: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  923\n",
      "Epoch 50/200\n",
      "Learning rate :  9.805323622522014e-08\n",
      "Average loss :  1.3206019394348956e-12\n",
      "\n",
      "\n",
      "Stage  923\n",
      "Epoch 100/200\n",
      "Learning rate :  9.805323622522014e-08\n",
      "Average loss :  1.3206019394348956e-12\n",
      "\n",
      "\n",
      "Stage  923\n",
      "Epoch 150/200\n",
      "Learning rate :  9.805323622522014e-08\n",
      "Average loss :  1.3206019394348956e-12\n",
      "\n",
      "\n",
      "Stage  923\n",
      "Epoch 200/200\n",
      "Learning rate :  9.805323622522014e-08\n",
      "Average loss :  1.3206019394348956e-12\n",
      "expression length:\t 5\n",
      "Result stage 925: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  924\n",
      "Epoch 50/200\n",
      "Learning rate :  9.707759022334712e-08\n",
      "Average loss :  1.3190589029030142e-12\n",
      "\n",
      "\n",
      "Stage  924\n",
      "Epoch 100/200\n",
      "Learning rate :  9.707759022334712e-08\n",
      "Average loss :  1.3190589029030142e-12\n",
      "\n",
      "\n",
      "Stage  924\n",
      "Epoch 150/200\n",
      "Learning rate :  9.707759022334712e-08\n",
      "Average loss :  1.3190589029030142e-12\n",
      "\n",
      "\n",
      "Stage  924\n",
      "Epoch 200/200\n",
      "Learning rate :  9.707759022334712e-08\n",
      "Average loss :  1.3190589029030142e-12\n",
      "expression length:\t 5\n",
      "Result stage 926: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  925\n",
      "Epoch 50/200\n",
      "Learning rate :  9.61116520613947e-08\n",
      "Average loss :  1.3197600564479606e-12\n",
      "\n",
      "\n",
      "Stage  925\n",
      "Epoch 100/200\n",
      "Learning rate :  9.61116520613947e-08\n",
      "Average loss :  1.3197600564479606e-12\n",
      "\n",
      "\n",
      "Stage  925\n",
      "Epoch 150/200\n",
      "Learning rate :  9.61116520613947e-08\n",
      "Average loss :  1.3197600564479606e-12\n",
      "\n",
      "\n",
      "Stage  925\n",
      "Epoch 200/200\n",
      "Learning rate :  9.61116520613947e-08\n",
      "Average loss :  1.3197600564479606e-12\n",
      "expression length:\t 5\n",
      "Result stage 927: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  926\n",
      "Epoch 50/200\n",
      "Learning rate :  9.515532514474171e-08\n",
      "Average loss :  1.3197600564479606e-12\n",
      "\n",
      "\n",
      "Stage  926\n",
      "Epoch 100/200\n",
      "Learning rate :  9.515532514474171e-08\n",
      "Average loss :  1.3197600564479606e-12\n",
      "\n",
      "\n",
      "Stage  926\n",
      "Epoch 150/200\n",
      "Learning rate :  9.515532514474171e-08\n",
      "Average loss :  1.3197600564479606e-12\n",
      "\n",
      "\n",
      "Stage  926\n",
      "Epoch 200/200\n",
      "Learning rate :  9.515532514474171e-08\n",
      "Average loss :  1.3197600564479606e-12\n",
      "expression length:\t 5\n",
      "Result stage 928: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  927\n",
      "Epoch 50/200\n",
      "Learning rate :  9.42085138398996e-08\n",
      "Average loss :  1.3148539331972464e-12\n",
      "\n",
      "\n",
      "Stage  927\n",
      "Epoch 100/200\n",
      "Learning rate :  9.42085138398996e-08\n",
      "Average loss :  1.3148539331972464e-12\n",
      "\n",
      "\n",
      "Stage  927\n",
      "Epoch 150/200\n",
      "Learning rate :  9.42085138398996e-08\n",
      "Average loss :  1.3148539331972464e-12\n",
      "\n",
      "\n",
      "Stage  927\n",
      "Epoch 200/200\n",
      "Learning rate :  9.42085138398996e-08\n",
      "Average loss :  1.3148539331972464e-12\n",
      "expression length:\t 5\n",
      "Result stage 929: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  928\n",
      "Epoch 50/200\n",
      "Learning rate :  9.327112346494881e-08\n",
      "Average loss :  1.3287870153158576e-12\n",
      "\n",
      "\n",
      "Stage  928\n",
      "Epoch 100/200\n",
      "Learning rate :  9.327112346494881e-08\n",
      "Average loss :  1.3287870153158576e-12\n",
      "\n",
      "\n",
      "Stage  928\n",
      "Epoch 150/200\n",
      "Learning rate :  9.327112346494881e-08\n",
      "Average loss :  1.3287870153158576e-12\n",
      "\n",
      "\n",
      "Stage  928\n",
      "Epoch 200/200\n",
      "Learning rate :  9.327112346494881e-08\n",
      "Average loss :  1.3287870153158576e-12\n",
      "expression length:\t 5\n",
      "Result stage 930: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  929\n",
      "Epoch 50/200\n",
      "Learning rate :  9.234306028007055e-08\n",
      "Average loss :  1.3082601408448413e-12\n",
      "\n",
      "\n",
      "Stage  929\n",
      "Epoch 100/200\n",
      "Learning rate :  9.234306028007055e-08\n",
      "Average loss :  1.273894943525089e-12\n",
      "\n",
      "\n",
      "Stage  929\n",
      "Epoch 150/200\n",
      "Learning rate :  9.234306028007055e-08\n",
      "Average loss :  1.2890284542890762e-12\n",
      "\n",
      "\n",
      "Stage  929\n",
      "Epoch 200/200\n",
      "Learning rate :  9.234306028007055e-08\n",
      "Average loss :  1.3082601408448413e-12\n",
      "expression length:\t 5\n",
      "Result stage 931: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  930\n",
      "Epoch 50/200\n",
      "Learning rate :  9.142423147817328e-08\n",
      "Average loss :  1.2842556879055778e-12\n",
      "\n",
      "\n",
      "Stage  930\n",
      "Epoch 100/200\n",
      "Learning rate :  9.142423147817328e-08\n",
      "Average loss :  1.2905192322762438e-12\n",
      "\n",
      "\n",
      "Stage  930\n",
      "Epoch 150/200\n",
      "Learning rate :  9.142423147817328e-08\n",
      "Average loss :  1.2918324179475582e-12\n",
      "\n",
      "\n",
      "Stage  930\n",
      "Epoch 200/200\n",
      "Learning rate :  9.142423147817328e-08\n",
      "Average loss :  1.2842556879055778e-12\n",
      "expression length:\t 5\n",
      "Result stage 932: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  931\n",
      "Epoch 50/200\n",
      "Learning rate :  9.051454517561092e-08\n",
      "Average loss :  1.2850355545282466e-12\n",
      "\n",
      "\n",
      "Stage  931\n",
      "Epoch 100/200\n",
      "Learning rate :  9.051454517561092e-08\n",
      "Average loss :  1.2850355545282466e-12\n",
      "\n",
      "\n",
      "Stage  931\n",
      "Epoch 150/200\n",
      "Learning rate :  9.051454517561092e-08\n",
      "Average loss :  1.2850355545282466e-12\n",
      "\n",
      "\n",
      "Stage  931\n",
      "Epoch 200/200\n",
      "Learning rate :  9.051454517561092e-08\n",
      "Average loss :  1.2850355545282466e-12\n",
      "expression length:\t 5\n",
      "Result stage 933: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  932\n",
      "Epoch 50/200\n",
      "Learning rate :  8.961391040299518e-08\n",
      "Average loss :  1.3012943587270565e-12\n",
      "\n",
      "\n",
      "Stage  932\n",
      "Epoch 100/200\n",
      "Learning rate :  8.961391040299518e-08\n",
      "Average loss :  1.3012943587270565e-12\n",
      "\n",
      "\n",
      "Stage  932\n",
      "Epoch 150/200\n",
      "Learning rate :  8.961391040299518e-08\n",
      "Average loss :  1.3012943587270565e-12\n",
      "\n",
      "\n",
      "Stage  932\n",
      "Epoch 200/200\n",
      "Learning rate :  8.961391040299518e-08\n",
      "Average loss :  1.3012943587270565e-12\n",
      "expression length:\t 5\n",
      "Result stage 934: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  933\n",
      "Epoch 50/200\n",
      "Learning rate :  8.872223709609824e-08\n",
      "Average loss :  1.280818441758147e-12\n",
      "\n",
      "\n",
      "Stage  933\n",
      "Epoch 100/200\n",
      "Learning rate :  8.872223709609824e-08\n",
      "Average loss :  1.3016534464865837e-12\n",
      "\n",
      "\n",
      "Stage  933\n",
      "Epoch 150/200\n",
      "Learning rate :  8.872223709609824e-08\n",
      "Average loss :  1.280818441758147e-12\n",
      "\n",
      "\n",
      "Stage  933\n",
      "Epoch 200/200\n",
      "Learning rate :  8.872223709609824e-08\n",
      "Average loss :  1.3016534464865837e-12\n",
      "expression length:\t 5\n",
      "Result stage 935: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  934\n",
      "Epoch 50/200\n",
      "Learning rate :  8.783943608684634e-08\n",
      "Average loss :  1.2708764162566721e-12\n",
      "\n",
      "\n",
      "Stage  934\n",
      "Epoch 100/200\n",
      "Learning rate :  8.783943608684634e-08\n",
      "Average loss :  1.2708764162566721e-12\n",
      "\n",
      "\n",
      "Stage  934\n",
      "Epoch 150/200\n",
      "Learning rate :  8.783943608684634e-08\n",
      "Average loss :  1.2708764162566721e-12\n",
      "\n",
      "\n",
      "Stage  934\n",
      "Epoch 200/200\n",
      "Learning rate :  8.783943608684634e-08\n",
      "Average loss :  1.2708764162566721e-12\n",
      "expression length:\t 5\n",
      "Result stage 936: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  935\n",
      "Epoch 50/200\n",
      "Learning rate :  8.696541909440292e-08\n",
      "Average loss :  1.2894627856793739e-12\n",
      "\n",
      "\n",
      "Stage  935\n",
      "Epoch 100/200\n",
      "Learning rate :  8.696541909440292e-08\n",
      "Average loss :  1.2894627856793739e-12\n",
      "\n",
      "\n",
      "Stage  935\n",
      "Epoch 150/200\n",
      "Learning rate :  8.696541909440292e-08\n",
      "Average loss :  1.2894627856793739e-12\n",
      "\n",
      "\n",
      "Stage  935\n",
      "Epoch 200/200\n",
      "Learning rate :  8.696541909440292e-08\n",
      "Average loss :  1.2894627856793739e-12\n",
      "expression length:\t 5\n",
      "Result stage 937: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  936\n",
      "Epoch 50/200\n",
      "Learning rate :  8.610009871634035e-08\n",
      "Average loss :  1.2930813104300443e-12\n",
      "\n",
      "\n",
      "Stage  936\n",
      "Epoch 100/200\n",
      "Learning rate :  8.610009871634035e-08\n",
      "Average loss :  1.3531290888116332e-12\n",
      "\n",
      "\n",
      "Stage  936\n",
      "Epoch 150/200\n",
      "Learning rate :  8.610009871634035e-08\n",
      "Average loss :  1.304525172780846e-12\n",
      "\n",
      "\n",
      "Stage  936\n",
      "Epoch 200/200\n",
      "Learning rate :  8.610009871634035e-08\n",
      "Average loss :  1.2930813104300443e-12\n",
      "expression length:\t 5\n",
      "Result stage 938: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  937\n",
      "Epoch 50/200\n",
      "Learning rate :  8.52433884198996e-08\n",
      "Average loss :  1.2870066340778252e-12\n",
      "\n",
      "\n",
      "Stage  937\n",
      "Epoch 100/200\n",
      "Learning rate :  8.52433884198996e-08\n",
      "Average loss :  1.2870066340778252e-12\n",
      "\n",
      "\n",
      "Stage  937\n",
      "Epoch 150/200\n",
      "Learning rate :  8.52433884198996e-08\n",
      "Average loss :  1.2870066340778252e-12\n",
      "\n",
      "\n",
      "Stage  937\n",
      "Epoch 200/200\n",
      "Learning rate :  8.52433884198996e-08\n",
      "Average loss :  1.2870066340778252e-12\n",
      "expression length:\t 5\n",
      "Result stage 939: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999991]*t)\n",
      "\n",
      "\n",
      "Stage  938\n",
      "Epoch 50/200\n",
      "Learning rate :  8.439520253333737e-08\n",
      "Average loss :  1.3229898947197949e-12\n",
      "\n",
      "\n",
      "Stage  938\n",
      "Epoch 100/200\n",
      "Learning rate :  8.439520253333737e-08\n",
      "Average loss :  1.3229898947197949e-12\n",
      "\n",
      "\n",
      "Stage  938\n",
      "Epoch 150/200\n",
      "Learning rate :  8.439520253333737e-08\n",
      "Average loss :  1.3229898947197949e-12\n",
      "\n",
      "\n",
      "Stage  938\n",
      "Epoch 200/200\n",
      "Learning rate :  8.439520253333737e-08\n",
      "Average loss :  1.3229898947197949e-12\n",
      "expression length:\t 5\n",
      "Result stage 940: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.1399999]*t)\n",
      "\n",
      "\n",
      "Stage  939\n",
      "Epoch 50/200\n",
      "Learning rate :  8.355545623735804e-08\n",
      "Average loss :  1.3177552582108176e-12\n",
      "\n",
      "\n",
      "Stage  939\n",
      "Epoch 100/200\n",
      "Learning rate :  8.355545623735804e-08\n",
      "Average loss :  1.3177552582108176e-12\n",
      "\n",
      "\n",
      "Stage  939\n",
      "Epoch 150/200\n",
      "Learning rate :  8.355545623735804e-08\n",
      "Average loss :  1.3177552582108176e-12\n",
      "\n",
      "\n",
      "Stage  939\n",
      "Epoch 200/200\n",
      "Learning rate :  8.355545623735804e-08\n",
      "Average loss :  1.3177552582108176e-12\n",
      "expression length:\t 5\n",
      "Result stage 941: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  940\n",
      "Epoch 50/200\n",
      "Learning rate :  8.272406555663223e-08\n",
      "Average loss :  1.3159638309612198e-12\n",
      "\n",
      "\n",
      "Stage  940\n",
      "Epoch 100/200\n",
      "Learning rate :  8.272406555663223e-08\n",
      "Average loss :  1.3159638309612198e-12\n",
      "\n",
      "\n",
      "Stage  940\n",
      "Epoch 150/200\n",
      "Learning rate :  8.272406555663223e-08\n",
      "Average loss :  1.3159638309612198e-12\n",
      "\n",
      "\n",
      "Stage  940\n",
      "Epoch 200/200\n",
      "Learning rate :  8.272406555663223e-08\n",
      "Average loss :  1.3159638309612198e-12\n",
      "expression length:\t 5\n",
      "Result stage 942: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  941\n",
      "Epoch 50/200\n",
      "Learning rate :  8.190094735139904e-08\n",
      "Average loss :  1.3097689165880722e-12\n",
      "\n",
      "\n",
      "Stage  941\n",
      "Epoch 100/200\n",
      "Learning rate :  8.190094735139904e-08\n",
      "Average loss :  1.3097689165880722e-12\n",
      "\n",
      "\n",
      "Stage  941\n",
      "Epoch 150/200\n",
      "Learning rate :  8.190094735139904e-08\n",
      "Average loss :  1.3097689165880722e-12\n",
      "\n",
      "\n",
      "Stage  941\n",
      "Epoch 200/200\n",
      "Learning rate :  8.190094735139904e-08\n",
      "Average loss :  1.3097689165880722e-12\n",
      "expression length:\t 5\n",
      "Result stage 943: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999988]*t)\n",
      "\n",
      "\n",
      "Stage  942\n",
      "Epoch 50/200\n",
      "Learning rate :  8.108601930915201e-08\n",
      "Average loss :  1.2657571388588473e-12\n",
      "\n",
      "\n",
      "Stage  942\n",
      "Epoch 100/200\n",
      "Learning rate :  8.108601930915201e-08\n",
      "Average loss :  1.2657571388588473e-12\n",
      "\n",
      "\n",
      "Stage  942\n",
      "Epoch 150/200\n",
      "Learning rate :  8.108601930915201e-08\n",
      "Average loss :  1.2657571388588473e-12\n",
      "\n",
      "\n",
      "Stage  942\n",
      "Epoch 200/200\n",
      "Learning rate :  8.108601930915201e-08\n",
      "Average loss :  1.2657571388588473e-12\n",
      "expression length:\t 5\n",
      "Result stage 944: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999994]*t)\n",
      "\n",
      "\n",
      "Stage  943\n",
      "Epoch 50/200\n",
      "Learning rate :  8.027919993640778e-08\n",
      "Average loss :  1.3547441163677676e-12\n",
      "\n",
      "\n",
      "Stage  943\n",
      "Epoch 100/200\n",
      "Learning rate :  8.027919993640778e-08\n",
      "Average loss :  1.3796944272823075e-12\n",
      "\n",
      "\n",
      "Stage  943\n",
      "Epoch 150/200\n",
      "Learning rate :  8.027919993640778e-08\n",
      "Average loss :  1.3547441163677676e-12\n",
      "\n",
      "\n",
      "Stage  943\n",
      "Epoch 200/200\n",
      "Learning rate :  8.027919993640778e-08\n",
      "Average loss :  1.3796944272823075e-12\n",
      "expression length:\t 5\n",
      "Result stage 945: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999987]*t)\n",
      "\n",
      "\n",
      "Stage  944\n",
      "Epoch 50/200\n",
      "Learning rate :  7.948040855055677e-08\n",
      "Average loss :  1.3366475894865948e-12\n",
      "\n",
      "\n",
      "Stage  944\n",
      "Epoch 100/200\n",
      "Learning rate :  7.948040855055677e-08\n",
      "Average loss :  1.3915321802823732e-12\n",
      "\n",
      "\n",
      "Stage  944\n",
      "Epoch 150/200\n",
      "Learning rate :  7.948040855055677e-08\n",
      "Average loss :  1.3933434484317275e-12\n",
      "\n",
      "\n",
      "Stage  944\n",
      "Epoch 200/200\n",
      "Learning rate :  7.948040855055677e-08\n",
      "Average loss :  1.3366475894865948e-12\n",
      "expression length:\t 5\n",
      "Result stage 946: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  945\n",
      "Epoch 50/200\n",
      "Learning rate :  7.868956527179456e-08\n",
      "Average loss :  1.3828578039609685e-12\n",
      "\n",
      "\n",
      "Stage  945\n",
      "Epoch 100/200\n",
      "Learning rate :  7.868956527179456e-08\n",
      "Average loss :  1.3828578039609685e-12\n",
      "\n",
      "\n",
      "Stage  945\n",
      "Epoch 150/200\n",
      "Learning rate :  7.868956527179456e-08\n",
      "Average loss :  1.3828578039609685e-12\n",
      "\n",
      "\n",
      "Stage  945\n",
      "Epoch 200/200\n",
      "Learning rate :  7.868956527179456e-08\n",
      "Average loss :  1.3828578039609685e-12\n",
      "expression length:\t 5\n",
      "Result stage 947: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  946\n",
      "Epoch 50/200\n",
      "Learning rate :  7.790659101513453e-08\n",
      "Average loss :  1.3828578039609685e-12\n",
      "\n",
      "\n",
      "Stage  946\n",
      "Epoch 100/200\n",
      "Learning rate :  7.790659101513453e-08\n",
      "Average loss :  1.3828578039609685e-12\n",
      "\n",
      "\n",
      "Stage  946\n",
      "Epoch 150/200\n",
      "Learning rate :  7.790659101513453e-08\n",
      "Average loss :  1.3828578039609685e-12\n",
      "\n",
      "\n",
      "Stage  946\n",
      "Epoch 200/200\n",
      "Learning rate :  7.790659101513453e-08\n",
      "Average loss :  1.3828578039609685e-12\n",
      "expression length:\t 5\n",
      "Result stage 948: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  947\n",
      "Epoch 50/200\n",
      "Learning rate :  7.71314074824984e-08\n",
      "Average loss :  1.3828578039609685e-12\n",
      "\n",
      "\n",
      "Stage  947\n",
      "Epoch 100/200\n",
      "Learning rate :  7.71314074824984e-08\n",
      "Average loss :  1.3828578039609685e-12\n",
      "\n",
      "\n",
      "Stage  947\n",
      "Epoch 150/200\n",
      "Learning rate :  7.71314074824984e-08\n",
      "Average loss :  1.3828578039609685e-12\n",
      "\n",
      "\n",
      "Stage  947\n",
      "Epoch 200/200\n",
      "Learning rate :  7.71314074824984e-08\n",
      "Average loss :  1.3828578039609685e-12\n",
      "expression length:\t 5\n",
      "Result stage 949: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  948\n",
      "Epoch 50/200\n",
      "Learning rate :  7.636393715488689e-08\n",
      "Average loss :  1.382313209209729e-12\n",
      "\n",
      "\n",
      "Stage  948\n",
      "Epoch 100/200\n",
      "Learning rate :  7.636393715488689e-08\n",
      "Average loss :  1.382313209209729e-12\n",
      "\n",
      "\n",
      "Stage  948\n",
      "Epoch 150/200\n",
      "Learning rate :  7.636393715488689e-08\n",
      "Average loss :  1.382313209209729e-12\n",
      "\n",
      "\n",
      "Stage  948\n",
      "Epoch 200/200\n",
      "Learning rate :  7.636393715488689e-08\n",
      "Average loss :  1.382313209209729e-12\n",
      "expression length:\t 5\n",
      "Result stage 950: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  949\n",
      "Epoch 50/200\n",
      "Learning rate :  7.56041032846277e-08\n",
      "Average loss :  1.382313209209729e-12\n",
      "\n",
      "\n",
      "Stage  949\n",
      "Epoch 100/200\n",
      "Learning rate :  7.56041032846277e-08\n",
      "Average loss :  1.382313209209729e-12\n",
      "\n",
      "\n",
      "Stage  949\n",
      "Epoch 150/200\n",
      "Learning rate :  7.56041032846277e-08\n",
      "Average loss :  1.382313209209729e-12\n",
      "\n",
      "\n",
      "Stage  949\n",
      "Epoch 200/200\n",
      "Learning rate :  7.56041032846277e-08\n",
      "Average loss :  1.382313209209729e-12\n",
      "expression length:\t 5\n",
      "Result stage 951: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  950\n",
      "Epoch 50/200\n",
      "Learning rate :  7.48518298877006e-08\n",
      "Average loss :  1.382313209209729e-12\n",
      "\n",
      "\n",
      "Stage  950\n",
      "Epoch 100/200\n",
      "Learning rate :  7.48518298877006e-08\n",
      "Average loss :  1.382313209209729e-12\n",
      "\n",
      "\n",
      "Stage  950\n",
      "Epoch 150/200\n",
      "Learning rate :  7.48518298877006e-08\n",
      "Average loss :  1.382313209209729e-12\n",
      "\n",
      "\n",
      "Stage  950\n",
      "Epoch 200/200\n",
      "Learning rate :  7.48518298877006e-08\n",
      "Average loss :  1.382313209209729e-12\n",
      "expression length:\t 5\n",
      "Result stage 952: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999985]*t)\n",
      "\n",
      "\n",
      "Stage  951\n",
      "Epoch 50/200\n",
      "Learning rate :  7.4107041736139e-08\n",
      "Average loss :  1.281739254663239e-12\n",
      "\n",
      "\n",
      "Stage  951\n",
      "Epoch 100/200\n",
      "Learning rate :  7.4107041736139e-08\n",
      "Average loss :  1.2869398472240001e-12\n",
      "\n",
      "\n",
      "Stage  951\n",
      "Epoch 150/200\n",
      "Learning rate :  7.4107041736139e-08\n",
      "Average loss :  1.281739254663239e-12\n",
      "\n",
      "\n",
      "Stage  951\n",
      "Epoch 200/200\n",
      "Learning rate :  7.4107041736139e-08\n",
      "Average loss :  1.2869398472240001e-12\n",
      "expression length:\t 5\n",
      "Result stage 953: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  952\n",
      "Epoch 50/200\n",
      "Learning rate :  7.336966435050709e-08\n",
      "Average loss :  1.2877853080781043e-12\n",
      "\n",
      "\n",
      "Stage  952\n",
      "Epoch 100/200\n",
      "Learning rate :  7.336966435050709e-08\n",
      "Average loss :  1.2877853080781043e-12\n",
      "\n",
      "\n",
      "Stage  952\n",
      "Epoch 150/200\n",
      "Learning rate :  7.336966435050709e-08\n",
      "Average loss :  1.2877853080781043e-12\n",
      "\n",
      "\n",
      "Stage  952\n",
      "Epoch 200/200\n",
      "Learning rate :  7.336966435050709e-08\n",
      "Average loss :  1.2877853080781043e-12\n",
      "expression length:\t 5\n",
      "Result stage 954: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  953\n",
      "Epoch 50/200\n",
      "Learning rate :  7.263962399245182e-08\n",
      "Average loss :  1.2859418391242272e-12\n",
      "\n",
      "\n",
      "Stage  953\n",
      "Epoch 100/200\n",
      "Learning rate :  7.263962399245182e-08\n",
      "Average loss :  1.2859418391242272e-12\n",
      "\n",
      "\n",
      "Stage  953\n",
      "Epoch 150/200\n",
      "Learning rate :  7.263962399245182e-08\n",
      "Average loss :  1.2859418391242272e-12\n",
      "\n",
      "\n",
      "Stage  953\n",
      "Epoch 200/200\n",
      "Learning rate :  7.263962399245182e-08\n",
      "Average loss :  1.2859418391242272e-12\n",
      "expression length:\t 5\n",
      "Result stage 955: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  954\n",
      "Epoch 50/200\n",
      "Learning rate :  7.191684765732889e-08\n",
      "Average loss :  1.3040617847723257e-12\n",
      "\n",
      "\n",
      "Stage  954\n",
      "Epoch 100/200\n",
      "Learning rate :  7.191684765732889e-08\n",
      "Average loss :  1.3040617847723257e-12\n",
      "\n",
      "\n",
      "Stage  954\n",
      "Epoch 150/200\n",
      "Learning rate :  7.191684765732889e-08\n",
      "Average loss :  1.3040617847723257e-12\n",
      "\n",
      "\n",
      "Stage  954\n",
      "Epoch 200/200\n",
      "Learning rate :  7.191684765732889e-08\n",
      "Average loss :  1.3040617847723257e-12\n",
      "expression length:\t 5\n",
      "Result stage 956: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  955\n",
      "Epoch 50/200\n",
      "Learning rate :  7.120126306690273e-08\n",
      "Average loss :  1.3166686707935527e-12\n",
      "\n",
      "\n",
      "Stage  955\n",
      "Epoch 100/200\n",
      "Learning rate :  7.120126306690273e-08\n",
      "Average loss :  1.3166686707935527e-12\n",
      "\n",
      "\n",
      "Stage  955\n",
      "Epoch 150/200\n",
      "Learning rate :  7.120126306690273e-08\n",
      "Average loss :  1.3166686707935527e-12\n",
      "\n",
      "\n",
      "Stage  955\n",
      "Epoch 200/200\n",
      "Learning rate :  7.120126306690273e-08\n",
      "Average loss :  1.3166686707935527e-12\n",
      "expression length:\t 5\n",
      "Result stage 957: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  956\n",
      "Epoch 50/200\n",
      "Learning rate :  7.049279866211784e-08\n",
      "Average loss :  1.3166686707935527e-12\n",
      "\n",
      "\n",
      "Stage  956\n",
      "Epoch 100/200\n",
      "Learning rate :  7.049279866211784e-08\n",
      "Average loss :  1.3166686707935527e-12\n",
      "\n",
      "\n",
      "Stage  956\n",
      "Epoch 150/200\n",
      "Learning rate :  7.049279866211784e-08\n",
      "Average loss :  1.3166686707935527e-12\n",
      "\n",
      "\n",
      "Stage  956\n",
      "Epoch 200/200\n",
      "Learning rate :  7.049279866211784e-08\n",
      "Average loss :  1.3166686707935527e-12\n",
      "expression length:\t 5\n",
      "Result stage 958: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999993]*t)\n",
      "\n",
      "\n",
      "Stage  957\n",
      "Epoch 50/200\n",
      "Learning rate :  6.979138359594336e-08\n",
      "Average loss :  1.296689101579207e-12\n",
      "\n",
      "\n",
      "Stage  957\n",
      "Epoch 100/200\n",
      "Learning rate :  6.979138359594336e-08\n",
      "Average loss :  1.296689101579207e-12\n",
      "\n",
      "\n",
      "Stage  957\n",
      "Epoch 150/200\n",
      "Learning rate :  6.979138359594336e-08\n",
      "Average loss :  1.296689101579207e-12\n",
      "\n",
      "\n",
      "Stage  957\n",
      "Epoch 200/200\n",
      "Learning rate :  6.979138359594336e-08\n",
      "Average loss :  1.296689101579207e-12\n",
      "expression length:\t 5\n",
      "Result stage 959: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999997]*t)\n",
      "\n",
      "\n",
      "Stage  958\n",
      "Epoch 50/200\n",
      "Learning rate :  6.909694772628816e-08\n",
      "Average loss :  1.266304877796387e-12\n",
      "\n",
      "\n",
      "Stage  958\n",
      "Epoch 100/200\n",
      "Learning rate :  6.909694772628816e-08\n",
      "Average loss :  1.266304877796387e-12\n",
      "\n",
      "\n",
      "Stage  958\n",
      "Epoch 150/200\n",
      "Learning rate :  6.909694772628816e-08\n",
      "Average loss :  1.266304877796387e-12\n",
      "\n",
      "\n",
      "Stage  958\n",
      "Epoch 200/200\n",
      "Learning rate :  6.909694772628816e-08\n",
      "Average loss :  1.266304877796387e-12\n",
      "expression length:\t 5\n",
      "Result stage 960: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  959\n",
      "Epoch 50/200\n",
      "Learning rate :  6.840942160898655e-08\n",
      "Average loss :  1.266304877796387e-12\n",
      "\n",
      "\n",
      "Stage  959\n",
      "Epoch 100/200\n",
      "Learning rate :  6.840942160898655e-08\n",
      "Average loss :  1.266304877796387e-12\n",
      "\n",
      "\n",
      "Stage  959\n",
      "Epoch 150/200\n",
      "Learning rate :  6.840942160898655e-08\n",
      "Average loss :  1.266304877796387e-12\n",
      "\n",
      "\n",
      "Stage  959\n",
      "Epoch 200/200\n",
      "Learning rate :  6.840942160898655e-08\n",
      "Average loss :  1.266304877796387e-12\n",
      "expression length:\t 5\n",
      "Result stage 961: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  960\n",
      "Epoch 50/200\n",
      "Learning rate :  6.77287364908539e-08\n",
      "Average loss :  1.266304877796387e-12\n",
      "\n",
      "\n",
      "Stage  960\n",
      "Epoch 100/200\n",
      "Learning rate :  6.77287364908539e-08\n",
      "Average loss :  1.266304877796387e-12\n",
      "\n",
      "\n",
      "Stage  960\n",
      "Epoch 150/200\n",
      "Learning rate :  6.77287364908539e-08\n",
      "Average loss :  1.266304877796387e-12\n",
      "\n",
      "\n",
      "Stage  960\n",
      "Epoch 200/200\n",
      "Learning rate :  6.77287364908539e-08\n",
      "Average loss :  1.266304877796387e-12\n",
      "expression length:\t 5\n",
      "Result stage 962: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  961\n",
      "Epoch 50/200\n",
      "Learning rate :  6.705482430281113e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  961\n",
      "Epoch 100/200\n",
      "Learning rate :  6.705482430281113e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  961\n",
      "Epoch 150/200\n",
      "Learning rate :  6.705482430281113e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  961\n",
      "Epoch 200/200\n",
      "Learning rate :  6.705482430281113e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "expression length:\t 5\n",
      "Result stage 963: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  962\n",
      "Epoch 50/200\n",
      "Learning rate :  6.638761765307773e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  962\n",
      "Epoch 100/200\n",
      "Learning rate :  6.638761765307773e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  962\n",
      "Epoch 150/200\n",
      "Learning rate :  6.638761765307773e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  962\n",
      "Epoch 200/200\n",
      "Learning rate :  6.638761765307773e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "expression length:\t 5\n",
      "Result stage 964: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  963\n",
      "Epoch 50/200\n",
      "Learning rate :  6.572704982043296e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  963\n",
      "Epoch 100/200\n",
      "Learning rate :  6.572704982043296e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  963\n",
      "Epoch 150/200\n",
      "Learning rate :  6.572704982043296e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  963\n",
      "Epoch 200/200\n",
      "Learning rate :  6.572704982043296e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "expression length:\t 5\n",
      "Result stage 965: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  964\n",
      "Epoch 50/200\n",
      "Learning rate :  6.507305474754295e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  964\n",
      "Epoch 100/200\n",
      "Learning rate :  6.507305474754295e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  964\n",
      "Epoch 150/200\n",
      "Learning rate :  6.507305474754295e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  964\n",
      "Epoch 200/200\n",
      "Learning rate :  6.507305474754295e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "expression length:\t 5\n",
      "Result stage 966: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  965\n",
      "Epoch 50/200\n",
      "Learning rate :  6.442556703435542e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  965\n",
      "Epoch 100/200\n",
      "Learning rate :  6.442556703435542e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  965\n",
      "Epoch 150/200\n",
      "Learning rate :  6.442556703435542e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "\n",
      "\n",
      "Stage  965\n",
      "Epoch 200/200\n",
      "Learning rate :  6.442556703435542e-08\n",
      "Average loss :  1.2604909520666507e-12\n",
      "expression length:\t 5\n",
      "Result stage 967: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  966\n",
      "Epoch 50/200\n",
      "Learning rate :  6.378452193155948e-08\n",
      "Average loss :  1.2583692768353139e-12\n",
      "\n",
      "\n",
      "Stage  966\n",
      "Epoch 100/200\n",
      "Learning rate :  6.378452193155948e-08\n",
      "Average loss :  1.2583692768353139e-12\n",
      "\n",
      "\n",
      "Stage  966\n",
      "Epoch 150/200\n",
      "Learning rate :  6.378452193155948e-08\n",
      "Average loss :  1.2583692768353139e-12\n",
      "\n",
      "\n",
      "Stage  966\n",
      "Epoch 200/200\n",
      "Learning rate :  6.378452193155948e-08\n",
      "Average loss :  1.2583692768353139e-12\n",
      "expression length:\t 5\n",
      "Result stage 968: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  967\n",
      "Epoch 50/200\n",
      "Learning rate :  6.314985533411063e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  967\n",
      "Epoch 100/200\n",
      "Learning rate :  6.314985533411063e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  967\n",
      "Epoch 150/200\n",
      "Learning rate :  6.314985533411063e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  967\n",
      "Epoch 200/200\n",
      "Learning rate :  6.314985533411063e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "expression length:\t 5\n",
      "Result stage 969: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  968\n",
      "Epoch 50/200\n",
      "Learning rate :  6.252150377482026e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  968\n",
      "Epoch 100/200\n",
      "Learning rate :  6.252150377482026e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  968\n",
      "Epoch 150/200\n",
      "Learning rate :  6.252150377482026e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  968\n",
      "Epoch 200/200\n",
      "Learning rate :  6.252150377482026e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "expression length:\t 5\n",
      "Result stage 970: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  969\n",
      "Epoch 50/200\n",
      "Learning rate :  6.189940441800879e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  969\n",
      "Epoch 100/200\n",
      "Learning rate :  6.189940441800879e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  969\n",
      "Epoch 150/200\n",
      "Learning rate :  6.189940441800879e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  969\n",
      "Epoch 200/200\n",
      "Learning rate :  6.189940441800879e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "expression length:\t 5\n",
      "Result stage 971: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  970\n",
      "Epoch 50/200\n",
      "Learning rate :  6.128349505322202e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  970\n",
      "Epoch 100/200\n",
      "Learning rate :  6.128349505322202e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  970\n",
      "Epoch 150/200\n",
      "Learning rate :  6.128349505322202e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  970\n",
      "Epoch 200/200\n",
      "Learning rate :  6.128349505322202e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "expression length:\t 5\n",
      "Result stage 972: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  971\n",
      "Epoch 50/200\n",
      "Learning rate :  6.067371408901044e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  971\n",
      "Epoch 100/200\n",
      "Learning rate :  6.067371408901044e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  971\n",
      "Epoch 150/200\n",
      "Learning rate :  6.067371408901044e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "\n",
      "\n",
      "Stage  971\n",
      "Epoch 200/200\n",
      "Learning rate :  6.067371408901044e-08\n",
      "Average loss :  1.2514530427568116e-12\n",
      "expression length:\t 5\n",
      "Result stage 973: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.13999999]*t)\n",
      "\n",
      "\n",
      "Stage  972\n",
      "Epoch 50/200\n",
      "Learning rate :  6.007000054676936e-08\n",
      "Average loss :  1.2809522323062317e-12\n",
      "\n",
      "\n",
      "Stage  972\n",
      "Epoch 100/200\n",
      "Learning rate :  6.007000054676936e-08\n",
      "Average loss :  1.2380732290068197e-12\n",
      "\n",
      "\n",
      "Stage  972\n",
      "Epoch 150/200\n",
      "Learning rate :  6.007000054676936e-08\n",
      "Average loss :  1.2614481941647382e-12\n",
      "\n",
      "\n",
      "Stage  972\n",
      "Epoch 200/200\n",
      "Learning rate :  6.007000054676936e-08\n",
      "Average loss :  1.2809522323062317e-12\n",
      "expression length:\t 5\n",
      "Result stage 974: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000003]*t)\n",
      "\n",
      "\n",
      "Stage  973\n",
      "Epoch 50/200\n",
      "Learning rate :  5.947229405464145e-08\n",
      "Average loss :  1.28146928832229e-12\n",
      "\n",
      "\n",
      "Stage  973\n",
      "Epoch 100/200\n",
      "Learning rate :  5.947229405464145e-08\n",
      "Average loss :  1.28146928832229e-12\n",
      "\n",
      "\n",
      "Stage  973\n",
      "Epoch 150/200\n",
      "Learning rate :  5.947229405464145e-08\n",
      "Average loss :  1.28146928832229e-12\n",
      "\n",
      "\n",
      "Stage  973\n",
      "Epoch 200/200\n",
      "Learning rate :  5.947229405464145e-08\n",
      "Average loss :  1.28146928832229e-12\n",
      "expression length:\t 5\n",
      "Result stage 975: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000003]*t)\n",
      "\n",
      "\n",
      "Stage  974\n",
      "Epoch 50/200\n",
      "Learning rate :  5.888053484147942e-08\n",
      "Average loss :  1.28146928832229e-12\n",
      "\n",
      "\n",
      "Stage  974\n",
      "Epoch 100/200\n",
      "Learning rate :  5.888053484147942e-08\n",
      "Average loss :  1.28146928832229e-12\n",
      "\n",
      "\n",
      "Stage  974\n",
      "Epoch 150/200\n",
      "Learning rate :  5.888053484147942e-08\n",
      "Average loss :  1.28146928832229e-12\n",
      "\n",
      "\n",
      "Stage  974\n",
      "Epoch 200/200\n",
      "Learning rate :  5.888053484147942e-08\n",
      "Average loss :  1.28146928832229e-12\n",
      "expression length:\t 5\n",
      "Result stage 976: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000003]*t)\n",
      "\n",
      "\n",
      "Stage  975\n",
      "Epoch 50/200\n",
      "Learning rate :  5.829466373086881e-08\n",
      "Average loss :  1.277418166904798e-12\n",
      "\n",
      "\n",
      "Stage  975\n",
      "Epoch 100/200\n",
      "Learning rate :  5.829466373086881e-08\n",
      "Average loss :  1.277418166904798e-12\n",
      "\n",
      "\n",
      "Stage  975\n",
      "Epoch 150/200\n",
      "Learning rate :  5.829466373086881e-08\n",
      "Average loss :  1.277418166904798e-12\n",
      "\n",
      "\n",
      "Stage  975\n",
      "Epoch 200/200\n",
      "Learning rate :  5.829466373086881e-08\n",
      "Average loss :  1.277418166904798e-12\n",
      "expression length:\t 5\n",
      "Result stage 977: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000005]*t)\n",
      "\n",
      "\n",
      "Stage  976\n",
      "Epoch 50/200\n",
      "Learning rate :  5.771462213521033e-08\n",
      "Average loss :  1.277468365465384e-12\n",
      "\n",
      "\n",
      "Stage  976\n",
      "Epoch 100/200\n",
      "Learning rate :  5.771462213521033e-08\n",
      "Average loss :  1.277468365465384e-12\n",
      "\n",
      "\n",
      "Stage  976\n",
      "Epoch 150/200\n",
      "Learning rate :  5.771462213521033e-08\n",
      "Average loss :  1.277468365465384e-12\n",
      "\n",
      "\n",
      "Stage  976\n",
      "Epoch 200/200\n",
      "Learning rate :  5.771462213521033e-08\n",
      "Average loss :  1.277468365465384e-12\n",
      "expression length:\t 5\n",
      "Result stage 978: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000005]*t)\n",
      "\n",
      "\n",
      "Stage  977\n",
      "Epoch 50/200\n",
      "Learning rate :  5.714035204986106e-08\n",
      "Average loss :  1.277468365465384e-12\n",
      "\n",
      "\n",
      "Stage  977\n",
      "Epoch 100/200\n",
      "Learning rate :  5.714035204986106e-08\n",
      "Average loss :  1.277468365465384e-12\n",
      "\n",
      "\n",
      "Stage  977\n",
      "Epoch 150/200\n",
      "Learning rate :  5.714035204986106e-08\n",
      "Average loss :  1.277468365465384e-12\n",
      "\n",
      "\n",
      "Stage  977\n",
      "Epoch 200/200\n",
      "Learning rate :  5.714035204986106e-08\n",
      "Average loss :  1.277468365465384e-12\n",
      "expression length:\t 5\n",
      "Result stage 979: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000005]*t)\n",
      "\n",
      "\n",
      "Stage  978\n",
      "Epoch 50/200\n",
      "Learning rate :  5.657179604733388e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  978\n",
      "Epoch 100/200\n",
      "Learning rate :  5.657179604733388e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  978\n",
      "Epoch 150/200\n",
      "Learning rate :  5.657179604733388e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  978\n",
      "Epoch 200/200\n",
      "Learning rate :  5.657179604733388e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "expression length:\t 5\n",
      "Result stage 980: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000005]*t)\n",
      "\n",
      "\n",
      "Stage  979\n",
      "Epoch 50/200\n",
      "Learning rate :  5.6008897271554666e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  979\n",
      "Epoch 100/200\n",
      "Learning rate :  5.6008897271554666e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  979\n",
      "Epoch 150/200\n",
      "Learning rate :  5.6008897271554666e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  979\n",
      "Epoch 200/200\n",
      "Learning rate :  5.6008897271554666e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "expression length:\t 5\n",
      "Result stage 981: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000005]*t)\n",
      "\n",
      "\n",
      "Stage  980\n",
      "Epoch 50/200\n",
      "Learning rate :  5.545159943217695e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  980\n",
      "Epoch 100/200\n",
      "Learning rate :  5.545159943217695e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  980\n",
      "Epoch 150/200\n",
      "Learning rate :  5.545159943217695e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  980\n",
      "Epoch 200/200\n",
      "Learning rate :  5.545159943217695e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "expression length:\t 5\n",
      "Result stage 982: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000005]*t)\n",
      "\n",
      "\n",
      "Stage  981\n",
      "Epoch 50/200\n",
      "Learning rate :  5.489984679895225e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  981\n",
      "Epoch 100/200\n",
      "Learning rate :  5.489984679895225e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  981\n",
      "Epoch 150/200\n",
      "Learning rate :  5.489984679895225e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  981\n",
      "Epoch 200/200\n",
      "Learning rate :  5.489984679895225e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "expression length:\t 5\n",
      "Result stage 983: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000005]*t)\n",
      "\n",
      "\n",
      "Stage  982\n",
      "Epoch 50/200\n",
      "Learning rate :  5.435358419615749e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  982\n",
      "Epoch 100/200\n",
      "Learning rate :  5.435358419615749e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  982\n",
      "Epoch 150/200\n",
      "Learning rate :  5.435358419615749e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  982\n",
      "Epoch 200/200\n",
      "Learning rate :  5.435358419615749e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "expression length:\t 5\n",
      "Result stage 984: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000005]*t)\n",
      "\n",
      "\n",
      "Stage  983\n",
      "Epoch 50/200\n",
      "Learning rate :  5.3812756997077146e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  983\n",
      "Epoch 100/200\n",
      "Learning rate :  5.3812756997077146e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  983\n",
      "Epoch 150/200\n",
      "Learning rate :  5.3812756997077146e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  983\n",
      "Epoch 200/200\n",
      "Learning rate :  5.3812756997077146e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "expression length:\t 5\n",
      "Result stage 985: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000005]*t)\n",
      "\n",
      "\n",
      "Stage  984\n",
      "Epoch 50/200\n",
      "Learning rate :  5.327731111854062e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  984\n",
      "Epoch 100/200\n",
      "Learning rate :  5.327731111854062e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  984\n",
      "Epoch 150/200\n",
      "Learning rate :  5.327731111854062e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "\n",
      "\n",
      "Stage  984\n",
      "Epoch 200/200\n",
      "Learning rate :  5.327731111854062e-08\n",
      "Average loss :  1.2751763620727496e-12\n",
      "expression length:\t 5\n",
      "Result stage 986: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000005]*t)\n",
      "\n",
      "\n",
      "Stage  985\n",
      "Epoch 50/200\n",
      "Learning rate :  5.274719301551385e-08\n",
      "Average loss :  1.268681340538258e-12\n",
      "\n",
      "\n",
      "Stage  985\n",
      "Epoch 100/200\n",
      "Learning rate :  5.274719301551385e-08\n",
      "Average loss :  1.2836178517675045e-12\n",
      "\n",
      "\n",
      "Stage  985\n",
      "Epoch 150/200\n",
      "Learning rate :  5.274719301551385e-08\n",
      "Average loss :  1.2704445785313712e-12\n",
      "\n",
      "\n",
      "Stage  985\n",
      "Epoch 200/200\n",
      "Learning rate :  5.274719301551385e-08\n",
      "Average loss :  1.268681340538258e-12\n",
      "expression length:\t 5\n",
      "Result stage 987: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000003]*t)\n",
      "\n",
      "\n",
      "Stage  986\n",
      "Epoch 50/200\n",
      "Learning rate :  5.222234967574478e-08\n",
      "Average loss :  1.2680122793776172e-12\n",
      "\n",
      "\n",
      "Stage  986\n",
      "Epoch 100/200\n",
      "Learning rate :  5.222234967574478e-08\n",
      "Average loss :  1.2680122793776172e-12\n",
      "\n",
      "\n",
      "Stage  986\n",
      "Epoch 150/200\n",
      "Learning rate :  5.222234967574478e-08\n",
      "Average loss :  1.2680122793776172e-12\n",
      "\n",
      "\n",
      "Stage  986\n",
      "Epoch 200/200\n",
      "Learning rate :  5.222234967574478e-08\n",
      "Average loss :  1.2680122793776172e-12\n",
      "expression length:\t 5\n",
      "Result stage 988: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000003]*t)\n",
      "\n",
      "\n",
      "Stage  987\n",
      "Epoch 50/200\n",
      "Learning rate :  5.170272861446196e-08\n",
      "Average loss :  1.2680122793776172e-12\n",
      "\n",
      "\n",
      "Stage  987\n",
      "Epoch 100/200\n",
      "Learning rate :  5.170272861446196e-08\n",
      "Average loss :  1.2680122793776172e-12\n",
      "\n",
      "\n",
      "Stage  987\n",
      "Epoch 150/200\n",
      "Learning rate :  5.170272861446196e-08\n",
      "Average loss :  1.2680122793776172e-12\n",
      "\n",
      "\n",
      "Stage  987\n",
      "Epoch 200/200\n",
      "Learning rate :  5.170272861446196e-08\n",
      "Average loss :  1.2680122793776172e-12\n",
      "expression length:\t 5\n",
      "Result stage 989: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000003]*t)\n",
      "\n",
      "\n",
      "Stage  988\n",
      "Epoch 50/200\n",
      "Learning rate :  5.1188277869126426e-08\n",
      "Average loss :  1.2733184732299785e-12\n",
      "\n",
      "\n",
      "Stage  988\n",
      "Epoch 100/200\n",
      "Learning rate :  5.1188277869126426e-08\n",
      "Average loss :  1.2733184732299785e-12\n",
      "\n",
      "\n",
      "Stage  988\n",
      "Epoch 150/200\n",
      "Learning rate :  5.1188277869126426e-08\n",
      "Average loss :  1.2733184732299785e-12\n",
      "\n",
      "\n",
      "Stage  988\n",
      "Epoch 200/200\n",
      "Learning rate :  5.1188277869126426e-08\n",
      "Average loss :  1.2733184732299785e-12\n",
      "expression length:\t 5\n",
      "Result stage 990: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000003]*t)\n",
      "\n",
      "\n",
      "Stage  989\n",
      "Epoch 50/200\n",
      "Learning rate :  5.0678945994234845e-08\n",
      "Average loss :  1.2733184732299785e-12\n",
      "\n",
      "\n",
      "Stage  989\n",
      "Epoch 100/200\n",
      "Learning rate :  5.0678945994234845e-08\n",
      "Average loss :  1.2733184732299785e-12\n",
      "\n",
      "\n",
      "Stage  989\n",
      "Epoch 150/200\n",
      "Learning rate :  5.0678945994234845e-08\n",
      "Average loss :  1.2733184732299785e-12\n",
      "\n",
      "\n",
      "Stage  989\n",
      "Epoch 200/200\n",
      "Learning rate :  5.0678945994234845e-08\n",
      "Average loss :  1.2733184732299785e-12\n",
      "expression length:\t 5\n",
      "Result stage 991: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000003]*t)\n",
      "\n",
      "\n",
      "Stage  990\n",
      "Epoch 50/200\n",
      "Learning rate :  5.017468205617529e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "\n",
      "\n",
      "Stage  990\n",
      "Epoch 100/200\n",
      "Learning rate :  5.017468205617529e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "\n",
      "\n",
      "Stage  990\n",
      "Epoch 150/200\n",
      "Learning rate :  5.017468205617529e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "\n",
      "\n",
      "Stage  990\n",
      "Epoch 200/200\n",
      "Learning rate :  5.017468205617529e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "expression length:\t 5\n",
      "Result stage 992: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000002]*t)\n",
      "\n",
      "\n",
      "Stage  991\n",
      "Epoch 50/200\n",
      "Learning rate :  4.967543562813372e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "\n",
      "\n",
      "Stage  991\n",
      "Epoch 100/200\n",
      "Learning rate :  4.967543562813372e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "\n",
      "\n",
      "Stage  991\n",
      "Epoch 150/200\n",
      "Learning rate :  4.967543562813372e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "\n",
      "\n",
      "Stage  991\n",
      "Epoch 200/200\n",
      "Learning rate :  4.967543562813372e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "expression length:\t 5\n",
      "Result stage 993: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000002]*t)\n",
      "\n",
      "\n",
      "Stage  992\n",
      "Epoch 50/200\n",
      "Learning rate :  4.91811567850513e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "\n",
      "\n",
      "Stage  992\n",
      "Epoch 100/200\n",
      "Learning rate :  4.91811567850513e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "\n",
      "\n",
      "Stage  992\n",
      "Epoch 150/200\n",
      "Learning rate :  4.91811567850513e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "\n",
      "\n",
      "Stage  992\n",
      "Epoch 200/200\n",
      "Learning rate :  4.91811567850513e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "expression length:\t 5\n",
      "Result stage 994: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000002]*t)\n",
      "\n",
      "\n",
      "Stage  993\n",
      "Epoch 50/200\n",
      "Learning rate :  4.8691796098631817e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "\n",
      "\n",
      "Stage  993\n",
      "Epoch 100/200\n",
      "Learning rate :  4.8691796098631817e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "\n",
      "\n",
      "Stage  993\n",
      "Epoch 150/200\n",
      "Learning rate :  4.8691796098631817e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "\n",
      "\n",
      "Stage  993\n",
      "Epoch 200/200\n",
      "Learning rate :  4.8691796098631817e-08\n",
      "Average loss :  1.2856363109520208e-12\n",
      "expression length:\t 5\n",
      "Result stage 995: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000002]*t)\n",
      "\n",
      "\n",
      "Stage  994\n",
      "Epoch 50/200\n",
      "Learning rate :  4.820730463239883e-08\n",
      "Average loss :  1.2814800219237976e-12\n",
      "\n",
      "\n",
      "Stage  994\n",
      "Epoch 100/200\n",
      "Learning rate :  4.820730463239883e-08\n",
      "Average loss :  1.2635967576099527e-12\n",
      "\n",
      "\n",
      "Stage  994\n",
      "Epoch 150/200\n",
      "Learning rate :  4.820730463239883e-08\n",
      "Average loss :  1.262660332193577e-12\n",
      "\n",
      "\n",
      "Stage  994\n",
      "Epoch 200/200\n",
      "Learning rate :  4.820730463239883e-08\n",
      "Average loss :  1.2814800219237976e-12\n",
      "expression length:\t 5\n",
      "Result stage 996: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14]*t)\n",
      "\n",
      "\n",
      "Stage  995\n",
      "Epoch 50/200\n",
      "Learning rate :  4.7727633936801884e-08\n",
      "Average loss :  1.2635967576099527e-12\n",
      "\n",
      "\n",
      "Stage  995\n",
      "Epoch 100/200\n",
      "Learning rate :  4.7727633936801884e-08\n",
      "Average loss :  1.262660332193577e-12\n",
      "\n",
      "\n",
      "Stage  995\n",
      "Epoch 150/200\n",
      "Learning rate :  4.7727633936801884e-08\n",
      "Average loss :  1.2814800219237976e-12\n",
      "\n",
      "\n",
      "Stage  995\n",
      "Epoch 200/200\n",
      "Learning rate :  4.7727633936801884e-08\n",
      "Average loss :  1.2635967576099527e-12\n",
      "expression length:\t 5\n",
      "Result stage 997: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000005]*t)\n",
      "\n",
      "\n",
      "Stage  996\n",
      "Epoch 50/200\n",
      "Learning rate :  4.725273604437187e-08\n",
      "Average loss :  1.262660332193577e-12\n",
      "\n",
      "\n",
      "Stage  996\n",
      "Epoch 100/200\n",
      "Learning rate :  4.725273604437187e-08\n",
      "Average loss :  1.2814800219237976e-12\n",
      "\n",
      "\n",
      "Stage  996\n",
      "Epoch 150/200\n",
      "Learning rate :  4.725273604437187e-08\n",
      "Average loss :  1.2635967576099527e-12\n",
      "\n",
      "\n",
      "Stage  996\n",
      "Epoch 200/200\n",
      "Learning rate :  4.725273604437187e-08\n",
      "Average loss :  1.262660332193577e-12\n",
      "expression length:\t 5\n",
      "Result stage 998: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000002]*t)\n",
      "\n",
      "\n",
      "Stage  997\n",
      "Epoch 50/200\n",
      "Learning rate :  4.67825634649237e-08\n",
      "Average loss :  1.2814800219237976e-12\n",
      "\n",
      "\n",
      "Stage  997\n",
      "Epoch 100/200\n",
      "Learning rate :  4.67825634649237e-08\n",
      "Average loss :  1.2635967576099527e-12\n",
      "\n",
      "\n",
      "Stage  997\n",
      "Epoch 150/200\n",
      "Learning rate :  4.67825634649237e-08\n",
      "Average loss :  1.262660332193577e-12\n",
      "\n",
      "\n",
      "Stage  997\n",
      "Epoch 200/200\n",
      "Learning rate :  4.67825634649237e-08\n",
      "Average loss :  1.2814800219237976e-12\n",
      "expression length:\t 5\n",
      "Result stage 999: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14]*t)\n",
      "\n",
      "\n",
      "Stage  998\n",
      "Epoch 50/200\n",
      "Learning rate :  4.631706918080762e-08\n",
      "Average loss :  1.2775567279424416e-12\n",
      "\n",
      "\n",
      "Stage  998\n",
      "Epoch 100/200\n",
      "Learning rate :  4.631706918080762e-08\n",
      "Average loss :  1.2814800219237976e-12\n",
      "\n",
      "\n",
      "Stage  998\n",
      "Epoch 150/200\n",
      "Learning rate :  4.631706918080762e-08\n",
      "Average loss :  1.2775567279424416e-12\n",
      "\n",
      "\n",
      "Stage  998\n",
      "Epoch 200/200\n",
      "Learning rate :  4.631706918080762e-08\n",
      "Average loss :  1.2814800219237976e-12\n",
      "expression length:\t 5\n",
      "Result stage 1000: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14]*t)\n",
      "\n",
      "\n",
      "Stage  999\n",
      "Epoch 50/200\n",
      "Learning rate :  4.585620664220731e-08\n",
      "Average loss :  1.2679129664586175e-12\n",
      "\n",
      "\n",
      "Stage  999\n",
      "Epoch 100/200\n",
      "Learning rate :  4.585620664220731e-08\n",
      "Average loss :  1.2679129664586175e-12\n",
      "\n",
      "\n",
      "Stage  999\n",
      "Epoch 150/200\n",
      "Learning rate :  4.585620664220731e-08\n",
      "Average loss :  1.2679129664586175e-12\n",
      "\n",
      "\n",
      "Stage  999\n",
      "Epoch 200/200\n",
      "Learning rate :  4.585620664220731e-08\n",
      "Average loss :  1.2679129664586175e-12\n",
      "expression length:\t 5\n",
      "Result stage 1001: -1.739*sin(x0) + 25.088*cos(x0) + 1.42*x0_t**2 + 19.836*x0_t*sin(x0) + -12.419*x0_t*cos(x0) + \n",
      "exp([0.14000003]*t)\n"
     ]
    }
   ],
   "source": [
    "momentum = True\n",
    "lr_initial = 1e-3\n",
    "decay_rate = 0.01\n",
    "for stage in range(1000):\n",
    "    lr = lr_initial * np.exp(-decay_rate * stage)\n",
    "    #Redefine computation after thresholding\n",
    "    Zeta, Eta, Delta, Gamma = LagrangianLibraryTensor(X,Xdot,expr,states,states_dot,device,scaling=False)\n",
    "    Eta = Eta.to(device)\n",
    "    Zeta = Zeta.to(device)\n",
    "    Delta = Delta.to(device)\n",
    "    Gamma = Gamma.to(device)\n",
    "    #Training\n",
    "    Epoch = 200\n",
    "    i = 1\n",
    "    threshold = 2e-1\n",
    "    if len(xi_L) == 2:\n",
    "        #c_training = True\n",
    "        threshold = 0\n",
    "        momentum = True\n",
    "    if(stage==1):\n",
    "        lam = 0\n",
    "    else:\n",
    "        lam = 0.1\n",
    "    temp = 1000\n",
    "    while(i<=Epoch):   \n",
    "        xi_L , prevxi_L,c,prec, lossitem= training_loop(xi_L,c,prevxi_L,prec,Zeta,Eta,Delta,Gamma,Xdot,128,lr=lr,lam=lam,momentum=momentum)\n",
    "        if i %50 == 0:\n",
    "            print(\"\\n\")\n",
    "            print(\"Stage \",stage)\n",
    "            print(\"Epoch \"+str(i) + \"/\" + str(Epoch))\n",
    "            print(\"Learning rate : \", lr)\n",
    "            print(\"Average loss : \" , lossitem)\n",
    "        temp = lossitem\n",
    "\n",
    "        i+=1\n",
    "    \n",
    "    ## Thresholding small indices ##\n",
    "\n",
    "    surv_index = ((torch.abs(xi_L) >= threshold)).nonzero(as_tuple=True)[0].detach().cpu().numpy()\n",
    "    expr = np.array(expr)[surv_index].tolist()\n",
    "\n",
    "    xi_L =xi_L[surv_index].clone().detach().requires_grad_(True)\n",
    "    prevxi_L = xi_L.clone().detach()\n",
    "    mask = torch.ones(len(expr),device=device)\n",
    "\n",
    "    ## obtaining analytical model\n",
    "    xi_Lcpu = np.around(xi_L.detach().cpu().numpy(),decimals=3)\n",
    "    c_cpu = c.detach().cpu().numpy()\n",
    "    L = HL.generateExpression(xi_Lcpu,expr)\n",
    "    print(\"expression length:\\t\",len(xi_L))\n",
    "    print(\"Result stage \" + str(stage+2) + \":\" , L)\n",
    "    print('exp({}*t)'.format(c_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fda7f63-7451-4f1f-8bb8-6d994abdedee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8813673-d9ae-4769-9aa8-dc6b89ba4f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
