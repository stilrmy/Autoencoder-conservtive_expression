{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc0cfb5-fb6e-47c5-ab0a-4b3f3021d9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6073796015734873e-65\n"
     ]
    }
   ],
   "source": [
    "def __clear_env():\n",
    "    for key in globals().keys():\n",
    "        if not key.startswith(\"__\"):# 排除系统内建函数\n",
    "            globals().pop(key)\n",
    "__clear_env\n",
    "import example_pendulum\n",
    "import torch; torch.manual_seed(66)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "#import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b199479c-728d-4425-ba21-8216ff0642c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_route = R'/mnt/ssd1/stilrmy/Autoencoder-conservtive_expression/progress/AE'\n",
    "device = 'cuda:0'\n",
    "data = example_pendulum.get_pendulum_data(20)\n",
    "val_data = example_pendulum.get_pendulum_data(10)\n",
    "save_params = True\n",
    "load_params = False\n",
    "\n",
    "load_date = str(datetime.date.today())\n",
    "load_ver = 1\n",
    "widths = [512,128,64]\n",
    "params={}\n",
    "params['ver'] = \"1\"\n",
    "params['accumulate_epochs'] = 0\n",
    "params['date'] = '4-21'\n",
    "params['widths'] = widths\n",
    "params['activation'] = 'sigmoid'\n",
    "params['max_epochs'] = 40000\n",
    "params['epoch_size'] = data[\"x\"].shape[0]\n",
    "params['batch_size'] = 500\n",
    "params['learning_rate'] = 0\n",
    "params['loss_weight_x'] = 1\n",
    "params['loss_weight_dx'] = 1\n",
    "params['loss_weight_ddx'] = 1\n",
    "params['learning_rate_switching_point'] = 500\n",
    "loss_history = []\n",
    "loss_z_history = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e8acc6-fe30-4a7c-9e70-17ced93a831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['learning_rate_stage1'] = 1e-6\n",
    "params['learning_rate_stage2'] = 1e-6\n",
    "params['learning_rate'] = params['learning_rate_stage1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e3c08a-5221-4677-b438-f97797ff3e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(input_dim,latent_dim,widths,device):\n",
    "    #generate the parameters of the autoencoder\n",
    "    encoder_weights,encoder_biases = build_network_layers(input_dim,latent_dim,widths,device)\n",
    "    decoder_weights, decoder_biases = build_network_layers(latent_dim, input_dim, widths[::-1],device)\n",
    "    return encoder_weights,encoder_biases,decoder_weights,decoder_biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df85ec5-9e1f-4660-9747-58ada3d52edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network_layers(input_dim,output_dim,widths,device):\n",
    "    #universal function for building network\n",
    "    weights = []\n",
    "    biases = []\n",
    "    last_width = input_dim\n",
    "    #middle layers\n",
    "    for i,n_units in enumerate(widths):\n",
    "        w = torch.Tensor(last_width,n_units,).to(device)\n",
    "        nn.init.xavier_uniform_(w, gain=1.0)\n",
    "        w = Variable(w, requires_grad=True)\n",
    "        b = torch.Tensor(n_units).to(device)\n",
    "        nn.init.constant_(b, 0.0)\n",
    "        b = Variable(b, requires_grad=True)\n",
    "        last_width = n_units\n",
    "        weights.append(w)\n",
    "        biases.append(b)\n",
    "    #latent layer\n",
    "    w = torch.Tensor(last_width,output_dim).to(device)\n",
    "    nn.init.xavier_uniform_(w, gain=1.0)\n",
    "    w = Variable(w,requires_grad=True)\n",
    "    b = torch.Tensor(output_dim).to(device)\n",
    "    nn.init.constant_(b, 0.0)\n",
    "    b = Variable(b, requires_grad=True)\n",
    "    weights.append(w)\n",
    "    biases.append(b)\n",
    "    return weights,biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d9d0ce-9c55-487f-9979-eb26dfe73b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_forward(input,params):\n",
    "    #pass through the autoencoder\n",
    "    for i,weights in enumerate(params['encoder_weights']):\n",
    "        input = torch.matmul(input,weights)+params['encoder_biases'][i]\n",
    "        if params['activation'] == 'sigmoid' and i <len(params['encoder_weights'])-1:\n",
    "            input = torch.sigmoid(input)\n",
    "    for i,weights in enumerate(params['decoder_weights']):\n",
    "        input = torch.matmul(input,weights)+params['decoder_biases'][i]\n",
    "        if params['activation'] == 'sigmoid'and i <len(params['decoder_weights'])-1:\n",
    "            input = torch.sigmoid(input)\n",
    "    return input\n",
    "def encoder_forward(input,params):\n",
    "    for i,weights in enumerate(params['encoder_weights']):\n",
    "        input = torch.matmul(input,weights)+params['encoder_biases'][i]\n",
    "        if params['activation'] == 'sigmoid' and i <len(params['encoder_weights'])-1:\n",
    "            input = torch.sigmoid(input)\n",
    "    return input\n",
    "\n",
    "def decoder_forward(input,params):\n",
    "    for i,weights in enumerate(params['decoder_weights']):\n",
    "        input = torch.matmul(input,weights)+params['decoder_biases'][i]\n",
    "        if params['activation'] == 'sigmoid' and i <len(params['decoder_weights'])-1:\n",
    "            input = torch.sigmoid(input)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc9d1c44-974a-40a5-99c8-7dffe6010430",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encoder_derivative(image,image_t,image_tt,params):\n",
    "    #calculate the time/second time derivative of the latent(s) using the autoencoder\n",
    "    dz = image_t\n",
    "    ddz = image_tt\n",
    "    input = image\n",
    "    weights = params['encoder_weights']\n",
    "    biases = params['encoder_biases']\n",
    "    if params['activation'] == 'sigmoid':\n",
    "        for i in range(len(weights)-1):\n",
    "            input = torch.matmul(input,weights[i])+biases[i]\n",
    "            input = torch.sigmoid(input)\n",
    "            dz_prev = torch.matmul(dz,weights[i])\n",
    "            sigmoid_derivative = torch.multiply(input,1-input)\n",
    "            sigmoid_derivative2 = torch.multiply(sigmoid_derivative,1-2*input)\n",
    "            dz = torch.multiply(sigmoid_derivative,dz_prev)\n",
    "            ddz = torch.multiply(sigmoid_derivative2,torch.square(dz_prev))\\\n",
    "                  + torch.multiply(sigmoid_derivative,torch.matmul(ddz,weights[i]))\n",
    "        dz = torch.matmul(dz,weights[-1])\n",
    "        ddz = torch.matmul(ddz,weights[-1])\n",
    "    return dz,ddz\n",
    "\n",
    "def decoder_derivative(z,dz,ddz,params):\n",
    "    #calculate the time/second time derivative of the latent(s) using the autoencoder\n",
    "    input = z\n",
    "    weights = params['decoder_weights']\n",
    "    biases = params['decoder_biases']\n",
    "    if params['activation'] == 'sigmoid':\n",
    "        for i in range(len(weights)-1):\n",
    "            input = torch.matmul(input,weights[i])+biases[i]\n",
    "            input = torch.sigmoid(input)\n",
    "            dz_prev = torch.matmul(dz,weights[i])\n",
    "            sigmoid_derivative = torch.multiply(input,1-input)\n",
    "            sigmoid_derivative2 = torch.multiply(sigmoid_derivative,1-2*input)\n",
    "            dz = torch.multiply(sigmoid_derivative,dz_prev)\n",
    "            #print(sigmoid_derivative.shape)\n",
    "            ddz = torch.multiply(sigmoid_derivative2,torch.square(dz_prev))\\\n",
    "                  + torch.multiply(sigmoid_derivative,torch.matmul(ddz,weights[i]))\n",
    "        dz = torch.matmul(dz,weights[-1])\n",
    "        ddz = torch.matmul(ddz,weights[-1])\n",
    "    return dz,ddz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e69dd597-1ed1-4d11-9f38-85a473af0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(data,params,device):\n",
    "    opt = torch.optim.Adam(generate_parameter(params), lr=params['learning_rate'])\n",
    "    total_loss = 0\n",
    "    total_loss_z = 0\n",
    "    for j in range(params['epoch_size']//params['batch_size']):\n",
    "        batch_idxs = np.arange(j * params['batch_size'], (j + 1) * params['batch_size'])\n",
    "        z = torch.from_numpy(data['z'][batch_idxs]).to(torch.float32).to(device)\n",
    "        x = torch.from_numpy(data['x'][batch_idxs]).to(torch.float32).to(device)\n",
    "        dx = torch.from_numpy(data['dx'][batch_idxs]).to(torch.float32).to(device)\n",
    "        ddx = torch.from_numpy(data['ddx'][batch_idxs]).to(torch.float32).to(device)\n",
    "        x_predict = autoencoder_forward(x,params)\n",
    "        z_predict = encoder_forward(x,params)\n",
    "        dz_predict,ddz_predict = encoder_derivative(x,dx,ddx,params)\n",
    "        dx_predict,ddx_predict = decoder_derivative(z_predict,dz_predict,ddz_predict,params)\n",
    "        loss_x = torch.mean((x - x_predict)**2)\n",
    "        loss_dx = torch.mean((dx - dx_predict) ** 2)\n",
    "        loss_ddx = torch.mean((ddx - ddx_predict) ** 2)\n",
    "        loss_z = torch.mean((z - z_predict)**2)\n",
    "        loss = params['loss_weight_x'] * loss_x \\\n",
    "               + params['loss_weight_dx'] * loss_dx \\\n",
    "               + params['loss_weight_ddx'] * loss_ddx\n",
    "        total_loss += loss\n",
    "        total_loss_z += loss_z\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    avg_loss = total_loss/(params['epoch_size']//params['batch_size'])\n",
    "    avg_loss_z = total_loss_z/(params['epoch_size']//params['batch_size'])\n",
    "    return avg_loss,avg_loss_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832f43d0-2d2a-4527-a19e-bdf70e84c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parameter(params):\n",
    "    encoder_weights = params['encoder_weights']\n",
    "    encoder_biases = params['encoder_biases']\n",
    "    params_temp = []\n",
    "    for i in range(len(params['widths'])):\n",
    "        params_temp.append(encoder_weights[i])\n",
    "        params_temp.append(encoder_biases[i])\n",
    "    decoder_weights = params['decoder_weights']\n",
    "    decoder_biases = params['decoder_biases']\n",
    "    for i in range(len(params['widths'])):\n",
    "        params_temp.append(decoder_weights[i])\n",
    "        params_temp.append(decoder_biases[i])\n",
    "    return params_temp\n",
    "\n",
    "def generate_vhat(vhat):\n",
    "    vhat = tuple(vhat)\n",
    "    yield vhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d0474d4-99c4-4ed7-b5fd-730544f1bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(data,params,device):\n",
    "    total_loss = 0\n",
    "    total_loss_z = 0\n",
    "    params['epoch_size'] = val_data[\"x\"].shape[0]\n",
    "    for j in range(params['epoch_size']//params['batch_size']):\n",
    "        batch_idxs = np.arange(j * params['batch_size'], (j + 1) * params['batch_size'])\n",
    "        z = torch.from_numpy(data['z'][batch_idxs]).to(torch.float32).to(device)\n",
    "        x = torch.from_numpy(data['x'][batch_idxs]).to(torch.float32).to(device)\n",
    "        dx = torch.from_numpy(data['dx'][batch_idxs]).to(torch.float32).to(device)\n",
    "        ddx = torch.from_numpy(data['ddx'][batch_idxs]).to(torch.float32).to(device)\n",
    "        x_predict = autoencoder_forward(x,params)\n",
    "        z_predict = encoder_forward(x,params)\n",
    "        dz_predict,ddz_predict = encoder_derivative(x,dx,ddx,params)\n",
    "        dx_predict,ddx_predict = decoder_derivative(z_predict,dz_predict,ddz_predict,params)\n",
    "        loss_x = torch.mean((x - x_predict)**2)\n",
    "        loss_dx = torch.mean((x - dx_predict) ** 2)\n",
    "        loss_ddx = torch.mean((x - ddx_predict) ** 2)\n",
    "        loss_z = torch.mean((z - z_predict)**2)\n",
    "        loss = params['loss_weight_x'] * loss_x \\\n",
    "               + params['loss_weight_dx'] * loss_dx \\\n",
    "               + params['loss_weight_ddx'] * loss_ddx\n",
    "        total_loss += loss\n",
    "        total_loss_z += loss_z\n",
    "        print('batch_{} --- image loss: {} --- z loss: {}'.format(j,loss,loss_z))\n",
    "    avg_loss = total_loss/(params['epoch_size']//params['batch_size'])\n",
    "    avg_loss_z = total_loss_z/(params['epoch_size']//params['batch_size'])\n",
    "    return avg_loss,avg_loss_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "824989ee-33b0-46a8-b1a2-e164e6902549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving(params):\n",
    "    PATH = os.path.join('/mnt/ssd1/stilrmy/Autoencoder-conservtive_expression/progress',params['date'],params['ver'])\n",
    "    if os.path.exists(PATH) == False:\n",
    "        os.makedirs(PATH)\n",
    "    params_names = [params['encoder_weights'],params['encoder_biases'],params['decoder_weights'],params['decoder_biases']]\n",
    "    params_names_str = ['encoder_weights','encoder_biases','decoder_weights','decoder_biases']\n",
    "    for j,param_set in enumerate(params_names):\n",
    "        for i,elements in enumerate(param_set):\n",
    "            np.save(r\"/mnt/ssd1/stilrmy/Autoencoder-conservtive_expression/progress/{}/{}/autoencoder_{}_layer{}.npy\".format(params['date'],params['ver'],params_names_str[j],i),\n",
    "                   elements.clone().detach().cpu().numpy())\n",
    "    sub_params = params.copy()\n",
    "    del sub_params['encoder_weights']\n",
    "    del sub_params['encoder_biases']\n",
    "    del sub_params['decoder_weights']\n",
    "    del sub_params['decoder_biases']\n",
    "    with open(r\"/mnt/ssd1/stilrmy/Autoencoder-conservtive_expression/progress/{}/{}/params.txt\".format(params['date'],params['ver']),'w') as file:\n",
    "        file.write(str(sub_params))\n",
    "        file.write('\\r\\t')\n",
    "        file.close()\n",
    "    print('params saved')\n",
    "    return\n",
    "\n",
    "def loading_coef(params,date,load_number,file_route,device):\n",
    "    print('loading params')\n",
    "    params_names_str = ['encoder_weights', 'encoder_biases', 'decoder_weights', 'decoder_biases']\n",
    "    for param_name in params_names_str:\n",
    "        params['{}'.format(param_name)] = []\n",
    "        for i in range(len(params['widths'])+1):\n",
    "            file_name = 'autoencoder_{}_layer{}.npy'.format(param_name,i)\n",
    "            route = os.path.join(file_route,date,load_number,file_name)\n",
    "            temp_loader = np.load(route)\n",
    "            temp_loader = torch.tensor(temp_loader).to(device)\n",
    "            temp_loader = Variable(temp_loader, requires_grad=True)\n",
    "            print(temp_loader.shape)\n",
    "            params['{}'.format(param_name)].append(temp_loader)\n",
    "    #coef = np.load(r'{}\\{}\\{}\\coef.npy'.format(file_route,date,load_number))\n",
    "    #coef = torch.Tensor(coef).to(device)\n",
    "    #coef = Variable(coef,requires_grad=True)\n",
    "    #expr = np.load(r'{}\\{}\\{}\\expr.npy'.format(file_route,date,load_number))\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5284f09f-b5f7-4d2c-8498-60064b590849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(loss_history,loss_z_history):\n",
    "    fig, a = plt.subplots(2, 1)\n",
    "    a[0].plot(loss_history)\n",
    "    a[0].set_title(\"loss\")\n",
    "    a[1].plot(loss_z_history)\n",
    "    a[1].set_title(\"z_loss\")\n",
    "    plt.subplots_adjust(hspace=1)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4933057b-96b4-4111-870c-591a95d26dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_params == True:\n",
    "    params = loading(params,load_date,load_ver,file_route,device)\n",
    "else:\n",
    "    encoder_weights,encoder_biases,decoder_weights,decoder_biases = autoencoder(2601,1,widths,device)\n",
    "    params['encoder_weights'] = encoder_weights\n",
    "    params['encoder_biases'] = encoder_biases\n",
    "    params['decoder_weights'] = decoder_weights\n",
    "    params['decoder_biases'] = decoder_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82b00fec-1118-49be-8577-86e9c658c78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 === loss: 817.2769165039062\t=== loss_z: 1.3720128536224365\n",
      "epoch: 100 === loss: 817.2557983398438\t=== loss_z: 1.3594263792037964\n",
      "epoch: 200 === loss: 817.1991577148438\t=== loss_z: 1.3641341924667358\n",
      "epoch: 300 === loss: 817.059326171875\t=== loss_z: 1.377677083015442\n",
      "epoch: 400 === loss: 816.7647705078125\t=== loss_z: 1.395790934562683\n",
      "epoch: 500 === loss: 816.2145385742188\t=== loss_z: 1.4211463928222656\n",
      "epoch: 600 === loss: 815.2804565429688\t=== loss_z: 1.4582293033599854\n",
      "epoch: 700 === loss: 813.8214721679688\t=== loss_z: 1.5135093927383423\n",
      "epoch: 800 === loss: 811.7183227539062\t=== loss_z: 1.5991562604904175\n",
      "epoch: 900 === loss: 808.926513671875\t=== loss_z: 1.7433311939239502\n",
      "epoch: 1000 === loss: 805.5582885742188\t=== loss_z: 1.9206966161727905\n",
      "epoch: 1100 === loss: 801.9605102539062\t=== loss_z: 2.0929415225982666\n",
      "epoch: 1200 === loss: 798.7465209960938\t=== loss_z: 2.2560031414031982\n",
      "epoch: 1300 === loss: 796.4766235351562\t=== loss_z: 2.346388578414917\n",
      "epoch: 1400 === loss: 794.83544921875\t=== loss_z: 2.340433120727539\n",
      "epoch: 1500 === loss: 793.392333984375\t=== loss_z: 2.304272413253784\n",
      "epoch: 1600 === loss: 792.0840454101562\t=== loss_z: 2.260934352874756\n",
      "epoch: 1700 === loss: 790.8893432617188\t=== loss_z: 2.209690809249878\n",
      "epoch: 1800 === loss: 789.7994384765625\t=== loss_z: 2.180729389190674\n",
      "epoch: 1900 === loss: 788.7990112304688\t=== loss_z: 2.1752772331237793\n",
      "epoch: 2000 === loss: 787.895263671875\t=== loss_z: 2.1961722373962402\n",
      "epoch: 2100 === loss: 787.1298828125\t=== loss_z: 2.267260789871216\n",
      "epoch: 2200 === loss: 786.5676879882812\t=== loss_z: 2.3656165599823\n",
      "epoch: 2300 === loss: 786.2116088867188\t=== loss_z: 2.4651944637298584\n",
      "epoch: 2400 === loss: 785.9412231445312\t=== loss_z: 2.545029878616333\n",
      "epoch: 2500 === loss: 785.7191772460938\t=== loss_z: 2.6102535724639893\n",
      "epoch: 2600 === loss: 785.5287475585938\t=== loss_z: 2.6231276988983154\n",
      "epoch: 2700 === loss: 785.3546752929688\t=== loss_z: 2.60509991645813\n",
      "epoch: 2800 === loss: 785.1871948242188\t=== loss_z: 2.565005302429199\n",
      "epoch: 2900 === loss: 785.0223388671875\t=== loss_z: 2.49835205078125\n",
      "epoch: 3000 === loss: 784.8601684570312\t=== loss_z: 2.4268290996551514\n",
      "epoch: 3100 === loss: 784.6937866210938\t=== loss_z: 2.4001786708831787\n",
      "epoch: 3200 === loss: 784.5160522460938\t=== loss_z: 2.416325092315674\n",
      "epoch: 3300 === loss: 784.3230590820312\t=== loss_z: 2.459562063217163\n",
      "epoch: 3400 === loss: 784.1129760742188\t=== loss_z: 2.528681993484497\n",
      "epoch: 3500 === loss: 783.8848266601562\t=== loss_z: 2.6223137378692627\n",
      "epoch: 3600 === loss: 783.6377563476562\t=== loss_z: 2.7377240657806396\n",
      "epoch: 3700 === loss: 783.3714599609375\t=== loss_z: 2.872351884841919\n",
      "epoch: 3800 === loss: 783.0864868164062\t=== loss_z: 3.0244252681732178\n",
      "epoch: 3900 === loss: 782.7836303710938\t=== loss_z: 3.1923282146453857\n",
      "epoch: 4000 === loss: 782.4647827148438\t=== loss_z: 3.3732166290283203\n",
      "epoch: 4100 === loss: 782.1310424804688\t=== loss_z: 3.56416392326355\n",
      "epoch: 4200 === loss: 781.7844848632812\t=== loss_z: 3.760927677154541\n",
      "epoch: 4300 === loss: 781.4267578125\t=== loss_z: 3.957822561264038\n",
      "epoch: 4400 === loss: 781.0601806640625\t=== loss_z: 4.148644924163818\n",
      "epoch: 4500 === loss: 780.68603515625\t=== loss_z: 4.326219081878662\n",
      "epoch: 4600 === loss: 780.3062133789062\t=== loss_z: 4.482620716094971\n",
      "epoch: 4700 === loss: 779.9215087890625\t=== loss_z: 4.6105780601501465\n",
      "epoch: 4800 === loss: 779.5322265625\t=== loss_z: 4.702199459075928\n",
      "epoch: 4900 === loss: 779.1386108398438\t=== loss_z: 4.75617790222168\n",
      "epoch: 5000 === loss: 778.7416381835938\t=== loss_z: 4.778355598449707\n",
      "epoch: 5100 === loss: 778.3414916992188\t=== loss_z: 4.772826671600342\n",
      "epoch: 5200 === loss: 777.9367065429688\t=== loss_z: 4.741944789886475\n",
      "epoch: 5300 === loss: 777.525634765625\t=== loss_z: 4.6894426345825195\n",
      "epoch: 5400 === loss: 777.1076049804688\t=== loss_z: 4.623279571533203\n",
      "epoch: 5500 === loss: 776.681640625\t=== loss_z: 4.552270412445068\n",
      "epoch: 5600 === loss: 776.2472534179688\t=== loss_z: 4.482038497924805\n",
      "epoch: 5700 === loss: 775.8038940429688\t=== loss_z: 4.418298244476318\n",
      "epoch: 5800 === loss: 775.3507690429688\t=== loss_z: 4.366632461547852\n",
      "epoch: 5900 === loss: 774.8875732421875\t=== loss_z: 4.331117153167725\n",
      "epoch: 6000 === loss: 774.4148559570312\t=== loss_z: 4.3147430419921875\n",
      "epoch: 6100 === loss: 773.9353637695312\t=== loss_z: 4.321593284606934\n",
      "epoch: 6200 === loss: 773.453369140625\t=== loss_z: 4.352750301361084\n",
      "epoch: 6300 === loss: 772.9736938476562\t=== loss_z: 4.405885696411133\n",
      "epoch: 6400 === loss: 772.5009155273438\t=== loss_z: 4.476717948913574\n",
      "epoch: 6500 === loss: 772.0394897460938\t=== loss_z: 4.559915542602539\n",
      "epoch: 6600 === loss: 771.5929565429688\t=== loss_z: 4.652507781982422\n",
      "epoch: 6700 === loss: 771.1636352539062\t=== loss_z: 4.751471519470215\n",
      "epoch: 6800 === loss: 770.7509765625\t=== loss_z: 4.8534932136535645\n",
      "epoch: 6900 === loss: 770.353515625\t=== loss_z: 4.957118988037109\n",
      "epoch: 7000 === loss: 769.9697265625\t=== loss_z: 5.061434745788574\n",
      "epoch: 7100 === loss: 769.5983276367188\t=== loss_z: 5.1678900718688965\n",
      "epoch: 7200 === loss: 769.2382202148438\t=== loss_z: 5.2763800621032715\n",
      "epoch: 7300 === loss: 768.8878784179688\t=== loss_z: 5.386756420135498\n",
      "epoch: 7400 === loss: 768.5459594726562\t=== loss_z: 5.502406597137451\n",
      "epoch: 7500 === loss: 768.2096557617188\t=== loss_z: 5.626735210418701\n",
      "epoch: 7600 === loss: 767.876220703125\t=== loss_z: 5.761613368988037\n",
      "epoch: 7700 === loss: 767.5433349609375\t=== loss_z: 5.909811019897461\n",
      "epoch: 7800 === loss: 767.2092895507812\t=== loss_z: 6.0680155754089355\n",
      "epoch: 7900 === loss: 766.8739624023438\t=== loss_z: 6.216169834136963\n",
      "epoch: 8000 === loss: 766.5362548828125\t=== loss_z: 6.334874629974365\n",
      "epoch: 8100 === loss: 766.1943969726562\t=== loss_z: 6.4330973625183105\n",
      "epoch: 8200 === loss: 765.8465576171875\t=== loss_z: 6.521078586578369\n",
      "epoch: 8300 === loss: 765.4913330078125\t=== loss_z: 6.604229927062988\n",
      "epoch: 8400 === loss: 765.1280517578125\t=== loss_z: 6.685972690582275\n",
      "epoch: 8500 === loss: 764.7564697265625\t=== loss_z: 6.768706798553467\n",
      "epoch: 8600 === loss: 764.3773803710938\t=== loss_z: 6.852276802062988\n",
      "epoch: 8700 === loss: 763.9913940429688\t=== loss_z: 6.928321361541748\n",
      "epoch: 8800 === loss: 763.5975341796875\t=== loss_z: 6.9959330558776855\n",
      "epoch: 8900 === loss: 763.1964111328125\t=== loss_z: 7.057254791259766\n",
      "epoch: 9000 === loss: 762.7890625\t=== loss_z: 7.1135454177856445\n",
      "epoch: 9100 === loss: 762.3764038085938\t=== loss_z: 7.1669745445251465\n",
      "epoch: 9200 === loss: 761.9600830078125\t=== loss_z: 7.217713356018066\n",
      "epoch: 9300 === loss: 761.5411987304688\t=== loss_z: 7.265455722808838\n",
      "epoch: 9400 === loss: 761.121337890625\t=== loss_z: 7.3119330406188965\n",
      "epoch: 9500 === loss: 760.7023315429688\t=== loss_z: 7.355922222137451\n",
      "epoch: 9600 === loss: 760.286376953125\t=== loss_z: 7.39376974105835\n",
      "epoch: 9700 === loss: 759.87548828125\t=== loss_z: 7.4237895011901855\n",
      "epoch: 9800 === loss: 759.4716186523438\t=== loss_z: 7.447560787200928\n",
      "epoch: 9900 === loss: 759.075927734375\t=== loss_z: 7.464775085449219\n",
      "epoch: 10000 === loss: 758.6890869140625\t=== loss_z: 7.476507663726807\n",
      "epoch: 10100 === loss: 758.311767578125\t=== loss_z: 7.484932899475098\n",
      "epoch: 10200 === loss: 757.9439697265625\t=== loss_z: 7.489895820617676\n",
      "epoch: 10300 === loss: 757.5856323242188\t=== loss_z: 7.490752696990967\n",
      "epoch: 10400 === loss: 757.236083984375\t=== loss_z: 7.488519191741943\n",
      "epoch: 10500 === loss: 756.8947143554688\t=== loss_z: 7.483316898345947\n",
      "epoch: 10600 === loss: 756.560546875\t=== loss_z: 7.4752349853515625\n",
      "epoch: 10700 === loss: 756.2332153320312\t=== loss_z: 7.4650115966796875\n",
      "epoch: 10800 === loss: 755.9115600585938\t=== loss_z: 7.453006744384766\n",
      "epoch: 10900 === loss: 755.594970703125\t=== loss_z: 7.4392924308776855\n",
      "epoch: 11000 === loss: 755.282470703125\t=== loss_z: 7.424318790435791\n",
      "epoch: 11100 === loss: 754.9737548828125\t=== loss_z: 7.407688140869141\n",
      "epoch: 11200 === loss: 754.668212890625\t=== loss_z: 7.391049861907959\n",
      "epoch: 11300 === loss: 754.3656616210938\t=== loss_z: 7.378261089324951\n",
      "epoch: 11400 === loss: 754.0651245117188\t=== loss_z: 7.366517066955566\n",
      "epoch: 11500 === loss: 753.7665405273438\t=== loss_z: 7.356486797332764\n",
      "epoch: 11600 === loss: 753.4694213867188\t=== loss_z: 7.3459014892578125\n",
      "epoch: 11700 === loss: 753.17333984375\t=== loss_z: 7.336162090301514\n",
      "epoch: 11800 === loss: 752.8780517578125\t=== loss_z: 7.326706886291504\n",
      "epoch: 11900 === loss: 752.5835571289062\t=== loss_z: 7.316832065582275\n",
      "epoch: 12000 === loss: 752.2899780273438\t=== loss_z: 7.308391094207764\n",
      "epoch: 12100 === loss: 751.9977416992188\t=== loss_z: 7.301194190979004\n",
      "epoch: 12200 === loss: 751.7071533203125\t=== loss_z: 7.295283794403076\n",
      "epoch: 12300 === loss: 751.4186401367188\t=== loss_z: 7.288687229156494\n",
      "epoch: 12400 === loss: 751.1317749023438\t=== loss_z: 7.282077789306641\n",
      "epoch: 12500 === loss: 750.8471069335938\t=== loss_z: 7.273124694824219\n",
      "epoch: 12600 === loss: 750.564697265625\t=== loss_z: 7.261830806732178\n",
      "epoch: 12700 === loss: 750.28466796875\t=== loss_z: 7.24853515625\n",
      "epoch: 12800 === loss: 750.0074462890625\t=== loss_z: 7.234603404998779\n",
      "epoch: 12900 === loss: 749.732421875\t=== loss_z: 7.220041751861572\n",
      "epoch: 13000 === loss: 749.45947265625\t=== loss_z: 7.203287601470947\n",
      "epoch: 13100 === loss: 749.1880493164062\t=== loss_z: 7.187021732330322\n",
      "epoch: 13200 === loss: 748.9182739257812\t=== loss_z: 7.17254638671875\n",
      "epoch: 13300 === loss: 748.6499633789062\t=== loss_z: 7.1597185134887695\n",
      "epoch: 13400 === loss: 748.3826904296875\t=== loss_z: 7.148252964019775\n",
      "epoch: 13500 === loss: 748.1167602539062\t=== loss_z: 7.138868808746338\n",
      "epoch: 13600 === loss: 747.8519287109375\t=== loss_z: 7.132354259490967\n",
      "epoch: 13700 === loss: 747.5880737304688\t=== loss_z: 7.129225254058838\n",
      "epoch: 13800 === loss: 747.3253173828125\t=== loss_z: 7.129494667053223\n",
      "epoch: 13900 === loss: 747.0629272460938\t=== loss_z: 7.1342902183532715\n",
      "epoch: 14000 === loss: 746.80078125\t=== loss_z: 7.146650791168213\n",
      "epoch: 14100 === loss: 746.5384521484375\t=== loss_z: 7.163816928863525\n",
      "epoch: 14200 === loss: 746.2767944335938\t=== loss_z: 7.178493499755859\n",
      "epoch: 14300 === loss: 746.0162963867188\t=== loss_z: 7.193004608154297\n",
      "epoch: 14400 === loss: 745.7569580078125\t=== loss_z: 7.209810733795166\n",
      "epoch: 14500 === loss: 745.4983520507812\t=== loss_z: 7.226574897766113\n",
      "epoch: 14600 === loss: 745.2409057617188\t=== loss_z: 7.239413738250732\n",
      "epoch: 14700 === loss: 744.9848022460938\t=== loss_z: 7.247441291809082\n",
      "epoch: 14800 === loss: 744.7299194335938\t=== loss_z: 7.250059604644775\n",
      "epoch: 14900 === loss: 744.4762573242188\t=== loss_z: 7.24764347076416\n",
      "epoch: 15000 === loss: 744.223876953125\t=== loss_z: 7.241416931152344\n",
      "epoch: 15100 === loss: 743.972412109375\t=== loss_z: 7.231905460357666\n",
      "epoch: 15200 === loss: 743.7223510742188\t=== loss_z: 7.218934535980225\n",
      "epoch: 15300 === loss: 743.4736328125\t=== loss_z: 7.202731609344482\n",
      "epoch: 15400 === loss: 743.2263793945312\t=== loss_z: 7.182866096496582\n",
      "epoch: 15500 === loss: 742.9807739257812\t=== loss_z: 7.161964416503906\n",
      "epoch: 15600 === loss: 742.7367553710938\t=== loss_z: 7.1406121253967285\n",
      "epoch: 15700 === loss: 742.4943237304688\t=== loss_z: 7.1187639236450195\n",
      "epoch: 15800 === loss: 742.2535400390625\t=== loss_z: 7.097675323486328\n",
      "epoch: 15900 === loss: 742.0140991210938\t=== loss_z: 7.076758861541748\n",
      "epoch: 16000 === loss: 741.7758178710938\t=== loss_z: 7.055649757385254\n",
      "epoch: 16100 === loss: 741.537841796875\t=== loss_z: 7.033847332000732\n",
      "epoch: 16200 === loss: 741.2999267578125\t=== loss_z: 7.012649059295654\n",
      "epoch: 16300 === loss: 741.0609741210938\t=== loss_z: 6.9919962882995605\n",
      "epoch: 16400 === loss: 740.8202514648438\t=== loss_z: 6.973655700683594\n",
      "epoch: 16500 === loss: 740.57861328125\t=== loss_z: 6.962445259094238\n",
      "epoch: 16600 === loss: 740.3375244140625\t=== loss_z: 6.959238529205322\n",
      "epoch: 16700 === loss: 740.0968627929688\t=== loss_z: 6.957482814788818\n",
      "epoch: 16800 === loss: 739.8568115234375\t=== loss_z: 6.956087589263916\n",
      "epoch: 16900 === loss: 739.6171264648438\t=== loss_z: 6.954564571380615\n",
      "epoch: 17000 === loss: 739.3776245117188\t=== loss_z: 6.952113628387451\n",
      "epoch: 17100 === loss: 739.1383056640625\t=== loss_z: 6.9493842124938965\n",
      "epoch: 17200 === loss: 738.8991088867188\t=== loss_z: 6.946944713592529\n",
      "epoch: 17300 === loss: 738.66015625\t=== loss_z: 6.944879055023193\n",
      "epoch: 17400 === loss: 738.4215698242188\t=== loss_z: 6.943215370178223\n",
      "epoch: 17500 === loss: 738.18359375\t=== loss_z: 6.942806243896484\n",
      "epoch: 17600 === loss: 737.9461669921875\t=== loss_z: 6.944207191467285\n",
      "epoch: 17700 === loss: 737.7091674804688\t=== loss_z: 6.947337627410889\n",
      "epoch: 17800 === loss: 737.4725952148438\t=== loss_z: 6.952261447906494\n",
      "epoch: 17900 === loss: 737.2360229492188\t=== loss_z: 6.960190773010254\n",
      "epoch: 18000 === loss: 736.9995727539062\t=== loss_z: 6.971405029296875\n",
      "epoch: 18100 === loss: 736.7630004882812\t=== loss_z: 6.983762264251709\n",
      "epoch: 18200 === loss: 736.5274658203125\t=== loss_z: 6.99224853515625\n",
      "epoch: 18300 === loss: 736.2940673828125\t=== loss_z: 6.995357036590576\n",
      "epoch: 18400 === loss: 736.0630493164062\t=== loss_z: 6.994382381439209\n",
      "epoch: 18500 === loss: 735.8342895507812\t=== loss_z: 6.988595008850098\n",
      "epoch: 18600 === loss: 735.60791015625\t=== loss_z: 6.978403568267822\n",
      "epoch: 18700 === loss: 735.3836669921875\t=== loss_z: 6.9638352394104\n",
      "epoch: 18800 === loss: 735.1614379882812\t=== loss_z: 6.944697856903076\n",
      "epoch: 18900 === loss: 734.941162109375\t=== loss_z: 6.921279430389404\n",
      "epoch: 19000 === loss: 734.7225952148438\t=== loss_z: 6.89328145980835\n",
      "epoch: 19100 === loss: 734.505859375\t=== loss_z: 6.862736701965332\n",
      "epoch: 19200 === loss: 734.2908935546875\t=== loss_z: 6.8301682472229\n",
      "epoch: 19300 === loss: 734.0775146484375\t=== loss_z: 6.796708583831787\n",
      "epoch: 19400 === loss: 733.8660888671875\t=== loss_z: 6.762645721435547\n",
      "epoch: 19500 === loss: 733.6563720703125\t=== loss_z: 6.728519439697266\n",
      "epoch: 19600 === loss: 733.448486328125\t=== loss_z: 6.694462776184082\n",
      "epoch: 19700 === loss: 733.2426147460938\t=== loss_z: 6.659976482391357\n",
      "epoch: 19800 === loss: 733.0385131835938\t=== loss_z: 6.625232696533203\n",
      "epoch: 19900 === loss: 732.8361206054688\t=== loss_z: 6.590315341949463\n",
      "epoch: 20000 === loss: 732.6356811523438\t=== loss_z: 6.555300235748291\n",
      "epoch: 20100 === loss: 732.43701171875\t=== loss_z: 6.520352840423584\n",
      "epoch: 20200 === loss: 732.2401123046875\t=== loss_z: 6.485605716705322\n",
      "epoch: 20300 === loss: 732.044677734375\t=== loss_z: 6.451366424560547\n",
      "epoch: 20400 === loss: 731.8507690429688\t=== loss_z: 6.41763162612915\n",
      "epoch: 20500 === loss: 731.6578979492188\t=== loss_z: 6.384219169616699\n",
      "epoch: 20600 === loss: 731.466064453125\t=== loss_z: 6.350870132446289\n",
      "epoch: 20700 === loss: 731.27490234375\t=== loss_z: 6.317445278167725\n",
      "epoch: 20800 === loss: 731.0842895507812\t=== loss_z: 6.284852027893066\n",
      "epoch: 20900 === loss: 730.8937377929688\t=== loss_z: 6.251829147338867\n",
      "epoch: 21000 === loss: 730.7033081054688\t=== loss_z: 6.219583034515381\n",
      "epoch: 21100 === loss: 730.5128784179688\t=== loss_z: 6.188350677490234\n",
      "epoch: 21200 === loss: 730.3226928710938\t=== loss_z: 6.158867835998535\n",
      "epoch: 21300 === loss: 730.1334228515625\t=== loss_z: 6.129876136779785\n",
      "epoch: 21400 === loss: 729.9449462890625\t=== loss_z: 6.101417064666748\n",
      "epoch: 21500 === loss: 729.7574462890625\t=== loss_z: 6.07410192489624\n",
      "epoch: 21600 === loss: 729.5706176757812\t=== loss_z: 6.048285961151123\n",
      "epoch: 21700 === loss: 729.3843994140625\t=== loss_z: 6.024001598358154\n",
      "epoch: 21800 === loss: 729.1986083984375\t=== loss_z: 6.001107215881348\n",
      "epoch: 21900 === loss: 729.0128784179688\t=== loss_z: 5.979613780975342\n",
      "epoch: 22000 === loss: 728.8272094726562\t=== loss_z: 5.95937967300415\n",
      "epoch: 22100 === loss: 728.6415405273438\t=== loss_z: 5.94026517868042\n",
      "epoch: 22200 === loss: 728.4555053710938\t=== loss_z: 5.922010898590088\n",
      "epoch: 22300 === loss: 728.2689819335938\t=== loss_z: 5.904473304748535\n",
      "epoch: 22400 === loss: 728.0819702148438\t=== loss_z: 5.887567520141602\n",
      "epoch: 22500 === loss: 727.8942260742188\t=== loss_z: 5.870747089385986\n",
      "epoch: 22600 === loss: 727.70556640625\t=== loss_z: 5.853891849517822\n",
      "epoch: 22700 === loss: 727.5164184570312\t=== loss_z: 5.838430404663086\n",
      "epoch: 22800 === loss: 727.32666015625\t=== loss_z: 5.823997497558594\n",
      "epoch: 22900 === loss: 727.136474609375\t=== loss_z: 5.810248374938965\n",
      "epoch: 23000 === loss: 726.9456176757812\t=== loss_z: 5.7972092628479\n",
      "epoch: 23100 === loss: 726.754150390625\t=== loss_z: 5.784890174865723\n",
      "epoch: 23200 === loss: 726.5623779296875\t=== loss_z: 5.772195339202881\n",
      "epoch: 23300 === loss: 726.3700561523438\t=== loss_z: 5.759089946746826\n",
      "epoch: 23400 === loss: 726.1771850585938\t=== loss_z: 5.745522499084473\n",
      "epoch: 23500 === loss: 725.9838256835938\t=== loss_z: 5.730865001678467\n",
      "epoch: 23600 === loss: 725.7901611328125\t=== loss_z: 5.714073657989502\n",
      "epoch: 23700 === loss: 725.5958251953125\t=== loss_z: 5.695870876312256\n",
      "epoch: 23800 === loss: 725.4007568359375\t=== loss_z: 5.676591396331787\n",
      "epoch: 23900 === loss: 725.2050170898438\t=== loss_z: 5.656949520111084\n",
      "epoch: 24000 === loss: 725.0086059570312\t=== loss_z: 5.636946678161621\n",
      "epoch: 24100 === loss: 724.8114013671875\t=== loss_z: 5.616663932800293\n",
      "epoch: 24200 === loss: 724.61376953125\t=== loss_z: 5.59554386138916\n",
      "epoch: 24300 === loss: 724.4158935546875\t=== loss_z: 5.574038982391357\n",
      "epoch: 24400 === loss: 724.2179565429688\t=== loss_z: 5.552365779876709\n",
      "epoch: 24500 === loss: 724.0197143554688\t=== loss_z: 5.5302863121032715\n",
      "epoch: 24600 === loss: 723.8214721679688\t=== loss_z: 5.507805347442627\n",
      "epoch: 24700 === loss: 723.6229858398438\t=== loss_z: 5.484277725219727\n",
      "epoch: 24800 === loss: 723.4247436523438\t=== loss_z: 5.460441589355469\n",
      "epoch: 24900 === loss: 723.2265014648438\t=== loss_z: 5.43671178817749\n",
      "epoch: 25000 === loss: 723.0282592773438\t=== loss_z: 5.413012981414795\n",
      "epoch: 25100 === loss: 722.830078125\t=== loss_z: 5.389596462249756\n",
      "epoch: 25200 === loss: 722.6319580078125\t=== loss_z: 5.366753578186035\n",
      "epoch: 25300 === loss: 722.433837890625\t=== loss_z: 5.3445258140563965\n",
      "epoch: 25400 === loss: 722.2360229492188\t=== loss_z: 5.322706699371338\n",
      "epoch: 25500 === loss: 722.0380249023438\t=== loss_z: 5.301101207733154\n",
      "epoch: 25600 === loss: 721.84033203125\t=== loss_z: 5.279708385467529\n",
      "epoch: 25700 === loss: 721.6423950195312\t=== loss_z: 5.258466720581055\n",
      "epoch: 25800 === loss: 721.4445190429688\t=== loss_z: 5.237435340881348\n",
      "epoch: 25900 === loss: 721.2467651367188\t=== loss_z: 5.2164835929870605\n",
      "epoch: 26000 === loss: 721.048828125\t=== loss_z: 5.195458889007568\n",
      "epoch: 26100 === loss: 720.8507690429688\t=== loss_z: 5.174282073974609\n",
      "epoch: 26200 === loss: 720.6527099609375\t=== loss_z: 5.153079509735107\n",
      "epoch: 26300 === loss: 720.4544677734375\t=== loss_z: 5.131833076477051\n",
      "epoch: 26400 === loss: 720.2562866210938\t=== loss_z: 5.110665798187256\n",
      "epoch: 26500 === loss: 720.0580444335938\t=== loss_z: 5.089231491088867\n",
      "epoch: 26600 === loss: 719.85986328125\t=== loss_z: 5.067653179168701\n",
      "epoch: 26700 === loss: 719.6618041992188\t=== loss_z: 5.046396255493164\n",
      "epoch: 26800 === loss: 719.4639282226562\t=== loss_z: 5.02567195892334\n",
      "epoch: 26900 === loss: 719.266357421875\t=== loss_z: 5.006048202514648\n",
      "epoch: 27000 === loss: 719.0692749023438\t=== loss_z: 4.987537860870361\n",
      "epoch: 27100 === loss: 718.8724975585938\t=== loss_z: 4.969838619232178\n",
      "epoch: 27200 === loss: 718.676025390625\t=== loss_z: 4.9530930519104\n",
      "epoch: 27300 === loss: 718.4798583984375\t=== loss_z: 4.937313079833984\n",
      "epoch: 27400 === loss: 718.283935546875\t=== loss_z: 4.921657085418701\n",
      "epoch: 27500 === loss: 718.0883178710938\t=== loss_z: 4.906373023986816\n",
      "epoch: 27600 === loss: 717.892578125\t=== loss_z: 4.891342639923096\n",
      "epoch: 27700 === loss: 717.6970825195312\t=== loss_z: 4.875574588775635\n",
      "epoch: 27800 === loss: 717.5017700195312\t=== loss_z: 4.860263347625732\n",
      "epoch: 27900 === loss: 717.3067626953125\t=== loss_z: 4.845011234283447\n",
      "epoch: 28000 === loss: 717.1118774414062\t=== loss_z: 4.829872131347656\n",
      "epoch: 28100 === loss: 716.9175415039062\t=== loss_z: 4.814720153808594\n",
      "epoch: 28200 === loss: 716.7240600585938\t=== loss_z: 4.799633026123047\n",
      "epoch: 28300 === loss: 716.5314331054688\t=== loss_z: 4.785282135009766\n",
      "epoch: 28400 === loss: 716.33984375\t=== loss_z: 4.7711920738220215\n",
      "epoch: 28500 === loss: 716.1492919921875\t=== loss_z: 4.757441997528076\n",
      "epoch: 28600 === loss: 715.9594116210938\t=== loss_z: 4.744338512420654\n",
      "epoch: 28700 === loss: 715.7705078125\t=== loss_z: 4.731855392456055\n",
      "epoch: 28800 === loss: 715.5822143554688\t=== loss_z: 4.720059394836426\n",
      "epoch: 28900 === loss: 715.3948364257812\t=== loss_z: 4.7090535163879395\n",
      "epoch: 29000 === loss: 715.2079467773438\t=== loss_z: 4.698327541351318\n",
      "epoch: 29100 === loss: 715.021728515625\t=== loss_z: 4.687990665435791\n",
      "epoch: 29200 === loss: 714.836181640625\t=== loss_z: 4.678109645843506\n",
      "epoch: 29300 === loss: 714.6512451171875\t=== loss_z: 4.668565273284912\n",
      "epoch: 29400 === loss: 714.4669799804688\t=== loss_z: 4.659388542175293\n",
      "epoch: 29500 === loss: 714.2835083007812\t=== loss_z: 4.650373935699463\n",
      "epoch: 29600 === loss: 714.1012573242188\t=== loss_z: 4.6408867835998535\n",
      "epoch: 29700 === loss: 713.920166015625\t=== loss_z: 4.6322021484375\n",
      "epoch: 29800 === loss: 713.74072265625\t=== loss_z: 4.623891830444336\n",
      "epoch: 29900 === loss: 713.5628051757812\t=== loss_z: 4.615663528442383\n",
      "epoch: 30000 === loss: 713.3866577148438\t=== loss_z: 4.607877731323242\n",
      "epoch: 30100 === loss: 713.212646484375\t=== loss_z: 4.600327968597412\n",
      "epoch: 30200 === loss: 713.0407104492188\t=== loss_z: 4.5926899909973145\n",
      "epoch: 30300 === loss: 712.8712158203125\t=== loss_z: 4.584939002990723\n",
      "epoch: 30400 === loss: 712.7037963867188\t=== loss_z: 4.577468395233154\n",
      "epoch: 30500 === loss: 712.5385131835938\t=== loss_z: 4.570105075836182\n",
      "epoch: 30600 === loss: 712.3750610351562\t=== loss_z: 4.562582015991211\n",
      "epoch: 30700 === loss: 712.2134399414062\t=== loss_z: 4.555139064788818\n",
      "epoch: 30800 === loss: 712.0538330078125\t=== loss_z: 4.547853469848633\n",
      "epoch: 30900 === loss: 711.8958740234375\t=== loss_z: 4.540539741516113\n",
      "epoch: 31000 === loss: 711.739501953125\t=== loss_z: 4.5331549644470215\n",
      "epoch: 31100 === loss: 711.58447265625\t=== loss_z: 4.52597713470459\n",
      "epoch: 31200 === loss: 711.4309692382812\t=== loss_z: 4.5191168785095215\n",
      "epoch: 31300 === loss: 711.2787475585938\t=== loss_z: 4.512589931488037\n",
      "epoch: 31400 === loss: 711.1279296875\t=== loss_z: 4.5063581466674805\n",
      "epoch: 31500 === loss: 710.9784545898438\t=== loss_z: 4.499991416931152\n",
      "epoch: 31600 === loss: 710.8303833007812\t=== loss_z: 4.493765830993652\n",
      "epoch: 31700 === loss: 710.683837890625\t=== loss_z: 4.487666606903076\n",
      "epoch: 31800 === loss: 710.5384521484375\t=== loss_z: 4.481723785400391\n",
      "epoch: 31900 === loss: 710.3944091796875\t=== loss_z: 4.475748062133789\n",
      "epoch: 32000 === loss: 710.2517700195312\t=== loss_z: 4.469663143157959\n",
      "epoch: 32100 === loss: 710.1107177734375\t=== loss_z: 4.463440895080566\n",
      "epoch: 32200 === loss: 709.9710083007812\t=== loss_z: 4.4571685791015625\n",
      "epoch: 32300 === loss: 709.8329467773438\t=== loss_z: 4.450717926025391\n",
      "epoch: 32400 === loss: 709.6964721679688\t=== loss_z: 4.443929672241211\n",
      "epoch: 32500 === loss: 709.5616455078125\t=== loss_z: 4.436976909637451\n",
      "epoch: 32600 === loss: 709.4283447265625\t=== loss_z: 4.430013179779053\n",
      "epoch: 32700 === loss: 709.2968139648438\t=== loss_z: 4.4229817390441895\n",
      "epoch: 32800 === loss: 709.1668701171875\t=== loss_z: 4.415848731994629\n",
      "epoch: 32900 === loss: 709.0382690429688\t=== loss_z: 4.4086689949035645\n",
      "epoch: 33000 === loss: 708.9114379882812\t=== loss_z: 4.401498317718506\n",
      "epoch: 33100 === loss: 708.7863159179688\t=== loss_z: 4.394290924072266\n",
      "epoch: 33200 === loss: 708.66259765625\t=== loss_z: 4.386910915374756\n",
      "epoch: 33300 === loss: 708.5403442382812\t=== loss_z: 4.379359722137451\n",
      "epoch: 33400 === loss: 708.4197998046875\t=== loss_z: 4.3717241287231445\n",
      "epoch: 33500 === loss: 708.3007202148438\t=== loss_z: 4.363956451416016\n",
      "epoch: 33600 === loss: 708.18310546875\t=== loss_z: 4.3561835289001465\n",
      "epoch: 33700 === loss: 708.0670776367188\t=== loss_z: 4.348420143127441\n",
      "epoch: 33800 === loss: 707.9523315429688\t=== loss_z: 4.340707302093506\n",
      "epoch: 33900 === loss: 707.8388671875\t=== loss_z: 4.333070278167725\n",
      "epoch: 34000 === loss: 707.7267456054688\t=== loss_z: 4.325519561767578\n",
      "epoch: 34100 === loss: 707.6159057617188\t=== loss_z: 4.318054676055908\n",
      "epoch: 34200 === loss: 707.5062866210938\t=== loss_z: 4.310628890991211\n",
      "epoch: 34300 === loss: 707.3978271484375\t=== loss_z: 4.303248405456543\n",
      "epoch: 34400 === loss: 707.2904663085938\t=== loss_z: 4.295918941497803\n",
      "epoch: 34500 === loss: 707.1842041015625\t=== loss_z: 4.28864860534668\n",
      "epoch: 34600 === loss: 707.0787963867188\t=== loss_z: 4.281470775604248\n",
      "epoch: 34700 === loss: 706.9744873046875\t=== loss_z: 4.274445533752441\n",
      "epoch: 34800 === loss: 706.8707885742188\t=== loss_z: 4.267645359039307\n",
      "epoch: 34900 === loss: 706.7679443359375\t=== loss_z: 4.260721683502197\n",
      "epoch: 35000 === loss: 706.6655883789062\t=== loss_z: 4.253381252288818\n",
      "epoch: 35100 === loss: 706.5638427734375\t=== loss_z: 4.246417045593262\n",
      "epoch: 35200 === loss: 706.4624633789062\t=== loss_z: 4.239362716674805\n",
      "epoch: 35300 === loss: 706.3617553710938\t=== loss_z: 4.231945514678955\n",
      "epoch: 35400 === loss: 706.261474609375\t=== loss_z: 4.224177837371826\n",
      "epoch: 35500 === loss: 706.1619262695312\t=== loss_z: 4.216203212738037\n",
      "epoch: 35600 === loss: 706.0628662109375\t=== loss_z: 4.207989692687988\n",
      "epoch: 35700 === loss: 705.9642944335938\t=== loss_z: 4.199524402618408\n",
      "epoch: 35800 === loss: 705.8663940429688\t=== loss_z: 4.191489219665527\n",
      "epoch: 35900 === loss: 705.7691650390625\t=== loss_z: 4.183683395385742\n",
      "epoch: 36000 === loss: 705.6725463867188\t=== loss_z: 4.176064491271973\n",
      "epoch: 36100 === loss: 705.5767211914062\t=== loss_z: 4.168652057647705\n",
      "epoch: 36200 === loss: 705.4816284179688\t=== loss_z: 4.161410808563232\n",
      "epoch: 36300 === loss: 705.3871459960938\t=== loss_z: 4.154383182525635\n",
      "epoch: 36400 === loss: 705.2936401367188\t=== loss_z: 4.147623062133789\n",
      "epoch: 36500 === loss: 705.2007446289062\t=== loss_z: 4.141173839569092\n",
      "epoch: 36600 === loss: 705.1088256835938\t=== loss_z: 4.134990215301514\n",
      "epoch: 36700 === loss: 705.0176391601562\t=== loss_z: 4.129067897796631\n",
      "epoch: 36800 === loss: 704.9273071289062\t=== loss_z: 4.123342514038086\n",
      "epoch: 36900 === loss: 704.8377685546875\t=== loss_z: 4.117766857147217\n",
      "epoch: 37000 === loss: 704.7492065429688\t=== loss_z: 4.1123576164245605\n",
      "epoch: 37100 === loss: 704.6615600585938\t=== loss_z: 4.106947422027588\n",
      "epoch: 37200 === loss: 704.5747680664062\t=== loss_z: 4.101545810699463\n",
      "epoch: 37300 === loss: 704.4889526367188\t=== loss_z: 4.096199035644531\n",
      "epoch: 37400 === loss: 704.4042358398438\t=== loss_z: 4.090928554534912\n",
      "epoch: 37500 === loss: 704.3204345703125\t=== loss_z: 4.085696697235107\n",
      "epoch: 37600 === loss: 704.2377319335938\t=== loss_z: 4.080471992492676\n",
      "epoch: 37700 === loss: 704.1561279296875\t=== loss_z: 4.075246810913086\n",
      "epoch: 37800 === loss: 704.0753784179688\t=== loss_z: 4.06995153427124\n",
      "epoch: 37900 === loss: 703.9955444335938\t=== loss_z: 4.06456184387207\n",
      "epoch: 38000 === loss: 703.9164428710938\t=== loss_z: 4.0591959953308105\n",
      "epoch: 38100 === loss: 703.8380737304688\t=== loss_z: 4.053934097290039\n",
      "epoch: 38200 === loss: 703.7606201171875\t=== loss_z: 4.04862117767334\n",
      "epoch: 38300 === loss: 703.6837768554688\t=== loss_z: 4.043262004852295\n",
      "epoch: 38400 === loss: 703.6078491210938\t=== loss_z: 4.0377888679504395\n",
      "epoch: 38500 === loss: 703.5325317382812\t=== loss_z: 4.032063007354736\n",
      "epoch: 38600 === loss: 703.4580078125\t=== loss_z: 4.026231288909912\n",
      "epoch: 38700 === loss: 703.38427734375\t=== loss_z: 4.020386695861816\n",
      "epoch: 38800 === loss: 703.3110961914062\t=== loss_z: 4.014566421508789\n",
      "epoch: 38900 === loss: 703.2387084960938\t=== loss_z: 4.0087809562683105\n",
      "epoch: 39000 === loss: 703.1669921875\t=== loss_z: 4.003028869628906\n",
      "epoch: 39100 === loss: 703.0956420898438\t=== loss_z: 3.997316837310791\n",
      "epoch: 39200 === loss: 703.0250244140625\t=== loss_z: 3.991727590560913\n",
      "epoch: 39300 === loss: 702.954833984375\t=== loss_z: 3.9862465858459473\n",
      "epoch: 39400 === loss: 702.8853149414062\t=== loss_z: 3.9807896614074707\n",
      "epoch: 39500 === loss: 702.816162109375\t=== loss_z: 3.97532057762146\n",
      "epoch: 39600 === loss: 702.7474975585938\t=== loss_z: 3.9698047637939453\n",
      "epoch: 39700 === loss: 702.67919921875\t=== loss_z: 3.9642486572265625\n",
      "epoch: 39800 === loss: 702.6112670898438\t=== loss_z: 3.9585723876953125\n",
      "epoch: 39900 === loss: 702.543701171875\t=== loss_z: 3.9527783393859863\n",
      "batch_0 --- image loss: 6.587894916534424 --- z loss: 0.838371753692627\n",
      "batch_1 --- image loss: 32.18465042114258 --- z loss: 2.664483070373535\n",
      "batch_2 --- image loss: 151.61581420898438 --- z loss: 6.2136664390563965\n",
      "batch_3 --- image loss: 15.872432708740234 --- z loss: 1.5601093769073486\n",
      "batch_4 --- image loss: 240.53753662109375 --- z loss: 6.566067218780518\n",
      "batch_5 --- image loss: 0.9813748002052307 --- z loss: 0.35394856333732605\n",
      "batch_6 --- image loss: 4.344017028808594 --- z loss: 0.6789344549179077\n",
      "batch_7 --- image loss: 29.621047973632812 --- z loss: 2.991488218307495\n",
      "batch_8 --- image loss: 10.445427894592285 --- z loss: 1.017269253730774\n",
      "batch_9 --- image loss: 0.19909077882766724 --- z loss: 0.07545512914657593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(49.2389, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(2.2960, device='cuda:0', grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epochs in range(params['max_epochs']):\n",
    "    if epochs >= params['learning_rate_switching_point']:\n",
    "        params['learning_rate'] = params['learning_rate_stage2']\n",
    "    loss,loss_z = training(data,params,device)\n",
    "    loss_history.append(loss.clone().detach().cpu().numpy())\n",
    "    loss_z_history.append(loss_z.clone().detach().cpu().numpy())\n",
    "    if epochs % 100 == 0:\n",
    "        print('epoch: {} === loss: {}\\t=== loss_z: {}'.format(epochs,loss,loss_z))\n",
    "\n",
    "validation(val_data,params,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63eff876-2bc0-4a7a-a3e8-67ae9fd0ca14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if save_params == True:\n",
    "    saving(params)\n",
    "plotting(loss_history,loss_z_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff75b85-abf4-44cc-850a-673c9abaa539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d67dc-e2da-4c2e-a611-d2f32c8b93d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183a9ee-1547-436c-b6e2-63d4ed00fddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
