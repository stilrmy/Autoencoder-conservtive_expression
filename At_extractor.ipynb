{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a61f655-b34a-4592-8e53-ca3c260ca455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __clear_env():\n",
    "    for key in globals().keys():\n",
    "        if not key.startswith(\"__\"):# 排除系统内建函数\n",
    "            globals().pop(key)\n",
    "__clear_env\n",
    "import example_pendulum\n",
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "#import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import csv\n",
    "import datetime\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf30d41-34e7-4709-aec7-e79e4e3fe949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ssd1/stilrmy/Angle_detector/progress/Angle_t_extractor/2023-06-25/2\n"
     ]
    }
   ],
   "source": [
    "environment = \"server\"\n",
    "loss_log = []\n",
    "params = {}\n",
    "#params['learning_rate'] = trial.suggest_float('lr',0,1)\n",
    "params['epochs'] = 3000\n",
    "params['batch_size'] = 500\n",
    "if environment == 'laptop':\n",
    "    params['root_dir'] =R'C:\\Users\\87106\\OneDrive\\sindy\\progress\\Angle_t_extractor'\n",
    "elif environment == 'desktop':\n",
    "    params['root_dir'] = R'E:\\OneDrive\\sindy\\progress\\Angle_t_extractor'\n",
    "elif environment == 'server':\n",
    "    params['root_dir'] = R'/mnt/ssd1/stilrmy/Angle_detector/progress/Angle_t_extractor'\n",
    "params['learning_rate'] = 1e-8\n",
    "\n",
    "# save parameters\n",
    "params['if_save'] = True\n",
    "params['save_date'] = str(datetime.date.today())\n",
    "params['save_ver'] = '2'\n",
    "#load parameters\n",
    "params['if_load'] = True\n",
    "params['load_date'] = '2023-05-11'\n",
    "params['load_ver'] = '1'\n",
    "#noise setting\n",
    "params['adding_noise'] = False\n",
    "params['noise_type'] = 'angle_noise'\n",
    "params['noiselevel'] = 1e-3\n",
    "#pendulum length setting\n",
    "params['changing_length'] = True\n",
    "params['c'] = 1.4e-2\n",
    "params['g'] = 9.8\n",
    "params['l'] = 1\n",
    "PATH = os.path.join(params['root_dir'], params['save_date'],params['save_ver'])\n",
    "loading_path = os.path.join(params['root_dir'], params['load_date'],params['load_ver'],'model.pth')\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a09a21fa-3f07-4fe5-a93f-dba66a87865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2601)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "data = example_pendulum.get_pendulum_data(10,params)\n",
    "image = data['x']\n",
    "image_t = data['dx']\n",
    "image_tt = data['ddx']\n",
    "angle = data['z']\n",
    "angle_t = data['dz']\n",
    "angle_tt = data['ddz']\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9146d1f-3803-4695-966b-928232c621cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n"
     ]
    }
   ],
   "source": [
    "class angle_predict(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(angle_predict, self).__init__()\n",
    "        self.fc1 = nn.Linear(7803, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 64)\n",
    "        self.fc6 = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        m = nn.ReLU()\n",
    "        x = self.fc1(x)\n",
    "        x = m(x)\n",
    "        x = self.fc2(x)\n",
    "        x = m(x)\n",
    "        x = self.fc3(x)\n",
    "        x = m(x)\n",
    "        x = self.fc4(x)\n",
    "        x = m(x)\n",
    "        x = self.fc5(x)\n",
    "        x = m(x)\n",
    "        x = self.fc6(x) \n",
    "        return x\n",
    "model = angle_predict()\n",
    "if params['if_load'] == True:\n",
    "    model.load_state_dict(torch.load(loading_path))\n",
    "    print('loading model')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "691295f6-acec-4af8-9ca4-1fb068c85b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 loss:  0.22608713663246738\n",
      "epoch:  2 loss:  0.20278718634302836\n",
      "epoch:  3 loss:  0.18394028996846762\n",
      "epoch:  4 loss:  0.1707366943359375\n",
      "epoch:  5 loss:  0.16282444230045182\n",
      "epoch:  6 loss:  0.15896230184409513\n",
      "epoch:  7 loss:  0.15595647972750376\n",
      "epoch:  8 loss:  0.15328214714326055\n",
      "epoch:  9 loss:  0.15092315061025352\n",
      "epoch:  10 loss:  0.14846724544663026\n",
      "epoch:  11 loss:  0.1463233304310994\n",
      "epoch:  12 loss:  0.14435147817833835\n",
      "epoch:  13 loss:  0.14238967589106424\n",
      "epoch:  14 loss:  0.14043744558311372\n",
      "epoch:  15 loss:  0.13883727046859312\n",
      "epoch:  16 loss:  0.13720569533995355\n",
      "epoch:  17 loss:  0.13578985129973017\n",
      "epoch:  18 loss:  0.13446742291431352\n",
      "epoch:  19 loss:  0.13289342673428087\n",
      "epoch:  20 loss:  0.13125813802083333\n",
      "epoch:  21 loss:  0.1301400303361885\n",
      "epoch:  22 loss:  0.12893817702450427\n",
      "epoch:  23 loss:  0.12745215481064884\n",
      "epoch:  24 loss:  0.12634584970742344\n",
      "epoch:  25 loss:  0.12569397462898468\n",
      "epoch:  26 loss:  0.12436077317080824\n",
      "epoch:  27 loss:  0.12313227519452812\n",
      "epoch:  28 loss:  0.12236670068947665\n",
      "epoch:  29 loss:  0.12144537623148845\n",
      "epoch:  30 loss:  0.12056810003686622\n",
      "epoch:  31 loss:  0.11941498905779367\n",
      "epoch:  32 loss:  0.11861884795039533\n",
      "epoch:  33 loss:  0.11810208362747866\n",
      "epoch:  34 loss:  0.11688581719455948\n",
      "epoch:  35 loss:  0.11593022480547188\n",
      "epoch:  36 loss:  0.1156228674463479\n",
      "epoch:  37 loss:  0.11446579776135793\n",
      "epoch:  38 loss:  0.11382875251004015\n",
      "epoch:  39 loss:  0.11269128025774974\n",
      "epoch:  40 loss:  0.11211615259867595\n",
      "epoch:  41 loss:  0.11141150294537525\n",
      "epoch:  42 loss:  0.1109294355154995\n",
      "epoch:  43 loss:  0.1097697675467495\n",
      "epoch:  44 loss:  0.10968670825881652\n",
      "epoch:  45 loss:  0.10921210476672315\n",
      "epoch:  46 loss:  0.10835259985253515\n",
      "epoch:  47 loss:  0.10743348148453188\n",
      "epoch:  48 loss:  0.10683336372835091\n",
      "epoch:  49 loss:  0.1059161818171122\n",
      "epoch:  50 loss:  0.10533238912681978\n",
      "epoch:  51 loss:  0.10488706535124874\n",
      "epoch:  52 loss:  0.1040787172126004\n",
      "epoch:  53 loss:  0.10338349246595759\n",
      "epoch:  54 loss:  0.10295383192927962\n",
      "epoch:  55 loss:  0.10215708414713541\n",
      "epoch:  56 loss:  0.10186229537289784\n",
      "epoch:  57 loss:  0.10154573371611446\n",
      "epoch:  58 loss:  0.10063412831011546\n",
      "epoch:  59 loss:  0.09944413273210027\n",
      "epoch:  60 loss:  0.09923294864026418\n",
      "epoch:  61 loss:  0.09897440715008471\n",
      "epoch:  62 loss:  0.09837535567072979\n",
      "epoch:  63 loss:  0.09762587949454066\n",
      "epoch:  64 loss:  0.09729545623901857\n",
      "epoch:  65 loss:  0.09659733906328438\n",
      "epoch:  66 loss:  0.09627509059676205\n",
      "epoch:  67 loss:  0.09549070304656125\n",
      "epoch:  68 loss:  0.0947469872164439\n",
      "epoch:  69 loss:  0.09454452330807606\n",
      "epoch:  70 loss:  0.09399652442778929\n",
      "epoch:  71 loss:  0.09321656131361383\n",
      "epoch:  72 loss:  0.09296714445673318\n",
      "epoch:  73 loss:  0.09247997850778113\n",
      "epoch:  74 loss:  0.09183353286191641\n",
      "epoch:  75 loss:  0.09146485232923883\n",
      "epoch:  76 loss:  0.0908154529740054\n",
      "epoch:  77 loss:  0.09010830921341617\n",
      "epoch:  78 loss:  0.09050965213392632\n",
      "epoch:  79 loss:  0.08903185373329255\n",
      "epoch:  80 loss:  0.08873469341232115\n",
      "epoch:  81 loss:  0.0882022106982618\n",
      "epoch:  82 loss:  0.08802019601844879\n",
      "epoch:  83 loss:  0.08762665407724649\n",
      "epoch:  84 loss:  0.08671041588227911\n",
      "epoch:  85 loss:  0.0868540507243819\n",
      "epoch:  86 loss:  0.08612675800859688\n",
      "epoch:  87 loss:  0.0857811617564006\n",
      "epoch:  88 loss:  0.08496104780449924\n",
      "epoch:  89 loss:  0.08490077252368851\n",
      "epoch:  90 loss:  0.08418522723707329\n",
      "epoch:  91 loss:  0.08372108428832517\n",
      "epoch:  92 loss:  0.0834517145731363\n",
      "epoch:  93 loss:  0.08295275217079255\n",
      "epoch:  94 loss:  0.08297164488030245\n",
      "epoch:  95 loss:  0.08223244540662651\n",
      "epoch:  96 loss:  0.08180290130247553\n",
      "epoch:  97 loss:  0.08197547881957518\n",
      "epoch:  98 loss:  0.0808850514362136\n",
      "epoch:  99 loss:  0.08083049973330823\n",
      "epoch:  100 loss:  0.08031038950724774\n",
      "epoch:  101 loss:  0.07966580065378702\n",
      "epoch:  102 loss:  0.0796585695810586\n",
      "epoch:  103 loss:  0.07932405893103665\n",
      "epoch:  104 loss:  0.07902268865501066\n",
      "epoch:  105 loss:  0.07864726729182354\n",
      "epoch:  106 loss:  0.07826487836110066\n",
      "epoch:  107 loss:  0.07783899268950803\n",
      "epoch:  108 loss:  0.07699602732217935\n",
      "epoch:  109 loss:  0.07773375606919868\n",
      "epoch:  110 loss:  0.07665294968938254\n",
      "epoch:  111 loss:  0.0761269320445846\n",
      "epoch:  112 loss:  0.07599736715416353\n",
      "epoch:  113 loss:  0.07589463689719816\n",
      "epoch:  114 loss:  0.07531939893362513\n",
      "epoch:  115 loss:  0.07496289479205887\n",
      "epoch:  116 loss:  0.07439809285972013\n",
      "epoch:  117 loss:  0.07404687107806225\n",
      "epoch:  118 loss:  0.07368564222711158\n",
      "epoch:  119 loss:  0.07344981733574925\n",
      "epoch:  120 loss:  0.07277571590071222\n",
      "epoch:  121 loss:  0.07231368099350527\n",
      "epoch:  122 loss:  0.07289752270801958\n",
      "epoch:  123 loss:  0.07211779245889809\n",
      "epoch:  124 loss:  0.07205414676283257\n",
      "epoch:  125 loss:  0.07169735460396273\n",
      "epoch:  126 loss:  0.07123004959290286\n",
      "epoch:  127 loss:  0.07073160194488894\n",
      "epoch:  128 loss:  0.07106475830078125\n",
      "epoch:  129 loss:  0.07004476646821661\n",
      "epoch:  130 loss:  0.07027226336988579\n",
      "epoch:  131 loss:  0.07033622772339357\n",
      "epoch:  132 loss:  0.0697582750435335\n",
      "epoch:  133 loss:  0.0691654128721919\n",
      "epoch:  134 loss:  0.06921180817018072\n",
      "epoch:  135 loss:  0.06845682289705698\n",
      "epoch:  136 loss:  0.06830353641127009\n",
      "epoch:  137 loss:  0.0678718965216334\n",
      "epoch:  138 loss:  0.06811074253066955\n",
      "epoch:  139 loss:  0.06696640688731488\n",
      "epoch:  140 loss:  0.06696611887001129\n",
      "epoch:  141 loss:  0.06702112404696912\n",
      "epoch:  142 loss:  0.06685617592440073\n",
      "epoch:  143 loss:  0.06646702777908509\n",
      "epoch:  144 loss:  0.06586885873572415\n",
      "epoch:  145 loss:  0.06598826335615901\n",
      "epoch:  146 loss:  0.06569275147464859\n",
      "epoch:  147 loss:  0.06571802346103163\n",
      "epoch:  148 loss:  0.06531424771351028\n",
      "epoch:  149 loss:  0.06489732121846763\n",
      "epoch:  150 loss:  0.06441694512424699\n",
      "epoch:  151 loss:  0.06457106502180597\n",
      "epoch:  152 loss:  0.06469407905057731\n",
      "epoch:  153 loss:  0.06351852723393574\n",
      "epoch:  154 loss:  0.06428463487740023\n",
      "epoch:  155 loss:  0.06412622536042607\n",
      "epoch:  156 loss:  0.06285755203430911\n",
      "epoch:  157 loss:  0.06327976088926017\n",
      "epoch:  158 loss:  0.06256198500054908\n",
      "epoch:  159 loss:  0.06214617993458208\n",
      "epoch:  160 loss:  0.062289710600213356\n",
      "epoch:  161 loss:  0.06255585697281313\n",
      "epoch:  162 loss:  0.06163553138334588\n",
      "epoch:  163 loss:  0.06193942640679907\n",
      "epoch:  164 loss:  0.06119082653857618\n",
      "epoch:  165 loss:  0.06123154728288153\n",
      "epoch:  166 loss:  0.06029088889738642\n",
      "epoch:  167 loss:  0.06111417716765499\n",
      "epoch:  168 loss:  0.060247974319151604\n",
      "epoch:  169 loss:  0.06037931633761609\n",
      "epoch:  170 loss:  0.06083774183648657\n",
      "epoch:  171 loss:  0.05999598369062186\n",
      "epoch:  172 loss:  0.059635055113030244\n",
      "epoch:  173 loss:  0.05920940843451933\n",
      "epoch:  174 loss:  0.059226327919098265\n",
      "epoch:  175 loss:  0.05910252950277673\n",
      "epoch:  176 loss:  0.05857960038395771\n",
      "epoch:  177 loss:  0.05900614175451807\n",
      "epoch:  178 loss:  0.058598143795886674\n",
      "epoch:  179 loss:  0.05786751130498557\n",
      "epoch:  180 loss:  0.05788603633283133\n",
      "epoch:  181 loss:  0.058139105494242595\n",
      "epoch:  182 loss:  0.05747368747450741\n",
      "epoch:  183 loss:  0.057369063656971635\n",
      "epoch:  184 loss:  0.0574834555507185\n",
      "epoch:  185 loss:  0.057642490126521714\n",
      "epoch:  186 loss:  0.05685601291886295\n",
      "epoch:  187 loss:  0.057445817204364334\n",
      "epoch:  188 loss:  0.05619520930401293\n",
      "epoch:  189 loss:  0.05647959268715487\n",
      "epoch:  190 loss:  0.05614396673608497\n",
      "epoch:  191 loss:  0.05605637270762739\n",
      "epoch:  192 loss:  0.05572309991920808\n",
      "epoch:  193 loss:  0.05561636193210341\n",
      "epoch:  194 loss:  0.05540769645966679\n",
      "epoch:  195 loss:  0.05570950795368976\n",
      "epoch:  196 loss:  0.05482891649606238\n",
      "epoch:  197 loss:  0.055343303144217496\n",
      "epoch:  198 loss:  0.054385896858920056\n",
      "epoch:  199 loss:  0.05409122451720946\n",
      "epoch:  200 loss:  0.0544547820186998\n",
      "epoch:  201 loss:  0.05435013368905309\n",
      "epoch:  202 loss:  0.05394006445704694\n",
      "epoch:  203 loss:  0.053829410660219\n",
      "epoch:  204 loss:  0.053284016191720004\n",
      "epoch:  205 loss:  0.05274014147409952\n",
      "epoch:  206 loss:  0.053545211117909136\n",
      "epoch:  207 loss:  0.05285318520174448\n",
      "epoch:  208 loss:  0.0533523130608371\n",
      "epoch:  209 loss:  0.053035628843498994\n",
      "epoch:  210 loss:  0.052805331433154495\n",
      "epoch:  211 loss:  0.052426024900382784\n",
      "epoch:  212 loss:  0.05210598865187312\n",
      "epoch:  213 loss:  0.05204937180362073\n",
      "epoch:  214 loss:  0.05215351150696536\n",
      "epoch:  215 loss:  0.05194966266432919\n",
      "epoch:  216 loss:  0.05137642243779807\n",
      "epoch:  217 loss:  0.05127517822755867\n",
      "epoch:  218 loss:  0.051147592690096326\n",
      "epoch:  219 loss:  0.05104381147637425\n",
      "epoch:  220 loss:  0.05070845822253859\n",
      "epoch:  221 loss:  0.05105654858202341\n",
      "epoch:  222 loss:  0.05095152950669867\n",
      "epoch:  223 loss:  0.050645743986688946\n",
      "epoch:  224 loss:  0.04995081644939132\n",
      "epoch:  225 loss:  0.050419206121360444\n",
      "epoch:  226 loss:  0.050394041375462786\n",
      "epoch:  227 loss:  0.05025640893652736\n",
      "epoch:  228 loss:  0.04943139256243725\n",
      "epoch:  229 loss:  0.049660164093875504\n",
      "epoch:  230 loss:  0.04921401609857398\n",
      "epoch:  231 loss:  0.04940079838396555\n",
      "epoch:  232 loss:  0.049242247922353474\n",
      "epoch:  233 loss:  0.0486150381555519\n",
      "epoch:  234 loss:  0.048864543868834716\n",
      "epoch:  235 loss:  0.04846121240332423\n",
      "epoch:  236 loss:  0.048247570972366025\n",
      "epoch:  237 loss:  0.04854289288501663\n",
      "epoch:  238 loss:  0.04830556356284513\n",
      "epoch:  239 loss:  0.04773893241422722\n",
      "epoch:  240 loss:  0.048421401671137676\n",
      "epoch:  241 loss:  0.04746367979241183\n",
      "epoch:  242 loss:  0.04743962115552052\n",
      "epoch:  243 loss:  0.047272445494870106\n",
      "epoch:  244 loss:  0.047461204069206515\n",
      "epoch:  245 loss:  0.04773046041588228\n",
      "epoch:  246 loss:  0.04776290525873023\n",
      "epoch:  247 loss:  0.04675845410450395\n",
      "epoch:  248 loss:  0.047347709931522965\n",
      "epoch:  249 loss:  0.04669293016793737\n",
      "epoch:  250 loss:  0.04665978979394139\n",
      "epoch:  251 loss:  0.04669661004859281\n",
      "epoch:  252 loss:  0.046102243446442016\n",
      "epoch:  253 loss:  0.04670775999505836\n",
      "epoch:  254 loss:  0.04605049225221197\n",
      "epoch:  255 loss:  0.04618411083298036\n",
      "epoch:  256 loss:  0.04611048257973299\n",
      "epoch:  257 loss:  0.04600604566704317\n",
      "epoch:  258 loss:  0.04587325437001914\n",
      "epoch:  259 loss:  0.04605738015538717\n",
      "epoch:  260 loss:  0.04550246273178652\n",
      "epoch:  261 loss:  0.04502926562205855\n",
      "epoch:  262 loss:  0.04489643142884036\n",
      "epoch:  263 loss:  0.04575992875309833\n",
      "epoch:  264 loss:  0.04572544940504204\n",
      "epoch:  265 loss:  0.04492037056919083\n",
      "epoch:  266 loss:  0.04503782034877792\n",
      "epoch:  267 loss:  0.04429153381102535\n",
      "epoch:  268 loss:  0.04436108692582831\n",
      "epoch:  269 loss:  0.04412621494277893\n",
      "epoch:  270 loss:  0.04393650652414345\n",
      "epoch:  271 loss:  0.04430837056722986\n",
      "epoch:  272 loss:  0.04410592197893135\n",
      "epoch:  273 loss:  0.043482150035689636\n",
      "epoch:  274 loss:  0.04366716132106551\n",
      "epoch:  275 loss:  0.043889948833419616\n",
      "epoch:  276 loss:  0.04341492250741246\n",
      "epoch:  277 loss:  0.04347717407716805\n",
      "epoch:  278 loss:  0.04311752932138711\n",
      "epoch:  279 loss:  0.04310689412925138\n",
      "epoch:  280 loss:  0.04317458125960875\n",
      "epoch:  281 loss:  0.043540513371846765\n",
      "epoch:  282 loss:  0.04292168061896021\n",
      "epoch:  283 loss:  0.04315085660022904\n",
      "epoch:  284 loss:  0.043419092630286774\n",
      "epoch:  285 loss:  0.04267894331231175\n",
      "epoch:  286 loss:  0.042673688528528174\n",
      "epoch:  287 loss:  0.04254547793223676\n",
      "epoch:  288 loss:  0.04258325722322885\n",
      "epoch:  289 loss:  0.04242232908685523\n",
      "epoch:  290 loss:  0.04274121633016441\n",
      "epoch:  291 loss:  0.04256456367462036\n",
      "epoch:  292 loss:  0.04233283230578564\n",
      "epoch:  293 loss:  0.0415361549959604\n",
      "epoch:  294 loss:  0.04215847153261484\n",
      "epoch:  295 loss:  0.04129620900594566\n",
      "epoch:  296 loss:  0.04241154682205384\n",
      "epoch:  297 loss:  0.04148455087439602\n",
      "epoch:  298 loss:  0.04210324881067238\n",
      "epoch:  299 loss:  0.04159245318677052\n",
      "epoch:  300 loss:  0.04131364937288216\n",
      "epoch:  301 loss:  0.04132453581415506\n",
      "epoch:  302 loss:  0.041252105590330074\n",
      "epoch:  303 loss:  0.04122231111947791\n",
      "epoch:  304 loss:  0.041114607968004833\n",
      "epoch:  305 loss:  0.04094303238344001\n",
      "epoch:  306 loss:  0.04022264901892727\n",
      "epoch:  307 loss:  0.04041445935107618\n",
      "epoch:  308 loss:  0.040801735383918486\n",
      "epoch:  309 loss:  0.040008446873431226\n",
      "epoch:  310 loss:  0.03977972130220099\n",
      "epoch:  311 loss:  0.04026160489124467\n",
      "epoch:  312 loss:  0.039968982374811744\n",
      "epoch:  313 loss:  0.039762087902390816\n",
      "epoch:  314 loss:  0.03982497678703094\n",
      "epoch:  315 loss:  0.03961072868132687\n",
      "epoch:  316 loss:  0.0397363838900524\n",
      "epoch:  317 loss:  0.03903360941323889\n",
      "epoch:  318 loss:  0.039841887079568275\n",
      "epoch:  319 loss:  0.03909661779441987\n",
      "epoch:  320 loss:  0.039282609564233496\n",
      "epoch:  321 loss:  0.03906075964012299\n",
      "epoch:  322 loss:  0.0390747162232916\n",
      "epoch:  323 loss:  0.03880035829352566\n",
      "epoch:  324 loss:  0.03890773359551487\n",
      "epoch:  325 loss:  0.03845930903790945\n",
      "epoch:  326 loss:  0.03845917422129926\n",
      "epoch:  327 loss:  0.0385210948775571\n",
      "epoch:  328 loss:  0.038068196859704445\n",
      "epoch:  329 loss:  0.037645090248690075\n",
      "epoch:  330 loss:  0.03828674377686527\n",
      "epoch:  331 loss:  0.03829088938762864\n",
      "epoch:  332 loss:  0.03827017665388115\n",
      "epoch:  333 loss:  0.03807545857257154\n",
      "epoch:  334 loss:  0.03804906822112669\n",
      "epoch:  335 loss:  0.03725600951167953\n",
      "epoch:  336 loss:  0.03803584700128639\n",
      "epoch:  337 loss:  0.0373995983935743\n",
      "epoch:  338 loss:  0.03754565074261891\n",
      "epoch:  339 loss:  0.03790074237379204\n",
      "epoch:  340 loss:  0.03806216994442614\n",
      "epoch:  341 loss:  0.03706587213110254\n",
      "epoch:  342 loss:  0.03662137563927585\n",
      "epoch:  343 loss:  0.036487913323214737\n",
      "epoch:  344 loss:  0.03693953671129832\n",
      "epoch:  345 loss:  0.036727415031218624\n",
      "epoch:  346 loss:  0.036550296645566645\n",
      "epoch:  347 loss:  0.0363039407385401\n",
      "epoch:  348 loss:  0.03625391764813159\n",
      "epoch:  349 loss:  0.03631308069190826\n",
      "epoch:  350 loss:  0.03668777588380867\n",
      "epoch:  351 loss:  0.0371440443169161\n",
      "epoch:  352 loss:  0.0362534856221762\n",
      "epoch:  353 loss:  0.03545652335906124\n",
      "epoch:  354 loss:  0.03630780139601374\n",
      "epoch:  355 loss:  0.035784378970961976\n",
      "epoch:  356 loss:  0.035532100325128636\n",
      "epoch:  357 loss:  0.035185342811676394\n",
      "epoch:  358 loss:  0.03542945586055158\n",
      "epoch:  359 loss:  0.035782120792741276\n",
      "epoch:  360 loss:  0.035072014130741715\n",
      "epoch:  361 loss:  0.03480129318543706\n",
      "epoch:  362 loss:  0.03501891477040976\n",
      "epoch:  363 loss:  0.03524984949563881\n",
      "epoch:  364 loss:  0.03560715640883848\n",
      "epoch:  365 loss:  0.03605005654943995\n",
      "epoch:  366 loss:  0.03524680692986791\n",
      "epoch:  367 loss:  0.034326879662203505\n",
      "epoch:  368 loss:  0.034761234268127196\n",
      "epoch:  369 loss:  0.03498275021472609\n",
      "epoch:  370 loss:  0.03417609647574674\n",
      "epoch:  371 loss:  0.034802252221777734\n",
      "epoch:  372 loss:  0.03459579590333992\n",
      "epoch:  373 loss:  0.034510236380090674\n",
      "epoch:  374 loss:  0.0347941050089028\n",
      "epoch:  375 loss:  0.03478734885832392\n",
      "epoch:  376 loss:  0.03437608466090926\n",
      "epoch:  377 loss:  0.03384450583094095\n",
      "epoch:  378 loss:  0.03383525250905968\n",
      "epoch:  379 loss:  0.03381800211098299\n",
      "epoch:  380 loss:  0.03376608852401795\n",
      "epoch:  381 loss:  0.03356297810872396\n",
      "epoch:  382 loss:  0.033869051646037276\n",
      "epoch:  383 loss:  0.03389449521719691\n",
      "epoch:  384 loss:  0.033619610277045686\n",
      "epoch:  385 loss:  0.033233553721722826\n",
      "epoch:  386 loss:  0.03331055545423883\n",
      "epoch:  387 loss:  0.03304869257302648\n",
      "epoch:  388 loss:  0.03350027000090205\n",
      "epoch:  389 loss:  0.032902961945438\n",
      "epoch:  390 loss:  0.03293084753565041\n",
      "epoch:  391 loss:  0.03331501972244447\n",
      "epoch:  392 loss:  0.03309597337102316\n",
      "epoch:  393 loss:  0.032607661480884474\n",
      "epoch:  394 loss:  0.03235211966028175\n",
      "epoch:  395 loss:  0.032653269327309234\n",
      "epoch:  396 loss:  0.032919590348699485\n",
      "epoch:  397 loss:  0.03231827762711\n",
      "epoch:  398 loss:  0.0316390562248996\n",
      "epoch:  399 loss:  0.03172259962702372\n",
      "epoch:  400 loss:  0.032018856063904054\n",
      "epoch:  401 loss:  0.03183315231139401\n",
      "epoch:  402 loss:  0.03202531194112387\n",
      "epoch:  403 loss:  0.03239464510875533\n",
      "epoch:  404 loss:  0.03164276980970758\n",
      "epoch:  405 loss:  0.03203910000352975\n",
      "epoch:  406 loss:  0.03143460377153144\n",
      "epoch:  407 loss:  0.03157271726064414\n",
      "epoch:  408 loss:  0.03174771841271335\n",
      "epoch:  409 loss:  0.03142827964690795\n",
      "epoch:  410 loss:  0.03057858264111132\n",
      "epoch:  411 loss:  0.03196180106166855\n",
      "epoch:  412 loss:  0.03197157832992125\n",
      "epoch:  413 loss:  0.03096905750443179\n",
      "epoch:  414 loss:  0.031222181818092682\n",
      "epoch:  415 loss:  0.031273381489826495\n",
      "epoch:  416 loss:  0.031063864221534575\n",
      "epoch:  417 loss:  0.0304173389113093\n",
      "epoch:  418 loss:  0.030591374899010104\n",
      "epoch:  419 loss:  0.030491625927538277\n",
      "epoch:  420 loss:  0.031141791286238705\n",
      "epoch:  421 loss:  0.030383147580556602\n",
      "epoch:  422 loss:  0.030442954067245544\n",
      "epoch:  423 loss:  0.030359376960968874\n",
      "epoch:  424 loss:  0.03059025959796216\n",
      "epoch:  425 loss:  0.03009962212129769\n",
      "epoch:  426 loss:  0.03002458135765719\n",
      "epoch:  427 loss:  0.030787067336729732\n",
      "epoch:  428 loss:  0.0305301007496784\n",
      "epoch:  429 loss:  0.03028636763852284\n",
      "epoch:  430 loss:  0.030440775553385417\n",
      "epoch:  431 loss:  0.030367490469691266\n",
      "epoch:  432 loss:  0.030270661503435617\n",
      "epoch:  433 loss:  0.029978455692888744\n",
      "epoch:  434 loss:  0.03048684912991811\n",
      "epoch:  435 loss:  0.029768561550891064\n",
      "epoch:  436 loss:  0.029585214025045495\n",
      "epoch:  437 loss:  0.030138164351742908\n",
      "epoch:  438 loss:  0.02946969151018135\n",
      "epoch:  439 loss:  0.029593909696402798\n",
      "epoch:  440 loss:  0.030179883964569214\n",
      "epoch:  441 loss:  0.029219095007961535\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m         opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     23\u001b[0m         loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 24\u001b[0m         opt\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     25\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     26\u001b[0m loss_log\u001b[39m.\u001b[39mappend(loss_sum\u001b[39m.\u001b[39mitem()\u001b[39m/\u001b[39mcount)\n",
      "File \u001b[0;32m/mnt/ssd1/stilrmy/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/ssd1/stilrmy/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/mnt/ssd1/stilrmy/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/mnt/ssd1/stilrmy/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m/mnt/ssd1/stilrmy/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    436\u001b[0m params_ \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mview_as_real(x) \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(x) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m device_params]\n\u001b[1;32m    438\u001b[0m \u001b[39m# update steps\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m torch\u001b[39m.\u001b[39;49m_foreach_add_(device_state_steps, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m weight_decay \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    442\u001b[0m     device_grads \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_foreach_add(device_grads, device_params, alpha\u001b[39m=\u001b[39mweight_decay)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "for epoch in range(params['epochs']):\n",
    "    loss_sum = 0\n",
    "    loss_angle_sum = 0\n",
    "    loss_angle_t_sum = 0\n",
    "    loss_angle_tt_sum = 0\n",
    "    count = 0 \n",
    "    model.train()\n",
    "    for i in range(len(data['z'])//params['batch_size']):\n",
    "        image_temp = image[i*params['batch_size']:(i+1)*params['batch_size'],:]\n",
    "        angle_t_temp = angle_t[i*params['batch_size']:(i+1)*params['batch_size']]\n",
    "        for j in range(image_temp.shape[0]-2):\n",
    "            input = torch.tensor(image_temp[j:j+3,:],dtype=torch.float32).to(device)\n",
    "            input = input.view(-1)\n",
    "            input = Variable(input)\n",
    "            pre = model.forward(input)\n",
    "            angle_t_true = torch.tensor(angle_t_temp[j],dtype=torch.float32).to(device)\n",
    "            loss_angle_t = torch.abs(angle_t_true - pre)\n",
    "            loss = loss_angle_t\n",
    "            loss_sum += loss\n",
    "            count += 1\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        model.eval()\n",
    "    loss_log.append(loss_sum.item()/count)\n",
    "    print('epoch: ', epoch+1, 'loss: ', loss_sum.item()/count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e5527f-ba23-4f53-91e3-dc5dab3c6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving(model,PATH):\n",
    "    if os.path.exists(PATH) == False:\n",
    "        os.makedirs(PATH)\n",
    "    model_PATH = os.path.join(PATH, 'model.pth')\n",
    "    torch.save(model.state_dict(), model_PATH)\n",
    "    params_PATH = os.path.join(PATH, 'params.txt')\n",
    "    with open(params_PATH, 'w') as f:\n",
    "        f.write(str(params))\n",
    "        f.close()\n",
    "    loss_PATH = os.path.join(PATH, 'loss_log.csv')\n",
    "    with open(loss_PATH, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(loss_log)\n",
    "    #fig_PATH = os.path.join(PATH, 'loss.png') \n",
    "    #plt.savefig(fig_PATH)\n",
    "    print(\"data saved\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "571855e9-b3ff-4a38-b6ff-04e70449dee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved\n"
     ]
    }
   ],
   "source": [
    "if params['if_save'] == True:\n",
    "    saving(model,PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44e71fc5-1933-422b-9879-9542b8d3a319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting result\n",
    "plt.plot(loss_log)\n",
    "fig_PATH = os.path.join(PATH, 'loss.png') \n",
    "plt.savefig(fig_PATH, bbox_inches='tight', pad_inches = +0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce926ae3-b950-4bb0-84ec-88e0e2204018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
