{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a61f655-b34a-4592-8e53-ca3c260ca455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __clear_env():\n",
    "    for key in globals().keys():\n",
    "        if not key.startswith(\"__\"):# 排除系统内建函数\n",
    "            globals().pop(key)\n",
    "__clear_env\n",
    "import example_pendulum\n",
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "#import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import csv\n",
    "import datetime\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf30d41-34e7-4709-aec7-e79e4e3fe949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ssd1/stilrmy/Angle_detector/progress/Angle_t_extractor/2023-05-11/2\n"
     ]
    }
   ],
   "source": [
    "environment = \"server\"\n",
    "loss_log = []\n",
    "params = {}\n",
    "#params['learning_rate'] = trial.suggest_float('lr',0,1)\n",
    "params['epochs'] = 3000\n",
    "params['batch_size'] = 500\n",
    "if environment == 'laptop':\n",
    "    params['root_dir'] =R'C:\\Users\\87106\\OneDrive\\sindy\\progress\\Angle_t_extractor'\n",
    "elif environment == 'desktop':\n",
    "    params['root_dir'] = R'E:\\OneDrive\\sindy\\progress\\Angle_t_extractor'\n",
    "elif environment == 'server':\n",
    "    params['root_dir'] = R'/mnt/ssd1/stilrmy/Angle_detector/progress/Angle_t_extractor'\n",
    "params['learning_rate'] = 1e-8\n",
    "\n",
    "# save parameters\n",
    "params['if_save'] = True\n",
    "params['save_date'] = str(datetime.date.today())\n",
    "params['save_ver'] = '2'\n",
    "#load parameters\n",
    "params['if_load'] = True\n",
    "params['load_date'] = '2023-05-11'\n",
    "params['load_ver'] = '2'\n",
    "#noise setting\n",
    "params['adding_noise'] = False\n",
    "params['noise_type'] = 'angle_noise'\n",
    "params['noiselevel'] = 1e-3\n",
    "#pendulum length setting\n",
    "params['changing_length'] = True\n",
    "PATH = os.path.join(params['root_dir'], params['save_date'],params['save_ver'])\n",
    "loading_path = os.path.join(params['root_dir'], params['load_date'],params['load_ver'],'model.pth')\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a09a21fa-3f07-4fe5-a93f-dba66a87865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2601)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "data = example_pendulum.get_pendulum_data(10,params)\n",
    "image = data['x']\n",
    "image_t = data['dx']\n",
    "image_tt = data['ddx']\n",
    "angle = data['z']\n",
    "angle_t = data['dz']\n",
    "angle_tt = data['ddz']\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9146d1f-3803-4695-966b-928232c621cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n"
     ]
    }
   ],
   "source": [
    "class angle_predict(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(angle_predict, self).__init__()\n",
    "        self.fc1 = nn.Linear(7803, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 64)\n",
    "        self.fc6 = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        m = nn.ReLU()\n",
    "        x = self.fc1(x)\n",
    "        x = m(x)\n",
    "        x = self.fc2(x)\n",
    "        x = m(x)\n",
    "        x = self.fc3(x)\n",
    "        x = m(x)\n",
    "        x = self.fc4(x)\n",
    "        x = m(x)\n",
    "        x = self.fc5(x)\n",
    "        x = m(x)\n",
    "        x = self.fc6(x) \n",
    "        return x\n",
    "model = angle_predict()\n",
    "if params['if_load'] == True:\n",
    "    model.load_state_dict(torch.load(loading_path))\n",
    "    print('loading model')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "691295f6-acec-4af8-9ca4-1fb068c85b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1128 loss:  0.03753412085843374\n",
      "epoch:  1129 loss:  0.03745067856876726\n",
      "epoch:  1130 loss:  0.03743324739387236\n",
      "epoch:  1131 loss:  0.03733981948301016\n",
      "epoch:  1132 loss:  0.037485001652116275\n",
      "epoch:  1133 loss:  0.03740270530363642\n",
      "epoch:  1134 loss:  0.037329138330666416\n",
      "epoch:  1135 loss:  0.037485047612324296\n",
      "epoch:  1136 loss:  0.03700910821018449\n",
      "epoch:  1137 loss:  0.03675142770790192\n",
      "epoch:  1138 loss:  0.037409562566672945\n",
      "epoch:  1139 loss:  0.03751850664376255\n",
      "epoch:  1140 loss:  0.036997403677208836\n",
      "epoch:  1141 loss:  0.03728653628184613\n",
      "epoch:  1142 loss:  0.03705044788529117\n",
      "epoch:  1143 loss:  0.036564866031508846\n",
      "epoch:  1144 loss:  0.03649674074716836\n",
      "epoch:  1145 loss:  0.03656688828066171\n",
      "epoch:  1146 loss:  0.036789727881251566\n",
      "epoch:  1147 loss:  0.03700832688664815\n",
      "epoch:  1148 loss:  0.03725566634212632\n",
      "epoch:  1149 loss:  0.03654137423718311\n",
      "epoch:  1150 loss:  0.036892755347562124\n",
      "epoch:  1151 loss:  0.03603653199222672\n",
      "epoch:  1152 loss:  0.03694723351413466\n",
      "epoch:  1153 loss:  0.03633310402253546\n",
      "epoch:  1154 loss:  0.03635017977182166\n",
      "epoch:  1155 loss:  0.03643070512028583\n",
      "epoch:  1156 loss:  0.036685701546420056\n",
      "epoch:  1157 loss:  0.03546374830376192\n",
      "epoch:  1158 loss:  0.03663029191963165\n",
      "epoch:  1159 loss:  0.03604229540231237\n",
      "epoch:  1160 loss:  0.03584353588671091\n",
      "epoch:  1161 loss:  0.035723591999835276\n",
      "epoch:  1162 loss:  0.0365338459551095\n",
      "epoch:  1163 loss:  0.03563119053361885\n",
      "epoch:  1164 loss:  0.03619024437594127\n",
      "epoch:  1165 loss:  0.0356125123050797\n",
      "epoch:  1166 loss:  0.03541325335521774\n",
      "epoch:  1167 loss:  0.03589050109127918\n",
      "epoch:  1168 loss:  0.03571034320387017\n",
      "epoch:  1169 loss:  0.035414794554193336\n",
      "epoch:  1170 loss:  0.03541970923243756\n",
      "epoch:  1171 loss:  0.035129256037823166\n",
      "epoch:  1172 loss:  0.03513376320222295\n",
      "epoch:  1173 loss:  0.03502397958533352\n",
      "epoch:  1174 loss:  0.03537930714557449\n",
      "epoch:  1175 loss:  0.03494570322304844\n",
      "epoch:  1176 loss:  0.035509901544655186\n",
      "epoch:  1177 loss:  0.035312474875086285\n",
      "epoch:  1178 loss:  0.0350041309034968\n",
      "epoch:  1179 loss:  0.03471205684554625\n",
      "epoch:  1180 loss:  0.03490974089228006\n",
      "epoch:  1181 loss:  0.03497109776998619\n",
      "epoch:  1182 loss:  0.034471605293243286\n",
      "epoch:  1183 loss:  0.03520948724095601\n",
      "epoch:  1184 loss:  0.034799853098919115\n",
      "epoch:  1185 loss:  0.03454591375756934\n",
      "epoch:  1186 loss:  0.0351830846334557\n",
      "epoch:  1187 loss:  0.03391419069834024\n",
      "epoch:  1188 loss:  0.03464477416501945\n",
      "epoch:  1189 loss:  0.03508443870697634\n",
      "epoch:  1190 loss:  0.03382687243113077\n",
      "epoch:  1191 loss:  0.0341451713837773\n",
      "epoch:  1192 loss:  0.034560725200607115\n",
      "epoch:  1193 loss:  0.03430943316723927\n",
      "epoch:  1194 loss:  0.034030442448504956\n",
      "epoch:  1195 loss:  0.033816761185366466\n",
      "epoch:  1196 loss:  0.03473932044094346\n",
      "epoch:  1197 loss:  0.03438602738591083\n",
      "epoch:  1198 loss:  0.03433016734908383\n",
      "epoch:  1199 loss:  0.03455638655697007\n",
      "epoch:  1200 loss:  0.03426134346958145\n",
      "epoch:  1201 loss:  0.033994063411850524\n",
      "epoch:  1202 loss:  0.03379474318171122\n",
      "epoch:  1203 loss:  0.03435088621085906\n",
      "epoch:  1204 loss:  0.033487189725699675\n",
      "epoch:  1205 loss:  0.033272230768778235\n",
      "epoch:  1206 loss:  0.03342544984626004\n",
      "epoch:  1207 loss:  0.03327243605770739\n",
      "epoch:  1208 loss:  0.033098449094228474\n",
      "epoch:  1209 loss:  0.03418027272664878\n",
      "epoch:  1210 loss:  0.03267423943822163\n",
      "epoch:  1211 loss:  0.03335455775739678\n",
      "epoch:  1212 loss:  0.03366513845910988\n",
      "epoch:  1213 loss:  0.03343204666811778\n",
      "epoch:  1214 loss:  0.033179746574187374\n",
      "epoch:  1215 loss:  0.033234013323803026\n",
      "epoch:  1216 loss:  0.03344855557483842\n",
      "epoch:  1217 loss:  0.032722218831380205\n",
      "epoch:  1218 loss:  0.03325286620113266\n",
      "epoch:  1219 loss:  0.032994143934134974\n",
      "epoch:  1220 loss:  0.032664498938135354\n",
      "epoch:  1221 loss:  0.03287966011997208\n",
      "epoch:  1222 loss:  0.03251972428287368\n",
      "epoch:  1223 loss:  0.0325645324216789\n",
      "epoch:  1224 loss:  0.03223076019899912\n",
      "epoch:  1225 loss:  0.0330123472405246\n",
      "epoch:  1226 loss:  0.03191773441421938\n",
      "epoch:  1227 loss:  0.03275580042337318\n",
      "epoch:  1228 loss:  0.032623566776873114\n",
      "epoch:  1229 loss:  0.03237331957223425\n",
      "epoch:  1230 loss:  0.031757186215565385\n",
      "epoch:  1231 loss:  0.03243409735131934\n",
      "epoch:  1232 loss:  0.03188095705576211\n",
      "epoch:  1233 loss:  0.03182844292207894\n",
      "epoch:  1234 loss:  0.03155160926910768\n",
      "epoch:  1235 loss:  0.03194632472762143\n",
      "epoch:  1236 loss:  0.031957048776159326\n",
      "epoch:  1237 loss:  0.03170508878776826\n",
      "epoch:  1238 loss:  0.03153204247654681\n",
      "epoch:  1239 loss:  0.03154095569288874\n",
      "epoch:  1240 loss:  0.03122321439076619\n",
      "epoch:  1241 loss:  0.031631613735214295\n",
      "epoch:  1242 loss:  0.03198911674530152\n",
      "epoch:  1243 loss:  0.03093046931377855\n",
      "epoch:  1244 loss:  0.031332961239489206\n",
      "epoch:  1245 loss:  0.03191054317367125\n",
      "epoch:  1246 loss:  0.031267369894617536\n",
      "epoch:  1247 loss:  0.031111984559331073\n",
      "epoch:  1248 loss:  0.03161920447904901\n",
      "epoch:  1249 loss:  0.031587574663889936\n",
      "epoch:  1250 loss:  0.03098908696308672\n",
      "epoch:  1251 loss:  0.031104594157881527\n",
      "epoch:  1252 loss:  0.03066615215745796\n",
      "epoch:  1253 loss:  0.03134603845067771\n",
      "epoch:  1254 loss:  0.03042225052553966\n",
      "epoch:  1255 loss:  0.03128790491556068\n",
      "epoch:  1256 loss:  0.03147923726154619\n",
      "epoch:  1257 loss:  0.030343149943524095\n",
      "epoch:  1258 loss:  0.03035115008373337\n",
      "epoch:  1259 loss:  0.03079604489736289\n",
      "epoch:  1260 loss:  0.030255274025790663\n",
      "epoch:  1261 loss:  0.030699451860175076\n",
      "epoch:  1262 loss:  0.030136037926118537\n",
      "epoch:  1263 loss:  0.031023238461659136\n",
      "epoch:  1264 loss:  0.03015792417717746\n",
      "epoch:  1265 loss:  0.030857815416941204\n",
      "epoch:  1266 loss:  0.030497082936237135\n",
      "epoch:  1267 loss:  0.030789178442284765\n",
      "epoch:  1268 loss:  0.029923864157803088\n",
      "epoch:  1269 loss:  0.03057566569990901\n",
      "epoch:  1270 loss:  0.030169772718804905\n",
      "epoch:  1271 loss:  0.030097890953462287\n",
      "epoch:  1272 loss:  0.030834865953070095\n",
      "epoch:  1273 loss:  0.030468737743944527\n",
      "epoch:  1274 loss:  0.029918079299620357\n",
      "epoch:  1275 loss:  0.029607783551196976\n",
      "epoch:  1276 loss:  0.029748182794655183\n",
      "epoch:  1277 loss:  0.029938516272119728\n",
      "epoch:  1278 loss:  0.02947922059331074\n",
      "epoch:  1279 loss:  0.03058583822595068\n",
      "epoch:  1280 loss:  0.030278643259561686\n",
      "epoch:  1281 loss:  0.029752696087082704\n",
      "epoch:  1282 loss:  0.029300401679962035\n",
      "epoch:  1283 loss:  0.02955199705070281\n",
      "epoch:  1284 loss:  0.029681044122780182\n",
      "epoch:  1285 loss:  0.029580333050953814\n",
      "epoch:  1286 loss:  0.0290214324093248\n",
      "epoch:  1287 loss:  0.029367629208239206\n",
      "epoch:  1288 loss:  0.03008400177859877\n",
      "epoch:  1289 loss:  0.028937083171553402\n",
      "epoch:  1290 loss:  0.029031758136059866\n",
      "epoch:  1291 loss:  0.02922648540941108\n",
      "epoch:  1292 loss:  0.029262224067167105\n",
      "epoch:  1293 loss:  0.029237751788403616\n",
      "epoch:  1294 loss:  0.029221889388609125\n",
      "epoch:  1295 loss:  0.02956227681722986\n",
      "epoch:  1296 loss:  0.028912555740540285\n",
      "epoch:  1297 loss:  0.028794870031885352\n",
      "epoch:  1298 loss:  0.02897935737088981\n",
      "epoch:  1299 loss:  0.029012188279485127\n",
      "epoch:  1300 loss:  0.02894605766817269\n",
      "epoch:  1301 loss:  0.028534275652414346\n",
      "epoch:  1302 loss:  0.028104501747223266\n",
      "epoch:  1303 loss:  0.028741657303040288\n",
      "epoch:  1304 loss:  0.029073382764456264\n",
      "epoch:  1305 loss:  0.027776952536709337\n",
      "epoch:  1306 loss:  0.028189166578423068\n",
      "epoch:  1307 loss:  0.028734729567684802\n",
      "epoch:  1308 loss:  0.027999176270511735\n",
      "epoch:  1309 loss:  0.02801871855096166\n",
      "epoch:  1310 loss:  0.027414056862214483\n",
      "epoch:  1311 loss:  0.028334508076250313\n",
      "epoch:  1312 loss:  0.028076086082611695\n",
      "epoch:  1313 loss:  0.02845995186801895\n",
      "epoch:  1314 loss:  0.027657201682707393\n",
      "epoch:  1315 loss:  0.027234009279304718\n",
      "epoch:  1316 loss:  0.0280386131930064\n",
      "epoch:  1317 loss:  0.027907436631290788\n",
      "epoch:  1318 loss:  0.027878641028959587\n",
      "epoch:  1319 loss:  0.027812700386506965\n",
      "epoch:  1320 loss:  0.027747976157559927\n",
      "epoch:  1321 loss:  0.02706708486779148\n",
      "epoch:  1322 loss:  0.027571914856692394\n",
      "epoch:  1323 loss:  0.027981616407034386\n",
      "epoch:  1324 loss:  0.027388055640530873\n",
      "epoch:  1325 loss:  0.0270917838835812\n",
      "epoch:  1326 loss:  0.026571446920494478\n",
      "epoch:  1327 loss:  0.026596047887840424\n",
      "epoch:  1328 loss:  0.027196953095585466\n",
      "epoch:  1329 loss:  0.02694034193414282\n",
      "epoch:  1330 loss:  0.02738793001596229\n",
      "epoch:  1331 loss:  0.027145526686825426\n",
      "epoch:  1332 loss:  0.027116109089679027\n",
      "epoch:  1333 loss:  0.026937657857994478\n",
      "epoch:  1334 loss:  0.02676714855025571\n",
      "epoch:  1335 loss:  0.026889706040960717\n",
      "epoch:  1336 loss:  0.026436918327607303\n",
      "epoch:  1337 loss:  0.026487272331513555\n",
      "epoch:  1338 loss:  0.025875425530245983\n",
      "epoch:  1339 loss:  0.026581665406744164\n",
      "epoch:  1340 loss:  0.026372469859908383\n",
      "epoch:  1341 loss:  0.026235483927899095\n",
      "epoch:  1342 loss:  0.02649268950803213\n",
      "epoch:  1343 loss:  0.026351855174604668\n",
      "epoch:  1344 loss:  0.026863876404053716\n",
      "epoch:  1345 loss:  0.026330952471997366\n",
      "epoch:  1346 loss:  0.025914488643048756\n",
      "epoch:  1347 loss:  0.02628668053561904\n",
      "epoch:  1348 loss:  0.025981388321842054\n",
      "epoch:  1349 loss:  0.026051918857068902\n",
      "epoch:  1350 loss:  0.02617829717306727\n",
      "epoch:  1351 loss:  0.025672307454917324\n",
      "epoch:  1352 loss:  0.025753352153732118\n",
      "epoch:  1353 loss:  0.0251875682049487\n",
      "epoch:  1354 loss:  0.025970330295792547\n",
      "epoch:  1355 loss:  0.0258988621723221\n",
      "epoch:  1356 loss:  0.02523088416900022\n",
      "epoch:  1357 loss:  0.02565911840722264\n",
      "epoch:  1358 loss:  0.025735179487481174\n",
      "epoch:  1359 loss:  0.025264925363073388\n",
      "epoch:  1360 loss:  0.025188024743015028\n",
      "epoch:  1361 loss:  0.02500932839022104\n",
      "epoch:  1362 loss:  0.02573592404285109\n",
      "epoch:  1363 loss:  0.024862445693418205\n",
      "epoch:  1364 loss:  0.025433432337749435\n",
      "epoch:  1365 loss:  0.0249752703440716\n",
      "epoch:  1366 loss:  0.02524705756620231\n",
      "epoch:  1367 loss:  0.024996289479205885\n",
      "epoch:  1368 loss:  0.025608847131690825\n",
      "epoch:  1369 loss:  0.025023658783081545\n",
      "epoch:  1370 loss:  0.024323248192967183\n",
      "epoch:  1371 loss:  0.024732142375654964\n",
      "epoch:  1372 loss:  0.025312857264017004\n",
      "epoch:  1373 loss:  0.02453767707548946\n",
      "epoch:  1374 loss:  0.02454984733857304\n",
      "epoch:  1375 loss:  0.024135647815872865\n",
      "epoch:  1376 loss:  0.024201551690159074\n",
      "epoch:  1377 loss:  0.024399601886550108\n",
      "epoch:  1378 loss:  0.024905271415250847\n",
      "epoch:  1379 loss:  0.02418364252910078\n",
      "epoch:  1380 loss:  0.02394913516370168\n",
      "epoch:  1381 loss:  0.024766493035128796\n",
      "epoch:  1382 loss:  0.023923622652230015\n",
      "epoch:  1383 loss:  0.024165227805754266\n",
      "epoch:  1384 loss:  0.02418098756108418\n",
      "epoch:  1385 loss:  0.02355267474929013\n",
      "epoch:  1386 loss:  0.024327707865152013\n",
      "epoch:  1387 loss:  0.023836010239689225\n",
      "epoch:  1388 loss:  0.024889303306977913\n",
      "epoch:  1389 loss:  0.023430065170349366\n",
      "epoch:  1390 loss:  0.02350078261042216\n",
      "epoch:  1391 loss:  0.024230408572767634\n",
      "epoch:  1392 loss:  0.023258221484571098\n",
      "epoch:  1393 loss:  0.02369661139675891\n",
      "epoch:  1394 loss:  0.023067943159356175\n",
      "epoch:  1395 loss:  0.023443617303687405\n",
      "epoch:  1396 loss:  0.023577003019401827\n",
      "epoch:  1397 loss:  0.022892693822163655\n",
      "epoch:  1398 loss:  0.02294022893331137\n",
      "epoch:  1399 loss:  0.023472586022802146\n",
      "epoch:  1400 loss:  0.023074861702670056\n",
      "epoch:  1401 loss:  0.022618800090498714\n",
      "epoch:  1402 loss:  0.023319760671102377\n",
      "epoch:  1403 loss:  0.022649671562225464\n",
      "epoch:  1404 loss:  0.02297688373121392\n",
      "epoch:  1405 loss:  0.022611368324861946\n",
      "epoch:  1406 loss:  0.02312268789513523\n",
      "epoch:  1407 loss:  0.023043705277653582\n",
      "epoch:  1408 loss:  0.023078869432809363\n",
      "epoch:  1409 loss:  0.022595162755514243\n",
      "epoch:  1410 loss:  0.022802121572226407\n",
      "epoch:  1411 loss:  0.023215403422773125\n",
      "epoch:  1412 loss:  0.02230215723734783\n",
      "epoch:  1413 loss:  0.022478383994964234\n",
      "epoch:  1414 loss:  0.022288568335843372\n",
      "epoch:  1415 loss:  0.022743516178973706\n",
      "epoch:  1416 loss:  0.02284151559852692\n",
      "epoch:  1417 loss:  0.021779326166972576\n",
      "epoch:  1418 loss:  0.02236767351387974\n",
      "epoch:  1419 loss:  0.02157226010977504\n",
      "epoch:  1420 loss:  0.0217062969284364\n",
      "epoch:  1421 loss:  0.022359230623666543\n",
      "epoch:  1422 loss:  0.021632903072249937\n",
      "epoch:  1423 loss:  0.022023011785913184\n",
      "epoch:  1424 loss:  0.022495873386122616\n",
      "epoch:  1425 loss:  0.022619253564551172\n",
      "epoch:  1426 loss:  0.021910003294427712\n",
      "epoch:  1427 loss:  0.021390561023390438\n",
      "epoch:  1428 loss:  0.02149628175789094\n",
      "epoch:  1429 loss:  0.02192184111200662\n",
      "epoch:  1430 loss:  0.02168593808829066\n",
      "epoch:  1431 loss:  0.02234611970832549\n",
      "epoch:  1432 loss:  0.021883023120313285\n",
      "epoch:  1433 loss:  0.021963379948014713\n",
      "epoch:  1434 loss:  0.021568503628772905\n",
      "epoch:  1435 loss:  0.021239739536760324\n",
      "epoch:  1436 loss:  0.02140973409016927\n",
      "epoch:  1437 loss:  0.021443550079223144\n",
      "epoch:  1438 loss:  0.021903051046961282\n",
      "epoch:  1439 loss:  0.021361422251506026\n",
      "epoch:  1440 loss:  0.021306795480260887\n",
      "epoch:  1441 loss:  0.021403232252741433\n",
      "epoch:  1442 loss:  0.021378295775876945\n",
      "epoch:  1443 loss:  0.021473009040556757\n",
      "epoch:  1444 loss:  0.021309769105719755\n",
      "epoch:  1445 loss:  0.02163035534471872\n",
      "epoch:  1446 loss:  0.020725089383412557\n",
      "epoch:  1447 loss:  0.02098802620148563\n",
      "epoch:  1448 loss:  0.02070125748354747\n",
      "epoch:  1449 loss:  0.021013964610884946\n",
      "epoch:  1450 loss:  0.021526909640515186\n",
      "epoch:  1451 loss:  0.02105325446071395\n",
      "epoch:  1452 loss:  0.021368978109704444\n",
      "epoch:  1453 loss:  0.02116950927489254\n",
      "epoch:  1454 loss:  0.021582391271629486\n",
      "epoch:  1455 loss:  0.020977296024919993\n",
      "epoch:  1456 loss:  0.020674280373446912\n",
      "epoch:  1457 loss:  0.021281828363257718\n",
      "epoch:  1458 loss:  0.020617352527786927\n",
      "epoch:  1459 loss:  0.021083413549216397\n",
      "epoch:  1460 loss:  0.020761476080101655\n",
      "epoch:  1461 loss:  0.020728462862681193\n",
      "epoch:  1462 loss:  0.020469114004847515\n",
      "epoch:  1463 loss:  0.020581489777469254\n",
      "epoch:  1464 loss:  0.02100663242569889\n",
      "epoch:  1465 loss:  0.020559514670008158\n",
      "epoch:  1466 loss:  0.019914677631424134\n",
      "epoch:  1467 loss:  0.020265081321379268\n",
      "epoch:  1468 loss:  0.020470056189111917\n",
      "epoch:  1469 loss:  0.021303267268291917\n",
      "epoch:  1470 loss:  0.02028131753086565\n",
      "epoch:  1471 loss:  0.02035475275123933\n",
      "epoch:  1472 loss:  0.02052699169480657\n",
      "epoch:  1473 loss:  0.02066701866057982\n",
      "epoch:  1474 loss:  0.02026631611896806\n",
      "epoch:  1475 loss:  0.020669097593989237\n",
      "epoch:  1476 loss:  0.020097763184083992\n",
      "epoch:  1477 loss:  0.020275753281681415\n",
      "epoch:  1478 loss:  0.020592095861473238\n",
      "epoch:  1479 loss:  0.020458962926902923\n",
      "epoch:  1480 loss:  0.02005931134204788\n",
      "epoch:  1481 loss:  0.020368913091330165\n",
      "epoch:  1482 loss:  0.020170383376768793\n",
      "epoch:  1483 loss:  0.02017389780067536\n",
      "epoch:  1484 loss:  0.02075759550653787\n",
      "epoch:  1485 loss:  0.020082420134640122\n",
      "epoch:  1486 loss:  0.019925698889307227\n",
      "epoch:  1487 loss:  0.019670414445869415\n",
      "epoch:  1488 loss:  0.01964647530551895\n",
      "epoch:  1489 loss:  0.0192787338930919\n",
      "epoch:  1490 loss:  0.019477239095542324\n",
      "epoch:  1491 loss:  0.020313036202426894\n",
      "epoch:  1492 loss:  0.02009947290382232\n",
      "epoch:  1493 loss:  0.01981890268593907\n",
      "epoch:  1494 loss:  0.019902432300000786\n",
      "epoch:  1495 loss:  0.019411833123509664\n",
      "epoch:  1496 loss:  0.019414125005882906\n",
      "epoch:  1497 loss:  0.0195380613028285\n",
      "epoch:  1498 loss:  0.019916687624521524\n",
      "epoch:  1499 loss:  0.019725019769017475\n",
      "epoch:  1500 loss:  0.01925626547939806\n",
      "epoch:  1501 loss:  0.019359599347095413\n",
      "epoch:  1502 loss:  0.019594992212502355\n",
      "epoch:  1503 loss:  0.019276890888750314\n",
      "epoch:  1504 loss:  0.019344240977582205\n",
      "epoch:  1505 loss:  0.020096312373517507\n",
      "epoch:  1506 loss:  0.019825796717142005\n",
      "epoch:  1507 loss:  0.01948209555752306\n",
      "epoch:  1508 loss:  0.01941864902235897\n",
      "epoch:  1509 loss:  0.019502537126043235\n",
      "epoch:  1510 loss:  0.0198685121344754\n",
      "epoch:  1511 loss:  0.01969196671941673\n",
      "epoch:  1512 loss:  0.01903633822398971\n",
      "epoch:  1513 loss:  0.01854247740473613\n",
      "epoch:  1514 loss:  0.019138374481813974\n",
      "epoch:  1515 loss:  0.01980469025761248\n",
      "epoch:  1516 loss:  0.01932172047565261\n",
      "epoch:  1517 loss:  0.019484827125886357\n",
      "epoch:  1518 loss:  0.019219831290494007\n",
      "epoch:  1519 loss:  0.01934100384693069\n",
      "epoch:  1520 loss:  0.018935683836419897\n",
      "epoch:  1521 loss:  0.018924786671098457\n",
      "epoch:  1522 loss:  0.018676828284818963\n",
      "epoch:  1523 loss:  0.019319819255047534\n",
      "epoch:  1524 loss:  0.01857056521986383\n",
      "epoch:  1525 loss:  0.01907770394321426\n",
      "epoch:  1526 loss:  0.018147611809542857\n",
      "epoch:  1527 loss:  0.018422725018727253\n",
      "epoch:  1528 loss:  0.018785996034920933\n",
      "epoch:  1529 loss:  0.018794743794513992\n",
      "epoch:  1530 loss:  0.01884801780363642\n",
      "epoch:  1531 loss:  0.01857311447940198\n",
      "epoch:  1532 loss:  0.018600281558362356\n",
      "epoch:  1533 loss:  0.019175102816049353\n",
      "epoch:  1534 loss:  0.0189373246158462\n",
      "epoch:  1535 loss:  0.018830661697081294\n",
      "epoch:  1536 loss:  0.018574422813323607\n",
      "epoch:  1537 loss:  0.018332900388173787\n",
      "epoch:  1538 loss:  0.018166038788944842\n",
      "epoch:  1539 loss:  0.01872349168402124\n",
      "epoch:  1540 loss:  0.018207502556613173\n",
      "epoch:  1541 loss:  0.018074464606472766\n",
      "epoch:  1542 loss:  0.017830201420918047\n",
      "epoch:  1543 loss:  0.018661266158383535\n",
      "epoch:  1544 loss:  0.018890598404359627\n",
      "epoch:  1545 loss:  0.018634065375270615\n",
      "epoch:  1546 loss:  0.018640573340726187\n",
      "epoch:  1547 loss:  0.018294733499427396\n",
      "epoch:  1548 loss:  0.018116501344734408\n",
      "epoch:  1549 loss:  0.018703025603390124\n",
      "epoch:  1550 loss:  0.018297282758965548\n",
      "epoch:  1551 loss:  0.01854204691078768\n",
      "epoch:  1552 loss:  0.018604468533312938\n",
      "epoch:  1553 loss:  0.01799515107549338\n",
      "epoch:  1554 loss:  0.0188431981098221\n",
      "epoch:  1555 loss:  0.018515270493595477\n",
      "epoch:  1556 loss:  0.01832119738720507\n",
      "epoch:  1557 loss:  0.01817794554683578\n",
      "epoch:  1558 loss:  0.018408753115489302\n",
      "epoch:  1559 loss:  0.01743180148572807\n",
      "epoch:  1560 loss:  0.01812720394517523\n",
      "epoch:  1561 loss:  0.018029846436527358\n",
      "epoch:  1562 loss:  0.01815104810109579\n",
      "epoch:  1563 loss:  0.018520548257483057\n",
      "epoch:  1564 loss:  0.017309392599695658\n",
      "epoch:  1565 loss:  0.017656936032705038\n",
      "epoch:  1566 loss:  0.018254827782810932\n",
      "epoch:  1567 loss:  0.017924949921757343\n",
      "epoch:  1568 loss:  0.017644125390723048\n",
      "epoch:  1569 loss:  0.017990967164556664\n",
      "epoch:  1570 loss:  0.01767383713320077\n",
      "epoch:  1571 loss:  0.017766017990418707\n",
      "epoch:  1572 loss:  0.017868876935966522\n",
      "epoch:  1573 loss:  0.017906526006369227\n",
      "epoch:  1574 loss:  0.017816301522005994\n",
      "epoch:  1575 loss:  0.0181893375503969\n",
      "epoch:  1576 loss:  0.018171858883287054\n",
      "epoch:  1577 loss:  0.017517567829913403\n",
      "epoch:  1578 loss:  0.017658572216110537\n",
      "epoch:  1579 loss:  0.018025611969361824\n",
      "epoch:  1580 loss:  0.017240904229711817\n",
      "epoch:  1581 loss:  0.017406099005396587\n",
      "epoch:  1582 loss:  0.017187083294113954\n",
      "epoch:  1583 loss:  0.0177980047631934\n",
      "epoch:  1584 loss:  0.017763381406485316\n",
      "epoch:  1585 loss:  0.016967433331960654\n",
      "epoch:  1586 loss:  0.01736894936925436\n",
      "epoch:  1587 loss:  0.017816830064398218\n",
      "epoch:  1588 loss:  0.01727954910462161\n",
      "epoch:  1589 loss:  0.01767705281575521\n",
      "epoch:  1590 loss:  0.017505075845373683\n",
      "epoch:  1591 loss:  0.018068992277704567\n",
      "epoch:  1592 loss:  0.017588305186076337\n",
      "epoch:  1593 loss:  0.017326782410403332\n",
      "epoch:  1594 loss:  0.01726745697389166\n",
      "epoch:  1595 loss:  0.0169151137631581\n",
      "epoch:  1596 loss:  0.016592788696289062\n",
      "epoch:  1597 loss:  0.01752622673310429\n",
      "epoch:  1598 loss:  0.01716150643835106\n",
      "epoch:  1599 loss:  0.017175613158199203\n",
      "epoch:  1600 loss:  0.016911055476789973\n",
      "epoch:  1601 loss:  0.017253478942625973\n",
      "epoch:  1602 loss:  0.0168575945628216\n",
      "epoch:  1603 loss:  0.016641252203638775\n",
      "epoch:  1604 loss:  0.017497601183542766\n",
      "epoch:  1605 loss:  0.017177970916870608\n",
      "epoch:  1606 loss:  0.016671512404598864\n",
      "epoch:  1607 loss:  0.01760573636097123\n",
      "epoch:  1608 loss:  0.016499397553593278\n",
      "epoch:  1609 loss:  0.017421710156053902\n",
      "epoch:  1610 loss:  0.017527933388828753\n",
      "epoch:  1611 loss:  0.016934979297071096\n",
      "epoch:  1612 loss:  0.016813420674887048\n",
      "epoch:  1613 loss:  0.016873625483378826\n",
      "epoch:  1614 loss:  0.016368397172675075\n",
      "epoch:  1615 loss:  0.017335300368956294\n",
      "epoch:  1616 loss:  0.016579614968663718\n",
      "epoch:  1617 loss:  0.016740930702791635\n",
      "epoch:  1618 loss:  0.017253652059409513\n",
      "epoch:  1619 loss:  0.017117093557334807\n",
      "epoch:  1620 loss:  0.016557149618983746\n",
      "epoch:  1621 loss:  0.01626843218822556\n",
      "epoch:  1622 loss:  0.01680275484261264\n",
      "epoch:  1623 loss:  0.016656843438205948\n",
      "epoch:  1624 loss:  0.01670802472585655\n",
      "epoch:  1625 loss:  0.01644159493197399\n",
      "epoch:  1626 loss:  0.016138144190531657\n",
      "epoch:  1627 loss:  0.01705484045557229\n",
      "epoch:  1628 loss:  0.016818874619572037\n",
      "epoch:  1629 loss:  0.01635477303501114\n",
      "epoch:  1630 loss:  0.01636934854898108\n",
      "epoch:  1631 loss:  0.01654523979707894\n",
      "epoch:  1632 loss:  0.01623759901667216\n",
      "epoch:  1633 loss:  0.01658608003792514\n",
      "epoch:  1634 loss:  0.017211955426687218\n",
      "epoch:  1635 loss:  0.017036595784995452\n",
      "epoch:  1636 loss:  0.016196248617516944\n",
      "epoch:  1637 loss:  0.016313008993983746\n",
      "epoch:  1638 loss:  0.016675532390793644\n",
      "epoch:  1639 loss:  0.0167935888451266\n",
      "epoch:  1640 loss:  0.01635872561290082\n",
      "epoch:  1641 loss:  0.01654269053754079\n",
      "epoch:  1642 loss:  0.015339472207678369\n",
      "epoch:  1643 loss:  0.01630187896360834\n",
      "epoch:  1644 loss:  0.015915250969699108\n",
      "epoch:  1645 loss:  0.016115193194653616\n",
      "epoch:  1646 loss:  0.01629062177665741\n",
      "epoch:  1647 loss:  0.01638258815290459\n",
      "epoch:  1648 loss:  0.016383991471256118\n",
      "epoch:  1649 loss:  0.016097955052632406\n",
      "epoch:  1650 loss:  0.01629014532250094\n",
      "epoch:  1651 loss:  0.016076439547251506\n",
      "epoch:  1652 loss:  0.015561533548745765\n",
      "epoch:  1653 loss:  0.016251558663854637\n",
      "epoch:  1654 loss:  0.015694888624321505\n",
      "epoch:  1655 loss:  0.0162031978009695\n",
      "epoch:  1656 loss:  0.016017774405728383\n",
      "epoch:  1657 loss:  0.01624777001070689\n",
      "epoch:  1658 loss:  0.0160510787044663\n",
      "epoch:  1659 loss:  0.015286377443367218\n",
      "epoch:  1660 loss:  0.016098638327724964\n",
      "epoch:  1661 loss:  0.015597456047333867\n",
      "epoch:  1662 loss:  0.015985393907171654\n",
      "epoch:  1663 loss:  0.016118606506102535\n",
      "epoch:  1664 loss:  0.015986838589710405\n",
      "epoch:  1665 loss:  0.015542936516574108\n",
      "epoch:  1666 loss:  0.016285314904638085\n",
      "epoch:  1667 loss:  0.016003430224805472\n",
      "epoch:  1668 loss:  0.0160854186398916\n",
      "epoch:  1669 loss:  0.01600465889436653\n",
      "epoch:  1670 loss:  0.016121632219797156\n",
      "epoch:  1671 loss:  0.01583459540064555\n",
      "epoch:  1672 loss:  0.015527129269029242\n",
      "epoch:  1673 loss:  0.016248482393931195\n",
      "epoch:  1674 loss:  0.015200571267001601\n",
      "epoch:  1675 loss:  0.015600150847530749\n",
      "epoch:  1676 loss:  0.015634610279496895\n",
      "epoch:  1677 loss:  0.01630497974564273\n",
      "epoch:  1678 loss:  0.015184918752157066\n",
      "epoch:  1679 loss:  0.01500324877390421\n",
      "epoch:  1680 loss:  0.015438678848695564\n",
      "epoch:  1681 loss:  0.015259596430154211\n",
      "epoch:  1682 loss:  0.016260667977084118\n",
      "epoch:  1683 loss:  0.015626369614198984\n",
      "epoch:  1684 loss:  0.015516659533642382\n",
      "epoch:  1685 loss:  0.015726509247438975\n",
      "epoch:  1686 loss:  0.016043973256306476\n",
      "epoch:  1687 loss:  0.015320913475680063\n",
      "epoch:  1688 loss:  0.015177764279775352\n",
      "epoch:  1689 loss:  0.015252460341855704\n",
      "epoch:  1690 loss:  0.01588574451615054\n",
      "epoch:  1691 loss:  0.015420711471373777\n",
      "epoch:  1692 loss:  0.01544990386350088\n",
      "epoch:  1693 loss:  0.015579827243544491\n",
      "epoch:  1694 loss:  0.015453545443982962\n",
      "epoch:  1695 loss:  0.01564387432542671\n",
      "epoch:  1696 loss:  0.015530027826148343\n",
      "epoch:  1697 loss:  0.015452215661964263\n",
      "epoch:  1698 loss:  0.015020266306926926\n",
      "epoch:  1699 loss:  0.015903417748141\n",
      "epoch:  1700 loss:  0.01465905277604559\n",
      "epoch:  1701 loss:  0.015604081977323356\n",
      "epoch:  1702 loss:  0.014704649898421813\n",
      "epoch:  1703 loss:  0.015340500184331075\n",
      "epoch:  1704 loss:  0.015269514643044836\n",
      "epoch:  1705 loss:  0.015281626689864929\n",
      "epoch:  1706 loss:  0.014930702117552241\n",
      "epoch:  1707 loss:  0.01576929054107053\n",
      "epoch:  1708 loss:  0.014376661001917828\n",
      "epoch:  1709 loss:  0.014844024229241184\n",
      "epoch:  1710 loss:  0.014924603197948041\n",
      "epoch:  1711 loss:  0.01505050505978994\n",
      "epoch:  1712 loss:  0.015331404659164\n",
      "epoch:  1713 loss:  0.015416993290544993\n",
      "epoch:  1714 loss:  0.014544149191982774\n",
      "epoch:  1715 loss:  0.014939567841679217\n",
      "epoch:  1716 loss:  0.01510496024625847\n",
      "epoch:  1717 loss:  0.015003438742764025\n",
      "epoch:  1718 loss:  0.014530981592385165\n",
      "epoch:  1719 loss:  0.01445212919549291\n",
      "epoch:  1720 loss:  0.01459601988275367\n",
      "epoch:  1721 loss:  0.015041142965416353\n",
      "epoch:  1722 loss:  0.015286602648386514\n",
      "epoch:  1723 loss:  0.014842193480955071\n",
      "epoch:  1724 loss:  0.014219942820598802\n",
      "epoch:  1725 loss:  0.014732463484308327\n",
      "epoch:  1726 loss:  0.014577851812523532\n",
      "epoch:  1727 loss:  0.014105504966643919\n",
      "epoch:  1728 loss:  0.015184541878451306\n",
      "epoch:  1729 loss:  0.015353307762299196\n",
      "epoch:  1730 loss:  0.01478422540258691\n",
      "epoch:  1731 loss:  0.014447834980056947\n",
      "epoch:  1732 loss:  0.014557614000925577\n",
      "epoch:  1733 loss:  0.015437310766503514\n",
      "epoch:  1734 loss:  0.014982157634444026\n",
      "epoch:  1735 loss:  0.014867557387754141\n",
      "epoch:  1736 loss:  0.014625939978174416\n",
      "epoch:  1737 loss:  0.01489736717867564\n",
      "epoch:  1738 loss:  0.015026372886565794\n",
      "epoch:  1739 loss:  0.014679024018437029\n",
      "epoch:  1740 loss:  0.014447301841643919\n",
      "epoch:  1741 loss:  0.01469932923834008\n",
      "epoch:  1742 loss:  0.014736576922926079\n",
      "epoch:  1743 loss:  0.014478374006279023\n",
      "epoch:  1744 loss:  0.014563362090941893\n",
      "epoch:  1745 loss:  0.014519224971173757\n",
      "epoch:  1746 loss:  0.014592350726146775\n",
      "epoch:  1747 loss:  0.014182013392927177\n",
      "epoch:  1748 loss:  0.014891344859418142\n",
      "epoch:  1749 loss:  0.014356185729245106\n",
      "epoch:  1750 loss:  0.014560596818426048\n",
      "epoch:  1751 loss:  0.01444295860198607\n",
      "epoch:  1752 loss:  0.014244238918564885\n",
      "epoch:  1753 loss:  0.014790246189837476\n",
      "epoch:  1754 loss:  0.014201802326493474\n",
      "epoch:  1755 loss:  0.014131379031752008\n",
      "epoch:  1756 loss:  0.014156502413462443\n",
      "epoch:  1757 loss:  0.014824656597581733\n",
      "epoch:  1758 loss:  0.014457762384989175\n",
      "epoch:  1759 loss:  0.014404891293690386\n",
      "epoch:  1760 loss:  0.014327275226393857\n",
      "epoch:  1761 loss:  0.014564425303754078\n",
      "epoch:  1762 loss:  0.014393563634420495\n",
      "epoch:  1763 loss:  0.014356269989626474\n",
      "epoch:  1764 loss:  0.014147636689335467\n",
      "epoch:  1765 loss:  0.014037770344071599\n",
      "epoch:  1766 loss:  0.014410021984912305\n",
      "epoch:  1767 loss:  0.014529794287011327\n",
      "epoch:  1768 loss:  0.014112302481410014\n",
      "epoch:  1769 loss:  0.013973704878106175\n",
      "epoch:  1770 loss:  0.014501773880188723\n",
      "epoch:  1771 loss:  0.014198669372313472\n",
      "epoch:  1772 loss:  0.014163568029441987\n",
      "epoch:  1773 loss:  0.01426606082533258\n",
      "epoch:  1774 loss:  0.01422828306634742\n",
      "epoch:  1775 loss:  0.01427581970950207\n",
      "epoch:  1776 loss:  0.013947323718702937\n",
      "epoch:  1777 loss:  0.013791728498466523\n",
      "epoch:  1778 loss:  0.014477941980323638\n",
      "epoch:  1779 loss:  0.013325256899178746\n",
      "epoch:  1780 loss:  0.014281005552973612\n",
      "epoch:  1781 loss:  0.01363055370897653\n",
      "epoch:  1782 loss:  0.013768434333035266\n",
      "epoch:  1783 loss:  0.014697313117214953\n",
      "epoch:  1784 loss:  0.014245504356292358\n",
      "epoch:  1785 loss:  0.014399409772880584\n",
      "epoch:  1786 loss:  0.013437252734080855\n",
      "epoch:  1787 loss:  0.013992669591941986\n",
      "epoch:  1788 loss:  0.014151901796639684\n",
      "epoch:  1789 loss:  0.014447142512922785\n",
      "epoch:  1790 loss:  0.013880860661885824\n",
      "epoch:  1791 loss:  0.013849195610567269\n",
      "epoch:  1792 loss:  0.01387600419990509\n",
      "epoch:  1793 loss:  0.01477459367499294\n",
      "epoch:  1794 loss:  0.013774759989665694\n",
      "epoch:  1795 loss:  0.014344358635714734\n",
      "epoch:  1796 loss:  0.013804028982139496\n",
      "epoch:  1797 loss:  0.013130166540184174\n",
      "epoch:  1798 loss:  0.013860180100283948\n",
      "epoch:  1799 loss:  0.014443736861508533\n",
      "epoch:  1800 loss:  0.01356201937878467\n",
      "epoch:  1801 loss:  0.013609704626611917\n",
      "epoch:  1802 loss:  0.013866159523347295\n",
      "epoch:  1803 loss:  0.014284657857504235\n",
      "epoch:  1804 loss:  0.01355936747478194\n",
      "epoch:  1805 loss:  0.013734053033422754\n",
      "epoch:  1806 loss:  0.013953298545745481\n",
      "epoch:  1807 loss:  0.01381400847530748\n",
      "epoch:  1808 loss:  0.013642069805099303\n",
      "epoch:  1809 loss:  0.013264322855386389\n",
      "epoch:  1810 loss:  0.013888836289984155\n",
      "epoch:  1811 loss:  0.013003180017433013\n",
      "epoch:  1812 loss:  0.012918642342808736\n",
      "epoch:  1813 loss:  0.013641702123435146\n",
      "epoch:  1814 loss:  0.014271505577975966\n",
      "epoch:  1815 loss:  0.013113398724291698\n",
      "epoch:  1816 loss:  0.013621337155261672\n",
      "epoch:  1817 loss:  0.01396989018084055\n",
      "epoch:  1818 loss:  0.013088217126317771\n",
      "epoch:  1819 loss:  0.013597617091902768\n",
      "epoch:  1820 loss:  0.013427103188143198\n",
      "epoch:  1821 loss:  0.01330397272684488\n",
      "epoch:  1822 loss:  0.013199554198238265\n",
      "epoch:  1823 loss:  0.01356115839088777\n",
      "epoch:  1824 loss:  0.013180137542356928\n",
      "epoch:  1825 loss:  0.01398584143703721\n",
      "epoch:  1826 loss:  0.012785240541021509\n",
      "epoch:  1827 loss:  0.012702787161830917\n",
      "epoch:  1828 loss:  0.01392392537680017\n",
      "epoch:  1829 loss:  0.013150817993654305\n",
      "epoch:  1830 loss:  0.013222456169894422\n",
      "epoch:  1831 loss:  0.013353284966036019\n",
      "epoch:  1832 loss:  0.012925041535771994\n",
      "epoch:  1833 loss:  0.012875664952289628\n",
      "epoch:  1834 loss:  0.013524862082607775\n",
      "epoch:  1835 loss:  0.012681034195375251\n",
      "epoch:  1836 loss:  0.013575741564892382\n",
      "epoch:  1837 loss:  0.01269860631490807\n",
      "epoch:  1838 loss:  0.013314972536630899\n",
      "epoch:  1839 loss:  0.012907382091843939\n",
      "epoch:  1840 loss:  0.013311144051302867\n",
      "epoch:  1841 loss:  0.013325534192433798\n",
      "epoch:  1842 loss:  0.012787550041474492\n",
      "epoch:  1843 loss:  0.01267698433504526\n",
      "epoch:  1844 loss:  0.013235439928659953\n",
      "epoch:  1845 loss:  0.013077303108920055\n",
      "epoch:  1846 loss:  0.01301163056768088\n",
      "epoch:  1847 loss:  0.013430971505651512\n",
      "epoch:  1848 loss:  0.013480824543290349\n",
      "epoch:  1849 loss:  0.013631145063653049\n",
      "epoch:  1850 loss:  0.013417169655183234\n",
      "epoch:  1851 loss:  0.012571141805993506\n",
      "epoch:  1852 loss:  0.013261464130447572\n",
      "epoch:  1853 loss:  0.011922475516077984\n",
      "epoch:  1854 loss:  0.013122570849805473\n",
      "epoch:  1855 loss:  0.013891431509730328\n",
      "epoch:  1856 loss:  0.01305789870909419\n",
      "epoch:  1857 loss:  0.012738553395711753\n",
      "epoch:  1858 loss:  0.012897646187778458\n",
      "epoch:  1859 loss:  0.013184433289799824\n",
      "epoch:  1860 loss:  0.013641495302499059\n",
      "epoch:  1861 loss:  0.012149352720942364\n",
      "epoch:  1862 loss:  0.012867177633875345\n",
      "epoch:  1863 loss:  0.01307226587012111\n",
      "epoch:  1864 loss:  0.011838585114383314\n",
      "epoch:  1865 loss:  0.013387704565821881\n",
      "epoch:  1866 loss:  0.013650100585447258\n",
      "epoch:  1867 loss:  0.013301406615230453\n",
      "epoch:  1868 loss:  0.012770306537429013\n",
      "epoch:  1869 loss:  0.012429552959151057\n",
      "epoch:  1870 loss:  0.012515355305499342\n",
      "epoch:  1871 loss:  0.013010457050369446\n",
      "epoch:  1872 loss:  0.012349555387075646\n",
      "epoch:  1873 loss:  0.012876427891742752\n",
      "epoch:  1874 loss:  0.013146899119917168\n",
      "epoch:  1875 loss:  0.012636636634428338\n",
      "epoch:  1876 loss:  0.012995083360786898\n",
      "epoch:  1877 loss:  0.012460488775169035\n",
      "epoch:  1878 loss:  0.01235181662931021\n",
      "epoch:  1879 loss:  0.012719447737238014\n",
      "epoch:  1880 loss:  0.012693138582160673\n",
      "epoch:  1881 loss:  0.0126039152643288\n",
      "epoch:  1882 loss:  0.01241037299834102\n",
      "epoch:  1883 loss:  0.012507371251362873\n",
      "epoch:  1884 loss:  0.012287221088945626\n",
      "epoch:  1885 loss:  0.012405449128055189\n",
      "epoch:  1886 loss:  0.012232761306456294\n",
      "epoch:  1887 loss:  0.014009852581713573\n",
      "epoch:  1888 loss:  0.012634443566502337\n",
      "epoch:  1889 loss:  0.011844264264087601\n",
      "epoch:  1890 loss:  0.012663775371260432\n",
      "epoch:  1891 loss:  0.013386275203352472\n",
      "epoch:  1892 loss:  0.012405228519056696\n",
      "epoch:  1893 loss:  0.012924313832478352\n",
      "epoch:  1894 loss:  0.012157230300596919\n",
      "epoch:  1895 loss:  0.012461566542047095\n",
      "epoch:  1896 loss:  0.011995356149941563\n",
      "epoch:  1897 loss:  0.012155187369350449\n",
      "epoch:  1898 loss:  0.012389900023678698\n",
      "epoch:  1899 loss:  0.012514289794676755\n",
      "epoch:  1900 loss:  0.012551979463263209\n",
      "epoch:  1901 loss:  0.011796407431483748\n",
      "epoch:  1902 loss:  0.012654626991854136\n",
      "epoch:  1903 loss:  0.012853951818014244\n",
      "epoch:  1904 loss:  0.011959152528081074\n",
      "epoch:  1905 loss:  0.012135535550404744\n",
      "epoch:  1906 loss:  0.012522456157638365\n",
      "epoch:  1907 loss:  0.012652425497889997\n",
      "epoch:  1908 loss:  0.012340924826013037\n",
      "epoch:  1909 loss:  0.012070790639364098\n",
      "epoch:  1910 loss:  0.01172540886813857\n",
      "epoch:  1911 loss:  0.012057050069173177\n",
      "epoch:  1912 loss:  0.012094713693641755\n",
      "epoch:  1913 loss:  0.011959360881024096\n",
      "epoch:  1914 loss:  0.01208419187001914\n",
      "epoch:  1915 loss:  0.011850478850215314\n",
      "epoch:  1916 loss:  0.012178771084092228\n",
      "epoch:  1917 loss:  0.01244236589914345\n",
      "epoch:  1918 loss:  0.012537069971781658\n",
      "epoch:  1919 loss:  0.01331984278667404\n",
      "epoch:  1920 loss:  0.012152322516383894\n",
      "epoch:  1921 loss:  0.011970095653610536\n",
      "epoch:  1922 loss:  0.013054171336223802\n",
      "epoch:  1923 loss:  0.012194500965286929\n",
      "epoch:  1924 loss:  0.012828406368393495\n",
      "epoch:  1925 loss:  0.012587705098960294\n",
      "epoch:  1926 loss:  0.012460147137622756\n",
      "epoch:  1927 loss:  0.012576214280951932\n",
      "epoch:  1928 loss:  0.011559472601097751\n",
      "epoch:  1929 loss:  0.01220292470541345\n",
      "epoch:  1930 loss:  0.012247815572593107\n",
      "epoch:  1931 loss:  0.012141007113169474\n",
      "epoch:  1932 loss:  0.012324662572408775\n",
      "epoch:  1933 loss:  0.01227733121818328\n",
      "epoch:  1934 loss:  0.011960280851187955\n",
      "epoch:  1935 loss:  0.01167603075264927\n",
      "epoch:  1936 loss:  0.012303863280269516\n",
      "epoch:  1937 loss:  0.012690871211898375\n",
      "epoch:  1938 loss:  0.011394219609149488\n",
      "epoch:  1939 loss:  0.011996633843724508\n",
      "epoch:  1940 loss:  0.011820698933429028\n",
      "epoch:  1941 loss:  0.011984066024841554\n",
      "epoch:  1942 loss:  0.012288923148649284\n",
      "epoch:  1943 loss:  0.011748387440141426\n",
      "epoch:  1944 loss:  0.011741878708682386\n",
      "epoch:  1945 loss:  0.011544190065927773\n",
      "epoch:  1946 loss:  0.011603094966536066\n",
      "epoch:  1947 loss:  0.011962332974476029\n",
      "epoch:  1948 loss:  0.012004732798381023\n",
      "epoch:  1949 loss:  0.01224978879752408\n",
      "epoch:  1950 loss:  0.011822138253943508\n",
      "epoch:  1951 loss:  0.013005582204305503\n",
      "epoch:  1952 loss:  0.011873407631992815\n",
      "epoch:  1953 loss:  0.012120858923977159\n",
      "epoch:  1954 loss:  0.011534591276482885\n",
      "epoch:  1955 loss:  0.011747723315135543\n",
      "epoch:  1956 loss:  0.012714383688317723\n",
      "epoch:  1957 loss:  0.012004697562221542\n",
      "epoch:  1958 loss:  0.01164101137214875\n",
      "epoch:  1959 loss:  0.01108626400131777\n",
      "epoch:  1960 loss:  0.011485429173971275\n",
      "epoch:  1961 loss:  0.011484672362545887\n",
      "epoch:  1962 loss:  0.01156285297439759\n",
      "epoch:  1963 loss:  0.012531593812996126\n",
      "epoch:  1964 loss:  0.01221679779420416\n",
      "epoch:  1965 loss:  0.011276243585180565\n",
      "epoch:  1966 loss:  0.011472300640550484\n",
      "epoch:  1967 loss:  0.012529895583309802\n",
      "epoch:  1968 loss:  0.011856434527171184\n",
      "epoch:  1969 loss:  0.011905208265925029\n",
      "epoch:  1970 loss:  0.011340388715506557\n",
      "epoch:  1971 loss:  0.011292269143713526\n",
      "epoch:  1972 loss:  0.012179511043441343\n",
      "epoch:  1973 loss:  0.011224040448904994\n",
      "epoch:  1974 loss:  0.011554894964379\n",
      "epoch:  1975 loss:  0.01198269641064257\n",
      "epoch:  1976 loss:  0.011203144640328894\n",
      "epoch:  1977 loss:  0.011972129392815401\n",
      "epoch:  1978 loss:  0.011284234533348236\n",
      "epoch:  1979 loss:  0.0116463688003969\n",
      "epoch:  1980 loss:  0.01160841256260393\n",
      "epoch:  1981 loss:  0.01097360404140978\n",
      "epoch:  1982 loss:  0.01263898979707894\n",
      "epoch:  1983 loss:  0.011741807470359956\n",
      "epoch:  1984 loss:  0.01130907296176895\n",
      "epoch:  1985 loss:  0.01211595496978147\n",
      "epoch:  1986 loss:  0.011114468248972453\n",
      "epoch:  1987 loss:  0.011717722789350762\n",
      "epoch:  1988 loss:  0.011869092734463243\n",
      "epoch:  1989 loss:  0.011841657554289424\n",
      "epoch:  1990 loss:  0.011868727350809488\n",
      "epoch:  1991 loss:  0.011354539863555786\n",
      "epoch:  1992 loss:  0.011471917638816987\n",
      "epoch:  1993 loss:  0.011474213351207565\n",
      "epoch:  1994 loss:  0.010811648694386923\n",
      "epoch:  1995 loss:  0.011656518346334558\n",
      "epoch:  1996 loss:  0.012241944156018605\n",
      "epoch:  1997 loss:  0.011634638989306837\n",
      "epoch:  1998 loss:  0.011898326490777563\n",
      "epoch:  1999 loss:  0.011189593272994321\n",
      "epoch:  2000 loss:  0.011411893607143418\n",
      "epoch:  2001 loss:  0.011156819814659026\n",
      "epoch:  2002 loss:  0.011734794708619635\n",
      "epoch:  2003 loss:  0.011206217080235002\n",
      "epoch:  2004 loss:  0.011246520352650839\n",
      "epoch:  2005 loss:  0.011447073848372003\n",
      "epoch:  2006 loss:  0.011780357360839844\n",
      "epoch:  2007 loss:  0.010835439996068258\n",
      "epoch:  2008 loss:  0.011123543858049385\n",
      "epoch:  2009 loss:  0.01155313239040145\n",
      "epoch:  2010 loss:  0.01153541779422377\n",
      "epoch:  2011 loss:  0.01146890571318477\n",
      "epoch:  2012 loss:  0.01195065831563559\n",
      "epoch:  2013 loss:  0.01154907180602292\n",
      "epoch:  2014 loss:  0.011205956639056224\n",
      "epoch:  2015 loss:  0.011297952889438613\n",
      "epoch:  2016 loss:  0.011476086995687829\n",
      "epoch:  2017 loss:  0.010372172589282913\n",
      "epoch:  2018 loss:  0.011515340843353884\n",
      "epoch:  2019 loss:  0.011207439621768324\n",
      "epoch:  2020 loss:  0.012097737875329443\n",
      "epoch:  2021 loss:  0.012031349886852095\n",
      "epoch:  2022 loss:  0.011203444913687955\n",
      "epoch:  2023 loss:  0.011519204564841398\n",
      "epoch:  2024 loss:  0.011243604943455462\n",
      "epoch:  2025 loss:  0.011484588868167984\n",
      "epoch:  2026 loss:  0.011010465660248415\n",
      "epoch:  2027 loss:  0.01080315141792757\n",
      "epoch:  2028 loss:  0.011435520984082816\n",
      "epoch:  2029 loss:  0.011548785320726264\n",
      "epoch:  2030 loss:  0.011545537466026214\n",
      "epoch:  2031 loss:  0.011381959723660266\n",
      "epoch:  2032 loss:  0.011008573631684943\n",
      "epoch:  2033 loss:  0.0118955941564108\n",
      "epoch:  2034 loss:  0.010934528672551534\n",
      "epoch:  2035 loss:  0.010966447271017664\n",
      "epoch:  2036 loss:  0.011161141606219801\n",
      "epoch:  2037 loss:  0.011435982884173412\n",
      "epoch:  2038 loss:  0.01042578823595162\n",
      "epoch:  2039 loss:  0.011766749309248713\n",
      "epoch:  2040 loss:  0.010829786890481849\n",
      "epoch:  2041 loss:  0.011250370286075945\n",
      "epoch:  2042 loss:  0.010652050340032002\n",
      "epoch:  2043 loss:  0.011083586053197163\n",
      "epoch:  2044 loss:  0.011945874623984219\n",
      "epoch:  2045 loss:  0.011590594555958207\n",
      "epoch:  2046 loss:  0.011394778025676927\n",
      "epoch:  2047 loss:  0.011153006649400336\n",
      "epoch:  2048 loss:  0.011175207727884193\n",
      "epoch:  2049 loss:  0.010830345307009288\n",
      "epoch:  2050 loss:  0.011003540222903332\n",
      "epoch:  2051 loss:  0.01107344110328031\n",
      "epoch:  2052 loss:  0.011133580035473926\n",
      "epoch:  2053 loss:  0.011522836953281877\n",
      "epoch:  2054 loss:  0.010945756751370717\n",
      "epoch:  2055 loss:  0.011191418659256165\n",
      "epoch:  2056 loss:  0.010667800903320312\n",
      "epoch:  2057 loss:  0.011052723773512017\n",
      "epoch:  2058 loss:  0.011885387926216585\n",
      "epoch:  2059 loss:  0.010859913806838683\n",
      "epoch:  2060 loss:  0.011305317246770284\n",
      "epoch:  2061 loss:  0.011014639613140061\n",
      "epoch:  2062 loss:  0.01092239134761703\n",
      "epoch:  2063 loss:  0.011255174659820925\n",
      "epoch:  2064 loss:  0.010757595659738564\n",
      "epoch:  2065 loss:  0.010978996705817411\n",
      "epoch:  2066 loss:  0.01084893774316014\n",
      "epoch:  2067 loss:  0.010473350923224146\n",
      "epoch:  2068 loss:  0.010951103455570328\n",
      "epoch:  2069 loss:  0.010673004364871596\n",
      "epoch:  2070 loss:  0.01111636410755326\n",
      "epoch:  2071 loss:  0.010358731526447586\n",
      "epoch:  2072 loss:  0.011876314615150053\n",
      "epoch:  2073 loss:  0.01085076159741505\n",
      "epoch:  2074 loss:  0.011071803387867878\n",
      "epoch:  2075 loss:  0.010665390290409686\n",
      "epoch:  2076 loss:  0.01110646504474931\n",
      "epoch:  2077 loss:  0.011512338875766739\n",
      "epoch:  2078 loss:  0.010743545624146979\n",
      "epoch:  2079 loss:  0.010600108410938676\n",
      "epoch:  2080 loss:  0.011292383278230109\n",
      "epoch:  2081 loss:  0.0110968945974327\n",
      "epoch:  2082 loss:  0.010660303261385385\n",
      "epoch:  2083 loss:  0.011299083510555896\n",
      "epoch:  2084 loss:  0.010808542550328266\n",
      "epoch:  2085 loss:  0.010826674618395456\n",
      "epoch:  2086 loss:  0.010593423498682229\n",
      "epoch:  2087 loss:  0.010977224939798256\n",
      "epoch:  2088 loss:  0.010559507929177647\n",
      "epoch:  2089 loss:  0.011299895474230909\n",
      "epoch:  2090 loss:  0.01082512499338173\n",
      "epoch:  2091 loss:  0.010399895786760323\n",
      "epoch:  2092 loss:  0.011020740830754659\n",
      "epoch:  2093 loss:  0.010907857963837773\n",
      "epoch:  2094 loss:  0.010742792642738924\n",
      "epoch:  2095 loss:  0.010786925932489725\n",
      "epoch:  2096 loss:  0.010953895538207518\n",
      "epoch:  2097 loss:  0.011810406910846512\n",
      "epoch:  2098 loss:  0.01042667450196293\n",
      "epoch:  2099 loss:  0.010290977753788592\n",
      "epoch:  2100 loss:  0.010887373499123446\n",
      "epoch:  2101 loss:  0.01070336797629973\n",
      "epoch:  2102 loss:  0.010439730265054358\n",
      "epoch:  2103 loss:  0.01048663725335914\n",
      "epoch:  2104 loss:  0.010260506901875079\n",
      "epoch:  2105 loss:  0.010279568898151199\n",
      "epoch:  2106 loss:  0.010479171783569826\n",
      "epoch:  2107 loss:  0.010089796135224491\n",
      "epoch:  2108 loss:  0.010628028471307104\n",
      "epoch:  2109 loss:  0.010683589000778504\n",
      "epoch:  2110 loss:  0.011413385015893653\n",
      "epoch:  2111 loss:  0.010536658811760715\n",
      "epoch:  2112 loss:  0.010405324453330901\n",
      "epoch:  2113 loss:  0.010817674077658289\n",
      "epoch:  2114 loss:  0.010601675654032144\n",
      "epoch:  2115 loss:  0.00974685868106214\n",
      "epoch:  2116 loss:  0.010263210894113564\n",
      "epoch:  2117 loss:  0.011032258458884366\n",
      "epoch:  2118 loss:  0.010614160744540663\n",
      "epoch:  2119 loss:  0.010451422541974538\n",
      "epoch:  2120 loss:  0.011175511065257122\n",
      "epoch:  2121 loss:  0.010876794991244275\n",
      "epoch:  2122 loss:  0.010111870057132828\n",
      "epoch:  2123 loss:  0.010155906830446787\n",
      "epoch:  2124 loss:  0.01046128024059127\n",
      "epoch:  2125 loss:  0.010768943235098598\n",
      "epoch:  2126 loss:  0.011021733571247883\n",
      "epoch:  2127 loss:  0.010234270517127102\n",
      "epoch:  2128 loss:  0.010278620585859061\n",
      "epoch:  2129 loss:  0.010390267889183688\n",
      "epoch:  2130 loss:  0.010715450914988078\n",
      "epoch:  2131 loss:  0.011219283567374968\n",
      "epoch:  2132 loss:  0.009959128199810962\n",
      "epoch:  2133 loss:  0.011135463637999263\n",
      "epoch:  2134 loss:  0.010344227250800076\n",
      "epoch:  2135 loss:  0.0102890397650171\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m angle_t_temp \u001b[38;5;241m=\u001b[39m angle_t[i\u001b[38;5;241m*\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(image_temp\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_temp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m:\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m Variable(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "for epoch in range(params['epochs']):\n",
    "    loss_sum = 0\n",
    "    loss_angle_sum = 0\n",
    "    loss_angle_t_sum = 0\n",
    "    loss_angle_tt_sum = 0\n",
    "    count = 0 \n",
    "    model.train()\n",
    "    for i in range(len(data['z'])//params['batch_size']):\n",
    "        image_temp = image[i*params['batch_size']:(i+1)*params['batch_size'],:]\n",
    "        angle_t_temp = angle_t[i*params['batch_size']:(i+1)*params['batch_size']]\n",
    "        for j in range(image_temp.shape[0]-2):\n",
    "            input = torch.tensor(image_temp[j:j+3,:],dtype=torch.float32).to(device)\n",
    "            input = input.view(-1)\n",
    "            input = Variable(input)\n",
    "            pre = model.forward(input)\n",
    "            angle_t_true = torch.tensor(angle_t_temp[j],dtype=torch.float32).to(device)\n",
    "            loss_angle_t = torch.abs(angle_t_true - pre)\n",
    "            loss = loss_angle_t\n",
    "            loss_sum += loss\n",
    "            count += 1\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        model.eval()\n",
    "    loss_log.append(loss_sum.item()/count)\n",
    "    print('epoch: ', epoch+1, 'loss: ', loss_sum.item()/count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e5527f-ba23-4f53-91e3-dc5dab3c6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving(model,PATH):\n",
    "    if os.path.exists(PATH) == False:\n",
    "        os.makedirs(PATH)\n",
    "    model_PATH = os.path.join(PATH, 'model.pth')\n",
    "    torch.save(model.state_dict(), model_PATH)\n",
    "    params_PATH = os.path.join(PATH, 'params.txt')\n",
    "    with open(params_PATH, 'w') as f:\n",
    "        f.write(str(params))\n",
    "        f.close()\n",
    "    loss_PATH = os.path.join(PATH, 'loss_log.csv')\n",
    "    with open(loss_PATH, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(loss_log)\n",
    "    #fig_PATH = os.path.join(PATH, 'loss.png') \n",
    "    #plt.savefig(fig_PATH)\n",
    "    print(\"data saved\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "571855e9-b3ff-4a38-b6ff-04e70449dee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved\n"
     ]
    }
   ],
   "source": [
    "if params['if_save'] == True:\n",
    "    saving(model,PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e71fc5-1933-422b-9879-9542b8d3a319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting result\n",
    "plt.plot(loss_log)\n",
    "fig_PATH = os.path.join(PATH, 'loss.png') \n",
    "plt.savefig(fig_PATH, bbox_inches='tight', pad_inches = +0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce926ae3-b950-4bb0-84ec-88e0e2204018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
